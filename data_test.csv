answer,question,context
"As Sebastjan said, you first have to sort your data. This is important.

The part I didn't get is that in the example construction

groups = []
uniquekeys = []
for k, g in groupby(data, keyfunc):
   groups.append(list(g))    # Store group iterator as a list
   uniquekeys.append(k)


k is the current grouping key, and g is an iterator that you can use to iterate over the group defined by that grouping key. In other words, the groupby iterator itself returns iterators.

Here's an example of that, using clearer variable names:

from itertools import groupby

things = [(""animal"", ""bear""), (""animal"", ""duck""), (""plant"", ""cactus""), (""vehicle"", ""speed boat""), (""vehicle"", ""school bus"")]

for key, group in groupby(things, lambda x: x[0]):
    for thing in group:
        print ""A %s is a %s."" % (thing[1], key)
    print "" ""


This will give you the output:


  A bear is a animal.
  A duck is a animal.
  
  A cactus is a plant.
  
  A speed boat is a vehicle.
  A school bus is a vehicle.


In this example, things is a list of tuples where the first item in each tuple is the group the second item belongs to. 

The groupby() function takes two arguments: (1) the data to group and (2) the function to group it with. 

Here, lambda x: x[0] tells groupby() to use the first item in each tuple as the grouping key.

In the above for statement, groupby returns three (key, group iterator) pairs - once for each unique key. You can use the returned iterator to iterate over each individual item in that group.

Here's a slightly different example with the same data, using a list comprehension:

for key, group in groupby(things, lambda x: x[0]):
    listOfThings = "" and "".join([thing[1] for thing in group])
    print key + ""s:  "" + listOfThings + "".""


This will give you the output:


  animals: bear and duck.
  plants: cactus.
  vehicles: speed boat and school bus.

",How do I use Python's itertools.groupby()?,"I haven't been able to find an understandable explanation of how to actually use Python's itertools.groupby() function.  What I'm trying to do is this:


Take a list - in this case, the children of an objectified lxml element
Divide it into groups based on some criteria
Then later iterate over each of these groups separately.


I've reviewed the documentation, and the examples, but I've had trouble trying to apply them beyond a simple list of numbers. 

So, how do I use of itertools.groupby()?  Is there another technique I should be using?  Pointers to good ""prerequisite"" reading would also be appreciated.
"
"From the Python FAQ:


  Lists and tuples, while similar in many respects, are generally used in fundamentally different ways. Tuples can be thought of as being similar to Pascal records or C structs; they're small collections of related data which may be of different types which are operated on as a group. For example, a Cartesian coordinate is appropriately represented as a tuple of two or three numbers.
  
  Lists, on the other hand, are more like arrays in other languages. They tend to hold a varying number of objects all of which have the same type and which are operated on one-by-one.


Generally by convention you wouldn't choose a list or a tuple just based on its (im)mutability.  You would choose a tuple for small collections of completely different pieces of data in which a full-blown class would be too heavyweight, and a list for collections of any reasonable size where you have a homogeneous set of data.","Python: what is the difference between (1,2,3) and [1,2,3], and when should I use each?","In many places, (1,2,3) and [1,2,3] can be used interchangeably.

When should I use one or the other, and why?
"
erm.. HTML? (trying to be funny here... while we wait for real answers..),"Cross Platform, Language Agnostic GUI Markup Language?","I learned Swing back in the day but now I've moved to Python and want to make some apps with GUIs. I haven't had the time to learn a new GUI API so I've been using Jython, but I would prefer to use CPython. 

It would be great if I can have one simple markup that allows me to switch GUI libraries. It would be even better if I can use the same markup language across languages so I can quickly make GUIs for any language I'm using. Does anyone know of such a markup/library?

I've seen markups like Glade and wxWidget's markup (I forget the name). They're partly what I'm looking for (making a GUI without coding it in a language) but they're intertwined with a specific library. And neither are really nice looking or friendly to human editting."
"libxml2 has a number of advantages:


Compliance to the spec
Active development and a community participation 
Speed. This is really a python wrapper around a C implementation. 
Ubiquity. The libxml2 library is pervasive and thus well tested.


Downsides include:


Compliance to the spec. It's strict. Things like default namespace handling are easier in other libraries.
Use of native code. This can be a pain depending on your how your application is distributed / deployed. RPMs are available that ease some of this pain.
Manual resource handling. Note in the sample below the calls to freeDoc() and xpathFreeContext(). This is not very Pythonic.


If you are doing simple path selection, stick with ElementTree ( which is included in Python 2.5 ). If you need full spec compliance or raw speed and can cope with the distribution of native code, go with libxml2.

Sample of libxml2 XPath Use



import libxml2

doc = libxml2.parseFile(""tst.xml"")
ctxt = doc.xpathNewContext()
res = ctxt.xpathEval(""//*"")
if len(res) != 2:
    print ""xpath query: wrong node set size""
    sys.exit(1)
if res[0].name != ""doc"" or res[1].name != ""foo"":
    print ""xpath query: wrong node set value""
    sys.exit(1)
doc.freeDoc()
ctxt.xpathFreeContext()


Sample of ElementTree XPath Use



from elementtree.ElementTree import ElementTree
mydoc = ElementTree(file='tst.xml')
for e in mydoc.findall('/foo/bar'):
    print e.get('title').text


",How to use Xpath in Python?,"What is the library? Is there a full implementation? How is the library used? Where is its website?
"
"Closure on closures


  Objects are data with methods
  attached, closures are functions with
  data attached.


def make_counter():
    i = 0
    def counter(): # counter() is a closure
        nonlocal i
        i += 1
        return i
    return counter

c1 = make_counter()
c2 = make_counter()

print (c1(), c1(), c2(), c2())
# -> 1 2 1 2

",Can you explain closures (as they relate to Python)?,"I've been reading a lot about closures and I think I understand them, but without clouding the picture for myself and others, I am hoping someone can explain closures as succinctly and clearly as possible.  I'm looking for a simple explanation that might help me understand where and why I would want to use them.
"
"This answer suggests optparse which is appropriate for older Python versions. For Python 2.7 and above, argparse replaces optparse. See this answer for more information.

As other people pointed out, you are better off going with optparse over getopt.  getopt is pretty much a one-to-one mapping of the standard getopt(3) C library functions, and not very easy to use.

optparse, while being a bit more verbose, is much better structured and simpler to extend later on.

Here's a typical line to add an option to your parser:

parser.add_option('-q', '--query',
            action=""store"", dest=""query"",
            help=""query string"", default=""spam"")


It pretty much speaks for itself; at processing time, it will accept -q or --query as options, store the argument in an attribute called query and has a default value if you don't specify it.  It is also self-documenting in that you declare the help argument (which will be used when run with -h/--help) right there with the option.

Usually you parse your arguments with:

options, args = parser.parse_args()


This will, by default, parse the standard arguments passed to the script (sys.argv[1:])

options.query will then be set to the value you passed to the script.

You create a parser simply by doing

parser = optparse.OptionParser()


These are all the basics you need.  Here's a complete Python script that shows this:

import optparse

parser = optparse.OptionParser()

parser.add_option('-q', '--query',
    action=""store"", dest=""query"",
    help=""query string"", default=""spam"")

options, args = parser.parse_args()

print 'Query string:', options.query


5 lines of python that show you the basics.

Save it in sample.py, and run it once with

python sample.py


and once with

python sample.py --query myquery


Beyond that, you will find that optparse is very easy to extend.
In one of my projects, I created a Command class which allows you to nest subcommands in a command tree easily.  It uses optparse heavily to chain commands together.  It's not something I can easily explain in a few lines, but feel free to browse around in my repository for the main class, as well as a class that uses it and the option parser
",What's the best way to grab/parse command line arguments passed to a Python script?,"What's the easiest, tersest, and most flexible method or library for parsing Python command line arguments?
"
"There are drawbacks of using reference counting. One of the most mentioned is circular references: Suppose A references B, B references C and C references B. If A were to drop its reference to B, both B and C will still have a reference count of 1 and won't be deleted with traditional reference counting. CPython (reference counting is not part of python itself, but part of the C implementation thereof) catches circular references with a separate garbage collection routine that it runs periodically...

Another drawback: Reference counting can make execution slower. Each time an object is referenced and dereferenced, the interpreter/VM must check to see if the count has gone down to 0 (and then deallocate if it did). Garbage Collection does not need to do this.

Also, Garbage Collection can be done in a separate thread (though it can be a bit tricky). On machines with lots of RAM and for processes that use memory only slowly, you might not want to be doing GC at all! Reference counting would be a bit of a drawback there in terms of performance...
",Why Java and Python garbage collection methods are different?,"Python uses the reference count method to handle object life time. So an object that has no more use will be immediately destroyed.

But, in Java, the GC(garbage collector) destroys objects which are no longer used at a specific time.

Why does Java choose this strategy and what is the benefit from this?

Is this better than the Python approach?
"
"One more, using urlretrieve:

import urllib
urllib.urlretrieve (""http://www.example.com/songs/mp3.mp3"", ""mp3.mp3"")


(for Python 3+ use 'import urllib.request' and urllib.request.urlretrieve)

Yet another one, with a ""progressbar""

import urllib2

url = ""http://download.thinkbroadband.com/10MB.zip""

file_name = url.split('/')[-1]
u = urllib2.urlopen(url)
f = open(file_name, 'wb')
meta = u.info()
file_size = int(meta.getheaders(""Content-Length"")[0])
print ""Downloading: %s Bytes: %s"" % (file_name, file_size)

file_size_dl = 0
block_sz = 8192
while True:
    buffer = u.read(block_sz)
    if not buffer:
        break

    file_size_dl += len(buffer)
    f.write(buffer)
    status = r""%10d  [%3.2f%%]"" % (file_size_dl, file_size_dl * 100. / file_size)
    status = status + chr(8)*(len(status)+1)
    print status,

f.close()

",How do I download a file over HTTP using Python?,"I have a small utility that I use to download a MP3 from a website on a schedule and then builds/updates a podcast XML file which I've obviously added to iTunes.

The text processing that creates/updates the XML file is written in Python. I use wget inside a Windows .bat file to download the actual MP3 however. I would prefer to have the entire utility written in Python though.

I struggled though to find a way to actually down load the file in Python, thus why I resorted to wget.

So, how do I download the file using Python?
"
"is always returns True if it compares the same object instance

Whereas == is ultimately determined by the __eq__() method

i.e.


>>> class foo(object):
       def __eq__(self, other):
           return True

>>> f = foo()
>>> f == None
True
>>> f is None
False

","Is there any difference between ""foo is None"" and ""foo == None""?","Is there any difference between:

if foo is None: pass


and

if foo == None: pass


The convention that I've seen in most Python code (and the code I myself write) is the former, but I recently came across code which uses the latter.  None is an instance (and the only instance, IIRC) of NoneType, so it shouldn't matter, right?  Are there any circumstances in which it might?
"
"Using with template tag, I could do tree/recursive list.

Sample code:

main template: assuming 'all_root_elems' is list of one or more root of tree


{%for node in all_root_elems %} 
    {%include ""tree_view_template.html"" %}
{%endfor%}



tree_view_template.html renders the nested ul, li and uses node template variable as below:

 {{node.name}}
    {%if node.has_childs %}
        
         {%for ch in node.all_childs %}
              {%with node=ch template_name=""tree_view_template.html"" %}
                   {%include template_name%}
              {%endwith%}
         {%endfor%}
         
    {%endif%}


",How can I render a tree structure (recursive) using a django template?,"I have a tree structure in memory that I would like to render in HTML using a Django template. 

class Node():
  name = ""node name""
  children = []


There will be some object root that is a Node, and children is a list of Nodes. root will be passed in the content of the template.

I have found this one discussion of how this might be achieved, but the poster suggests this might not be good in a production environment.

Does anybody know of a better way?
"
"We've used IronPython to build our flagship spreadsheet application (40kloc production code - and it's Python, which IMO means loc per feature is low) at Resolver Systems, so I'd definitely say it's ready for production use of complex apps.

There are two ways in which this might not be a useful answer to you :-)


We're using IronPython, not the more usual CPython.  This gives us the huge advantage of being able to use .NET class libraries.  I may be setting myself up for flaming here, but I would say that I've never really seen a CPython application that looked ""professional"" - so having access to the WinForms widget set was a huge win for us.  IronPython also gives us the advantage of being able to easily drop into C# if we need a performance boost.  (Though to be honest we have never needed to do that.  All of our performance problems to date have been because we chose dumb algorithms rather than because the language was slow.)  Using C# from IP is much easier than writing a C Extension for CPython.  
We're an Extreme Programming shop, so we write tests before we write code.  I would not write production code in a dynamic language without writing the tests first; the lack of a compile step needs to be covered by something, and as other people have pointed out, refactoring without it can be tough.  (Greg Hewgill's answer suggests he's had the same problem.  On the other hand, I don't think I would write - or especially refactor - production code in any language these days without writing the tests first - but YMMV.)


Re: the IDE - we've been pretty much fine with each person using their favourite text editor; if you prefer something a bit more heavyweight then WingIDE is pretty well-regarded.
",Is Python good for big software projects (not web based)?,"Right now I'm developing mostly in C/C++, but I wrote some small utilities in Python to automatize some tasks and I really love it as language (especially the productivity). 

Except for the performances (a problem that could be sometimes solved thanks to the ease of interfacing Python with C modules), do you think it is proper for production use in the development of stand-alone complex applications (think for example to a word processor or a graphic tool)?

What IDE would you suggest? The IDLE provided with Python is not enough even for small projects in my opinion.
"
"shlex.quote() does what you want since python 3.

(Use pipes.quote to support both python 2 and python 3)
",How to escape os.system() calls in Python?,"When using os.system() it's often necessary to escape filenames and other arguments passed as parameters to commands.  How can I do this?  Preferably something that would work on multiple operating systems/shells but in particular for bash.

I'm currently doing the following, but am sure there must be a library function for this, or at least a more elegant/robust/efficient option:

def sh_escape(s):
   return s.replace(""("",""\\("").replace("")"",""\\)"").replace("" "",""\\ "")

os.system(""cat %s | grep something | sort > %s"" 
          % (sh_escape(in_filename), 
             sh_escape(out_filename)))


Edit: I've accepted the simple answer of using quotes, don't know why I didn't think of that; I guess because I came from Windows where ' and "" behave a little differently.

Regarding security, I understand the concern, but, in this case, I'm interested in a quick and easy solution which os.system() provides, and the source of the strings is either not user-generated or at least entered by a trusted user (me).
"
"The *args and **kwargs is a common idiom to allow arbitrary number of arguments to functions as described in the section more on defining functions in the Python documentation.

The *args will give you all function parameters as a tuple:

In [1]: def foo(*args):
   ...:     for a in args:
   ...:         print a
   ...:         
   ...:         

In [2]: foo(1)
1


In [4]: foo(1,2,3)
1
2
3


The **kwargs will give you all 
keyword arguments except for those corresponding to a formal parameter as a dictionary.

In [5]: def bar(**kwargs):
   ...:     for a in kwargs:
   ...:         print a, kwargs[a]
   ...:         
   ...:         

In [6]: bar(name='one', age=27)
age 27
name one


Both idioms can be mixed with normal arguments to allow a set of fixed and some variable arguments:

def foo(kind, *args, **kwargs):
   pass


Another usage of the *l idiom is to unpack argument lists when calling a function.

In [9]: def foo(bar, lee):
   ...:     print bar, lee
   ...:     
   ...:     

In [10]: l = [1,2]

In [11]: foo(*l)
1 2


In Python 3 it is possible to use *l on the left side of an assignment (Extended Iterable Unpacking):

first, *rest = [1,2,3,4]
first, *l, last = [1,2,3,4]


Also Python 3 adds new semantic (refer PEP 3102):

def func(arg1, arg2, arg3='default', *, kwarg1='abc', kwarg2='xyz'):
    pass


Such function accepts only 2 positional arguments, and everything after * can only be passed as keyword argument, not positional one.

In Python 2 similar was true for all parameters after *args.
",What does ** (double star) and * (star) do for Python parameters?,"In the following method definitions, what does the * and ** do for param2?

def foo(param1, *param2):
def bar(param1, **param2):

"
"Class methods are for when you need to have methods that aren't specific to any particular instance, but still involve the class in some way. The most interesting thing about them is that they can be overridden by subclasses, something that's simply not possible in Java's static methods or Python's module-level functions.

If you have a class MyClass, and a module-level function that operates on MyClass (factory, dependency injection stub, etc), make it a classmethod. Then it'll be available to subclasses.
",What are Class methods in Python for?,"I'm teaching myself Python and my most recent lesson was that Python is not Java, and so I've just spent a while turning all my Class methods into functions.

I now realise that I don't need to use Class methods for what I would done with static methods in Java, but now I'm not sure when I would use them.  All the advice I can find about Python Class methods is along the lines of newbies like me should steer clear of them, and the standard documentation is at its most opaque when discussing them.

Does anyone have a good example of using a Class method in Python or at least can someone tell me when Class methods can be sensibly used?
"
"I'd say that a dictionary is definitely the best way to do it.  It's easily extensible, allows you to give each value a sensible name, and Python has a lot of built-in language features for using and manipulating dictionaries.  If you need to add more fields later, all you need to change is the code that converts the tuple to a dictionary and the code that actually makes use of the new values.

For example:

job={}
job['jobid'], job['label'], job['username']=

",Splitting tuples in Python - best practice?,"I have a method in my Python code that returns a tuple - a row from a SQL query. Let's say it has three fields: (jobId, label, username)

For ease of passing it around between functions, I've been passing the entire tuple as a variable called 'job'. Eventually, however, I want to get at the bits, so I've been using code like this:
(jobId, label, username) = job

I've realised, however, that this is a maintenance nightmare, because now I can never add new fields to the result set without breaking all of my existing code. How should I have written this?

Here are my two best guesses:
(jobId, label, username) = (job[0], job[1], job[2])
...but that doesn't scale nicely when you have 15...20 fields

or to convert the results from the SQL query to a dictionary straight away and pass that around (I don't have control over the fact that it starts life as a tuple, that's fixed for me)
"
"
Tuples are used whenever you want to return multiple results from a function.
Since they're immutable, they can be used as keys for a dictionary (lists can't).

",What is a tuple useful for?,"I am learning Python for a class now, and we just covered tuples as one of the data types. I read the Wikipedia page on it, but, I could not figure out where such a data type would be useful in practice. Can I have some examples, perhaps in Python, where an immutable set of numbers would be needed? How is this different from a list?
"
"The python-magic method suggested by toivotuo is outdated. Python-magic's current trunk is at Github and based on the readme there, finding the MIME-type, is done like this.

# For MIME types
>>> import magic
>>> mime = magic.Magic(mime=True)
>>> mime.from_file(""testdata/test.pdf"")
'application/pdf'
>>>

",How to find the mime type of a file in python?,"Let's say you want to save a bunch of files somewhere, for instance in BLOBs. Let's say you want to dish these files out via a web page and have the client automatically open the correct application/viewer.

Assumption: The browser figures out which application/viewer to use by the mime-type (content-type?) header in the HTTP response.

Based on that assumption, in addition to the bytes of the file, you also want to save the MIME type.

How would you find the MIME type of a file? I'm currently on a Mac, but this should also work on Windows. 

Does the browser add this information when posting the file to the web page?

Is there a neat python library for finding this information? A WebService or (even better) a downloadable database?
"
"By the way: most programming languages would disagree with Python and give the result -2. Depending on the interpretation of modulus this is correct. However, the most agreed-upon mathematical definition states that the modulus of a and b is the (strictly positive) rest r of the division of a / b. More precisely, 0 r b by definition.
",Modulus operation with negatives values - weird thing?,"Can you please tell me how much is (-2) % 5?
According to my Python interpreter is 3, but do you have a wise explanation for this?

I've read that in some languages the result can be machine-dependent, but I'm not sure though.
"
"myList = ['a','b','c','d']
myString = "","".join(myList )


This won't work if the list contains numbers.



As Ricardo Reyes suggested, if it contains non-string types (such as integers, floats, bools, None) then do:

myList = ','.join(map(str, myList)) 

",How would you make a comma-separated string from a list?,"What would be your preferred way to concatenate strings from a sequence such that between each two consecutive pair a comma is added. That is, how do you map, for instance, [ 'a', 'b', 'c' ] to 'a,b,c'? (The cases [ s ] and [] should be mapped to s and '', respectively.)

I usually end up using something like ''.join(map(lambda x: x+',',l))[:-1], but also feeling somewhat unsatisfied.

Edit: I'm both ashamed and happy that the solution is so simple. Obviously I have hardly a clue as to what I'm doing. (I probably needed ""simple"" concatenation in the past and somehow memorised s.join([e1,e2,...]) as a shorthand for s+e1+e2+....)
"
"I would say that it depends: if you find that using Glade you can build the apps you want or need to make than that's absolutely fine. If however you actually want to learn how GTK works or you have some non-standard UI requirements you will have to dig into GTK internals (which are not that complicated).

Personally I'm usually about 5 minutes into a rich client when I need some feature or customization that is simply impossible through a designer such as Glade or Stetic. Perhaps it's just me. Nevertheless it is still useful for me to bootstrap window design using a graphical tool.

My recommendation: if making rich clients using GTK is going to be a significant part of your job/hobby then learn GTK as well since you will need to write that code someday.

P.S. I personally find Stetic to be superior to Glade for design work, if a little bit more unstable.
",Glade or no glade: What is the best way to use PyGtk?,"I've been learning python for a while now with some success. I even managed to create one or two (simple) programs using PyGtk + Glade.

The thing is: I am not sure if the best way to use GTK with python is by building the interfaces using Glade.

I was wondering if the more experienced ones among us (remember, I'm just a beginner) could point out the benefits and caveats of using Glade as opposed to creating everything in the code itself (assuming that learning the correct gtk bindings wouldn't exactly be a problem).
"
"Look at this:
http://code.google.com/p/pywhois/

pywhois - Python module for retrieving WHOIS information of domains

Goal:
- Create a simple importable Python module which will produce parsed WHOIS data for a given domain.
- Able to extract data for all the popular TLDs (com, org, net, ...)
- Query a WHOIS server directly instead of going through an intermediate web service like many others do.
- Works with Python 2.4+ and no external dependencies

Example:

>>> import pywhois
>>> w = pywhois.whois('google.com')
>>> w.expiration_date
['14-sep-2011']
>>> w.emails
['contact-admin@google.com',
 'dns-admin@google.com',
 'dns-admin@google.com',
 'dns-admin@google.com']
>>> print w
...

",What Python way would you suggest to check whois database records?,"I'm trying to get a webservice up and running that actually requires to check whois databases. What I'm doing right now is ugly and I'd like to avoid it as much as I can: I call gwhois command and parse its output. Ugly.

I did some search to try to find a pythonic way to do this task. Generally I got quite much nothing - this old discussion list link has a way to check if domain exist. Quite not what I was looking for... But still, it was best anwser Google gave me - everything else is just a bunch of unanwsered questions.

Any of you have succeeded to get some method up and running? I'd very much appreciate some tips, or should I just do it the opensource-way, sit down and code something by myself? :) 
"
"As Google Web Toolkit is a subset of Java it works best when you Java at the backend too.  Since Google App Engine is currently Python only I think you'd have to do a lot of messing about to get your server and client to talk nicely to each other.

jQuery seems to be the most popular JavaScript library option in the AJAX Tag at DjangoSnippets.com.

Edit: The above is only true of Google App Engine applications written in Python.  As Google App Engine now supports Java, GWT could now be a good choice for writing an AJAX front end.  Google even have a tutorial showing you how to do it.
",Any good AJAX framework for Google App Engine apps?,"I am trying to implement AJAX in my Google App Engine application, and so I am looking for a good AJAX framework that will help me. Anyone has any idea?

I am thinking about Google Web Toolkit, how good it is in terms of creating AJAX for Google App Engine?
"
"From http://docs.python.org/2/reference/datamodel.html#new-style-and-classic-classes :


  Up to Python 2.1, old-style classes were the only flavour available to the user. The concept of (old-style) class is unrelated to the concept of type: if x is an instance of an old-style class, then x.__class__ designates the class of x, but type(x) is always . This reflects the fact that all old-style instances, independently of their class, are implemented with a single built-in type, called instance. 
  
  New-style classes were introduced in Python 2.2 to unify the concepts of class and type. A new-style class is simply a user-defined type, no more, no less. If x is an instance of a new-style class, then type(x) is typically the same as x.__class__ (although this is not guaranteed â a new-style class instance is permitted to override the value returned for x.__class__).
  
  The major motivation for introducing new-style classes is to provide a unified object model with a full meta-model. It also has a number of immediate benefits, like the ability to subclass most built-in types, or the introduction of ""descriptors"", which enable computed properties. 
  
  For compatibility reasons, classes are still old-style by default. New-style classes are created by specifying another new-style class (i.e. a type) as a parent class, or the ""top-level type"" object if no other parent is needed. The behaviour of new-style classes differs from that of old-style classes in a number of important details in addition to what type returns. Some of these changes are fundamental to the new object model, like the way special methods are invoked. Others are ""fixes"" that could not be implemented before for compatibility concerns, like the method resolution order in case of multiple inheritance. 
  
  Python 3 only has new-style classes. No matter if you subclass from object or not, classes are new-style in Python 3. It is however recommended that you still subclass from object.

",What is the difference between old style and new style classes in Python?,"What is the difference between old style and new style classes in Python?  Is there ever a reason to use old-style classes these days?
"
"The standard python dict isn't able to do this.

There is a proposal (PEP 372) to add an ""ordered dictionary"" (that keeps track of the order of insertion) to the collections module in the standard library. It includes links to various  implementations of ordered dictionaries (see also these two recipes in the Python Cookbook).

You might want to stick with the reference implementation in the PEP if you want your code to be compatible with the ""official"" version (if the proposal is eventually accepted).

EDIT: The PEP was accepted and added in python 2.7 and 3.1. See the docs.
",How do you retrieve items from a dictionary in the order that they're inserted?,"Is it possible to retrieve items from a Python dictionary in the order that they were inserted?
"
"Absolutely (for the example you provided).

Tuples are first class citizens in Python

There is a builtin function divmod() that does exactly that.

q, r = divmod(x, y) # ((x - x%y)/y, x%y) Invariant: div*y + mod == x


There are other examples: zip, enumerate, dict.items. 

for i, e in enumerate([1, 3, 3]):
    print ""index=%d, element=%s"" % (i, e)

# reverse keys and values in a dictionary
d = dict((v, k) for k, v in adict.items()) # or 
d = dict(zip(adict.values(), adict.keys()))


BTW, parentheses are not necessary most of the time.
Citation from Python Library Reference: 


  Tuples are constructed by the comma
  operator (not within square brackets),
  with or without enclosing parentheses,
  but an empty tuple must have the
  enclosing parentheses, such as a, b, c
  or (). A single item tuple must have a
  trailing comma, such as (d,).


Functions should serve single purpose

Therefore they should return a single object. In your case this object is a tuple. Consider tuple as an ad-hoc compound data structure. There are languages where almost every single function returns multiple values (list in Lisp).

Sometimes it is sufficient to return (x, y) instead of Point(x, y).

Named tuples

With the introduction of named tuples in Python 2.6 it is preferable in many cases to return named tuples instead of plain tuples.

>>> import collections
>>> Point = collections.namedtuple('Point', 'x y')
>>> x, y = Point(0, 1)
>>> p = Point(x, y)
>>> x, y, p
(0, 1, Point(x=0, y=1))
>>> p.x, p.y, p[0], p[1]
(0, 1, 0, 1)
>>> for i in p:
...   print(i)
...
0
1

",Is it pythonic for a function to return multiple values?,"In python, you can have a function return multiple values.  Here's a contrived example:

def divide(x, y):
    quotient = x/y
    remainder = x % y
    return quotient, remainder  

(q, r) = divide(22, 7)


This seems very useful, but it looks like it can also be abused (""Well..function X already computes what we need as an intermediate value.  Let's have X return that value also"").

When should you draw the line and define a different method?  
"
"If you are looking to do file transfers, XMLRPC is likely a bad choice.  It will require that you encode all of your data as XML (and load it into memory).

""Data requests"" and ""file transfers"" sounds a lot like plain old HTTP to me, but your statement of the problem doesn't make your requirements clear.  What kind of information needs to be encoded in the request?  Would a URL like ""http://yourserver.example.com/service/request?color=yellow&flavor=banana"" be good enough?

There are lots of HTTP clients and servers in Python, none of which are especially great, but all of which I'm sure will get the job done for basic file transfers.  You can do security the ""normal"" web way, which is to use HTTPS and passwords, which will probably be sufficient.

If you want two-way communication then HTTP falls down, and a protocol like Twisted's perspective broker (PB) or asynchronous messaging protocol (AMP) might suit you better.  These protocols are certainly well-supported by Twisted.
",Best Python supported server/client protocol?,"I'm looking for a good server/client protocol supported in Python for making data requests/file transfers between one server and many clients.  Security is also an issue - so secure login would be a plus.  I've been looking into XML-RPC, but it looks to be a pretty old (and possibly unused these days?) protocol.
"
"The name scrambling is used to ensure that subclasses don't accidentally override the private methods and attributes of their superclasses. It's not designed to prevent deliberate access from outside.

For example:

>>> class Foo(object):
...     def __init__(self):
...         self.__baz = 42
...     def foo(self):
...         print self.__baz
...     
>>> class Bar(Foo):
...     def __init__(self):
...         super(Bar, self).__init__()
...         self.__baz = 21
...     def bar(self):
...         print self.__baz
...
>>> x = Bar()
>>> x.foo()
42
>>> x.bar()
21
>>> print x.__dict__
{'_Bar__baz': 21, '_Foo__baz': 42}


Of course, it breaks down if two different classes have the same name.
",Why are Python's 'private' methods not actually private?,"Python gives us the ability to create 'private' methods and variables within a class by prepending double underscores to the name, like this: __myPrivateMethod(). How, then, can one explain this

>>> class MyClass:
...     def myPublicMethod(self):
...             print 'public method'
...     def __myPrivateMethod(self):
...             print 'this is private!!'
... 
>>> obj = MyClass()
>>> obj.myPublicMethod()
public method
>>> obj.__myPrivateMethod()
Traceback (most recent call last):
  File """", line 1, in 
AttributeError: MyClass instance has no attribute '__myPrivateMethod'
>>> dir(obj)
['_MyClass__myPrivateMethod', '__doc__', '__module__', 'myPublicMethod']
>>> obj._MyClass__myPrivateMethod()
this is private!!


What's the deal?!

I'll explain this a little for those who didn't quite get that.

>>> class MyClass:
...     def myPublicMethod(self):
...             print 'public method'
...     def __myPrivateMethod(self):
...             print 'this is private!!'
... 
>>> obj = MyClass()


What I did there is create a class with a public method and a private method and instantiate it.

Next, I call its public method.

>>> obj.myPublicMethod()
public method


Next, I try and call its private method.

>>> obj.__myPrivateMethod()
Traceback (most recent call last):
  File """", line 1, in 
AttributeError: MyClass instance has no attribute '__myPrivateMethod'


Everything looks good here; we're unable to call it. It is, in fact, 'private'. Well, actually it isn't. Running dir() on the object reveals a new magical method that python creates magically for all of your 'private' methods.

>>> dir(obj)
['_MyClass__myPrivateMethod', '__doc__', '__module__', 'myPublicMethod']


This new method's name is always an underscore, followed by the class name, followed by the method name.

>>> obj._MyClass__myPrivateMethod()
this is private!!


So much for encapsulation, eh?

In any case, I'd always heard Python doesn't support encapsulation, so why even try? What gives?
"
"It may look cleaner using a key instead a cmp:

newlist = sorted(list_to_be_sorted, key=lambda k: k['name']) 


or as J.F.Sebastian and others suggested,

from operator import itemgetter
newlist = sorted(list_to_be_sorted, key=itemgetter('name')) 


For completeness (as pointed out in comments by fitzgeraldsteele), add reverse=True to sort descending

newlist = sorted(l, key=itemgetter('name'), reverse=True)

",How do I sort a list of dictionaries by values of the dictionary in Python?,"I got a list of dictionaries and want that to be sorted by a value of that dictionary.

This

[{'name':'Homer', 'age':39}, {'name':'Bart', 'age':10}]


sorted by name, should become

[{'name':'Bart', 'age':10}, {'name':'Homer', 'age':39}]

"
"You asked for someone who used both Grails and Django. I've done work on both for big projects. Here's my Thoughts:

IDE's:
Django works really well in Eclipse, Grails works really well in IntelliJ Idea.

Debugging:
Practically the same (assuming you use IntelliJ for Grails, and Eclipse for Python). Step debugging, inspecting variables, etc... never need a print statement for either. Sometimes django error messages can be useless but Grails error messages are usually pretty lengthy and hard to parse through.

Time to run a unit test:
django: 2 seconds.
Grails: 20 seconds (the tests themselves both run in a fraction of a second, it's the part about loading the framework to run them that takes the rest... as you can see, Grails is frustratingly slow to load).

Deployment:
Django: copy & paste one file into an apache config, and to redeploy, just change the code and reload apache.
Grails: create a .war file, deploy it on tomcat, rinse and repeat to redeploy.

Programming languages:
Groovy is TOTALLY awesome. I love it, more so than Python. But I certainly have no complaints. 

Plugins:
Grails: lots of broken plugins (and can use every java lib ever).
Django: a few stable plugins, but enough to do most of what you need.

Database:
Django: schema migrations using South, and generally intuitive relations.
Grails: no schema migrations, and by default it deletes the database on startup... WTF

Usage:
Django: startups (especially in the Gov 2.0 space), independent web dev shops.
Grails: enterprise

Hope that helps!
",Django -vs- Grails -vs-?,"I'm wondering if there's such a thing as Django-like ease of web app development combined with good deployment, debugging and other tools? 

Django is a very productive framework for building content-heavy sites; the best I've tried and a breath of fresh air compared to some of the Java monstrosities out there. However it's written in Python which means there's little real support in the way of deployment/packaging, debugging, profilers and other tools that make building and maintaining applications much easier. 

Ruby has similar issues and although I do like Ruby much better than I like Python, I get the impression that Rails is roughly in the same boat at Django when it comes to managing/supporting the app. 

Has anyone here tried both Django and Grails (or other web frameworks) for non-trivial projects? How did they compare?
"
"It sounds like you don't want to compare the two languages, but that you want to compare two web systems.

This is tricky, because there are many variables involved.

For example, Python web applications can take advantage of mod_wsgi to talk to web servers, which is faster than any of the typical ways that PHP talks to web servers (even mod_php ends up being slower if you're using Apache, because Apache can only use the Prefork MPM with mod_php rather than multi-threaded MPM like Worker).

There is also the issue of code compilation. As you know, Python is compiled just-in-time to byte code (.pyc files) when a file is run each time the file changes. Therefore, after the first run of a Python file, the compilation step is skipped and the Python interpreter simply fetches the precompiled .pyc file. Because of this, one could argue that Python has a native advantage over PHP. However, optimizers and caching systems can be installed for PHP websites (my favorite is eAccelerator) to much the same effect.

In general, enough tools exist such that one can pretty much do everything that the other can do. Of course, as others have mentioned, there's more than just speed involved in the business case to switch languages. We have an app written in oCaml at my current employer, which turned out to be a mistake because the original author left the company and nobody else wants to touch it. Similarly, the PHP-web community is much larger than the Python-web community; Website hosting services are more likely to offer PHP support than Python support; etc.

But back to speed. You must recognize that the question of speed here involves many moving parts. Fortunately, many of these parts can be independently optimized, affording you various avenues to seek performance gains.
","Which is faster, python webpages or php webpages?","Does anyone know how the speed of pylons(or any of the other frameworks) compares to a  similar website made with php?
I know that serving a python base webpage via cgi is slower than php because of its long start up every time.

I enjoy using pylons and I would still use it if it was slower than php. But if pylons was faster than php, I could maybe, hopefully, eventually convince my employer to allow me to convert the site over to pylons.
"
"First, parse the string into a naive datetime object. This is an instance of datetime.datetime with no attached timezone information. See documentation for datetime.strptime for information on parsing the date string.

Use the pytz module, which comes with a full list of time zones + UTC. Figure out what the local timezone is, construct a timezone object from it, and manipulate and attach it to the naive datetime.

Finally, use datetime.astimezone() method to convert the datetime to UTC.

Source code, using local timezone ""America/Los_Angeles"", for the string ""2001-2-3 10:11:12"":

import pytz, datetime
local = pytz.timezone (""America/Los_Angeles"")
naive = datetime.datetime.strptime (""2001-2-3 10:11:12"", ""%Y-%m-%d %H:%M:%S"")
local_dt = local.localize(naive, is_dst=None)
utc_dt = local_dt.astimezone (pytz.utc)


From there, you can use the strftime() method to format the UTC datetime as needed:

utc_dt.strftime (""%Y-%m-%d %H:%M:%S"")

",How do I convert local time to UTC in Python?,"How do I convert a datetime string in local time to a string in UTC time?

I'm sure I've done this before, but can't find it and SO will hopefully help me (and others) do that in future.

Clarification:  For example, if I have 2008-09-17 14:02:00 in my local timezone (+10), I'd like to generate a string with the equivalent UTC time: 2008-09-17 04:02:00.

Also, from http://lucumr.pocoo.org/2011/7/15/eppur-si-muove/, note that in general this isn't possible as with DST and other issues there is no unique conversion from local time to UTC time.
"
"Don't throw away your code!

It's the single worst mistake you can make (on a large codebase).  See Things You Should Never Do, Part 1.

You've invested a lot of effort into that old code and worked out many bugs.  Throwing it away is a classic developer mistake (and one I've done many times).  It makes you feel ""better"", like a spring cleaning.  But you don't need to buy a new apartment and all new furniture to outfit your house.  You can work on one room at a time... and maybe some things just need a new paintjob.  Hence, this is where refactoring comes in.

For new functionality in your app, write it in C# and call it from your classic ASP.  You'll be forced to be modular when you rewrite this new code.  When you have time, refactor parts of your old code into C# as well, and work out the bugs as you go.  Eventually, you'll have replaced your app with all new code.

You could also write your own compiler.  We wrote one for our classic ASP app a long time ago to allow us to output PHP.  It's called Wasabi and I think it's the reason Jeff Atwood thought Joel Spolsky went off his rocker.  Actually, maybe we should just ship it, and then you could use that.  

It allowed us to switch our entire codebase to .NET for the next release while only rewriting a very small portion of our source.  It also caused a bunch of people to call us crazy, but writing a compiler is not that complicated, and it gave us a lot of flexibility.

Also, if this is an internal only app, just leave it.  Don't rewrite it - you are the only customer and if the requirement is you need to run it as classic asp, you can meet that requirement.
","If it is decided that our system needs an overhaul, what is the best way to go about it?","We are mainting a web application that is built on Classic ASP using VBScript as the primary language. We are in agreement that our backend (framework if you will) is out dated and doesn't provide us with the proper tools to move forward in a quick manner. We have pretty much embraced the current webMVC pattern that is all over the place, and cannot do it, in a reasonable manner, with the current technology. The big missing features are proper dispatching and templating with inheritance, amongst others.

Currently there are two paths being discussed:


Port the existing application to Classic ASP using JScript, which will allow us to hopefully go from there to .NET MSJscript without too much trouble, and eventually end up on the .NET platform (preferably the MVC stuff will be done by then, ASP.NET isn't much better than were we are on now, in our opinions). This has been argued as the safer path with less risk than the next option, albeit it might take slightly longer.
Completely rewrite the application using some other technology, right now the leader of the pack is Python WSGI with a custom framework, ORM, and a good templating solution. There is wiggle room here for even django and other pre-built solutions. This method would hopefully be the quickest solution, as we would probably run a beta beside the actual product, but it does have the potential for a big waste of time if we can't/don't get it right.


This does not mean that our logic is gone, as what we have built over the years is fairly stable, as noted just difficult to deal with. It is built on SQL Server 2005 with heavy use of stored procedures and published on IIS 6, just for a little more background.

Now, the question. Has anyone taken either of the two paths above? If so, was it successful, how could it have been better, etc. We aren't looking to deviate much from doing one of those two things, but some suggestions or other solutions would potentially be helpful.
"
"Update: django-configurations has been released which is probably a better option for most people than doing it manually.

If you would prefer to do things manually, my earlier answer still applies:

I have multiple settings files.


settings_local.py - host-specific configuration, such as database name, file paths, etc.
settings_development.py - configuration used for development, e.g. DEBUG = True.
settings_production.py - configuration used for production, e.g. SERVER_EMAIL.


I tie these all together with a settings.py file that firstly imports settings_local.py, and then one of the other two.  It decides which to load by two settings inside settings_local.py - DEVELOPMENT_HOSTS and PRODUCTION_HOSTS.  settings.py calls platform.node() to find the hostname of the machine it is running on, and then looks for that hostname in the lists, and loads the second settings file depending on which list it finds the hostname in.

That way, the only thing you really need to worry about is keeping the settings_local.py file up to date with the host-specific configuration, and everything else is handled automatically.

Check out an example here.
",How do you configure Django for simple development and deployment?,"I tend to use SQLite when doing Django
development, but on a live server something more robust is
often needed (MySQL/PostgreSQL, for example).
Invariably, there are other changes to make to the Django
settings as well: different logging locations / intensities,
media paths, etc.

How do you manage all these changes to make deployment a
simple, automated process?
"
"It just so happens that the tokens you want split are already Python tokens, so you can use the built-in tokenize module.  It's almost a one-liner:

from cStringIO import StringIO
from tokenize import generate_tokens
STRING = 1
list(token[STRING] for token 
     in generate_tokens(StringIO('2+24*48/32').readline)
     if token[STRING])
['2', '+', '24', '*', '48', '/', '32']

",How do I split a string into a list?,"If I have this string:


  2+24*48/32


what is the most efficient approach for creating this list:


  ['2', '+', '24', '*', '48', '/', '32']

"
"A regular expression will do the trick with very little code:

import re

...

if re.match(""^[A-Za-z0-9_-]*$"", my_little_string):
    # do something here

","How do I verify that a string only contains letters, numbers, underscores and dashes?","I know how to do this if I iterate through all of the characters in the string but I am looking for a more elegant method.

Thanks
"
"The solution is simple. It's actually well documented, but not too easy to find. (I had to dig around -- it didn't come up when I tried a few different Google searches.)

The following code works:

>>> from django.template import Template, Context
>>> from django.conf import settings
>>> settings.configure()
>>> t = Template('My name is {{ my_name }}.')
>>> c = Context({'my_name': 'Daryl Spitzer'})
>>> t.render(c)
u'My name is Daryl Spitzer.'


See the Django documentation (linked above) for a description of some of the settings you may want to define (as keyword arguments to configure).
",How do I use Django templates without the rest of Django?,"I want to use the Django template engine in my (Python) code, but I'm not building a Django-based web site.  How do I use it without having a settings.py file (and others) and having to set the DJANGO_SETTINGS_MODULE environment variable?

If I run the following code:

>>> import django.template
>>> from django.template import Template, Context
>>> t = Template('My name is {{ my_name }}.')


I get:

ImportError: Settings cannot be imported, because environment variable DJANGO_SETTINGS_MODULE is undefined.

"
"Classes as objects

Before understanding metaclasses, you need to master classes in Python. And Python has a very peculiar idea of what classes are, borrowed from the Smalltalk language.

In most languages, classes are just pieces of code that describe how to produce an object. That's kinda true in Python too:

>>> class ObjectCreator(object):
...       pass
... 

>>> my_object = ObjectCreator()
>>> print(my_object)



But classes are more than that in Python. Classes are objects too.

Yes, objects. 

As soon as you use the keyword class, Python executes it and creates
an OBJECT. The instruction

>>> class ObjectCreator(object):
...       pass
... 


creates in memory an object with the name ""ObjectCreator"". 

This object (the class) is itself capable of creating objects (the instances), 
and this is why it's a class. 

But still, it's an object, and therefore:


you can assign it to a variable
you can copy it
you can add attributes to it
you can pass it as a function parameter


e.g.:

>>> print(ObjectCreator) # you can print a class because it's an object

>>> def echo(o):
...       print(o)
... 
>>> echo(ObjectCreator) # you can pass a class as a parameter

>>> print(hasattr(ObjectCreator, 'new_attribute'))
False
>>> ObjectCreator.new_attribute = 'foo' # you can add attributes to a class
>>> print(hasattr(ObjectCreator, 'new_attribute'))
True
>>> print(ObjectCreator.new_attribute)
foo
>>> ObjectCreatorMirror = ObjectCreator # you can assign a class to a variable
>>> print(ObjectCreatorMirror.new_attribute)
foo
>>> print(ObjectCreatorMirror())



Creating classes dynamically

Since classes are objects, you can create them on the fly, like any object.

First, you can create a class in a function using class:

>>> def choose_class(name):
...     if name == 'foo':
...         class Foo(object):
...             pass
...         return Foo # return the class, not an instance
...     else:
...         class Bar(object):
...             pass
...         return Bar
...     
>>> MyClass = choose_class('foo') 
>>> print(MyClass) # the function returns a class, not an instance

>>> print(MyClass()) # you can create an object from this class



But it's not so dynamic, since you still have to write the whole class yourself.

Since classes are objects, they must be generated by something.

When you use the class keyword, Python creates this object automatically. But as
with most things in Python, it gives you a way to do it manually.

Remember the function type? The good old function that lets you know what 
type an object is:

>>> print(type(1))

>>> print(type(""1""))

>>> print(type(ObjectCreator))

>>> print(type(ObjectCreator()))



Well, type has a completely different ability, it can also create classes on the fly. type can take the description of a class as parameters, 
and return a class.

(I  know, it's silly that the same function can have two completely different uses according to the parameters you pass to it. It's an issue due to backwards 
compatibility in Python)

type works this way:

type(name of the class, 
     tuple of the parent class (for inheritance, can be empty), 
     dictionary containing attributes names and values)


e.g.:

>>> class MyShinyClass(object):
...       pass


can be created manually this way:

>>> MyShinyClass = type('MyShinyClass', (), {}) # returns a class object
>>> print(MyShinyClass)

>>> print(MyShinyClass()) # create an instance with the class



You'll notice that we use ""MyShinyClass"" as the name of the class
and as the variable to hold the class reference. They can be different,
but there is no reason to complicate things.

type accepts a dictionary to define the attributes of the class. So:

>>> class Foo(object):
...       bar = True


Can be translated to:

>>> Foo = type('Foo', (), {'bar':True})


And used as a normal class:

>>> print(Foo)

>>> print(Foo.bar)
True
>>> f = Foo()
>>> print(f)

>>> print(f.bar)
True


And of course, you can inherit from it, so:

>>>   class FooChild(Foo):
...         pass


would be:

>>> FooChild = type('FooChild', (Foo,), {})
>>> print(FooChild)

>>> print(FooChild.bar) # bar is inherited from Foo
True


Eventually you'll want to add methods to your class. Just define a function
with the proper signature and assign it as an attribute.

>>> def echo_bar(self):
...       print(self.bar)
... 
>>> FooChild = type('FooChild', (Foo,), {'echo_bar': echo_bar})
>>> hasattr(Foo, 'echo_bar')
False
>>> hasattr(FooChild, 'echo_bar')
True
>>> my_foo = FooChild()
>>> my_foo.echo_bar()
True


And you can add even more methods after you dynamically create the class, just like adding methods to a normally created class object.

>>> def echo_bar_more(self):
...       print('yet another method')
... 
>>> FooChild.echo_bar_more = echo_bar_more
>>> hasattr(FooChild, 'echo_bar_more')
True


You see where we are going: in Python, classes are objects, and you can create a class on the fly, dynamically.

This is what Python does when you use the keyword class, and it does so by using a metaclass.

What are metaclasses (finally)

Metaclasses are the 'stuff' that creates classes.

You define classes in order to create objects, right?

But we learned that Python classes are objects.

Well, metaclasses are what create these objects. They are the classes' classes,
you can picture them this way:

MyClass = MetaClass()
MyObject = MyClass()


You've seen that type lets you do something like this:

MyClass = type('MyClass', (), {})


It's because the function type is in fact a metaclass. type is the 
metaclass Python uses to create all classes behind the scenes.

Now you wonder why the heck is it written in lowercase, and not Type?

Well, I guess it's a matter of consistency with str, the class that creates
strings objects, and int the class that creates integer objects. type is
just the class that creates class objects.

You see that by checking the __class__ attribute. 

Everything, and I mean everything, is an object in Python. That includes ints, 
strings, functions and classes. All of them are objects. And all of them have
been created from a class:

>>> age = 35
>>> age.__class__

>>> name = 'bob'
>>> name.__class__

>>> def foo(): pass
>>> foo.__class__

>>> class Bar(object): pass
>>> b = Bar()
>>> b.__class__



Now, what is the __class__ of any __class__ ?

>>> age.__class__.__class__

>>> name.__class__.__class__

>>> foo.__class__.__class__

>>> b.__class__.__class__



So, a metaclass is just the stuff that creates class objects.

You can call it a 'class factory' if you wish.

type is the built-in metaclass Python uses, but of course, you can create your
own metaclass.

The __metaclass__ attribute

You can add a __metaclass__ attribute when you write a class:

class Foo(object):
  __metaclass__ = something...
  [...]


If you do so, Python will use the metaclass to create the class Foo.

Careful, it's tricky.

You write class Foo(object) first, but the class object Foo is not created
in memory yet.

Python will look for __metaclass__ in the class definition. If it finds it,
it will use it to create the object class Foo. If it doesn't, it will use
type to create the class.

Read that several times.

When you do:

class Foo(Bar):
  pass


Python does the following:

Is there a __metaclass__ attribute in Foo?

If yes, create in memory a class object (I said a class object, stay with me here), with the name Foo by using what is in __metaclass__.

If Python can't find __metaclass__, it will look for a __metaclass__ at the MODULE level, and try to do the same (but only for classes that don't inherit anything, basically old-style classes). 

Then if it can't find any __metaclass__ at all, it will use the Bar's (the first parent) own metaclass (which might be the default type) to create the class object.

Be careful here that the __metaclass__ attribute will not be inherited, the metaclass of the parent (Bar.__class__) will be. If Bar used a __metaclass__ attribute that created Bar with type() (and not type.__new__()), the subclasses will not inherit that behavior.

Now the big question is, what can you put in __metaclass__ ?

The answer is: something that can create a class.

And what can create a class? type, or anything that subclasses or uses it.

Custom metaclasses

The main purpose of a metaclass is to change the class automatically,
when it's created.

You usually do this for APIs, where you want to create classes matching the
current context.

Imagine a stupid example, where you decide that all classes in your module
should have their attributes written in uppercase. There are several ways to 
do this, but one way is to set __metaclass__ at the module level.

This way, all classes of this module will be created using this metaclass, 
and we just have to tell the metaclass to turn all attributes to uppercase.

Luckily, __metaclass__ can actually be any callable, it doesn't need to be a
formal class (I know, something with 'class' in its name doesn't need to be 
a class, go figure... but it's helpful).

So we will start with a simple example, by using a function.

# the metaclass will automatically get passed the same argument
# that you usually pass to `type`
def upper_attr(future_class_name, future_class_parents, future_class_attr):
  """"""
    Return a class object, with the list of its attribute turned 
    into uppercase.
  """"""

  # pick up any attribute that doesn't start with '__' and uppercase it
  uppercase_attr = {}
  for name, val in future_class_attr.items():
      if not name.startswith('__'):
          uppercase_attr[name.upper()] = val
      else:
          uppercase_attr[name] = val

  # let `type` do the class creation
  return type(future_class_name, future_class_parents, uppercase_attr)

__metaclass__ = upper_attr # this will affect all classes in the module

class Foo(): # global __metaclass__ won't work with ""object"" though
  # but we can define __metaclass__ here instead to affect only this class
  # and this will work with ""object"" children
  bar = 'bip'

print(hasattr(Foo, 'bar'))
# Out: False
print(hasattr(Foo, 'BAR'))
# Out: True

f = Foo()
print(f.BAR)
# Out: 'bip'


Now, let's do exactly the same, but using a real class for a metaclass:

# remember that `type` is actually a class like `str` and `int`
# so you can inherit from it
class UpperAttrMetaclass(type): 
    # __new__ is the method called before __init__
    # it's the method that creates the object and returns it
    # while __init__ just initializes the object passed as parameter
    # you rarely use __new__, except when you want to control how the object
    # is created.
    # here the created object is the class, and we want to customize it
    # so we override __new__
    # you can do some stuff in __init__ too if you wish
    # some advanced use involves overriding __call__ as well, but we won't
    # see this
    def __new__(upperattr_metaclass, future_class_name, 
                future_class_parents, future_class_attr):

        uppercase_attr = {}
        for name, val in future_class_attr.items():
            if not name.startswith('__'):
                uppercase_attr[name.upper()] = val
            else:
                uppercase_attr[name] = val

        return type(future_class_name, future_class_parents, uppercase_attr)


But this is not really OOP. We call type directly and we don't override
or call the parent __new__. Let's do it:

class UpperAttrMetaclass(type): 

    def __new__(upperattr_metaclass, future_class_name, 
                future_class_parents, future_class_attr):

        uppercase_attr = {}
        for name, val in future_class_attr.items():
            if not name.startswith('__'):
                uppercase_attr[name.upper()] = val
            else:
                uppercase_attr[name] = val

        # reuse the type.__new__ method
        # this is basic OOP, nothing magic in there
        return type.__new__(upperattr_metaclass, future_class_name, 
                            future_class_parents, uppercase_attr)


You may have noticed the extra argument upperattr_metaclass. There is
nothing special about it: __new__ always receives the class it's defined in, as first parameter. Just like you have self for ordinary methods which receive the instance as first parameter, or the defining class for class methods.

Of course, the names I used here are long for the sake of clarity, but like
for self, all the arguments have conventional names. So a real production
metaclass would look like this:

class UpperAttrMetaclass(type): 

    def __new__(cls, clsname, bases, dct):

        uppercase_attr = {}
        for name, val in dct.items():
            if not name.startswith('__'):
                uppercase_attr[name.upper()] = val
            else:
                uppercase_attr[name] = val

        return type.__new__(cls, clsname, bases, uppercase_attr)


We can make it even cleaner by using super, which will ease inheritance (because yes, you can have metaclasses, inheriting from metaclasses, inheriting from type):

class UpperAttrMetaclass(type): 

    def __new__(cls, clsname, bases, dct):

        uppercase_attr = {}
        for name, val in dct.items():
            if not name.startswith('__'):
                uppercase_attr[name.upper()] = val
            else:
                uppercase_attr[name] = val

        return super(UpperAttrMetaclass, cls).__new__(cls, clsname, bases, uppercase_attr)


That's it. There is really nothing more about metaclasses.

The reason behind the complexity of the code using metaclasses is not because
of metaclasses, it's because you usually use metaclasses to do twisted stuff
relying on introspection, manipulating inheritance, vars such as __dict__, etc.

Indeed, metaclasses are especially useful to do black magic, and therefore
complicated stuff. But by themselves, they are simple:


intercept a class creation
modify the class
return the modified class


Why would you use metaclasses classes instead of functions?

Since __metaclass__ can accept any callable, why would you use a class
since it's obviously more complicated?

There are several reasons to do so:


The intention is clear. When you read UpperAttrMetaclass(type), you know
what's going to follow
You can use OOP. Metaclass can inherit from metaclass, override parent methods. Metaclasses can even use metaclasses.
You can structure your code better. You never use metaclasses for something as
trivial as the above example. It's usually for something complicated. Having the
ability to make several methods and group them in one class is very useful
to make the code easier to read.
You can hook on __new__, __init__ and __call__. Which will allow
you to do different stuff. Even if usually you can do it all in __new__, 
some people are just more comfortable using __init__.
These are called metaclasses, damn it! It must mean something!


Why would you use metaclasses?

Now the big question. Why would you use some obscure error prone feature?

Well, usually you don't:


  Metaclasses are deeper magic that
  99% of users should never worry about.
  If you wonder whether you need them,
  you don't (the people who actually
  need them know with certainty that
  they need them, and don't need an
  explanation about why). 


Python Guru Tim Peters

The main use case for a metaclass is creating an API. A typical example of this is the Django ORM.

It allows you to define something like this:

class Person(models.Model):
  name = models.CharField(max_length=30)
  age = models.IntegerField()


But if you do this:

guy = Person(name='bob', age='35')
print(guy.age)


It won't return an IntegerField object. It will return an int, and can even take it directly from the database.

This is possible because models.Model defines __metaclass__ and 
it uses some magic that will turn the Person you just defined with simple statements
into a complex hook to a database field. 

Django makes something complex look simple by exposing a simple API
and using metaclasses, recreating code from this API to do the real job
behind the scenes.

The last word

First, you know that classes are objects that can create instances.

Well in fact, classes are themselves instances. Of metaclasses.

>>> class Foo(object): pass
>>> id(Foo)
142630324


Everything is an object in Python, and they are all either instances of classes
or instances of metaclasses.

Except for type.

type is actually its own metaclass. This is not something you could
reproduce in pure Python, and is done by cheating a little bit at the implementation
level.

Secondly, metaclasses are complicated. You may not want to use them for 
very simple class alterations. You can change classes by using two different techniques:


monkey patching
class decorators


99% of the time you need class alteration, you are better off using these.

But 99% of the time, you don't need class alteration at all.
",What is a metaclass in Python?,"What are metaclasses? What do you use them for?
"
"In the first test, Python try to convert the object to a bool value if it is not already one. Roughly, we are asking the object : are you meaningful or not ? This is done using the following algorithm :


If the object has a __nonzero__ special method (as do numeric built-ins, int and float), it calls this method. It must either return a bool value which is then directly used, or an int value that is considered False if equal to zero.
Otherwise, if the object has a __len__ special method (as do container built-ins, list, dict, set, tuple, ...), it calls this method, considering a container False if it is empty (length is zero).
Otherwise, the object is considered True unless it is None in which case, it is considered False.


In the second test, the object is compared for equality to None. Here, we are asking the object, ""Are you equal to this other value?"" This is done using the following algorithm :


If the object has a __eq__ method, it is called, and the return value is then converted to a boolvalue and used to determine the outcome of the if.
Otherwise, if the object has a __cmp__ method, it is called. This function must return an int indicating the order of the two object (-1 if self , 0 if self == other, +1 if self > other).
Otherwise, the object are compared for identity (ie. they are reference to the same object, as can be tested by the is operator).


There is another test possible using the is operator. We would be asking the object, ""Are you this particular object?""

Generally, I would recommend to use the first test with non-numerical values, to use the test for equality when you want to compare objects of the same nature (two strings, two numbers, ...) and to check for identity only when using sentinel values (None meaning not initialized for a member field for exemple, or when using the getattr or the __getitem__ methods).

To summarize, we have :

>>> class A(object):
...    def __repr__(self):
...        return 'A()'
...    def __nonzero__(self):
...        return False

>>> class B(object):
...    def __repr__(self):
...        return 'B()'
...    def __len__(self):
...        return 0

>>> class C(object):
...    def __repr__(self):
...        return 'C()'
...    def __cmp__(self, other):
...        return 0

>>> class D(object):
...    def __repr__(self):
...        return 'D()'
...    def __eq__(self, other):
...        return True

>>> for obj in ['', (), [], {}, 0, 0., A(), B(), C(), D(), None]:
...     print '%4s: bool(obj) -> %5s, obj == None -> %5s, obj is None -> %5s' % \
...         (repr(obj), bool(obj), obj == None, obj is None)
  '': bool(obj) -> False, obj == None -> False, obj is None -> False
  (): bool(obj) -> False, obj == None -> False, obj is None -> False
  []: bool(obj) -> False, obj == None -> False, obj is None -> False
  {}: bool(obj) -> False, obj == None -> False, obj is None -> False
   0: bool(obj) -> False, obj == None -> False, obj is None -> False
 0.0: bool(obj) -> False, obj == None -> False, obj is None -> False
 A(): bool(obj) -> False, obj == None -> False, obj is None -> False
 B(): bool(obj) -> False, obj == None -> False, obj is None -> False
 C(): bool(obj) ->  True, obj == None ->  True, obj is None -> False
 D(): bool(obj) ->  True, obj == None ->  True, obj is None -> False
None: bool(obj) -> False, obj == None ->  True, obj is None ->  True

","Why is ""if not someobj:"" better than ""if someobj == None:"" in Python?","I've seen several examples of code like this:

if not someobj:
    #do something


But I'm wondering why not doing:

if someobj == None:
    #do something


Is there any difference? Does one have an advantage over the other?
"
"You can use the module called win32clipboard, which is part of pywin32.

Here is an example that first sets the clipboard data then gets it:

import win32clipboard

# set clipboard data
win32clipboard.OpenClipboard()
win32clipboard.EmptyClipboard()
win32clipboard.SetClipboardText('testing 123')
win32clipboard.CloseClipboard()

# get clipboard data
win32clipboard.OpenClipboard()
data = win32clipboard.GetClipboardData()
win32clipboard.CloseClipboard()
print data


An important reminder from the documentation:


  When the window has finished examining or changing the clipboard,
  close the clipboard by calling CloseClipboard. This enables other
  windows to access the clipboard. Do not place an object on the
  clipboard after calling CloseClipboard.

",How do I read text from the (windows) clipboard from python?,"How do I read text from the (windows) clipboard from python?
"
"You will still need locks if you share state between threads. The GIL only protects the interpreter internally. You can still have inconsistent updates in your own code.

For example:

#!/usr/bin/env python
import threading

shared_balance = 0

class Deposit(threading.Thread):
    def run(self):
        for _ in xrange(1000000):
            global shared_balance
            balance = shared_balance
            balance += 100
            shared_balance = balance

class Withdraw(threading.Thread):
    def run(self):
        for _ in xrange(1000000):
            global shared_balance
            balance = shared_balance
            balance -= 100
            shared_balance = balance

threads = [Deposit(), Withdraw()]

for thread in threads:
    thread.start()

for thread in threads:
    thread.join()

print shared_balance


Here, your code can be interrupted between reading the shared state (balance = shared_balance) and writing the changed result back (shared_balance = balance), causing a lost update. The result is a random value for the shared state.

To make the updates consistent, run methods would need to lock the shared state around the read-modify-write sections (inside the loops) or have some way to detect when the shared state had changed since it was read.
",Are locks unnecessary in multi-threaded Python code because of the GIL?,"If you are relying on an implementation of Python that has a Global Interpreter Lock (i.e. CPython) and writing multithreaded code, do you really need locks at all?

If the GIL doesn't allow multiple instructions to be executed in parallel, wouldn't shared data be unnecessary to protect?

sorry if this is a dumb question, but it is something I have always wondered about Python on multi-processor/core machines.  

same thing would apply to any other language implementation that has a GIL.
"
"urllib2 can be used to perform a HEAD request.  This is a little nicer than using httplib since urllib2 parses the URL for you instead of requiring you to split the URL into host name and path.

>>> import urllib2
>>> class HeadRequest(urllib2.Request):
...     def get_method(self):
...         return ""HEAD""
... 
>>> response = urllib2.urlopen(HeadRequest(""http://google.com/index.html""))


Headers are available via response.info() as before.  Interestingly, you can find the URL that you were redirected to:

>>> print response.geturl()
http://www.google.com.au/index.html

",How do you send a HEAD HTTP request in Python 2?,"What I'm trying to do here is get the headers of a given URL so I can determine the MIME type. I want to be able to see if http://somedomain/foo/ will return an HTML document or a JPEG image for example. Thus, I need to figure out how to send a HEAD request so that I can read the MIME type without having to download the content. Does anyone know of an easy way of doing this?
"
"I found autonose to be pretty unreliable but sniffer seems to work very well.

$ pip install sniffer
$ cd myproject


Then instead of running ""nosetests"", you run:

$ sniffer


Or instead of nosetests --verbose --with-doctest, you run:

$ sniffer -x--verbose -x--with-doctest


As described in the readme, it's a good idea to install one of the platform-specific filesystem-watching libraries, pyinotify, pywin32 or MacFSEvents (all installable via pip etc)
",Is there something like 'autotest' for Python unittests?,"Basically, growl notifications (or other callbacks) when tests break or pass. Does anything like this exist?

If not, it should be pretty easy to write.. Easiest way would be to..


run python-autotest myfile1.py myfile2.py etc.py
Check if files-to-be-monitored have been modified (possibly just if they've been saved).
Run any tests in those files.
If a test fails, but in the previous run it passed, generate a growl alert. Same with tests that fail then pass.
Wait, and repeat steps 2-5.


The problem I can see there is if the tests are in a different file. The simple solution would be to run all the tests after each save.. but with slower tests, this might take longer than the time between saves, and/or could use a lot of CPU power etc..

The best way to do it would be to actually see what bits of code have changed, if function abc() has changed, only run tests that interact with this.. While this would be great, I think it'd be extremely complex to implement?

To summarise:


Is there anything like the Ruby tool autotest (part of the ZenTest package), but for Python code?
How do you check which functions have changed between two revisions of a script?
Is it possible to determine which functions a command will call? (Somewhat like a reverse traceback)

"
"We can use:

def quit():
    root.quit()


or

def quit():
    root.destroy()

",Close a tkinter window?,"How do I end a Tkinter program? Let's say I have this code:

from Tkinter import *

def quit():
    # code to exit

root = Tk()
Button(root, text=""Quit"", command=quit).pack()
root.mainloop()


How should I define the quit function?
"
"A callable is anything that can be called. 

The built-in callable (PyCallable_Check in objects.c) checks if the argument is either:


an instance of a class with a __call__ method or
is of a type that has a non null tp_call (c struct) member which indicates callability otherwise (such as in functions, methods etc.)


The method named __call__ is (according to the documentation)


  Called when the instance is ''called'' as a function


Example

class Foo:
  def __call__(self):
    print 'called'

foo_instance = Foo()
foo_instance() #this is calling the __call__ method

","What is a ""callable"" in Python?","Now that it's clear what a metaclass is, there is an associated concept that I use all the time without knowing what it really means. 

I suppose everybody made once a mistake with parenthesis, resulting  in an ""object is not callable"" exception. What's more, using __init__ and __new__ lead to wonder what this bloody __call__ can be used for.

Could you give me some explanations, including examples with the magic method ?
"
"I would recommend that you have a look at SUDS

""Suds is a lightweight SOAP python client for consuming Web Services.""
",How can I consume a WSDL (SOAP) web service in Python?,"I want to use a WSDL SOAP based web service in Python. I have looked at the Dive Into Python code but the SOAPpy module does not work under Python 2.5.

I have tried using suds which works partly, but breaks with certain types (suds.TypeNotFound: Type not found: 'item').

I have also looked at Client but this does not appear to support WSDL.

And I have looked at ZSI but it looks very complex. Does anyone have any sample code for it?

The WSDL is https://ws.pingdom.com/soap/PingdomAPI.wsdl and works fine with the PHP 5 SOAP client.
"
"After reading your post above, I made a 100% native Python docx module to solve this specific problem.

# Import the module
from docx import *

# Open the .docx file
document = opendocx('A document.docx')

# Search returns true if found    
search(document,'your search string')


The docx module is at https://python-docx.readthedocs.org/en/latest/
",How can I search a word in a Word 2007 .docx file?,"I'd like to search a Word 2007 file (.docx) for a text string, e.g., ""some special phrase"" that could/would be found from a search within Word.  

Is there a way from Python to see the text?  I have no interest in formatting - I just want to classify documents as having or not having ""some special phrase"".
"
"There are three options:

>>> 4 / float(100)
0.04
>>> 4 / 100.0
0.04


which is the same behavior as the C, C++, Java etc, or 

>>> from __future__ import division
>>> 4 / 100
0.04


You can also activate this behavior by passing the argument -Qnew to the Python interpreter:

$ python -Qnew
>>> 4 / 100
0.04


The second option will be the default in Python 3.0. If you want to have the old integer division, you have to use the // operator. 

Edit: added section about -Qnew, thanks to Î¤ÎÎ©Î¤ÎÎÎÎ¥!
",How do I get a decimal value when using the division operator in Python?,"For example, the standard division symbol '/' rounds to zero:

>>> 4 / 100
0


However, I want it to return 0.04. What do I use?
"
"There's a solution to your problem that is distributed with python itself. pindent.py, it's located in the Tools\Scripts directory in a windows install (my path to it is C:\Python25\Tools\Scripts), it looks like you'd have grab it from svn.python.org if you are running on Linux or OSX. 

It adds comments when blocks are closed, or can properly indent code if comments are put in. Here's an example of the code outputted by pindent with the command:

pindent -c myfile.py

def foobar(a, b):
   if a == b:
       a = a+1
   elif a < b:
       b = b-1
       if b > a: a = a-1
       # end if
   else:
       print 'oops!'
   # end if
# end def foobar


Where the original myfile.py was: 

def foobar(a, b):
   if a == b:
       a = a+1
   elif a < b:
       b = b-1
       if b > a: a = a-1
   else:
       print 'oops!'


You can also use pindent.py -d to insert the correct indentation based on comments (read the header of pindent.py for details), this should allow you to code in python without worrying about indentation.

I'd be interested to learn what solution you end up using, if you require any further assistance, please comment on this post and I'll try to help.
",Is there a way to convert indentation in Python code to braces?,"I am a totally blind programmer who would like to learn Python. Unfortunately the fact that code blocks are represented with different levels of indentation is a major stumbling block. I was wondering if there were any tools available that would allow me to write code using braces or some other code block delimiter and then convert that format into a properly indented representation that the Python interpreter could use?
"
">>> import random
>>> print random.sample(xrange(100), 5)
[61, 54, 91, 72, 85]


This should yield 5 unique values in the range 0 â 99. The xrange object generates values as requested so no memory is used for values that aren't sampled.
","How do I write this in Ruby/Python? Or, can you translate my LINQ to Ruby/Python?","Yesterday, I asked this question and never really got an answer I was really happy with. I really would like to know how to generate a list of N unique random numbers using a functional language such as Ruby without having to be extremely imperative in style.

Since I didn't see anything I really liked, I've written the solution I was looking for in LINQ:   


       static void Main(string[] args)
    	{
    		var temp = from q in GetRandomNumbers(100).Distinct().Take(5) select q;
    	}

    	private static IEnumerable GetRandomNumbers(int max)
    	{
    		Random r = new Random();
    		while (true)
    		{
    			yield return r.Next(max);
    		}
    	}


Can you translate my LINQ to Ruby? Python? Any other functional programming language?

Note: Please try not to use too many loops and conditionals - otherwise the solution is trivial. Also, I'd rather see a solution where you don't have to generate an array much bigger than N so you can then just remove the duplicates and trim it down to N.

I know I'm being picky, but I'd really like to see some elegant solutions to this problem.
Thanks!

Edit:
Why all the downvotes? 

Originally my code sample had the Distinct() after the Take() which, as many pointed out, could leave me with an empty list. I've changed the order in which those methods are called to reflect what I meant in the first place.

Apology:
I've been told this post came across as rather snobbish. I wasn't trying to imply that LINQ is better than Ruby/Python; or that my solution is much better than everyone else's. My intent is just to learn how to do this (with certain constraints) in Ruby. I'm sorry if I came across as a jerk.
"
"Using named groups and a dispatch table:

r = re.compile(r'(?Pfoo|bar|baz)(?P.+)')

def do_foo(data):
    ...

def do_bar(data):
    ...

def do_baz(data):
    ...

dispatch = {
    'foo': do_foo,
    'bar': do_bar,
    'baz': do_baz,
}


m = r.match(var)
if m:
    dispatch[m.group('cmd')](m.group('data'))


With a little bit of introspection you can auto-generate the regexp and the dispatch table.
",How do you translate this regular-expression idiom from Perl into Python?,"I switched from Perl to Python about a year ago and haven't looked back.  There is only one idiom that I've ever found I can do more easily in Perl than in Python:

if ($var =~ /foo(.+)/) {
  # do something with $1
} elsif ($var =~ /bar(.+)/) {
  # do something with $1
} elsif ($var =~ /baz(.+)/) {
  # do something with $1
}


The corresponding Python code is not so elegant since the if statements keep getting nested:

m = re.search(r'foo(.+)', var)
if m:
  # do something with m.group(1)
else:
  m = re.search(r'bar(.+)', var)
  if m:
    # do something with m.group(1)
  else:
    m = re.search(r'baz(.+)', var)
    if m:
      # do something with m.group(2)


Does anyone have an elegant way to reproduce this pattern in Python?  I've seen anonymous function dispatch tables used, but those seem kind of unwieldy to me for a small number of regular expressions...
"
">>> import site; site.getsitepackages()
['/usr/local/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages']


(or just first item with site.getsitepackages()[0])
",How do I find the location of my Python site-packages directory?,"How do I find the location of my site-packages directory?
"
"shutil has many methods you can use. One of which is:

from shutil import copyfile

copyfile(src, dst)


Copy the contents of the file named src to a file named dst. The destination location must be writable; otherwise, an IOError exception will be raised. If dst already exists, it will be replaced. Special files such as character or block devices and pipes cannot be copied with this function. src and dst are path names given as strings. 
",How do I copy a file in python?,"How do I copy a file in Python? I couldn't find anything under os.
"
"Module importing is quite fast, but not instant. This means that:


Putting the imports at the top of the module is fine, because it's a trivial cost that's only paid once.
Putting the imports within a function will cause calls to that function to take longer.


So if you care about efficiency, put the imports at the top. Only move them into a function if your profiling shows that would help (you did profile to see where best to improve performance, right??)



The best reasons I've seen to perform lazy imports are:


Optional library support. If your code has multiple paths that use different libraries, don't break if an optional library is not installed.
In the __init__.py of a plugin, which might be imported but not actually used. Examples are Bazaar plugins, which use bzrlib's lazy-loading framework.

",Should Python import statements always be at the top of a module?,"PEP 08 states:


  Imports are always put at the top of the file, just after any module comments and docstrings, and before module globals and constants.


However if the class/method/function that I am importing is only used in rare cases, surely it is more efficient to do the import when it is needed?

Isn't this:

class SomeClass(object):

    def not_often_called(self)
        from datetime import datetime
        self.datetime = datetime.now()


more efficient than this?

from datetime import datetime

class SomeClass(object):

    def not_often_called(self)
        self.datetime = datetime.now()

"
"Use TestCase.assertRaises (or TestCase.failUnlessRaises) from the unittest module, for example:

import mymod

class MyTestCase(unittest.TestCase):
    def test1(self):
        self.assertRaises(SomeCoolException, mymod.myfunc)

",How do you test that a Python function throws an exception?,"How does one write a unittest that fails only if a function doesn't throw an expected exception?
"
"Came up with my own answer after a minute of thought.  It can be done with nested comprehensions:

result = [y for y in (expensive(x) for x in mylist) if y]


I guess that works, though I find nested comprehensions are only marginally readable 
",How do I efficiently filter computed values within a Python list comprehension?,"The Python list comprehension syntax makes it easy to filter values within a comprehension.  For example:

result = [x**2 for x in mylist if type(x) is int]


Will return a list of the squares of integers in mylist.  However, what if the test involves some (costly) computation and you want to filter on the result?  One option is:

result = [expensive(x) for x in mylist if expensive(x)]


This will result in a list of non-""false"" expensive(x) values, however expensive() is called twice for each x.  Is there a comprehension syntax that allows you to do this test while only calling expensive once per x?
"
"is will return True if two variables point to the same object, == if the objects referred to by the variables are equal.

>>> a = [1, 2, 3]
>>> b = a
>>> b is a 
True
>>> b == a
True
>>> b = a[:]
>>> b is a
False
>>> b == a
True


In your case, the second test only works because Python caches small integer objects, which is an implementation detail. For larger integers, this does not work:

>>> 1000 is 10**3
False
>>> 1000 == 10**3
True


The same holds true for string literals:

>>> ""a"" is ""a""
True
>>> ""aa"" is ""a"" * 2
True
>>> x = ""a""
>>> ""aa"" is x * 2
False
>>> ""aa"" is intern(x*2)
True


Please see this question as well.
",Is there a difference between `==` and `is` in Python?,"My Google-fu has failed me.

In Python, are the following two tests for equality equivalent (ha!)?

n = 5
# Test one.
if n == 5:
    print 'Yay!'

# Test two.
if n is 5:
    print 'Yay!'


Does this hold true for objects where you would be comparing instances (a list say)?

Okay, so this kind of answers my question:

L = []
L.append(1)
if L == [1]:
    print 'Yay!'
# Holds true, but...

if L is [1]:
    print 'Yay!'
# Doesn't.


So == tests value where is tests to see if they are the same object?
"
"If you need to assign the lambda to a name, use a def instead. defs are just syntactic sugar for an assignment, so the result is the same, and they are a lot more flexible and readable.

lambdas can be used for use once, throw away functions which won't have a name.

However, this use case is very rare. You rarely need to pass around unnamed function objects.

The builtins map() and filter() need function objects, but list comprehensions and generator expressions are generally more readable than those functions and can cover all use cases, without the need of lambdas. 

For the cases you really need a small function object, you should use the operator module functions, like operator.add instead of lambda x, y: x + y

If you still need some lambda not covered, you might consider writing a def, just to be more readable. If the function is more complex than the ones at operator module, a def is probably better. 

So, real world good lambda use cases are very rare.
",Which is more preferable to use in Python: lambda functions or nested functions ('def')?,"I mostly use lambda functions but sometimes use nested functions that seem to provide the same behavior. 

Here are some trivial examples where they functionally do the same thing if either were found within another function:

Lambda function

>>> a = lambda x : 1 + x
>>> a(5)
6


Nested function

>>> def b(x): return 1 + x

>>> b(5)
6


Is there advantages to using one over the other? (Performance? Readability? Limitations? Consistency? etc.) Does it even matter? If doesn't then does that violate the Pythonic principle: âThere should be oneâand preferably only oneâobvious way to do itâ.
"
"For performance, especially when you're iterating over a large range, xrange() is usually better.  However, there are still a few cases why you might prefer range():


In python 3, range() does what xrange() used to do and xrange() does not exist.  If you want to write code that will run on both Python 2 and Python 3, you can't use xrange().
range() can actually be faster in some cases - eg. if iterating over the same sequence multiple times.  xrange() has to reconstruct the integer object every time, but range() will have real integer objects.  (It will always perform worse in terms of memory however)
xrange() isn't usable in all cases where a real list is needed.  For instance, it doesn't support slices, or any list methods.


[Edit] There are a couple of posts mentioning how range() will be upgraded by the 2to3 tool.  For the record, here's the output of running the tool on some sample usages of range() and xrange()

RefactoringTool: Skipping implicit fixer: buffer
RefactoringTool: Skipping implicit fixer: idioms
RefactoringTool: Skipping implicit fixer: ws_comma
--- range_test.py (original)
+++ range_test.py (refactored)
@@ -1,7 +1,7 @@

 for x in range(20):
-    a=range(20)
+    a=list(range(20))
     b=list(range(20))
     c=[x for x in range(20)]
     d=(x for x in range(20))
-    e=xrange(20)
+    e=range(20)


As you can see, when used in a for loop or comprehension, or where already wrapped with list(), range is left unchanged.
",Should you always favor xrange() over range()?,"Why or why not?
"
"In Python 2.5, there is

A if C else B


which behaves a lot like ?: in C. However, it's frowned upon for two reasons: readability, and the fact that there's usually a simpler way to approach the problem. For instance, in your case:

stringValue = otherString or defaultString

",How can I closely achieve ?: from C++/C# in Python?,"In C# I could easily write the following:

string stringValue = string.IsNullOrEmpty( otherString ) ? defaultString : otherString;


Is there a quick way of doing the same thing in Python or am I stuck with an 'if' statement?
"
"It's probably best to use the Python Image Library to do this which I'm afraid is a separate download.

The easiest way to do what you want is via the load() method on the Image object which returns a pixel access object which you can manipulate like an array:

from PIL import Image
im = Image.open(""dead_parrot.jpg"") #Can be many different formats.
pix = im.load()
print im.size #Get the width and hight of the image for iterating over
print pix[x,y] #Get the RGBA Value of the a pixel of an image
pix[x,y] = value # Set the RGBA Value of the image (tuple)


Alternatively, look at ImageDraw which gives a much richer API for creating images.
",How can I read the RGB value of a given pixel in Python?,"If I open an image with open(""image.jpg""), how can I get the RGB values of a pixel, if I have the coordinates of the pixel?

Then how can I do the reverse of this? Starting with a blank graphic, 'write' a pixel with a certain RGB value?

It would be so much better if I didn't have to download any additional libraries.
"
"As @Greg Hewgill says it, there are good reasons why this is not always possible. However, certain kinds of code (like very algorithmic code) can be turned into ""real"" machine code. 

There are several options:


Use Psyco, which emits machine code dynamically. You should choose carefully which methods/functions to convert, though.
Use Cython, which is a Python-like language that is compiled into a Python C extension
Use PyPy, which has a translator from RPython (a restricted subset of Python that does not support some of the most ""dynamic"" features of Python) to C or LLVM. 

PyPy is still highly experimental
not all extensions will be present



After that, you can use one of the existing packages (freeze, Py2exe, PyInstaller) to put everything into one binary.

All in all: there is no general answer for your question. If you have Python code that is performance-critical, try to use as much builtin functionality as possible (or ask a ""How do I make my Python code faster"" question). If that doesn't help, try to identify the code and port it to C (or Cython) and use the extension.
",Is it feasible to compile Python to machine code?,"How feasible would it be to compile Python (possibly via an intermediate C representation) into machine code?

Presumably it would need to link to a Python runtime library, and any parts of the Python standard library which were Python themselves would need to be compiled (and linked in) too.

Also, you would need to bundle the Python interpreter if you wanted to do dynamic evaluation of expressions, but perhaps a subset of Python that didn't allow this would still be useful.

Would it provide any speed and/or memory usage advantages?  Presumably the startup time of the Python interpreter would be eliminated (although shared libraries would still need loading at startup).
"
"I converted Greg Hewgill's python code to C# and it worked!

[Test]
public void ReplaceTextInQuotes()
{
  Assert.AreEqual(""axbx'cPdPe'fxgh'iPj'k"", 
    Regex.Replace(""axbx'cxdxe'fxgh'ixj'k"",
      @""x(?=[^']*'([^']|'[^']*')*$)"", ""P""));
}


That test passed.
",Can Regex be used for this particular string manipulation?,"I need to replace character (say) x with character (say) P in a string, but only if it is contained in a quoted substring.
An example makes it clearer:

axbx'cxdxe'fxgh'ixj'k  -> axbx'cPdPe'fxgh'iPj'k


Let's assume, for the sake of simplicity, that quotes always come in pairs. 

The obvious way is to just process the string one character at a time (a simple state machine approach);
however, I'm wondering if regular expressions can be used to do all the processing in one go.

My target language is C#, but I guess my question pertains to any language having builtin or library support for regular expressions.
"
"os.walk('.').next()[1]

",How to list only top level directories in Python?,"I want to be able to list only the directories inside some folder.
This means I don't want filenames listed, nor do I want additional sub-folders.

Let's see if an example helps. In the current directory we have:

>>> os.listdir(os.getcwd())
['cx_Oracle-doc', 'DLLs', 'Doc', 'include', 'Lib', 'libs', 'LICENSE.txt', 'mod_p
ython-wininst.log', 'NEWS.txt', 'pymssql-wininst.log', 'python.exe', 'pythonw.ex
e', 'README.txt', 'Removemod_python.exe', 'Removepymssql.exe', 'Scripts', 'tcl',
 'Tools', 'w9xpopen.exe']


However, I don't want filenames listed. Nor do I want sub-folders such as \Lib\curses. Essentially what I want works with the following:

>>> for root, dirnames, filenames in os.walk('.'):
...     print dirnames
...     break
...
['cx_Oracle-doc', 'DLLs', 'Doc', 'include', 'Lib', 'libs', 'Scripts', 'tcl', 'Tools']


However, I'm wondering if there's a simpler way of achieving the same results. I get the impression that using os.walk only to return the top level is inefficient/too much.
"
"If you need a global cross-module variable maybe just simple global module-level variable will suffice. 

a.py:

var = 1


b.py:

import a
print a.var
import c
print a.var


c.py:

import a
a.var = 2


Test:

$ python b.py
# -> 1 2


Real-world example: Django's global_settings.py (though in Django apps settings are used by importing the object django.conf.settings).
",Python: How to make a cross-module variable?,"The __debug__ variable is handy in part because it affects every module. If I want to create another variable that works the same way, how would I do it?

The variable (let's be original and call it 'foo') doesn't have to be truly global, in the sense that if I change foo in one module, it is updated in others. I'd be fine if I could set foo before importing other modules and then they would see the same value for it.
"
"If you mainly want to be able to name your bit fields and easily manipulate them, e.g. to work with flags represented as single bits in a communications protocol, then you can use the standard Structure and Union features of ctypes, as described at How Do I Properly Declare a ctype Structure + Union in Python? - Stack Overflow

For example, to work with the 4 least-significant bits of a byte individually, just name them from least to most significant in a LittleEndianStructure.  You use a union to provide access to the same data as a byte or int so you can move the data in or out of the communication protocol.  In this case that is done via the flags.asbyte field:

import ctypes
c_uint8 = ctypes.c_uint8

class Flags_bits(ctypes.LittleEndianStructure):
    _fields_ = [
            (""logout"", c_uint8, 1),
            (""userswitch"", c_uint8, 1),
            (""suspend"", c_uint8, 1),
            (""idle"", c_uint8, 1),
        ]

class Flags(ctypes.Union):
    _fields_ = [(""b"", Flags_bits),
                (""asbyte"", c_uint8)]

flags = Flags()
flags.asbyte = 0xc

print(flags.b.idle)
print(flags.b.suspend)
print(flags.b.userswitch)
print(flags.b.logout)


The four bits (which I've printed here starting with the most significant, which seems more natural when printing) are 1, 1, 0, 0, i.e. 0xc in binary.
",Does Python have a bitfield type?,"I need a compact representation of an array of booleans, does Python have a builtin bitfield type or will I need to find an alternate solution?
"
"Here you can find some info about this.

It covers code completion, having a list of classes and functions in open files. I haven't got around to do a full configuration for vim, since I don't use Python primarily, but I have the same interests in transforming vim in a better Python IDE.

Edit: The original site is down, so found it saved on the web archive.
",Has anyone found a good set of python plugins for vim -- specifically module completion?,"I'm looking for a suite of plugins that can help me finally switch over to vim full-time.

Right now I'm using Komodo with some good success, but their vim bindings have enough little errors that I'm tired of it.

What I do love in Komodo, though, is the code completion. So, here's what I'm looking for (ordered by importance).


Code completion, meaning: the ability to code complete modules/functions/etc. in any module that's on the pythonpath, not just system modules. Bonus points for showing docstrings when completing.
Jump-to a class definition. I'm guessing CTAGS will do this, so how do you all manage automatically updating your tags files?
Project type management for managing buffers: ideally the ability to grep for a filename in a directory structure to open it. Bonus for showing an index of class definitions while a buffer is open.
Bzr integration. Not super important, since most of it I can just drop to the shell to do.

"
"I like ctypes a lot, swig always tended to give me problems. Also ctypes has the advantage that you don't need to satisfy any compile time dependency on python, and your binding will work on any python that has ctypes, not just the one it was compiled against.

Suppose you have a simple C++ example class you want to talk to in a file called foo.cpp:

#include 

class Foo{
    public:
        void bar(){
            std::cout << ""Hello"" << std::endl;
        }
};


Since ctypes can only talk to C functions, you need to provide those declaring them as extern ""C""

extern ""C"" {
    Foo* Foo_new(){ return new Foo(); }
    void Foo_bar(Foo* foo){ foo->bar(); }
}


Next you have to compile this to a shared library

g++ -c -fPIC foo.cpp -o foo.o
g++ -shared -Wl,-soname,libfoo.so -o libfoo.so  foo.o


And finally you have to write your python wrapper (e.g. in fooWrapper.py)

from ctypes import cdll
lib = cdll.LoadLibrary('./libfoo.so')

class Foo(object):
    def __init__(self):
        self.obj = lib.Foo_new()

    def bar(self):
        lib.Foo_bar(self.obj)


Once you have that you can call it like

f = Foo()
f.bar() #and you will see ""Hello"" on the screen

",Calling C/C++ from python?,"What would be the quickest way to construct a python binding to a C or C++ library?

(using windows if this matters)
"
"From ""Whatâs New in Python 2.6 - Interpreter Changes"":


  Python can now be prevented from
  writing .pyc or .pyo files by
  supplying the -B switch to the Python
  interpreter, or by setting the
  PYTHONDONTWRITEBYTECODE environment
  variable before running the
  interpreter. This setting is available
  to Python programs as the
  sys.dont_write_bytecode variable, and
  Python code can change the value to
  modify the interpreterâs behaviour.


Update 2010-11-27: Python 3.2 addresses the issue of cluttering source folders with .pyc files by introducing a special __pycache__ subfolder, see What's New in Python 3.2 - PYC Repository Directories.
",How to avoid .pyc files?,"Can I run the python interpreter without generating the compiled .pyc files?
"
"See Python PEP 8.


  Function names should be lowercase,
  with words separated by underscores as
  necessary to improve readability.
  
  mixedCase is allowed only in contexts
  where that's already the prevailing
  style


Variables...


  Use the function naming rules:
  lowercase with words separated by
  underscores as necessary to improve
  readability.


Personally, I deviate from this because I also prefer mixedCase over lower_case for my own projects.
",What is the naming convention in Python for variable and function names?,"Coming from a C# background the naming convention for variables and method names are usually either CamelCase or Pascal Case:

// C# example
string thisIsMyVariable = ""a""
public void ThisIsMyMethod()


In Python, I have seen the above but I have also seen underscores being used:

# python example
this_is_my_variable = 'a'
def this_is_my_function():


Is there a more preferable, definitive coding style for Python?
"
"Popen.communicate() documentation:


  Note that if you want to send data to
  the processâs stdin, you need to
  create the Popen object with
  stdin=PIPE. Similarly, to get anything
  other than None in the result tuple,
  you need to give stdout=PIPE and/or
  stderr=PIPE too.
  
  Replacing os.popen*


    pipe = os.popen(cmd, 'w', bufsize)
    # ==>
    pipe = Popen(cmd, shell=True, bufsize=bufsize, stdin=PIPE).stdin



  Warning Use communicate() rather than
  stdin.write(), stdout.read() or
  stderr.read() to avoid deadlocks due
  to any of the other OS pipe buffers
  filling up and blocking the child
  process.


So your example could be written as follows:

from subprocess import Popen, PIPE, STDOUT

p = Popen(['grep', 'f'], stdout=PIPE, stdin=PIPE, stderr=STDOUT)    
grep_stdout = p.communicate(input=b'one\ntwo\nthree\nfour\nfive\nsix\n')[0]
print(grep_stdout.decode())
# -> four
# -> five
# ->

",Python - How do I pass a string into subprocess.Popen (using the stdin argument)?,"If I do the following:

import subprocess
from cStringIO import StringIO
subprocess.Popen(['grep','f'],stdout=subprocess.PIPE,stdin=StringIO('one\ntwo\nthree\nfour\nfive\nsix\n')).communicate()[0]


I get:

Traceback (most recent call last):
  File """", line 1, in ?
  File ""/build/toolchain/mac32/python-2.4.3/lib/python2.4/subprocess.py"", line 533, in __init__
    (p2cread, p2cwrite,
  File ""/build/toolchain/mac32/python-2.4.3/lib/python2.4/subprocess.py"", line 830, in _get_handles
    p2cread = stdin.fileno()
AttributeError: 'cStringIO.StringI' object has no attribute 'fileno'


Apparently a cStringIO.StringIO object doesn't quack close enough to a file duck to suit subprocess.Popen.  How do I work around this?
"
"As another option, you can do look ups like:

class UserAdmin(admin.ModelAdmin):
    list_display = (..., 'get_author')

    def get_author(self, obj):
        return obj.book.author
    get_author.short_description = 'Author'
    get_author.admin_order_field = 'book__author'

","Can ""list_display"" in a Django ModelAdmin display attributes of ForeignKey fields?","I have a Person model that has a foreign key relationship to Book.  Book has a number of fields, but I'm most concerned about ""author"" (a standard CharField).

With that being said, in my PersonAdmin model, I'd like to display ""book.author"" using ""list_display"".  I've tried all of the obvious methods for doing so (see below), but nothing seems to work.  Any suggestions?

class PersonAdmin(admin.ModelAdmin):
  list_display = ['book.author',]

"
"I've done this in the past for a Python script to determine the last updated files in a directory: 

import glob
import os

search_dir = ""/mydir/""
# remove anything from the list that is not a file (directories, symlinks)
# thanks to J.F. Sebastion for pointing out that the requirement was a list 
# of files (presumably not including directories)  
files = filter(os.path.isfile, glob.glob(search_dir + ""*""))
files.sort(key=lambda x: os.path.getmtime(x))


That should do what you're looking for based on file mtime.

EDIT: Note that you can also use os.listdir() in place of glob.glob() if desired - the reason I used glob in my original code was that I was wanting to use glob to only search for files with a particular set of file extensions, which glob() was better suited to. To use listdir here's what it would look like: 

import os

search_dir = ""/mydir/""
os.chdir(search_dir)
files = filter(os.path.isfile, os.listdir(search_dir))
files = [os.path.join(search_dir, f) for f in files] # add path to each file
files.sort(key=lambda x: os.path.getmtime(x))

",How do you get a directory listing sorted by creation date in python?,"What is the best way to get a list of all files in a directory, sorted by date [created | modified], using python, on a windows machine?
"
"Given your factorGenerator function, here is a divisorGen that should work:

def divisorGen(n):
    factors = list(factorGenerator(n))
    nfactors = len(factors)
    f = [0] * nfactors
    while True:
        yield reduce(lambda x, y: x*y, [factors[x][0]**f[x] for x in range(nfactors)], 1)
        i = 0
        while True:
            f[i] += 1
            if f[i] <= factors[i][1]:
                break
            f[i] = 0
            i += 1
            if i >= nfactors:
                return


The overall efficiency of this algorithm will depend entirely on the efficiency of the factorGenerator.
",What is the best way to get all the divisors of a number?,"Here's the very dumb way:

def divisorGenerator(n):
    for i in xrange(1,n/2+1):
        if n%i == 0: yield i
    yield n


The result I'd like to get is similar to this one, but I'd like a smarter algorithm (this one it's too much slow and dumb :-)

I can find prime factors and their multiplicity fast enough. 
I've an generator that generates factor in this way:

(factor1, multiplicity1)
(factor2, multiplicity2)
(factor3, multiplicity3)
and so on...

i.e. the output of 

for i in factorGenerator(100):
    print i


is:

(2, 2)
(5, 2)


I don't know how much is this useful for what I want to do (I coded it for other problems), anyway I'd like a smarter way to make

for i in divisorGen(100):
    print i


output this:

1
2
4
5
10
20
25
50
100




UPDATE: Many thanks to Greg Hewgill and his ""smart way"" :)
Calculating all divisors of 100000000 took 0.01s with his way against the 39s that the dumb way took on my machine, very cool :D

UPDATE 2: Stop saying this is a duplicate of this post. Calculating the number of divisor of a given number doesn't need to calculate all the divisors. It's a different problem, if you think it's not then look for ""Divisor function"" on wikipedia. Read the questions and the answer before posting, if you do not understand what is the topic just don't add not useful and already given answers.
"
"This sounds like the PHP array using named indices is very similar to a python dict:

shows = [
  {""id"": 1, ""name"": ""Sesaeme Street""},
  {""id"": 2, ""name"": ""Dora The Explorer""},
]


See http://docs.python.org/tutorial/datastructures.html#dictionaries for more on this.
",Python: can I have a list with named indices?,"In PHP I can name my array indicies so that I may have something like:

$shows = Array(0 => Array('id' => 1, 'name' => 'Sesaeme Street'), 
               1 => Array('id' => 2, 'name' => 'Dora The Explorer'));


Is this possible in Python?
"
"In Python 3.0, 5 / 2 will return 2.5 and 5 // 2 will return 2.  The former is floating point division, and the latter is floor division, sometimes also called integer division.

In Python 2.2 or later in the 2.x line, there is no difference for integers unless you perform a from __future__ import division, which causes Python 2.x to adopt the behavior of 3.0

Regardless of the future import, 5.0 // 2 will return 2.0 since that's the floor division result of the operation.

You can find a detailed description at https://docs.python.org/whatsnew/2.2.html#pep-238-changing-the-division-operator
","In Python, what is the difference between '/' and '//' when used for division?","Is there a benefit to using one over the other? They both seem to return the same results.

>>> 6/3
2
>>> 6//3
2

"
"If anyone is interested in performance of the above solutions, here they are for 4000x4000 grids, from fastest to slowest:


Brian: 1.08s (modified, with izip instead of zip)
John: 2.33s
DzinX: 2.36s
Î¤ÎÎ©Î¤ÎÎÎÎ¥: 2.41s (but object initialization took 62s)
Eugene: 3.17s
Robert: 4.56s
Brian: 27.24s (original, with zip)


EDIT: Added Brian's scores with izip modification and it won by a large amount!

John's solution is also very fast, although it uses indices (I was really surprised to see this!), whereas Robert's and Brian's (with zip) are slower than the question creator's initial solution.

So let's present Brian's winning function, as it is not shown in proper form anywhere in this thread:

from itertools import izip
for a_row,b_row in izip(alist, blist):
    for a_item, b_item in izip(a_row,b_row):
        if a_item.isWhatever:
            b_item.doSomething()

","How can I, in python, iterate over multiple 2d lists at once, cleanly?","If I'm making a simple grid based game, for example, I might have a few 2d lists. One might be for terrain, another might be for objects, etc. Unfortunately, when I need to iterate over the lists and have the contents of a square in one list affect part of another list, I have to do something like this.

for i in range(len(alist)):
    for j in range(len(alist[i])):
        if alist[i][j].isWhatever:
            blist[i][j].doSomething()


Is there a nicer way to do something like this?
"
"xmltodict (full disclosure: I wrote it) can help you convert your XML to a dict+list+string structure, following this ""standard"". It is Expat-based, so it's very fast and doesn't need to load the whole XML tree in memory.

Once you have that data structure, you can serialize it to JSON:

import xmltodict, json

o = xmltodict.parse(' text text ')
json.dumps(o) # '{""e"": {""a"": [""text"", ""text""]}}'

",Converting XML to JSON using Python?,"I've seen a fair share of ungainly XML->JSON code on the web, and having interacted with Stack's users for a bit, I'm convinced that this crowd can help more than the first few pages of Google results can.

So, we're parsing a weather feed, and we need to populate weather widgets on a multitude of web sites.  We're looking now into Python-based solutions.

This public weather.com RSS feed is a good example of what we'd be parsing (our actual weather.com feed contains additional information because of a partnership w/them).

In a nutshell, how should we convert XML to JSON using Python?
"
"No, you cannot. In Python, all data (classes, methods, functions, etc) defined in C extension modules (including builtins) are immutable. This is because C modules are shared between multiple interpreters in the same process, so monkeypatching them would also affect unrelated interpreters in the same process.

However, classes defined in Python code may be monkeypatched because they are local to that interpreter.
",Can you monkey patch methods on core types in python?,"Ruby can add methods to the Number class and other core types to get effects like:


1.should_equal(1)


But it seems like python cannot do this. Is this true? And if so, why? Does it have something to do with the fact that type can't be modified?

Update: Rather than talking about different definitions of monkey patching, I would like to just focus on the example above. I have already concluded that it cannot be done as a few of you have answered. But I would like a more detailed explanation of why it cannot be done, and maybe what feature, if available in python, would allow this.

To answer some of you: The reason I might want to do this is simply aesthetics/readability. 


item.price.should_equal(19.99)


reads more like English and clearly indicates which is the tested value and which is the expected value, as supposed to:


should_equal(item.price, 19.99)


This concept is what Rspec and some other Ruby frameworks are based on.
"
"Doesn't too much matter.  Whatever makes you happy will work.  There aren't a lot of silly rules because Python projects can be simple.


/scripts or /bin for that kind of command-line interface stuff
/tests for your tests
/lib for your C-language libraries
/doc for most documentation
/apidoc for the Epydoc-generated API docs.


And the top-level directory can contain README's, Config's and whatnot.

The hard choice is whether or not to use a /src tree.  Python doesn't have a distinction between /src, /lib, and /bin like Java or C has.

Since a top-level /src directory is seen by some as meaningless, your top-level directory can be the top-level architecture of your application.


/foo
/bar
/baz


I recommend putting all of this under the ""name-of-my-product"" directory.  So, if you're writing an application named quux, the directory that contains all this stuff is named  /quux.

Another project's PYTHONPATH, then, can include /path/to/quux/foo to reuse the QUUX.foo module.  

In my case, since I use Komodo Edit, my IDE cuft is a single .KPF file.  I actually put that in the top-level /quux directory, and omit adding it to SVN.
",What is the best project structure for a Python application?,"Imagine that you want to develop a non-trivial end-user desktop (not web) application in Python. What is the best way to structure the project's folder hierarchy?

Desirable features are ease of maintenance, IDE-friendliness, suitability for source control branching/merging, and easy generation of install packages.

In particular:


Where do you put the source?
Where do you put application startup scripts?
Where do you put the IDE project cruft?
Where do you put the unit/acceptance tests?
Where do you put non-Python data such as config files?
Where do you put non-Python sources such as C++ for pyd/so binary extension modules?

"
"In production code in our company, we try to follow the following rules.

We place imports at the beginning of the file, right after the main file's docstring, e.g.:

""""""
Registry related functionality.
""""""
import wx
# ...


Now, if we import a class that is one of few in the imported module, we import the name directly, so that in the code we only have to use the last part, e.g.:

from RegistryController import RegistryController
from ui.windows.lists import ListCtrl, DynamicListCtrl


There are modules, however, that contain dozens of classes, e.g. list of all possible exceptions. Then we import the module itself and reference to it in the code:

from main.core import Exceptions
# ...
raise Exceptions.FileNotFound()


We use the import X as Y as rarely as possible, because it makes searching for usage of a particular module or class difficult. Sometimes, however, you have to use it if you wish to import two classes that have the same name, but exist in different modules, e.g.:

from Queue import Queue
from main.core.MessageQueue import Queue as MessageQueue


As a general rule, we don't do imports inside methods -- they simply make code slower and less readable. Some may find this a good way to easily resolve cyclic imports problem, but a better solution is code reorganization.
",What are good rules of thumb for Python imports?,"I am a little confused by the multitude of ways in which you can import modules in Python.  

import X
import X as Y
from A import B


I have been reading up about scoping and namespaces, but I would like some practical advice on what is the best strategy, under which circumstances and why.  Should imports happen at a module level or a method/function level?  In the __init__.py or in the module code itself?

My question is not really answered by ""Python packages - import by class, not file"" although it is obviously related.
"
"I think you are not  asking the right question--

A string in python has no property corresponding to 'ascii', utf-8, or any other encoding. The source of your string (whether you read it from a file, input from a keyboard, etc.) may have encoded a unicode string in ascii to produce your string, but that's where you need to go for an answer.

Perhaps the question you can ask is: ""Is this string the result of encoding a unicode string in ascii?"" -- This you can answer
    by trying:

try:
    mystring.decode('ascii')
except UnicodeDecodeError:
    print ""it was not a ascii-encoded unicode string""
else:
    print ""It may have been an ascii-encoded unicode string""

",How to check if a string in Python is in ASCII?,"I want to I check whether a string is in ASCII or not.

I am aware of ord(), however when I try ord('Ã©'), I have TypeError: ord() expected a character, but string of length 2 found. I understood it is caused by the way I built Python (as explained in ord()'s documentation). 

Is there another way to check?
"
"I needed to achieve the same thing too.  

I turns out it caused me quite a headache before I finally figured out, thanks to this post, how to actually make it work in a binary format.

To insert/update:

pdata = cPickle.dumps(data, cPickle.HIGHEST_PROTOCOL)
curr.execute(""insert into table (data) values (:data)"", sqlite3.Binary(pdata))


You must specify the second argument to dumps to force a binary pickling.
Also note the sqlite3.Binary to make it fit in the BLOB field.

To retrieve data:

curr.execute(""select data from table limit 1"")
for row in curr:
  data = cPickle.loads(str(row['data']))


When retrieving a BLOB field, sqlite3 gets a 'buffer' python type, that needs to be strinyfied using str before being passed to the loads method.
",Can I pickle a python dictionary into a sqlite3 text field?,"Any gotchas I should be aware of?  Can I store it in a text field, or do I need to use a blob?
(I'm not overly familiar with either pickle or sqlite, so I wanted to make sure I'm barking up the right tree with some of my high-level design ideas.)
"
"I think Django has some of the best documentation of any project I've worked on. That's the reason we chose it over Turbogears two years ago, and it's been the best technology choice we've made.
",which python framework to use?,"I'm looking for a framework which is appropriate for beginners (in Python and web development).

I already found out about Django and web.py. 
I think that one of the most important things for me is good documentation.

Thanks for the help,
Dan
"
"The collections module has grown a namedtuple function in 2.6:

import collections
opt=collections.namedtuple('options','VERBOSE IGNORE_WARNINGS')
myoptions=opt(True, False)

>>> myoptions
options(VERBOSE=True, IGNORE_WARNINGS=False)
>>> myoptions.VERBOSE
True


A namedtuple is immutable, so you can only assign field values when you create it.

In earlier Python versions, you can create an empty class:

class options(object):
    pass

myoptions=options()
myoptions.VERBOSE=True
myoptions.IGNORE_WARNINGS=False
>>> myoptions.IGNORE_WARNINGS,myoptions.VERBOSE
(False, True)

",What is an easy way to create a trivial one-off Python object?,"I would like to create a trivial one-off Python object to hold some command-line options.  I would like to do something like this:

options = ??????
options.VERBOSE = True
options.IGNORE_WARNINGS = False

# Then, elsewhere in the code...
if options.VERBOSE:
    ...


Of course I could use a dictionary, but options.VERBOSE is more readable and easier to type than options['VERBOSE'].

I thought that I should be able to do

options = object()


, since object is the base type of all class objects and therefore should be something like a class with no attributes.  But it doesn't work, because an object created using object() doesn't have a __dict__ member, and so one cannot add attributes to it:

options.VERBOSE = True
Traceback (most recent call last):
  File """", line 1, in 
AttributeError: 'object' object has no attribute 'VERBOSE'


What is the simplest ""pythonic"" way to create an object that can be used this way, preferably without having to create an extra helper class?
"
"CherryPy. Features, as listed from the website:


A fast, HTTP/1.1-compliant, WSGI thread-pooled webserver. Typically, CherryPy itself takes only 1-2ms per page!
Support for any other WSGI-enabled webserver or adapter, including Apache, IIS, lighttpd, mod_python, FastCGI, SCGI, and mod_wsgi
Easy to run multiple HTTP servers (e.g. on multiple ports) at once
A powerful configuration system for developers and deployers alike
A flexible plugin system
Built-in tools for caching, encoding, sessions, authorization, static content, and many more
A native mod_python adapter
A complete test suite
Swappable and customizable...everything.
Built-in profiling, coverage, and testing support. 

",A good multithreaded python webserver?,"I am looking for a python webserver which is multithreaded instead of being multi-process (as in case of mod_python for apache). I want it to be multithreaded because I want to have an in memory object cache that will be used by various http threads. My webserver does a lot of expensive stuff and computes some large arrays which needs to be cached in memory for future use to avoid recomputing. This is not possible in a multi-process web server environment. Storing this information in memcache is also not a good idea as the arrays are large and storing them in memcache would lead to deserialization of data coming from memcache apart from the additional overhead of IPC.

I implemented a simple webserver using BaseHttpServer, it gives good performance but it gets stuck after a few hours time. I need some more matured webserver. Is it possible to configure apache to use mod_python under a thread model so that I can do some object caching?
"
"Python is well suited for these tasks, and I would guess much easier to develop in and debug than Windows batch files.

The question is, I think, how easy and painless it is to ensure that all the computers that you have to run these scripts on, have Python installed.
",Would Python make a good substitute for the Windows command-line/batch scripts?,"I've got some experience with Bash, which I don't mind, but now that I'm doing a lot of Windows development I'm needing to do basic stuff/write basic scripts using 
the Windows command-line language. For some reason said language really irritates me, so I was considering learning Python and using that instead.

Is Python suitable for such things? Moving files around, creating scripts to do things like unzipping a backup and restoring a SQL database, etc.
"
"You may find this useful - Python internals: adding a new statement to Python, quoted here:



This article is an attempt to better understand how the front-end of Python works. Just reading documentation and source code may be a bit boring, so I'm taking a hands-on approach here: I'm going to add an until statement to Python.

All the coding for this article was done against the cutting-edge Py3k branch in the Python Mercurial repository mirror.

The until statement

Some languages, like Ruby, have an until statement, which is the complement to while (until num == 0 is equivalent to while num != 0). In Ruby, I can write:

num = 3
until num == 0 do
  puts num
  num -= 1
end


And it will print:

3
2
1


So, I want to add a similar capability to Python. That is, being able to write:

num = 3
until num == 0:
  print(num)
  num -= 1


A language-advocacy digression

This article doesn't attempt to suggest the addition of an until statement to Python. Although I think such a statement would make some code clearer, and this article displays how easy it is to add, I completely respect Python's philosophy of minimalism. All I'm trying to do here, really, is gain some insight into the inner workings of Python.

Modifying the grammar

Python uses a custom parser generator named pgen. This is a LL(1) parser that converts Python source code into a parse tree. The input to the parser generator is the file Grammar/Grammar[1]. This is a simple text file that specifies the grammar of Python.

[1]: From here on, references to files in the Python source are given relatively to the root of the source tree, which is the directory where you run configure and make to build Python.

Two modifications have to be made to the grammar file. The first is to add a definition for the until statement. I found where the while statement was defined (while_stmt), and added until_stmt below [2]:

compound_stmt: if_stmt | while_stmt | until_stmt | for_stmt | try_stmt | with_stmt | funcdef | classdef | decorated
if_stmt: 'if' test ':' suite ('elif' test ':' suite)* ['else' ':' suite]
while_stmt: 'while' test ':' suite ['else' ':' suite]
until_stmt: 'until' test ':' suite


[2]: This demonstrates a common technique I use when modifying source code Iâm not familiar with: work by similarity. This principle wonât solve all your problems, but it can definitely ease the process. Since everything that has to be done for while also has to be done for until, it serves as a pretty good guideline.

Note that I've decided to exclude the else clause from my definition of until, just to make it a little bit different (and because frankly I dislike the else clause of loops and don't think it fits well with the Zen of Python).

The second change is to modify the rule for compound_stmt to include until_stmt, as you can see in the snippet above. It's right after while_stmt, again.

When you run make after modifying Grammar/Grammar, notice that the pgen program is run to re-generate Include/graminit.h and Python/graminit.c, and then several files get re-compiled.

Modifying the AST generation code

After the Python parser has created a parse tree, this tree is converted into an AST, since ASTs are much simpler to work with in subsequent stages of the compilation process.

So, we're going to visit Parser/Python.asdl which defines the structure of Python's ASTs and add an AST node for our new until statement, again right below the while:

| While(expr test, stmt* body, stmt* orelse)
| Until(expr test, stmt* body)


If you now run make, notice that before compiling a bunch of files, Parser/asdl_c.py is run to generate C code from the AST definition file. This (like Grammar/Grammar) is another example of the Python source-code using a mini-language (in other words, a DSL) to simplify programming. Also note that since Parser/asdl_c.py is a Python script, this is a kind of bootstrapping - to build Python from scratch, Python already has to be available.

While Parser/asdl_c.py generated the code to manage our newly defined AST node (into the files Include/Python-ast.h and Python/Python-ast.c), we still have to write the code that converts a relevant parse-tree node into it by hand. This is done in the file Python/ast.c. There, a function named ast_for_stmt converts parse tree nodes for statements into AST nodes. Again, guided by our old friend while, we jump right into the big switch for handling compound statements and add a clause for until_stmt:

case while_stmt:
    return ast_for_while_stmt(c, ch);
case until_stmt:
    return ast_for_until_stmt(c, ch);


Now we should implement ast_for_until_stmt. Here it is:

static stmt_ty
ast_for_until_stmt(struct compiling *c, const node *n)
{
    /* until_stmt: 'until' test ':' suite */
    REQ(n, until_stmt);

    if (NCH(n) == 4) {
        expr_ty expression;
        asdl_seq *suite_seq;

        expression = ast_for_expr(c, CHILD(n, 1));
        if (!expression)
            return NULL;
        suite_seq = ast_for_suite(c, CHILD(n, 3));
        if (!suite_seq)
            return NULL;
        return Until(expression, suite_seq, LINENO(n), n->n_col_offset, c->c_arena);
    }

    PyErr_Format(PyExc_SystemError,
                 ""wrong number of tokens for 'until' statement: %d"",
                 NCH(n));
    return NULL;
}


Again, this was coded while closely looking at the equivalent ast_for_while_stmt, with the difference that for until I've decided not to support the else clause. As expected, the AST is created recursively, using other AST creating functions like ast_for_expr for the condition expression and ast_for_suite for the body of the until statement. Finally, a new node named Until is returned.

Note that we access the parse-tree node n using some macros like NCH and CHILD. These are worth understanding - their code is in Include/node.h.

Digression: AST composition

I chose to create a new type of AST for the until statement, but actually this isn't necessary. I could've saved some work and implemented the new functionality using composition of existing AST nodes, since:

until condition:
   # do stuff


Is functionally equivalent to:

while not condition:
  # do stuff


Instead of creating the Until node in ast_for_until_stmt, I could have created a Not node with an While node as a child. Since the AST compiler already knows how to handle these nodes, the next steps of the process could be skipped.

Compiling ASTs into bytecode

The next step is compiling the AST into Python bytecode. The compilation has an intermediate result which is a CFG (Control Flow Graph), but since the same code handles it I will ignore this detail for now and leave it for another article.

The code we will look at next is Python/compile.c. Following the lead of while, we find the function compiler_visit_stmt, which is responsible for compiling statements into bytecode. We add a clause for Until:

case While_kind:
    return compiler_while(c, s);
case Until_kind:
    return compiler_until(c, s);


If you wonder what Until_kind is, it's a constant (actually a value of the _stmt_kind enumeration) automatically generated from the AST definition file into Include/Python-ast.h. Anyway, we call compiler_until which, of course, still doesn't exist. I'll get to it an a moment.

If you're curious like me, you'll notice that compiler_visit_stmt is peculiar. No amount of grep-ping the source tree reveals where it is called. When this is the case, only one option remains - C macro-fu. Indeed, a short investigation leads us to the VISIT macro defined in Python/compile.c:

#define VISIT(C, TYPE, V) {\
    if (!compiler_visit_ ## TYPE((C), (V))) \
        return 0; \


It's used to invoke compiler_visit_stmt in compiler_body. Back to our business, however...

As promised, here's compiler_until:

static int
compiler_until(struct compiler *c, stmt_ty s)
{
    basicblock *loop, *end, *anchor = NULL;
    int constant = expr_constant(s->v.Until.test);

    if (constant == 1) {
        return 1;
    }
    loop = compiler_new_block(c);
    end = compiler_new_block(c);
    if (constant == -1) {
        anchor = compiler_new_block(c);
        if (anchor == NULL)
            return 0;
    }
    if (loop == NULL || end == NULL)
        return 0;

    ADDOP_JREL(c, SETUP_LOOP, end);
    compiler_use_next_block(c, loop);
    if (!compiler_push_fblock(c, LOOP, loop))
        return 0;
    if (constant == -1) {
        VISIT(c, expr, s->v.Until.test);
        ADDOP_JABS(c, POP_JUMP_IF_TRUE, anchor);
    }
    VISIT_SEQ(c, stmt, s->v.Until.body);
    ADDOP_JABS(c, JUMP_ABSOLUTE, loop);

    if (constant == -1) {
        compiler_use_next_block(c, anchor);
        ADDOP(c, POP_BLOCK);
    }
    compiler_pop_fblock(c, LOOP, loop);
    compiler_use_next_block(c, end);

    return 1;
}


I have a confession to make: this code wasn't written based on a deep understanding of Python bytecode. Like the rest of the article, it was done in imitation of the kin compiler_while function. By reading it carefully, however, keeping in mind that the Python VM is stack-based, and glancing into the documentation of the dis module, which has a list of Python bytecodes with descriptions, it's possible to understand what's going on.

That's it, we're done... Aren't we?

After making all the changes and running make, we can run the newly compiled Python and try our new until statement:

>>> until num == 0:
...   print(num)
...   num -= 1
...
3
2
1


Voila, it works! Let's see the bytecode created for the new statement by using the dis module as follows:

import dis

def myfoo(num):
    until num == 0:
        print(num)
        num -= 1

dis.dis(myfoo)


Here's the result:

4           0 SETUP_LOOP              36 (to 39)
      >>    3 LOAD_FAST                0 (num)
            6 LOAD_CONST               1 (0)
            9 COMPARE_OP               2 (==)
           12 POP_JUMP_IF_TRUE        38

5          15 LOAD_NAME                0 (print)
           18 LOAD_FAST                0 (num)
           21 CALL_FUNCTION            1
           24 POP_TOP

6          25 LOAD_FAST                0 (num)
           28 LOAD_CONST               2 (1)
           31 INPLACE_SUBTRACT
           32 STORE_FAST               0 (num)
           35 JUMP_ABSOLUTE            3
      >>   38 POP_BLOCK
      >>   39 LOAD_CONST               0 (None)
           42 RETURN_VALUE


The most interesting operation is number 12: if the condition is true, we jump to after the loop. This is correct semantics for until. If the jump isn't executed, the loop body keeps running until it jumps back to the condition at operation 35.

Feeling good about my change, I then tried running the function (executing myfoo(3)) instead of showing its bytecode. The result was less than encouraging:

Traceback (most recent call last):
  File ""zy.py"", line 9, in
    myfoo(3)
  File ""zy.py"", line 5, in myfoo
    print(num)
SystemError: no locals when loading 'print'


Whoa... this can't be good. So what went wrong?

The case of the missing symbol table

One of the steps the Python compiler performs when compiling the AST is create a symbol table for the code it compiles. The call to PySymtable_Build in PyAST_Compile calls into the symbol table module (Python/symtable.c), which walks the AST in a manner similar to the code generation functions. Having a symbol table for each scope helps the compiler figure out some key information, such as which variables are global and which are local to a scope.

To fix the problem, we have to modify the symtable_visit_stmt function in Python/symtable.c, adding code for handling until statements, after the similar code for while statements [3]:

case While_kind:
    VISIT(st, expr, s->v.While.test);
    VISIT_SEQ(st, stmt, s->v.While.body);
    if (s->v.While.orelse)
        VISIT_SEQ(st, stmt, s->v.While.orelse);
    break;
case Until_kind:
    VISIT(st, expr, s->v.Until.test);
    VISIT_SEQ(st, stmt, s->v.Until.body);
    break;


[3]: By the way, without this code thereâs a compiler warning for Python/symtable.c. The compiler notices that the Until_kind enumeration value isnât handled in the switch statement of symtable_visit_stmt and complains. Itâs always important to check for compiler warnings!

And now we really are done. Compiling the source after this change makes the execution of myfoo(3) work as expected.

Conclusion

In this article I've demonstrated how to add a new statement to Python. Albeit requiring quite a bit of tinkering in the code of the Python compiler, the change wasn't difficult to implement, because I used a similar and existing statement as a guideline.

The Python compiler is a sophisticated chunk of software, and I don't claim being an expert in it. However, I am really interested in the internals of Python, and particularly its front-end. Therefore, I found this exercise a very useful companion to theoretical study of the compiler's principles and source code. It will serve as a base for future articles that will get deeper into the compiler.

References

I used a few excellent references for the construction of this article. Here they are, in no particular order:


PEP 339: Design of the CPython compiler - probably the most important and comprehensive piece of official documentation for the Python compiler. Being very short, it painfully displays the scarcity of good documentation of the internals of Python.
""Python Compiler Internals"" - an article by Thomas Lee
""Python: Design and Implementation"" - a presentation by Guido van Rossum
Python (2.5) Virtual Machine, A guided tour - a presentation by Peter TrÃ¶ger


original source
",Can you add new statements to Python's syntax?,"Can you add new statements (like print, raise, with) to Python's syntax?

Say, to allow..

mystatement ""Something""


Or,

new_if True:
    print ""example""


Not so much if you should, but rather if it's possible (short of modifying the python interpreters code)
"
"Append the first element of the list to a reversed sublist:

mylist = [1, 2, 3, 4, 5]
backwards = lambda l: (backwards (l[1:]) + l[:1] if l else []) 
print backwards (mylist)

",How do I reverse a list using recursion in Python?,"I want to have a function that will return the reverse of a list that it is given -- using recursion. How can I do that?
"
"Your DictObj example is actually quite common. Object-style dot-notation access can be a win if you are dealing with âthings that resemble objectsâ, ie. they have fixed property names containing only characters valid in Python identifiers. Stuff like database rows or form submissions can be usefully stored in this kind of object, making code a little more readable without the excess of ['item access'].

The implementation is a bit limited - you don't get the nice constructor syntax of dict, len(), comparisons, 'in', iteration or nice reprs. You can of course implement those things yourself, but in the new-style-classes world you can get them for free by simply subclassing dict:

class AttrDict(dict):
    __getattr__ = dict.__getitem__
    __setattr__ = dict.__setitem__
    __delattr__ = dict.__delitem__


To get the default-to-None behaviour, simply subclass Python 2.5's collections.defaultdict class instead of dict.
",Javascript style dot notation for dictionary keys unpythonic?,"I've started to use constructs like these:

class DictObj(object):
    def __init__(self):
        self.d = {}
    def __getattr__(self, m):
        return self.d.get(m, None)
    def __setattr__(self, m, v):
        super.__setattr__(self, m, v)


Update: based on this thread, I've revised the DictObj implementation to:

class dotdict(dict):
    def __getattr__(self, attr):
        return self.get(attr, None)
    __setattr__= dict.__setitem__
    __delattr__= dict.__delitem__

class AutoEnum(object):
    def __init__(self):
        self.counter = 0
        self.d = {}
    def __getattr__(self, c):
        if c not in self.d:
            self.d[c] = self.counter
            self.counter += 1        
        return self.d[c]


where DictObj is a dictionary that can be accessed via dot notation:

d = DictObj()
d.something = 'one'


I find it more aesthetically pleasing than d['something']. Note that accessing an undefined key returns None instead of raising an exception, which is also nice.

Update: Smashery makes a good point, which mhawke expands on for an easier solution. I'm wondering if there are any undesirable side effects of using dict instead of defining a new dictionary; if not, I like mhawke's solution a lot.

AutoEnum is an auto-incrementing Enum, used like this:

CMD = AutoEnum()

cmds = {
    ""peek"":  CMD.PEEK,
    ""look"":  CMD.PEEK,
    ""help"":  CMD.HELP,
    ""poke"":  CMD.POKE,
    ""modify"": CMD.POKE,
}


Both are working well for me, but I'm feeling unpythonic about them. 

Are these in fact bad constructs?
"
"The question you've asked (how to iterate through the alphabet) is not the same question as the problem you're trying to solve (how to count the frequency of letters in a string).

You can use string.lowercase, as other posters have suggested:

import string
allTheLetters = string.lowercase


To do things the way you're ""used to"", treating letters as numbers, you can use the ""ord"" and ""chr"" functions.  There's absolutely no reason to ever do exactly this, but maybe it comes closer to what you're actually trying to figure out:

def getAllTheLetters(begin='a', end='z'):
    beginNum = ord(begin)
    endNum = ord(end)
    for number in xrange(beginNum, endNum+1):
        yield chr(number)


You can tell it does the right thing because this code prints True:

import string
print ''.join(getAllTheLetters()) == string.lowercase


But, to solve the problem you're actually trying to solve, you want to use a dictionary and collect the letters as you go:

from collections import defaultdict    
def letterOccurrances(string):
    frequencies = defaultdict(lambda: 0)
    for character in string:
        frequencies[character.lower()] += 1
    return frequencies


Use like so:

occs = letterOccurrances(""Hello, world!"")
print occs['l']
print occs['h']


This will print '3' and '1' respectively.

Note that this works for unicode as well:

# -*- coding: utf-8 -*-
occs = letterOccurrances(u""hÃ©ÄºÄºÃ³, áºÃ³ÅÄºd!"")
print occs[u'l']
print occs[u'Äº']


If you were to try the other approach on unicode (incrementing through every character) you'd be waiting a long time; there are millions of unicode characters.

To implement your original function (print the counts of each letter in alphabetical order) in terms of this:

def alphCount(text):
    for character, count in sorted(letterOccurrances(text).iteritems()):
        print ""%s: %s"" % (character, count)

alphCount(""hello, world!"")

",How do I iterate through a string in Python?,"As an example, lets say I wanted to list the frequency of each letter of the alphabet in a string. What would be the easiest way to do it?

This is an example of what I'm thinking of... the question is how to make allTheLetters equal to said letters without something like allTheLetters = ""abcdefg...xyz"". In many other languages I could just do letter++ and increment my way through the alphabet, but thus far I haven't come across a way to do that in python.

def alphCount(text):
  lowerText = text.lower()
  for letter in allTheLetters:  
    print letter + "":"", lowertext.count(letter)

"
"import sys
sys.stdout.flush()


Print by default prints to sys.stdout.

References:


http://docs.python.org/reference/simple_stmts.html#the-print-statement
http://docs.python.org/library/sys.html
http://docs.python.org/library/stdtypes.html#file-objects

",How to flush output of Python print?,"How do I force Python's print function to output to the screen?
"
"You have a couple of choices. For one, you can use the os.path.getmtime and os.path.getctime functions:

import os.path, time
print ""last modified: %s"" % time.ctime(os.path.getmtime(file))
print ""created: %s"" % time.ctime(os.path.getctime(file))


Your other option is to use os.stat:

import os, time
(mode, ino, dev, nlink, uid, gid, size, atime, mtime, ctime) = os.stat(file)
print ""last modified: %s"" % time.ctime(mtime)


Note: ctime() does not refer to creation time on *nix systems, but rather the last time the inode data changed. (thanks to kojiro for making that fact more clear in the comments by providing a link to an interesting blog post)
",How to get file creation & modification date/times in Python?,"I have a script that needs to do some stuff based on file creation & modification dates but has to run on Linux & Windows.

What's the best cross-platform way to get file creation & modification date/times in Python?
"
"A generator will solve your problem nicely.

def imerge(a, b):
    for i, j in itertools.izip(a,b):
        yield i
        yield j

",How do I merge two python iterators?,"I have two iterators, a list and an itertools.count object (i.e. an infinite value generator). I would like to merge these two into a resulting iterator that will alternate yield values between the two:

>>> import itertools
>>> c = itertools.count(1)
>>> items = ['foo', 'bar']
>>> merged = imerge(items, c)  # the mythical ""imerge""
>>> merged.next()
'foo'
>>> merged.next()
1
>>> merged.next()
'bar'
>>> merged.next()
2
>>> merged.next()
Traceback (most recent call last):
    ...
StopIteration


What is the simplest, most concise way to do this?
"
"If you just plan on doing Python dev, I'd just go with Platform Runtime Binary.

After that, I'd follow the instructions http://pydev.org/download.html and http://pydev.org/manual_101_root.html to install PyDev.

I use the same setup for Python development.  I also have the RadRails plugin for Ruby on Rails development.
",Which Eclipse package to download for pydev?,"I'm getting started with python, eclipse and pydev. Which Eclipse package should I choose? Nothing on the eclipse homepage tells me what to choose and python documentation assumes I have eclipse installed. Does which package I choose matter?
"
"[This may come off sounding more negative than it really is.  I'm not saying Basic is the root of all evil, others have said that.  I'm saying it's a legacy we can afford to leave behind.]

""because it was so easy to understand and so hard to make a mistake"" That's certainly debatable.  I've had some bad experiences with utterly opaque basic.  Professional stuff -- commercial products -- perfectly awful code.  Had to give up and decline the work.

""What, if any, are the advantages Basic has over other languages?""  None, really.

""Why is it still around?""  Two reasons: (1) Microsoft, (2) all the IT departments that started doing VB and now have millions of lines of VB legacy code.

""Plenty of other languages are considered dead...""  Yep.  Basic is there along side COBOL, PL/I and RPG as legacies that sometimes have more cost than value.  But because of the ""if it ain't broke don't fix it"" policy of big IT, there they sit, sucking up resources who could easily replace it with something smaller, simpler and cheaper to maintain.  Except it hasn't ""failed"" -- it's just disproportionately expensive.

30-year old COBOL is a horrible situation to rework.  Starting in 2016 we'll be looking at 30-year old MS Basic that we just can't figure out, don't want to live without, and can't decide how to replace.

""but basic just keeps hanging on"" It appears that some folks love Basic.  Others see it as yet another poorly-designed language; it's advantages are being early to market and being backed by huge vendors (IBM, initially).  Poorly-design, early-to-market only leaves us with a legacy that we'll be suffering with for decades.

I still have my 1965-edition Dartmouth Basic manual.  I don't long for the good old days.
","With Lua and Python embeddable, is there a place for Basic?","I started off programming in Basic on the ZX81, then BASICA, GW-BASIC, and QBasic.  I moved on to C (Ah, Turbo C 3.1, I hardly knew ye...)

When I got started in microcontrollers I regressed with the BASIC Stamp from Parallax.  However, BASIC is/was awesome because it was so easy to understand and so hard to make a mistake.  I moved on to assembly and C eventually because I needed the additional power (speed, capacity, resources, etc.), but I know that if the bar was much higher many people would never get into programming microcontrollers.

I keep getting an itch to make my own on-chip BASIC interpretor, but I wonder if there's need for BASIC now that Lua and Python are easily embeddable, and just as approachable as BASIC.


What, if any, are the advantages BASIC has over other languages? 
Why is it still around?  
If I decide to make a general purpose microcontroller board with an interpreter, is there any reason to make a version of BASIC?


Plenty of other languages are considered dead, but BASIC just keeps hanging on.
"
"In general, don't use a generator when you need list operations, like len(), reversed(), and so on.

There may also be times when you don't want lazy evaluation (e.g. to do all the calculation up front so you can release a resource). In that case, a list expression might be better.
",When is not a good time to use python generators?,"This is rather the inverse of What can you use Python generator functions for?: python generators, generator expressions, and the itertools module are some of my favorite features of python these days. They're especially useful when setting up chains of operations to perform on a big pile of data--I often use them when processing DSV files.

So when is it not a good time to use a generator, or a generator expression, or an itertools function?


When should I prefer zip() over itertools.izip(), or
range() over xrange(), or
[x for x in foo] over (x for x in foo)?


Obviously, we eventually need to ""resolve"" a generator into actual data, usually by creating a list or iterating over it with a non-generator loop. Sometimes we just need to know the length. This isn't what I'm asking.

We use generators so that we're not assigning new lists into memory for interim data. This especially makes sense for large datasets. Does it make sense for small datasets too? Is there a noticeable memory/cpu trade-off?

I'm especially interested if anyone has done some profiling on this, in light of the eye-opening discussion of list comprehension performance vs. map() and filter(). (alt link)
"
"Lua is a cool language, light-weight and extremely fast!

But the point is: Is performance so important for those
tasks you mentioned?


Renaming a bunch of files
Download some files from the web
Webscraping


You write those programs once, and run them once, too maybe.
Why do you care about performance so much for a run-once program?

For example:


Cost 3 hours to write a C/C++ program, to handle data once, the program will take 1 hour to run.
Cost 30 Minute to write a Python program to handle data once, the program will take 10 hours to run.


If you choose the first, you save the time to run the program,
but you cost your time to develop the program.

On the other hand, if you choose the second, you waste time to run
the program, but you can do other things when the program is
running. How about play World of Warcraft, kill monsters
with your warlock? Eat my D.O.T! :P

That's it! Although Lua is not so difficult to write, everything about Lua is designed to be efficient.And what's more, there are little modules for Lua, but there are so many modules for Python. You don't want to port a C library for Lua just for a run-once program, do you? Instead, choose Python and use those module to achieve your task easily might be a better idea.

FYI: Actually, I have tried to use Lua to do webscraping,
but finally, I realized I do not have to care so much about language performance. The bottleneck of webscraping is
not on the performance of the language. The bottleneck is on
network I/O, HTML parsing and multitasking. All I have to do
is make sure the program works and find the bottleneck.
Finally, I chose Python rather than Lua. There is so
many excellent Python modules; I have no reason to build my
own.

According to my experience about webscraping, I chose
Twisted for network I/O and lxml for html parsing as the backend
of my webscraping program. I have wrote an article for an introduction to this technology.

The best choice to grab data from websites: Python + Twisted + lxml

Hope this is helpful.
",Lua as a general-purpose scripting language?,"When I see Lua, the only thing I ever read is ""great for embedding"", ""fast"", ""lightweight"" and more often than anything else: ""World of Warcraft"" or in short ""WoW"".

Why is it limited to embedding the whole thing into another application? Why not write general-purpose scripts like you do with Python or Perl?

Lua seems to be doing great in aspects like speed and memory-usage (The fastest scripting language afaik) so why is it that I never see Lua being used as a ""Desktop scripting-language"" to automate tasks? For example:


Renaming a bunch of files
Download some files from the web
Webscraping


Is it the lack of the standard library?
"
"Try the module paramiko_scp. It's very easy to use. See the following example:

def createSSHClient(server, port, user, password):
    client = paramiko.SSHClient()
    client.load_system_host_keys()
    client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
    client.connect(server, port, user, password)
    return client

ssh = createSSHClient(server, port, user, password)
scp = SCPClient(ssh.get_transport())


Then call scp.get() or scp.put() to do scp operations.

(SCPClient code)
",How to scp in python?,"What's the most pythonic way to scp a file in Python?  The only route I'm aware of is 

os.system('scp ""%s"" ""%s:%s""' % (localfile, remotehost, remotefile) )


which is a hack, and which doesn't work outside linux-like systems, and which needs help from the Pexpect module to avoid password prompts unless you already have passwordless SSH set up to the remote host.

I'm aware of Twisted's conch, but I'd prefer to avoid implementing scp myself via low-level ssh modules.

I'm aware of paramiko, a Python module that supports ssh and sftp; but it doesn't support scp.

Background: I'm connecting to a router which doesn't support sftp but does support ssh/scp, so sftp isn't an option.

EDIT:
This is a duplicate of http://stackoverflow.com/questions/68335/how-do-i-copy-a-file-to-a-remote-server-in-python-using-scp-or-ssh.  However, that question doesn't give an scp-specific answer that deals with keys from within python.  I'm hoping for a way to run code kind of like

import scp

client = scp.Client(host=host, user=user, keyfile=keyfile)
# or
client = scp.Client(host=host, user=user)
client.use_system_keys()
# or
client = scp.Client(host=host, user=user, password=password)

# and then
client.transfer('/etc/local/filename', '/etc/remote/filename')

"
"Just a comment. In Python 3, you will use

print('h', end='')


to suppress the endline terminator, and

print('a', 'b', 'c', sep='')


to suppress the whitespace separator between items.
",How do I keep Python print from adding newlines or spaces?,"In python, if I say

print 'h'


I get the letter h and a newline.  If I say 

print 'h',


I get the letter h and no newline.  If I say

print 'h',
print 'm',


I get the letter h, a space, and the letter m.  How can I prevent Python from printing the space?

The print statements are different iterations of the same loop so I can't just use the + operator.
"
"The obvious advantages to browser-based:


you can present the same UI regardless of platform
you can upgrade the application easily, and all users have the same version of the app running
you know the environment that your application will be running in (the server hardware/OS) which makes for easier testing and support compared to the multitude of operating system/hardware configurations that a GUI app will be installed on.


And for GUI based:


some applications (e.g.: image editing) arguably work better in a native GUI application
doesn't require network access


Also see my comments on this question:


  Cross-platform GUIs are an age-old problem. Qt, GTK, wxWindows, Java AWT, Java Swing, XUL -- they all suffer from the same problem: the resulting GUI doesn't look native on every platform. Worse still, every platform has a slightly different look and feel, so even if you were somehow able to get a toolkit that looked native on every platform, you'd have to somehow code your app to feel native on each platform.
  
  It comes down to a decision: do you want to minimise development effort and have a GUI that doesn't look and feel quite right on each platform, or do you want to maximise the user experience? If you choose the second option, you'll need to develop a common backend and a custom UI for each platform. [edit: or use a web application.]


Another thought I just had: you also need to consider the kind of data that your application manipulates and where it is stored, and how the users will feel about that. People are obviously okay having their facebook profile data stored on a webserver, but they might feel differently if you're writing a finance application like MYOB and you want to store all their personal financial details on your server. You might be able to get that to work, but it would require a lot of effort to implement the required security and to assure the userbase that their data is safe. In that situation you might decide that the overall effort is lower if you go with a native GUI app.
",Browser-based application or stand-alone GUI app?,"I'm sure this has been asked before, but I can't find it. 

What are the benefits/limitations of using a browser-based interface for a stand-alone application vs. using a normal GUI framework?

I'm working on a Python program currently implement with wxPython for the GUI. The application is simply user-entry forms and dialogs. I am considering moving to PyQt because of the widgets it has (for future expansion), then I realized I could probably just use a browser to do much of the same stuff.

The application currently doesn't require Internet access, though it's a possibility in the future. I was thinking of using Karrigell for the web framework if I go browser-based.



Edit For clarification, as of right now the application would be browser-based, not web-based. All the information would be stored locally on the client computer; no server calls would need to be made and no Internet access required (it may come later though). It would simply be a browser GUI instead of a wxPython/PyQt GUI. Hope that makes sense.
"
"max(stats, key=stats.get)

",Getting key with maximum value in dictionary?,"I have a dictionary: keys are strings, values are integers.

Example: 

stats = {'a':1000, 'b':3000, 'c': 100}


I'd like to get 'b' as an answer, since it's the key with a higher value.

I did the following, using an intermediate list with reversed key-value tuples:

inverse = [(value, key) for key, value in stats.items()]
print max(inverse)[1]


Is that one the better (or even more elegant) approach?
"
"Use the netifaces module.  Because networking is complex, using netifaces can be a little tricky, but here's how to do what you want:

>>> import netifaces
>>> netifaces.interfaces()
['lo', 'eth0']
>>> netifaces.ifaddresses('eth0')
{17: [{'broadcast': 'ff:ff:ff:ff:ff:ff', 'addr': '00:11:2f:32:63:45'}], 2: [{'broadcast': '10.0.0.255', 'netmask': '255.255.255.0', 'addr': '10.0.0.2'}], 10: [{'netmask': 'ffff:ffff:ffff:ffff::', 'addr': 'fe80::211:2fff:fe32:6345%eth0'}]}
>>> for interface in netifaces.interfaces():
...   print netifaces.ifaddresses(interface)[netifaces.AF_INET]
...
[{'peer': '127.0.0.1', 'netmask': '255.0.0.0', 'addr': '127.0.0.1'}]
[{'broadcast': '10.0.0.255', 'netmask': '255.255.255.0', 'addr': '10.0.0.2'}]
>>> for interface in netifaces.interfaces():
...   for link in netifaces.ifaddresses(interface)[netifaces.AF_INET]:
...     print link['addr']
...
127.0.0.1
10.0.0.2


This can be made a little more readable like this:

from netifaces import interfaces, ifaddresses, AF_INET

def ip4_addresses():
    ip_list = []
    for interface in interfaces():
        for link in ifaddresses(interface)[AF_INET]:
            ip_list.append(link['addr'])
    return ip_list


If you want IPv6 addresses, use AF_INET6 instead of AF_INET.  If you're wondering why netifaces uses lists and dictionaries all over the place, it's because a single computer can have multiple NICs, and each NIC can have multiple addresses, and each address has its own set of options.
",How do I determine all of my IP addresses when I have multiple NICs?,"I have multiple Network Interface Cards on my computer, each with its own IP address.

When I use gethostbyname(gethostname()) from Python's (built-in) socket module, it will only return one of them.  How do I get the others?
"
"Define a maximum size.
Then, compute a resize ratio by taking min(maxwidth/width, maxheight/height).

The proper size is oldsize*ratio.

There is of course also a library method to do this: the method Image.thumbnail.
Below is an (edited) example from the PIL documentation.

import os, sys
import Image

size = 128, 128

for infile in sys.argv[1:]:
    outfile = os.path.splitext(infile)[0] + "".thumbnail""
    if infile != outfile:
        try:
            im = Image.open(infile)
            im.thumbnail(size, Image.ANTIALIAS)
            im.save(outfile, ""JPEG"")
        except IOError:
            print ""cannot create thumbnail for '%s'"" % infile

",How do I resize an image using PIL and maintain its aspect ratio?,"Is there an obvious way to do this that I'm missing?  I'm just trying to make thumbnails.
"
"Given the Django use case, there are two answers to this.  Here is its django.utils.html.escape function, for reference:

def escape(html):
    """"""Returns the given HTML with ampersands, quotes and carets encoded.""""""
    return mark_safe(force_unicode(html).replace('&', '&amp;').replace('<', '&l
t;').replace('>', '&gt;').replace('""', '&quot;').replace(""'"", '&#39;'))


To reverse this, the Cheetah function described in Jake's answer should work, but is missing the single-quote.  This version includes an updated tuple, with the order of replacement reversed to avoid symmetric problems:

def html_decode(s):
    """"""
    Returns the ASCII decoded version of the given HTML string. This does
    NOT remove normal HTML tags like .
    """"""
    htmlCodes = (
            (""'"", '&#39;'),
            ('""', '&quot;'),
            ('>', '&gt;'),
            ('<', '&lt;'),
            ('&', '&amp;')
        )
    for code in htmlCodes:
        s = s.replace(code[1], code[0])
    return s

unescaped = html_decode(my_string)


This, however, is not a general solution; it is only appropriate for strings encoded with django.utils.html.escape.  More generally, it is a good idea to stick with the standard library:

# Python 2.x:
import HTMLParser
html_parser = HTMLParser.HTMLParser()
unescaped = html_parser.unescape(my_string)

# Python 3.x:
import html.parser
html_parser = html.parser.HTMLParser()
unescaped = html_parser.unescape(my_string)


As a suggestion: it may make more sense to store the HTML unescaped in your database.  It'd be worth looking into getting unescaped results back from BeautifulSoup if possible, and avoiding this process altogether.

With Django, escaping only occurs during template rendering; so to prevent escaping you just tell the templating engine not to escape your string.  To do that, use one of these options in your template:

{{ context_var|safe }}
{% autoescape off %}
    {{ context_var }}
{% endautoescape %}

",How do I perform HTML decoding/encoding using Python/Django?,"I have a string that is html encoded: 

&lt;img class=&quot;size-medium wp-image-113&quot; 
  style=&quot;margin-left: 15px;&quot; title=&quot;su1&quot; 
  src=&quot;http://blah.org/wp-content/uploads/2008/10/su1-300x194.jpg&quot; 
  alt=&quot;&quot; width=&quot;300&quot; height=&quot;194&quot; /&gt;


I want to change that to:

<img class=""size-medium wp-image-113"" style=""margin-left: 15px;"" 
  title=""su1"" src=""http://blah.org/wp-content/uploads/2008/10/su1-300x194.jpg"" 
  alt="""" width=""300"" height=""194"" />


I want this to register as HTML so that it is rendered as an image by the browser instead of being displayed as text. 

I've found how to do this in C# but not in in Python. Can someone help me out?

Thanks.

Edit: Someone asked why my strings are stored like that. It's because I am using a web-scraping tool that ""scans"" a web-page and gets certain content from it. The tool (BeautifulSoup) returns the string in that format.

Related


Convert XML/HTML Entities into Unicode String in Python

"
"One project I'm aware of that provides similar features (inline plotting, customisable rendering) is Reinteract.  Another (though possibly a bit heavyweight for general usage) is SAGE which provides functionality for web-based notebooks.

These aren't quite shells - they're designed more as a mathematical notebook (so for instance, you can modify an earlier result and have the change propogate to later calculations), but they're close to what you're looking for, and could probably be modified to be used as such.
",Is there a good Python GUI shell?,"I saw this the other day (scroll all the way down to see some of the clever stuff): 


  http://www.mono-project.com/docs/tools+libraries/tools/repl/


And wondered whether something like this exists for Python.

So, is there a good Python GUI shell that can do stuff like that C# shell can do?

Edit: Here are links to screenshots from the article, showing what I'm interested in doing.

An example of the type of things I'm interested: 

http://www.mono-project.com/archived/images/7/75/GSharpPlot.png

They are able to add hooks to produce GUI elements like the plot, or even do silly things like:

http://www.mono-project.com/archived/images/b/bf/GSharpRenderHandler.png

I don't think this is possible with any of the console shells I've tried (the regular python shell, ipython).

Edit: I'm not looking for an IDE. If you look at the link, you'll get an idea of what I want.
"
"As Tony said, this is really going to depend on your goals.  If you're ""tinkering"" to try to learn about OpenGL or 3D rendering in general that I would dispense with all pleasantries and start working with PyOpenGL, which is as close are you're going to get to ""raw"" 3D programming using Python.

On the other hand, if you're ""tinkering"" by way of mocking up a game or multimedia application, or trying to learn about programming practices in general than Pyglet will save you lots of up-front development time by providing hooks for input events, sounds, text/billboarding, etc. Often, this up-front investment is what prevents people from completing their projects, so having it done for you is not something to be ignored.  (It is also very Pythonic to avoid reinventing the wheel.)

If you are looking to do any sort of heavy-duty lifting (which normally falls outside my definition of ""tinkering"", but maybe not if you're tinkering with 3D engine design) then you might want to take a look at Python-Ogre, which wraps the very full-featured and robust OGRE 3D graphics engine.
",PyOpenGl or pyglet?,"I am looking to do some tinkering with openGL and Python and haven't been able to find good reasons for using PyOpenGl versus pyglet

Which would you recommend and why?
"
"The short answer is ""no"".  There is not a swiss-army-knife like IDE that is both a full-featured Python code-editor and a full-featured WYSIWYG GUI editor.  However, there are several stand-alone tools that make creating a GUI easier and there are a myriad of code editors, so if you can handle having two windows open, then you can accomplish what you are trying to.

As for stand-alone GUI editors, which you choose is going to depend on what library you choose to develop your GUI with.  I would recommend using GTK+, which binds to Python via PyGtk and has the Glade GUI designer.  I believe that there are other GUI libraries for Python that have WYSIWYG designers (Qt, Tkinter, wxWindows, etc.), but GTK+ is the one I have the most experience with so I will leave the others for other commentators.

Note, however, that the designer in this case is not at all language dependent.  It just spits out a .glade file that could be loaded into any language that has GTK+ bindings.  If you are looking for a designer that produces raw Python code (like the Code-Behind model that VS.Net uses), then I am not aware of any.

As for general code-editing IDE's (that do not include a GUI designer), there are many, of which PyDev/Eclipse is probably the most Visual Studio-like.

(Revised for clarity.)
",With what kind of IDE (if any) you build python GUI projects?,"Is there any IDE (like VS) with drag and drop support for building python GUI, connecting to dbs etc?
Eventhough I am an emacs guy, I find it much easier to create GUI with VS.
"
"As of 2.6, use abstract base classes.

>>> import collections
>>> isinstance([], collections.Sequence)
True
>>> isinstance(0, collections.Sequence)
False


Furthermore ABC's can be customized to account for exceptions, such as not considering strings to be sequences.  Here an example:

import abc
import collections

class Atomic(object):
    __metaclass__ = abc.ABCMeta
    @classmethod
    def __subclasshook__(cls, other):
        return not issubclass(other, collections.Sequence) or NotImplemented

Atomic.register(basestring)


After registration the Atomic class can be used with isinstance and issubclass:

assert isinstance(""hello"", Atomic) == True


This is still much better than a hard-coded list, because you only need to register the exceptions to the rule, and external users of the code can register their own.

Note that in Python 3 the syntax for specifying metaclasses changed and the basestring abstract superclass was removed, which requires something like the following to be used instead:

class Atomic(metaclass=abc.ABCMeta):
    @classmethod
    def __subclasshook__(cls, other):
        return not issubclass(other, collections.Sequence) or NotImplemented

Atomic.register(str)


If desired, it's possible to write code which is compatible both both Python 2.6+ and 3.x, but doing so requires using a slightly more complicated technique which dynamically creates the needed abstract base class, thereby avoiding syntax errors due to the metaclass syntax difference. This is essentially the same as what Benjamin Peterson's six module'swith_metaclass()function does.

class _AtomicBase(object):
    @classmethod
    def __subclasshook__(cls, other):
        return not issubclass(other, collections.Sequence) or NotImplemented

class Atomic(abc.ABCMeta(""NewMeta"", (_AtomicBase,), {})):
    pass

try:
    unicode = unicode
except NameError:  # 'unicode' is undefined, assume Python >= 3
    Atomic.register(str)  # str includes unicode in Py3, make both Atomic
    Atomic.register(bytes)  # bytes will also be considered Atomic (optional)
else:
    # basestring is the abstract superclass of both str and unicode types
    Atomic.register(basestring)  # make both types of strings Atomic


In versions before 2.6, there are type checkers in theoperatormodule.

>>> import operator
>>> operator.isSequenceType([])
True
>>> operator.isSequenceType(0)
False

",Correct way to detect sequence parameter?,"I want to write a function that accepts a parameter which can be either a sequence or a single value. The type of value is str, int, etc., but I don't want it to be restricted to a hardcoded list. 
In other words, I want to know if the parameter X is a sequence or something I have to convert to a sequence to avoid special-casing later. I could do

type(X) in (list, tuple)

but there may be other sequence types I'm not aware of, and no common base class.

-N.

Edit: See my ""answer"" below for why most of these answers don't help me. Maybe you have something better to suggest.
"
"Use random.choice:

import random

foo = ['a', 'b', 'c', 'd', 'e']
print(random.choice(foo))

",How do I randomly select an item from a list using Python?,"Assume I have the following list:

foo = ['a', 'b', 'c', 'd', 'e']


What is the simplest way to retrieve an item at random from this list?
"
"First Option - Online Installation (i.e. remaining connected to the Internet during the entire installation process):


Download setuptools-0.6c9.tar.gz
Use 7-zip to extract it to a folder(directory) outside your Windows Python installation folder
Go the folder (refer step 2) and run ez_setup.py from the corresponding dos (command) prompt
Ensure that your PATH includes the appropriate C:\Python2X\Scripts directory


Second Option:


Download setuptools-0.6c9.tar.gz
Download setuptools-0.6c9-py2.6.egg to a folder(directory) outside your Windows Python installation folder
Use 7-zip to extract ez_setup.py in the same folder as setuptools-0.6c9-py2.6.egg
Go to the corresponding dos prompt and run python ez_setup.py setuptools-0.6c9-py2.6.egg from the command prompt
Ensure that your PATH includes the appropriate C:\Python2X\Scripts directory


Third Option (assuming that you have Visual Studio 2005 or MinGW on your machine)


Download setuptools-0.6c9.tar.gz
Use 7-zip to extract it to a folder(directory) outside your Windows Python installation folder
Go the folder (refer step 2) and run python setup.py install from the corresponding dos (command) prompt


Please provide feedback.
",How to setup setuptools for python 2.6 on Windows?,"Is there any way to install setuptools for python 2.6 in Windows without having an .exe installer? 

There isn't one built at the moment, and the maintainer of setuptools has stated that it's probable be a while before he'll get to it. 

Does anyone know of a way to install it anyway?
"
"See this pure Python ping by Matthew Dixon Cowles and Jens Diemer.  Also, remember that Python requires root to spawn ICMP (i.e. ping) sockets in linux.

import ping, socket
try:
    ping.verbose_ping('www.google.com', count=3)
    delay = ping.Ping('www.wikipedia.org', timeout=2000).do()
except socket.error, e:
    print ""Ping Error:"", e


The source code itself is easy to read, see the implementations of verbose_ping and of Ping.do for inspiration.
",Ping a site in Python?,"The basic code is:

from Tkinter import *
import os,sys

ana= Tk()
def ping1():
    os.system('ping')

a=Button(pen)
ip=(""192.168.0.1"")

a.config(text=""PING"",bg=""white"",fg=""blue"")
a=ping1.ip ??? 
a.pack()

ana.mainloop()


How could I ping a sites or address?
"
"Assuming ASCII strings:

string1 = 'Hello'
string2 = 'hello'

if string1.lower() == string2.lower():
    print ""The strings are the same (case insensitive)""
else:
    print ""The strings are not the same (case insensitive)""

",How do I do a case insensitive string comparison in Python?,"What's the best way to do case insensitive string comparison in Python?

I would like to encapsulate comparison of a regular strings to a repository string using in a very simple and pythonic way.  I also would like to have ability to look up values in a dict hashed by strings using regular python strings.  Much obliged for advice.
"
"Expressed as a generator function:

def neighborhood(iterable):
    iterator = iter(iterable)
    prev = None
    item = iterator.next()  # throws StopIteration if empty.
    for next in iterator:
        yield (prev,item,next)
        prev = item
        item = next
    yield (prev,item,None)


Usage:

for prev,item,next in neighborhood(l):
    print prev, item, next


Edit: I thought it would reduce the readability, but this way seem to look better.
",How to access previous/next element while for looping?,"Is there a way to access a list(or tuple, or other iterable)'s next, or previous element while looping through with for loop?

l=[1,2,3]
for item in l:
    if item==2:
        get_previous(l,item)

"
"(Well, since this is tagged with Python):

We use Python's optparse module for this purpose. It has a much friendlier API than lots of ifs.
",How to analyse .exe parameters inside the program?,"I have a program that can have a lot of parameters (we have over +30 differents options).

Example:
myProgram.exe -t alpha 1 -prod 1 2 -sleep 200

This is 3 Commands (from command pattern object at the end) that each contain some parameters. Inside the code we parse all command (start with -) and get a list of string (split all space) for the parameters. So in fact, we have : string-->Collection of String parameters for each command.

For the moment, we use string comparison and we can get the whole thing works (instance the concrete command and return the ICommand interface). The problem is we require to do a lot of IF everytime to get the good command.

Do you have some pattern that can be used to extract all parameters from an EXE without using a lot of IF?

The code is in C# but I think the logic can be any other language too...
"
"As per comments, I've updated the code:

import time
import math

def timeit1():
    s = time.time()
    for i in xrange(750000):
        z=i**.5
    print ""Took %f seconds"" % (time.time() - s)

def timeit2(arg=math.sqrt):
    s = time.time()
    for i in xrange(750000):
        z=arg(i)
    print ""Took %f seconds"" % (time.time() - s)

timeit1()
timeit2()


Now the math.sqrt function is directly in a local argument, meaning it has the fastest lookup possible. 

UPDATE: The python version seems to matter here. I used to think that timeit1 would be faster, since when python parses ""i**.5"" it knows, syntactically, which method to call (__pow__ or some variant), so it doesn't have to go through the overhead of lookup that the math.sqrt variant does. But I might be wrong:

Python 2.5: 0.191000 vs. 0.224000

Python 2.6: 0.195000 vs. 0.139000

Also psyco seems to deal with math.sqrt better:

Python 2.5 + Psyco 2.0: 0.109000 vs. 0.043000

Python 2.6 + Psyco 2.0: 0.128000 vs. 0.067000



| Interpreter    |  x**.5, |   sqrt, | sqrt faster, % |
|                | seconds | seconds |                |
|----------------+---------+---------+----------------|
| Python 3.2rc1+ |    0.32 |    0.27 |             19 |
| Python 3.1.2   |   0.136 |   0.088 |             55 |
| Python 3.0.1   |   0.155 |   0.102 |             52 |
| Python 2.7     |   0.132 |   0.079 |             67 |
| Python 2.6.6   |   0.121 |   0.075 |             61 |
| PyPy 1.4.1     |   0.083 |  0.0159 |            422 |
| Jython 2.5.1   |   0.132 |    0.22 |            -40 |
| Python 2.5.5   |   0.129 |   0.125 |              3 |
| Python 2.4.6   |   0.131 |   0.123 |              7 |
#+TBLFM: $4=100*($2-$3)/$3;%.0f


Table results produced on machine:

$ uname -vms
Linux #42-Ubuntu SMP Thu Dec 2 02:41:37 UTC 2010 x86_64
$ cat /proc/cpuinfo | grep 'model name' | head -1
model name      : Intel(R) Core(TM) i7 CPU         920  @ 2.67GHz


To reproduce results:


get source: git clone git://gist.github.com/783011.git gist-783011
install tox: pip install tox
run tox from the directory with tox.ini file.

",Which is faster in Python: x**.5 or math.sqrt(x)?,"I've been wondering this for some time. As the title say, which is faster, the actual function or simply raising to the half power?

UPDATE

This is not a matter of premature optimization. This is simply a question of how the underlying code actually works. What is the theory of how Python code works?

I sent Guido van Rossum an email cause I really wanted to know the differences in these methods.

My email:


  There are at least 3 ways to do a square root in Python: math.sqrt, the
  '**' operator and pow(x,.5).  I'm just curious as to the differences in
  the implementation of each of these.  When it comes to efficiency which
  is better?


His response:


  pow and ** are equivalent; math.sqrt doesn't work for complex numbers,
  and links to the C  sqrt() function. As to which one is
  faster, I have no idea...

"
"figure tells you the call signature:

figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')


So figure(figsize=(1,1)) creates an inch-by-inch image, which will be 80-by-80 pixels unless you also give a different dpi argument.
",How do you change the size of figures drawn with matplotlib?,"How do you change the size of figure drawn with matplotlib?
"
"You need to take some parts into mind here,


What will you gain from re-writing
Is it an economically wise decision
Will the code be easier to handle for new programmers
Performance-wise, will this be a good option?


These four points is something that is important, will the work be more efficient after you re-write the code? Probably. But will it be worth the cost of re-development?

One important step to follow, if you decide to re-write, make 3 documents, first Analyze the project, what needs to be done? How should everything work? Then put up a document with Requirements, what specificly do we need and how should this be done? Last but not least, the design document, where you put all your final class diagrams, the system operations and how the design and flow of the page should work.

This will help a new developer, and old ones, to actually think about ""do we really need to re-write?"".
",Is rewriting a PHP app into Python a productive step?,"I have some old apps written in PHP that I'm thinking of converting to Python - both are websites that started as simple static html, then progressed to PHP and now include blogs with admin areas, rss etc. I'm thinking of rewriting them in Python to improve maintainability as well as to take advantage of my increase in experience to write things more robustly.

Is this worth the effort?
"
"The official solution for coexistence seems to be the Python Launcher for Windows, PEP 397 which was included in Python 3.3.0.  Installing the release dumps py.exe and pyw.exe launchers into %SYSTEMROOT% (C:\Windows) which is then associated with py and pyw scripts, respectively.

In order to use the new launcher (without manually setting up your own associations to it), leave the ""Register Extensions"" option enabled.  I'm not quite sure why, but on my machine it left Py 2.7 as the ""default"" (of the launcher).

Running scripts by calling them directly from the command line will route them through the launcher and parse the shebang (if it exists).  You can also explicitly call the launcher and use switches: py -3 mypy2script.py.  

All manner of shebangs seem to work


#!C:\Python33\python.exe
#!python3
#!/usr/bin/env python3


as well as wanton abuses


#! notepad.exe

",Can I install Python 3.x and 2.x on the same computer?,"I'm running Windows and the shell/OS automatically runs Python based on the registry settings when you run a program on the command line. Will this break if I install a 2.x and 3.x version of Python on the same machine?

I want to play with Python 3 while still being able to run 2.x scripts on the same machine.
"
"Honestly, no.  The Windows API is an 800 pound monster covered with hair.  Charlie Petzold's 15 pound book was the canonical reference once upon a time.

That said, the Python for Windows folks have some good material.  Microsoft has the whole API online, including some sample code and such.  And the Wikipedia article is a good overview.
",How should I learn to use the Windows API with Python?,"I have very little experience building software for Windows, and zero experience using the Windows API, but I'm reasonably familiar with Python. So, how should I go about learning to use the Windows API with Python?
"
"You will only have a first language for a little while. Pick any direction that interests you, and follow it. There is no way around the introduction ""Drink from the Firehose"" experience.

Keep early project simple, and tangible. Build useful things and the motivation will be there.

Web / desktop / mobile / etc, its all good. Find the one that gets you thinking about code when your not coding, and you'll know your going in the right direction.
",Where do I go from here -- regarding programming?,"I seem to be in a never ending tail spin of Linux, or not, Windows or not. Web programming or system programming. Python or PHP.

I'am self teaching myself programming. But it seems I keep being torn about which way to go. Unfortunately it is always seemingly good reasons to get side tracked. You know the whole open source or proprietary thing. Lately I have decided after a year that Linux just doesn't cut it for me and it mostly stems from me wanting to watch videos on Channel 9 etc, and the clunkiness that is Linux. So that lead me to, ""Should I learn ASP.NET, since I am more so deciding Windows IS a ""necessary"" evil.

I hope this made sense. The reason I settled in on Web Development as my course to learning programming is because I actually have a task to implement rather then aimlessly reading reference books etc.

Does anyone have any advice at what they may have done to stay focused and not get lead down every tangent or idea.
"
"Here's my favorite approach to the ""family of related tests"".  I like explicit subclasses of a TestCase that expresses the common features.

class MyTestF1( unittest.TestCase ):
    theFunction= staticmethod( f1 )
    def setUp(self):
        self.matrix1 = numpy.ones((5,10))
        self.matrix2 = numpy.identity(5)
    def testOutputShape( self ):
        """"""Output of functions be of a certain shape""""""
        output = self.theFunction(self.matrix1, self.matrix2)
        fail_message = ""%s produces output of the wrong shape"" % (self.theFunction.__name__,)
        self.assertEqual(self.matrix1.shape, output.shape, fail_message)

class TestF2( MyTestF1 ):
    """"""Includes ALL of TestF1 tests, plus a new test.""""""
    theFunction= staticmethod( f2 )
    def testUniqueFeature( self ):
         # blah blah blah
         pass

class TestF3( MyTestF1 ):
    """"""Includes ALL of TestF1 tests with no additional code.""""""
    theFunction= staticmethod( f3 )


Add a function, add a subclass of MyTestF1.  Each subclass of MyTestF1 includes all of the tests in MyTestF1 with no duplicated code of any kind.

Unique features are handled in an obvious way.  New methods are added to the subclass.

It's completely compatible with unittest.main()
",How do I concisely implement multiple similar unit tests in the Python unittest framework?,"I'm implementing unit tests for a family of functions that all share a number of invariants. For example, calling the function with two matrices produce a matrix of known shape.

I would like to write unit tests to test the entire family of functions for this property, without having to write an individual test case for each function (particularly since more functions might be added later). 

One way to do this would be to iterate over a list of these functions:

import unittest
import numpy

from somewhere import the_functions
from somewhere.else import TheClass

class Test_the_functions(unittest.TestCase):
  def setUp(self):
    self.matrix1 = numpy.ones((5,10))
    self.matrix2 = numpy.identity(5)

  def testOutputShape(unittest.TestCase):
     """"""Output of functions be of a certain shape""""""
     for function in all_functions:
       output = function(self.matrix1, self.matrix2)
       fail_message = ""%s produces output of the wrong shape"" % str(function)
       self.assertEqual(self.matrix1.shape, output.shape, fail_message)

if __name__ == ""__main__"":
  unittest.main()


I got the idea for this from Dive Into Python. There, it's not a list of functions being tested but a list of known input-output pairs. The problem with this approach is that if any element of the list fails the test, the later elements don't get tested.

I looked at subclassing unittest.TestCase and somehow providing the specific function to test as an argument, but as far as I can tell that prevents us from using unittest.main() because there would be no way to pass the argument to the testcase.

I also looked at dynamically attaching ""testSomething"" functions to the testcase, by using setattr with a lamdba, but the testcase did not recognize them.

How can I rewrite this so it remains trivial to expand the list of tests, while still ensuring every test is run?
"
"Hard one :-)

import email, getpass, imaplib, os

detach_dir = '.' # directory where to save attachments (default: current)
user = raw_input(""Enter your GMail username:"")
pwd = getpass.getpass(""Enter your password: "")

# connecting to the gmail imap server
m = imaplib.IMAP4_SSL(""imap.gmail.com"")
m.login(user,pwd)
m.select(""[Gmail]/All Mail"") # here you a can choose a mail box like INBOX instead
# use m.list() to get all the mailboxes

resp, items = m.search(None, ""ALL"") # you could filter using the IMAP rules here (check http://www.example-code.com/csharp/imap-search-critera.asp)
items = items[0].split() # getting the mails id

for emailid in items:
    resp, data = m.fetch(emailid, ""(RFC822)"") # fetching the mail, ""`(RFC822)`"" means ""get the whole stuff"", but you can ask for headers only, etc
    email_body = data[0][1] # getting the mail content
    mail = email.message_from_string(email_body) # parsing the mail content to get a mail object

    #Check if any attachments at all
    if mail.get_content_maintype() != 'multipart':
        continue

    print ""[""+mail[""From""]+""] :"" + mail[""Subject""]

    # we use walk to create a generator so we can iterate on the parts and forget about the recursive headach
    for part in mail.walk():
        # multipart are just containers, so we skip them
        if part.get_content_maintype() == 'multipart':
            continue

        # is this part an attachment ?
        if part.get('Content-Disposition') is None:
            continue

        filename = part.get_filename()
        counter = 1

        # if there is no filename, we create one with a counter to avoid duplicates
        if not filename:
            filename = 'part-%03d%s' % (counter, 'bin')
            counter += 1

        att_path = os.path.join(detach_dir, filename)

        #Check if its already there
        if not os.path.isfile(att_path) :
            # finally write the stuff
            fp = open(att_path, 'wb')
            fp.write(part.get_payload(decode=True))
            fp.close()


Wowww! That was something. ;-) But try the same in Java, just for fun!

By the way, I tested that in a shell, so some errors likely remain.

Enjoy

EDIT:

Because mail-box names can change from one country to another, I recommend doing m.list() and picking an item in it before m.select(""the mailbox name"") to avoid this error:


  imaplib.error: command SEARCH illegal in state AUTH, only allowed in
  states SELECTED

",How can I download all emails with attachments from Gmail?,"How do I connect to Gmail and determine which messages have attachments?  I then want to download each attachment, printing out the Subject: and From: for each message as I process it.
"
"[NOTE: this answer is now somewhat outdated - please see the discussion below it].

If f is a form, its fields are f.fields, which is a django.utils.datastructures.SortedDict  (it presents the items in the order they are added). After form construction f.fields has a keyOrder attribute, which is a list containing the field names in the order they should be presented. You can set this to the correct ordering (though you need to exercise care to ensure you don't omit items or add extras).

Here's an example I just created in my current project:

class PrivEdit(ModelForm):
    def __init__(self, *args, **kw):
        super(ModelForm, self).__init__(*args, **kw)
        self.fields.keyOrder = [
            'super_user',
            'all_districts',
            'multi_district',
            'all_schools',
            'manage_users',
            'direct_login',
            'student_detail',
            'license']
    class Meta:
        model = Privilege

",How does Django Know the Order to Render Form Fields?,"If I have a Django form such as:

class ContactForm(forms.Form):
    subject = forms.CharField(max_length=100)
    message = forms.CharField()
    sender = forms.EmailField()


And I call the as_table() method of an instance of this form, Django will render the fields as the same order as specified above.

My question is how does Django know the order that class variables where defined?  

(Also how do I override this order, for example when I want to add a field from the classe's init method?)
"
"Yes, and there are also statistical studies that prove that dogs are more productive than cats. Both are equally valid. ;-)

by popular demand, here are a couple of ""studies"" - take them with a block of salt!


An empirical comparison of C, C++, Java, Perl, Python, Rexx, and Tcl PDF warning!
Programming Language Productivity PDF warning! Note that these statistics are for a ""string processing problem"", so one might expect the winner to be...Perl of course!


and Jeff Atwood's musings are interesting as well

the issues of programmer productivity are far more complex than what language is being used. Productivity among programmers can vary wildly, and is affected by the problem domain plus many other factors. Thus no ""study"" can ever be ""definitive"". See Understanding Software Productivity and Productivity Variations Among Software Developers and Teams for additional information.

Finally, the right tool for the right job is still the rule. No exceptions.
","Are there statistical studies that indicates that Python is ""more productive""?","If I do a google search with the string  ""python productive"" the first results is a page http://www.ferg.org/projects/python_java_side-by-side.html claiming that ""python is more productive of Java"". Many Python programmers that I have talked with claim that Python is ""more productive"", and most of them report the arguments listed in the above cited article.

The article could be summarized in these stametements:


Python allow you write terser code  
A more terser is written in lesser time 
Then Python is more productive


But the article does not reports any statisticals evidences that support the hypothesis that a more terse code could be developed (not written) in lesser time.

Do you know if there any article that reports statistical evidences that Python is more productive of something else?

Update:

I'm not interested in adovacy arguments. Please do not tell why something should be more productive of something else. I'm interested in studies that measures that the use of something is related or not related to the productivity.

I'm interested in statisticals evidences. If you claim that the productivity depends from many other factors then there should be a statistical study that proves that the language choiche is not statistically correlated to the productivity.
"
"Named tuples were added in 2.6 for this purpose.  Also see os.stat for a similar builtin example.

>>> import collections
>>> point = collections.namedtuple('Point', ['x', 'y'])
>>> p = point(1, y=2)
>>> p.x, p.y
1 2
>>> p[0], p[1]
1 2

",How do you return multiple values in Python?,"The canonical way to return multiple values in languages that support it is often tupling. 

Option: Using a tuple

Consider this trivial example:

def f(x):
  y0 = x + 1
  y1 = x * 3
  y2 = y0 ** y3
  return (y0,y1,y2)


However, this quickly gets problematic as the number of values returned increases. What if you want to return four or five values? Sure, you could keep tupling them, but it gets easy to forget which value is where. It's also rather ugly to unpack them wherever you want to receive them.

Option: Using a dictionary

The next logical step seems to be to introduce some sort of 'record notation'. In python, the obvious way to do this is by means of a dict. 

Consider the following:

def g(x):
  y0 = x + 1
  y1 = x * 3
  y2 = y0 ** y3
  return {'y0':y0, 'y1':y1 ,'y2':y2 }


(edit- Just to be clear, y0, y1 and y2 are just meant as abstract identifiers. As pointed out, in practice you'd use meaningful identifiers)

Now, we have a mechanism whereby we can project out a particular member of the returned object. For example, 

result['y0']


Option: Using a class

However, there is another option. We could instead return a specialized structure. I've framed this in the context of Python, but I'm sure it applies to other languages as well. Indeed, if you were working in C this might very well be your only option. Here goes:

class ReturnValue(object):
  def __init__(self, y0, y1, y2):
     self.y0 = y0
     self.y1 = y1
     self.y2 = y2

def g(x):
  y0 = x + 1
  y1 = x * 3
  y2 = y0 ** y3
  return ReturnValue(y0, y1, y2)


In python the previous two are perhaps very similar in terms of plumbing- After all { y0, y1, y2 } just end up being entries in the internal __dict__ of the ReturnValue.

There is one additional feature provided by Python though for tiny objects, the __slots__ attribute. The class could be expressed as:

class ReturnValue(object):
  __slots__ = [""y0"", ""y1"", ""y2""]
  def __init__(self, y0, y1, y2):
     self.y0 = y0
     self.y1 = y1
     self.y2 = y2


From the Python Reference Manual:


  The __slots__ declaration takes a sequence of instance variables and reserves just enough space in each instance to hold a value for each variable. Space is saved because __dict__ is not created for each instance.


Option: Using a list

Another suggestion which I'd overlooked comes from Bill the Lizard:

def h(x):
  result = [x + 1]
  result.append(x * 3)
  result.append(y0 ** y3)
  return result


This is my least favorite method though. I suppose I'm tainted by exposure to Haskell, but the idea of mixed-type lists has always felt uncomfortable to me. In this particular example the list is -not- mixed type, but it conceivably could be. A list used in this way really doesn't gain anything with respect to the tuple as far as I can tell. The only real difference between lists and tuples in Python is that lists are mutable, wheras tuples are not. I personally tend to carry over the conventions from functional programming: use lists for any number of elements of the same type, and tuples for a fixed number of elements of predetermined types.

Question

After the lengthy preamble, comes the inevitable question. Which method (do you think) is best?

I've typically found myself going the dictionary route because it involves less set-up work. From a types perspective however, you might be better off going the class route, since that may help you avoid confusing what a dictionary represents. On the other hand, there are some in the Python community that feel implied interfaces should be preferred to explicit interfaces, at which point the type of the object really isn't relevant, since you're basically relying on the convention that the same attribute will always have the same meaning. 

So, how do -you- return multiple values in Python?
"
"You can use the type(name, bases, dict) builtin function to create classes on the fly.  For example:

op = type(""MyOptionParser"", (OptionParser,object), {""foo"": lambda self: ""foo"" })
op().foo()


Since OptionParser isn't a new-style class, you have to explicitly include object in the list of base classes.
",Does Python have something like anonymous inner classes of Java?,"In Java you can define a new class inline using anonymous inner classes. This is useful when you need to rewrite only a single method of the class.

Suppose that you want create a subclass of OptionParser that overrides only a single method (for example exit()). In Java you can write something like this:

new OptionParser () {

    public void exit() {
        // body of the method
    }
};


This piece of code creates a anonymous class that extends OptionParser and override only the exit() method.

There is a similar idiom in Python? Which idiom is used in these circumstances?
"
"Haven't tested this very extensively, but works in Python 2.5.2.

>>> d = {""x"":2, ""h"":15, ""a"":2222}
>>> it = iter(sorted(d.iteritems()))
>>> it.next()
('a', 2222)
>>> it.next()
('h', 15)
>>> it.next()
('x', 2)
>>>

","In Python, how do I iterate over a dictionary in sorted order?","There's an existing function that ends in:

return dict.iteritems()


that returns an unsorted iterator for a given dictionary. I would like to return an iterator that goes through the items in sorted order. How do I do that?
"
"Hmmm.  There was an answer with a list comprehension here, but it's disappeared.

Here:

 [i for i,x in enumerate(testlist) if x == 1]


Example:

>>> testlist
[1, 2, 3, 5, 3, 1, 2, 1, 6]
>>> [i for i,x in enumerate(testlist) if x == 1]
[0, 5, 7]


Update:

Okay, you want a generator expression, we'll have a generator expression.  Here's the list comprehension again, in a for loop:

>>> for i in [i for i,x in enumerate(testlist) if x == 1]:
...     print i
... 
0
5
7


Now we'll construct a generator...

>>> (i for i,x in enumerate(testlist) if x == 1)

>>> for i in (i for i,x in enumerate(testlist) if x == 1):
...     print i
... 
0
5
7


and niftily enough, we can assign that to a variable, and use it from there...

>>> gen = (i for i,x in enumerate(testlist) if x == 1)
>>> for i in gen: print i
... 
0
5
7


And to think I used to write FORTRAN.
",How to get item's position in a list?,"I am iterating over a list and I want to print out the index of the item if it meets a certain condition. How would I do this?

Example:  

testlist = [1,2,3,5,3,1,2,1,6]
for item in testlist:
    if item == 1:
        print position

"
"You'd have similar issues with procedural/functional programming languages. How do you store that much data in memory? A struct or array wouldn't work either. 

You need to take special steps to manage this scale of data.

BTW: I wouldn't use this as a reason to pick either an OO language or not. 
",What is the object oriented programming computing overhead cost?,"I have a large set of data (a data cube of 250,000 X 1,000 doubles, about a 4 gig file) and I want to manipulate it using a previous set of OOP classes I have written in Python.  Currently the data set is already so large that to read into my machine memory I have to at least split it in half so computing overhead is a concern.  My OOP classes create new objects (in this case I will need 250,000 new objects, each object is an array of 1,000 doubles) to handle the data.  What is the overhead in terms of memory and computing required in creating objects for a generic OOP language?  In python?  What about in C++?

Yes, I realize I could make a new class that is an array.  But 1) I already have these classes finished and 2) I put each object that I create back into an array for access later anyways.  The question is pedagogical 

*update:  I want to be efficient with time, my time and the computers. I don't want to rewrite a program I already have if I don't have to and spending time optimizing the code wastes my time, I don't care that much if I waste the computers time.  I actually do have a 64bit machine with 4Gig ram.  The data is an image and I need to do several filters on each pixel.*
"
"

Connecting to MYSQL with Python in 3 steps

1 - Setting

You must install a MySQL driver before doing anything. Unlike PHP, only the SQLite driver is installed by default with Python. The most used package to do so is MySQLdb but it's hard to install it using easy_install.

For Windows user, you can get an exe of MySQLdb. 

For Linux, this is a casual package (python-mysqldb). (You can use sudo apt-get install python-mysqldb (for debian based distros), yum install mysql-python (for rpm-based), or dnf install python-mysql (for modern fedora distro) in command line to download.)

For Mac, you can install MySQLdb using Macport.

2 - Usage

After installing, reboot. This is not mandatory, but will prevent me from answering 3 or 4 other questions in this post if something goes wrong. So please reboot.

Then it is just like using another package :

#!/usr/bin/python
import MySQLdb

db = MySQLdb.connect(host=""localhost"",    # your host, usually localhost
                     user=""john"",         # your username
                     passwd=""megajonhy"",  # your password
                     db=""jonhydb"")        # name of the data base

# you must create a Cursor object. It will let
#  you execute all the queries you need
cur = db.cursor()

# Use all the SQL you like
cur.execute(""SELECT * FROM YOUR_TABLE_NAME"")

# print all the first cell of all the rows
for row in cur.fetchall():
    print row[0]

db.close()


Of course, there are thousand of possibilities and options; this is a very basic example. You will have to look at the documentation. A good starting point.

3 - More advanced usage

Once you know how it works, you may want to use an ORM to avoid writting SQL manually and manipulate your tables as they were Python objects. The most famous ORM in the Python community is SQLAlchemy. 

I strongly advise you to use it: your life is going to be much easier.

I recently discovered another jewel in the Python world: peewee. It's a very lite ORM, really easy and fast to setup then use. It makes my day for small projects or stand alone apps, where using big tools like SQLAlchemy or Django is overkill :

import peewee
from peewee import *

db = MySQLDatabase('jonhydb', user='john',passwd='megajonhy')

class Book(peewee.Model):
    author = peewee.CharField()
    title = peewee.TextField()

    class Meta:
        database = db

Book.create_table()
book = Book(author=""me"", title='Peewee is cool')
book.save()
for book in Book.filter(author=""me""):
    print book.title

Peewee is cool


This example works out of the box. Nothing other than having peewee (pip install peewee :-)) is required. No complicated setup. It's really cool.
",How do I connect to a MySQL Database in Python?,"How do I connect to a MySQL database using a python program?
"
"It appears the MySQLdb is pretty much a dead project. However, PyMySQL is a dbapi compliant, pure-python implementation of a mysql client, and it has python 3 support.

EDIT: There's also MySQL Connector/Python. Same idea.
",MySQL-db lib for Python 3.x?,"So, looking for a mysql-db-lib that is compatible with py3k/py3.0/py3000, any ideas? Google turned up nothing.
"
"It can also appear if you have a circular structure with a list pointing to itself. Like this:

>>> a = [1,2]
>>> a.append(a)
>>> a
[1, 2, [...]]
>>>


Since python can't print out the structure (it would be an infinite loop) it uses the ellipsis to show that there is recursion in the structure.



I'm not quite sure if the question was what what going on or how to fix it, but I'll try to correct the functions above.

In both of them, you first make two recursive calls, which add data to the list y, and then AGAIN append the returned data to y. This means the same data will be present several times in the result.

Either just collect all the data without adding to any y, with something like

return [x[2]]+keys(x[0])+keys(x[1])


or just do the appending in the calls, with something like

y += [x[2]]
keys(x[0], y) #Add left children to y...
keys(x[1], y) #Add right children to y...
return y


(Of course, both these snippets need handling for empty lists etc)

@Abgan also noted that you really don't want y=[] in the initializer.
",Confusing [...] List in Python: What is it?,"So I was writing up a simple binary tree in Python and came across [...]

I don't believe this to be related to the Ellipsis object, more it seems to have something to do with an infinity loop (due to Python's shallow copy?). The source of this infinity loop and why it doesn't get expanded while expanding when accessed is something I'm completely lost to, however


>>> a
[[[[[], [], 8, 3], [[], [], 3, 2], 6, 3], [], 1, 4], [[], [], -4, 2], 0, 0]
>>> Keys(a)#With a+b
[0, 1, 6, 8, 3, -4]
>>> Keys(a)#With [a,b]
[8, [...], [...], 3, [...], [...], 6, [...], [...], 1, [...], [...], -4, [...], [...], 0, [...], [...]]
>>> Keys(a)[1]#??
[8, [...], [...], 3, [...], [...], 6, [...], [...], 1, [...], [...], -4, [...], [...], 0, [...], [...], 8, [...], [...], 3, [...], [...], 6, [...], [...], 1, [...], [...], -4, [...], [...], 0, [...], [...]]




Version using a+b

def Keys(x,y=[]):
    if len(x):y+=[x[2]]+Keys(x[0],y)+Keys(x[1],y)#Though it seems I was using y=y[:]+, this actually outputs an ugly mess
    return y


version using [a,b]

def Keys(x,y=[]):
    if len(x):y+=[x[2],Keys(x[0],y),Keys(x[1],y)]
    return y


So what exactly is [...]?
"
"Well, I would expect this to be heavily I/O bound task.
As such, optimizations on python side would be quite ineffective; the only optimization I could think of is some different way of accessing/listing files, in order to reduce the actual read from the file system.
This of course requires a deep knowledge of the file system, that I do not have, and I do not expect python's developer to have while implementing os.walk.

What about spawning a command prompt, and then issue 'dir' and parse the results?
It could be a bit an overkill, but with any luck, 'dir' is making some effort for such optimizations.
",Fast file/directory scan method for windows?,"I'm looking for a high performance method or library for scanning all files on disk or in a given directory and grabbing their basic stats - filename, size, and modification date. 

I've written a python program that uses os.walk along with os.path.getsize to get the file list, and it works fine, but is not particularly fast. I noticed one of the freeware programs I had downloaded accomplished the same scan much faster than my program. 

Any ideas for speeding up the file scan? Here's my python code, but keep in mind that I'm not at all married to os.walk and perfectly willing to use others APIs (including windows native APIs) if there are better alternatives.

for root, dirs, files in os.walk(top, topdown=False):
    for name in files:
        ...


I should also note I realize the python code probably can't be sped up that much; I'm particularly interested in any native APIs that provide better speed.
"
"If it's really dictionary like arbitrary data you're looking for you can probably use a two-level setup with one model that's a container and another model that's key-value pairs. You'd create an instance of the container, create each of the key-value instances, and associate the set of key-value instances with the container instance. Something like:

class Dicty(models.Model):
    name      = models.CharField(max_length=50)

class KeyVal(models.Model):
    container = models.ForeignKey(Dicty, db_index=True)
    key       = models.CharField(max_length=240, db_index=True)
    value     = models.CharField(max_length=240, db_index=True)


It's not pretty, but it'll let you access/search the innards of the dictionary using the DB whereas a pickle/serialize solution will not.
",How to store a dictionary on a Django Model?,"I need to store some data in a Django model. These data are not equal to all instances of the model.

At first I thought about subclassing the model, but Iâm trying to keep the application flexible. If I use subclasses, Iâll need to create a whole class each time I need a new kind of object, and thatâs no good. Iâll also end up with a lot of subclasses only to store a pair of extra fields.

I really feel that a dictionary would be the best approach, but thereâs nothing in the Django documentation about storing a dictionary in a Django model (or I canât find it).

Any clues?
"
"Python doesn't have the same types as C/C++, which appears to be your question.

Try this:

>>> i = 123
>>> type(i)

>>> type(i) is int
True
>>> i = 123456789L
>>> type(i)

>>> type(i) is long
True
>>> i = 123.456
>>> type(i)

>>> type(i) is float
True


The distinction between int and long goes away in Python 3.0, though.
",How to determine the variable type in Python?,"How do I see the type of a variable whether it is unsigned 32 bit, signed 16 bit, etc.?

How do I view it?
"
"Lots of things.  Circular buffer, for example:  you have some collection of data with a front and a back, but an arbitrary number of nodes, and the ""next"" item from the last should take you back to the first.

Graph structures are often cyclic; acyclicity is a special case.  Consider, for example, a graph containing all the cities and roads in a traveling salesman problem.



Okay, here's a particular example for you.  I set up a collection of towns here in Colorado:

V=[""Boulder"", ""Denver"", ""Colorado Springs"", ""Pueblo"", ""Limon""]


I then set up pairs of cities where there is a road connecting them.

E=[[""Boulder"", ""Denver""],
   [""Denver"", ""Colorado Springs""],
   [""Colorado Springs"", ""Pueblo""],
   [""Denver"", ""Limon""],
   [""Colorado Springs"", ""Limon""]]


This has a bunch of cycles.  For example, you can drive from Colorado Springs, to Limon, to Denver, and back to Colorado Springs.

If you create a data structure that contains all the cities in V and all the roads in E, that's a graph data structure.  This graph would have cycles.
",What is a cyclic data structure good for?,"I was just reading through ""Learning Python"" by Mark Lutz and came across this code sample:


>>> L = ['grail']
>>> L.append(L)
>>> L
['grail', [...]]



It was identified as a cyclic data structure.

So I was wondering, and here is my question:

What is a 'cyclic data structure' used for in real life programming?

There seems to be a little confusion, which i think stems from the very brief code sample... here's a few more lines using the same object L


>>> L[0]
'grail'
>>> L[1][0]
'grail'
>>> L[1][1][0]
'grail'


"
"As I see it, Rails put Ruby on the map. The simple fact is that before Rails, Ruby was a minor esoteric language, with very little adoption.  Ruby owes its success to Rails.  As such, Rails has a central place in the Ruby ecosystem.  As slim points out, there are other web frameworks, but it's going to be very difficult to overtake Rails as the leader.

Python on the other hand, had a very different adoption curve.  Before Rails, Python was much more widely used than Ruby, and so had a number of competing web frameworks, each slowly building their constituencies.  Django has done a good job consolidating support, and becoming the leader in the Python web framework world, but it will never be the One True Framework simply because of the way the community developed.
",Why does Ruby have Rails while Python has no central framework?,"This is a(n) historical question, not a comparison-between-languages question:

This article from 2005 talks about the lack of a single, central framework for Python. For Ruby, this framework is clearly Rails. Why, historically speaking, did this happen for Ruby but not for Python? (or did it happen, and that framework is Django?)

Also, the hypothetical questions: would Python be more popular if it had one, good framework? Would Ruby be less popular if it had no central framework?

[Please avoid discussions of whether Ruby or Python is better, which is just too open-ended to answer.]

Edit: Though I thought this is obvious, I'm not saying that other frameworks do not exist for Ruby, but rather that the big one in terms of popularity is Rails. Also, I should mention that I'm not saying that frameworks for Python are not as good (or better than) Rails. Every framework has its pros and cons, but Rails seems to, as Ben Blank says in the one of the comments below, have surpassed Ruby in terms of popularity. There are no examples of that on the Python side. WHY? That's the question.
"
"
  I'm learning Python, and I have a situation where I want to consume items from an iterator. The tricky part is that under certain conditions, I want to ""un-iterate."" That is, put an item back onto the front of the iterator before I loop.


Here's a simple solution:

class MyIterator(object):   # undo-able iterator wrapper
    def __init__(self, iterable):
    	super(MyIterator, self).__init__()
    	self.iterator = iter(iterable)
    	self.stack = []

    def __iter__(self):
    	return self

    def next(self):
    	if self.stack:
    		return self.stack.pop()
    	return self.iterator.next()  # Raises StopIteration eventually

    def undo(self, item):
    	self.stack.append(item)


for i in  MyIterator(xrange(5)): print i
0
1
2
3
4


rng = MyIterator(xrange(5))
rng.next()
0
rng.next()
1
rng.undo(1)
rng.next()
1

",Pythonic equivalent of unshift or redo?,"I'm learning Python, and I have a situation where I want to consume items from an iterator.  The tricky part is that under certain conditions, I want to ""un-iterate.""  That is, put an item back onto the front of the iterator before I loop.

For example, suppose I'm picking apples from a tree.  My fruit basket can only hold 10kg before it needs to be emptied.  But I have to pick each apple before I can weigh it and determine if this apple would exceed the capacity of the basket.

In a language like Perl, I could unshift() the apple back onto the tree, and then let the loop expression re-pick the apple:

while ($apple = shift(@tree)) {
  $wt = weight($apple);
  if ($wt + weight(@basket) > 10) {
    send(@basket);
    @basket = ();
    unshift(@tree, $apple);
  } else {
    push(@basket, $element);
  }
}


Or else I can also use redo, which resumes processing at the top of block, without evaluating the loop expression.  So the same apple can be re-processed, after the basket has been emptied.

while ($apple = shift(@tree)) {
  $wt = weight($apple);
  if ($wt + weight(@basket) > 10) {
    send(@basket);
    @basket = ();
    redo;
  } else {
    push(@basket, $apple);
  }
}


What would be the most pythonic solution for this kind of problem?
"
"You can change the working directory with

os.chdir(path)


There are two best practices to follow when using this method:


Catch the exception (WindowsError, OSError) on invalid path.  If the exception is thrown, do not perform any recursive operations, especially destructive ones.  They will operate on the old path and not the new one.
Return to your old directory when you're done.  This can be done in an exception-safe manner by wrapping your chdir call in a context manager, like Brian M. Hunt did in his answer.


Changing the current working directory in a subprocess does not change the current working directory in the parent process.  This is true of the Python interpreter as well.  You cannot use os.chdir() to change the CWD of the calling process.
","How do I ""cd"" in Python?","cd as in the shell command to change the working directory.

How do I change the current working directory in Python?
"
"Don't over-engineer it.  It's a 2-D array or maybe a Board class that represents a 2-D array at best.  Have functions that calculate a given row/column and functions that let you access each square.  Additional methods can be used validate that each sub-3x3 and row/column don't violate the required constraints.
",Programming Design Help - How to Structure a Sudoku Solver program?,"I'm trying to create a sudoku solver program in Java (maybe Python).
I'm just wondering how I should go about structuring this...

Do I create a class and make each box a object of that class (9x9=81 objects)? If yes, how do I control all the objects - in other words, how do I make them all call a certain method in the class?

Do I just create functions to calculate and just control all the numbers in there with something like an multi-D array?

And actually, even if I could just create multiple functions, how would I control all the objects if I were to make each box an object?

Thanks.
"
"My automatic response would be WebFaction.  

I haven't personally hosted with them, but they are primarily Python-oriented (founded by the guy who wrote CherryPy, for example, and as far as I know they were the first to roll out Python 3.0 support).
","For Python support, what company would be best to get hosting from?","I want to be able to run WSGI apps but my current hosting restricts it. Does anybody know a company that can accommodate my requirements?
"
"You are just supposed to read the file and exec the code yourself. 2to3 current replaces

execfile(""somefile.py"", global_vars, local_vars)


as

with open(""somefile.py"") as f:
    code = compile(f.read(), ""somefile.py"", 'exec')
    exec(code, global_vars, local_vars)


(The compile call isn't strictly needed, but it associates the filename with the code object making debugging a little easier.)

See:


http://docs.python.org/release/2.7.3/library/functions.html#execfile
http://docs.python.org/release/3.2.3/library/functions.html#compile
http://docs.python.org/release/3.2.3/library/functions.html#exec

",What is an alternative to execfile in Python 3.0?,"It seems they canceled in Python 3.0 all the easy way to quickly load a script file - both execfile() and reload(). 

Is there an obvious alternative I'm missing?
"
"You can reload a module when it has already been imported by using the reload builtin function in Python 2:

import foo

while True:
    # Do some things.
    if is_changed(foo):
        foo = reload(foo)


In Python 3, reload was moved to the imp module. In 3.4, imp was deprecated in favor of importlib, and reload was added to the latter. When targeting 3 or later, either reference the appropriate module when calling reload or import it.

I think that this is what you want. Web servers like Django's development server use this so that you can see the effects of your code changes without restarting the server process itself.

To quote from the docs:


  Python modulesâ code is recompiled and
  the module-level code reexecuted,
  defining a new set of objects which
  are bound to names in the moduleâs
  dictionary. The init function of
  extension modules is not called a
  second time. As with all other objects
  in Python the old objects are only
  reclaimed after their reference counts
  drop to zero. The names in the module
  namespace are updated to point to any
  new or changed objects. Other
  references to the old objects (such as
  names external to the module) are not
  rebound to refer to the new objects
  and must be updated in each namespace
  where they occur if that is desired.


As you noted in your question, you'll have to reconstruct Foo objects if the Foo class resides in the foo module.
",How do I unload (reload) a Python module?,"I have a long-running Python server and would like to be able to upgrade a service without restarting the server. What's the best way do do this?

if foo.py has changed:
    unimport foo  <-- How do I do this?
    import foo
    myfoo = foo.Foo()

"
"Depending on how you are going to use the list, it may be that you actually want a dictionary.  This will work:

d = {}

for row in rows:
  c = list_of_categories.index(row[""id""])
  print c
  d[c] = row[""name""]


... or more compactly:

d = dict((list_of_categories.index(row['id']), row['name']) for row in rows)
print d


PHP arrays are much more like Python dicts than they are like Python lists.  For example, they can have strings for keys.

And confusingly, Python has an array module, which is described as ""efficient arrays of numeric values"", which is definitely not what you want.
",How do you create a list like PHP's in Python?,"This is an incredibly simple question (I'm new to Python).

I basically want a data structure like a PHP array -- i.e., I want to initialise it and then just add values into it.

As far as I can tell, this is not possible with Python, so I've got the maximum value I might want to use as an index, but I can't figure out how to create an empty list of a specified length.

Also, is a list the right data structure to use to model what feels like it should just be an array? I tried to use an array, but it seemed unhappy with storing strings.

Edit: Sorry, I didn't explain very clearly what I was looking for. When I add items into the list, I do not want to put them in in sequence, but rather I want to insert them into specified slots in the list.

I.e., I want to be able to do this:

list = []

for row in rows:
  c = list_of_categories.index(row[""id""])
  print c
  list[c] = row[""name""]

"
"No, Python does not support labels and goto, if that is what you're after. It's a (highly) structured programming language.
",Is there a label/goto in Python?,"Is there a goto or any equivalent in Python to be able to jump to a specific line of code?
"
"A virtual machine is a virtual computing environment with a specific set of atomic well defined instructions that are supported independent of any specific language and it is generally thought of as a sandbox unto itself. The VM is analogous to an instruction set of a specific CPU and tends to work at a more fundamental level with very basic building blocks of such instructions (or byte codes) that are independent of the next. An instruction executes deterministically based only on the current state of the virtual machine and does not depend on information elsewhere in the instruction stream at that point in time.

An interpreter on the other hand is more sophisticated in that it is tailored to parse a stream of some syntax that is of a specific language and of a specific grammer that must be decoded in the context of the surrounding tokens. You can't look at each byte or even each line in isolation and know exactly what to do next. The tokens in the language can't be taken in isolation like they can relative to the instructions (byte codes) of a VM.

A Java compiler converts Java language into a byte-code stream no different than a C compiler converts C Language programs into assembly code. An interpreter on the other hand doesn't really convert the program into any well defined intermediate form, it just takes the program actions as a matter of the process of interpreting the source.

Another test of the difference between a VM and an interpreter is whether you think of it as being language independent. What we know as the Java VM is not really Java specific. You could make a compiler from other languages that result in byte codes that can be run on the JVM. On the other hand, I don't think we would really think of ""compiling"" some other language other than Python into Python for interpretation by the Python interpreter.

Because of the sophistication of the interpretation process, this can be a relatively slow process....specifically parsing and identifying the language tokens, etc. and understanding the context of the source to be able to undertake the execution process within the interpreter. To help accelerate such interpreted languages, this is where we can define intermediate forms of pre-parsed, pre-tokenized source code that is more readily directly interpreted. This sort of binary form is still interpreted at execution time, it is just starting from a much less human readable form to improve performance. However, the logic executing that form is not a virtual machine, because those codes still can't be taken in isolation - the context of the surrounding tokens still matter, they are just now in a different more computer efficient form.
","Java ""Virtual Machine"" vs. Python ""Interpreter"" parlance?","It's seems rare to read of a Python ""virtual machine"" while in Java ""virtual machine"" is used all the time. Both interpret byte codes, why call one a virtual machine and the other an interpreter? 
"
"So, you're not going to like the answer, partly because I'm not yet done writing the code and partly because it's a lot of work.

What you need to do, as I discovered when I ran into this myself, is:


Spend a lot of time reading through the formset and model-formset code to get a feel for how it all works (not helped by the fact that some of the functionality lives on the formset classes, and some of it lives in factory functions which spit them out). You will need this knowledge in the later steps.
Write your own formset class which subclasses from BaseInlineFormSet and accepts initial. The really tricky bit here is that you must override __init__(), and you must make sure that it calls up to BaseFormSet.__init__() rather than using the direct parent or grandparent __init__() (since those are BaseInlineFormSet and BaseModelFormSet, respectively, and neither of them can handle initial data).
Write your own subclass of the appropriate admin inline class (in my case it was TabularInline) and override its get_formset method to return the result of inlineformset_factory() using your custom formset class.
On the actual ModelAdmin subclass for the model with the inline, override add_view and change_view, and replicate most of the code, but with one big change: build the initial data your formset will need, and pass it to your custom formset (which will be returned by your ModelAdmin's get_formsets() method).


I've had a few productive chats with Brian and Joseph about improving this for future Django releases; at the moment, the way the model formsets work just make this more trouble than it's usually worth, but with a bit of API cleanup I think it could be made extremely easy.
",Pre-populate an inline FormSet?,"I'm working on an attendance entry form for a band.  My idea is to have a section of the form to enter event information for a performance or rehearsal.  Here's the model for the event table:

class Event(models.Model):
    event_id = models.AutoField(primary_key=True)
    date = models.DateField()
    event_type = models.ForeignKey(EventType)
    description = models.TextField()


Then I'd like to have an inline FormSet that links the band members to the event and records whether they were present, absent, or excused:

class Attendance(models.Model):
    attendance_id = models.AutoField(primary_key=True)
    event_id = models.ForeignKey(Event)
    member_id = models.ForeignKey(Member)
    attendance_type = models.ForeignKey(AttendanceType)
    comment = models.TextField(blank=True)


Now, what I'd like to do is to pre-populate this inline FormSet with entries for all the current members and default them to being present (around 60 members).  Unfortunately, Django doesn't allow initial values in this case.

Any suggestions?
"
"You can test using eval:

try:
  eval(""1 if True else 2"")
except SyntaxError:
  # doesn't have ternary


Also, with is available in Python 2.5, just add from __future__ import with_statement .

EDIT: to get control early enough, you could split it do different .py files and check compatibility in the main file before importing (e.g. in __init__.py in a package):

# __init__.py

# Check compatibility
try:
  eval(""1 if True else 2"")
except SyntaxError:
  raise ImportError(""requires ternary support"")

# import from another module
from impl import *

",How can I check for Python version in a program that uses new language features?,"If I have a Python script that requires at least a particular
version of Python, what is the correct way to fail gracefully
when an earlier version of Python is used to launch the script?

How do I get control early enough to issue an error message
and exit?

For example, I have a program that uses the ternery operator (new in 2.5) and ""with"" blocks
(new in 2.6).  I wrote a simple little interpreter-version
checker routine which is the first thing the script would
call ... except it doesn't get that far. Instead, the
script fails during python compilation, before my routines
are even called. Thus the user of the script sees some very
obscure synax error tracebacks - which pretty much require
an expert to deduce that it is simply the case of running
the wrong version of Python.

I know how to check the version of Python. The issue is that some syntax is illegal in older versions of Python. Consider this program:

import sys
if sys.version_info < (2, 4):
    raise ""must use python 2.5 or greater""
else:
    # syntax error in 2.4, ok in 2.5
    x = 1 if True else 2
    print x


When run under 2.4, I want this result

$ ~/bin/python2.4 tern.py 
must use python 2.5 or greater


and not this result:

$ ~/bin/python2.4 tern.py 
  File ""tern.py"", line 5
    x = 1 if True else 2
           ^
SyntaxError: invalid syntax


(Channeling for a coworker.)
"
"You can get Windows executables in all three languages.  


As usual with Perl, there's more than one way to do it:

PAR Packer (free/open-source)
perl2exe (shareware)
PerlApp (part of the Perl Dev Kit from ActiveState, commercial)

Python 

py2exe
PyInstaller

Ruby 

RubyScript2Exe
OCRA


",How can I deploy a Perl/Python/Ruby script without installing an interpreter?,"I want to write a piece of software which is essentially a regex data scrubber. I am going to take a contact list in CSV and remove all non-word characters and such from the person's name.

This project has Perl written all over it but my client base is largely non-technical and installing Perl on Windows would not be worth it for them.

Any ideas on how I can use a Perl/Python/Ruby type language without all the headaches of getting the interpreter on their computer?

Thought about web for a second but it would not work for business reasons.
"
"It's a part of a package. Here's the documentation.


  The __init__.py files are required to make Python treat the directories as containing packages; this is done to prevent directories with a common name, such as string, from unintentionally hiding valid modules that occur later (deeper) on the module search path. In the simplest case, __init__.py can just be an empty file, but it can also execute initialization code for the package or set the __all__ variable, described later.

",What is __init__.py for?,"What is __init__.py for in a Python source directory?
"
"This page on the python site has a good description and example of what you need to do to run a python CGI script.  Start out with the simplest case first.  Just make a short script that prints html.  

#!/usr/bin/python                   #on windows change to your path to the python exe

print ""Content-Type: text/html""     # HTML is following
print                               # blank line, end of headers
print ""CGI script output""
print ""This is my first CGI script""
print ""Hello, world!""


When you try this the first time, the hardest part is usually figuring out where to put the script and how to make the web server recognize and run it.  If you are using an apache web sever, take a look at these configuration steps.

Once you have this simple script working, you will just need to add an html form and button tag and use the action property to point it to scripts you want to run.
",How do I create a webpage with buttons that invoke various Python scripts on the system serving the webpage?,"I'm a hobbyist (and fairly new) programmer who has written several useful (to me) scripts in python to handle various system automation tasks that involve copying, renaming, and downloading files amongst other sundry activities.

I'd like to create a web page served from one of my systems that would merely present a few buttons which would allow me to initiate these scripts remotely.

The problem is that I don't know where to start investigating how to do this.  Let's say I have a script called:

*file_arranger.py*

What do I need to do to have a webpage execute that script?  This isn't meant for public consumption, so anything lightweight would be great.  For bonus points, what do I need to look into to provide the web user with the output from such scripts?

edit:  The first answer made me realize I forgot to include that this is a Win2k3 system.
"
"Just use the sys.getsizeof function defined in the sys module.


  sys.getsizeof(object[, default]):
  
  Return the size of an object in bytes.
  The object can be any type of object.
  All built-in objects will return
  correct results, but this does not
  have to hold true for third-party
  extensions as it is implementation
  specific.
  
  The default argument allows to define
  a value which will be returned if the
  object type does not provide means to
  retrieve the size and would cause a
  TypeError.
  
  getsizeof calls the objectâs
  __sizeof__ method and adds an additional garbage collector overhead
  if the object is managed by the
  garbage collector.


Usage example, in python 3.0:

>>> import sys
>>> x = 2
>>> sys.getsizeof(x)
14
>>> sys.getsizeof(sys.getsizeof)
32
>>> sys.getsizeof('this')
38
>>> sys.getsizeof('this also')
48


If you are in python sys.getsizeof you can use this extensive module instead. Never used it though.
",How do I determine the size of an object in Python?,"In C, we can find the size of an int, char, etc. I want to know how to get size of objects like a string, integer, etc. in Python.

Related question: How many bytes per element are there in a Python list (tuple)?

I am using an XML file which contains size fields that specify the size of value. I must parse this XML and do my coding. When I want to change the value of a particular field, I will check the size field of that value. Here I want to compare whether the new value that I'm gong to enter is of the same size as in XML. I need to check the size of new value. In case of a string I can say its the length. But in case of int, float, etc. I am confused.
"
"Django is, IMHO, one of the major benefits of using Python. Model your domain, code your classes, and voila, your ORM is done, and you can focus on the UI. Add in the ease of templating with the built-in templating language (or one of many others you can use as well), and it becomes very easy to whip up effective web applications in no time. Throw in the built-in admin interface, and it's a no-brainer.
",What are the benefits of using Python for web programming?,"What makes Python stand out for use in web development?  What are some examples of highly successful uses of Python on the web?
"
"How about this:

A = '1, 2,,3,4  '
B = [int(x) for x in A.split(',') if x.strip()]


x.strip() trims whitespace from the string, which will make it empty if the string is all whitespace. An empty string is ""false"" in a boolean context, so it's filtered by the if part of the list comprehension.
","How do I do what strtok() does in C, in Python?","I am learning Python and trying to figure out an efficient way to tokenize a string of numbers separated by commas into a list. Well formed cases work as I expect, but less well formed cases not so much.

If I have this:

A = '1,2,3,4'
B = [int(x) for x in A.split(',')]

B results in [1, 2, 3, 4]


which is what I expect, but if the string is something more like

A = '1,,2,3,4,'


if I'm using the same list comprehension expression for B as above, I get an exception. I think I understand why (because some of the ""x"" string values are not integers), but I'm thinking that there would be a way to parse this still quite elegantly such that tokenization of the string a works a bit more directly like strtok(A,"",\n\t"") would have done when called iteratively in C.

To be clear what I am asking; I am looking for an elegant/efficient/typical way in Python to have all of the following example cases of strings:

A='1,,2,3,\n,4,\n'
A='1,2,3,4'
A=',1,2,3,4,\t\n'
A='\n\t,1,2,3,,4\n'


return with the same list of:

B=[1,2,3,4]


via some sort of compact expression.
"
"Use matplotlib's calls that won't block:

Using draw():

from matplotlib.pyplot import plot, draw, show
plot([1,2,3])
draw()
print 'continue computation'

# at the end call show to ensure window won't close.
show()


Using interactive mode:

from matplotlib.pyplot import plot, ion, show
ion() # enables interactive mode
plot([1,2,3]) # result shows immediatelly (implicit draw())

print 'continue computation'

# at the end call show to ensure window won't close.
show()

",Is there a way to detach matplotlib plots so that the computation can continue?,"After these instructions in the Python interpreter one gets a window with a plot:

from matplotlib.pyplot import *
plot([1,2,3])
show()
# other code


Unfortunately, I don't know how to continue to interactively explore the figure created by show() while the program does further calculations.

Is it possible at all? Sometimes calculations are long and it would help if they would proceed during examination of intermediate results.
"
"Here is how I do this. Advantages of the following method:


It provides a __version__ attribute.
It provides the standard metadata version. Therefore it will be detected by pkg_resources or other tools that parse the package metadata (EGG-INFO and/or PKG-INFO, PEP 0345).
It doesn't import your package (or anything else) when building your package, which can cause problems in some situations. (See the comments below about what problems this can cause.)
There is only one place that the version number is written down, so there is only one place to change it when the version number changes, and there is less chance of inconsistent versions.


Here is how it works: the ""one canonical place"" to store the version number is a .py file, named ""_version.py"" which is in your Python package, for example in myniftyapp/_version.py. This file is a Python module, but your setup.py doesn't import it! (That would defeat feature 3.) Instead your setup.py knows that the contents of this file is very simple, something like:

__version__ = ""3.6.5""


And so your setup.py opens the file and parses it, with code like:

import re
VERSIONFILE=""myniftyapp/_version.py""
verstrline = open(VERSIONFILE, ""rt"").read()
VSRE = r""^__version__ = ['\""]([^'\""]*)['\""]""
mo = re.search(VSRE, verstrline, re.M)
if mo:
    verstr = mo.group(1)
else:
    raise RuntimeError(""Unable to find version string in %s."" % (VERSIONFILE,))


Then your setup.py passes that string as the value of the ""version"" argument to setup(), thus satisfying feature 2.

To satisfy feature 1, you can have your package (at run-time, not at setup time!) import the _version file from myniftyapp/__init__.py like this:

from _version import __version__


Here is an example of this technique that I've been using for years.

The code in that example is a bit more complicated, but the simplified example that I wrote into this comment should be a complete implementation.

Here is example code of importing the version.

If you see anything wrong with this approach, please let me know: zooko at zooko dot com. If you don't see anything wrong with this approach then use it! Because the more packages come with their version numbers in the expected places the better!
",Standard way to embed version into python package?,"Is there a standard way to associate version string with a python package in such way that I could do the following?

import foo
print foo.version


I would imagine there's some way to retrieve that data without any extra hardcoding, since minor/major strings are specified in setup.py already. Alternative solution that I found was to have import __version__ in my foo/__init__.py and then have __version__.py generated by setup.py.
"
"This answer missed one aspect: the OP asked for ALL combinations... not just combinations of length ""r"".

So you'd either have to loop through all lengths ""L"":

import itertools

stuff = [1, 2, 3]
for L in range(0, len(stuff)+1):
  for subset in itertools.combinations(stuff, L):
    print(subset)


Or -- if you want to get snazzy (or bend the brain of whoever reads your code after you) -- you can generate the chain of ""combinations()"" generators, and iterate through that:

from itertools import chain, combinations
def all_subsets(ss):
  return chain(*map(lambda x: combinations(ss, x), range(0, len(ss)+1)))

for subset in all_subsets(stuff):
  print(subset)

",Python code to pick out all possible combinations from a list?,"I have a list with 15 numbers in, and I need to write some code that produces all 32,768 combinations of those numbers. 

I've found some code (by googling) that apparently does what I'm looking for, but I found the code fairly opaque and am wary of using it. Plus I have a feeling there must be a more elegant solution.

The only thing that occurs to me would be to just loop through the decimal integers 1-32768 and convert those to binary, and use the binary representation as a filter to pick out the appropriate numbers. 

Does anyone know of a better way? Using map(), maybe?
"
"As far as I know not exactly but you get somewhere with

object.methods.sort

","Ruby equivalent of Python's ""dir""?","In Python we can ""dir"" a module, like this:

>>> import re
>>> dir(re)


And it lists all functions in the module. Is there a similar way to do this in Ruby?
"
"It's compiled to bytecode which can be used much, much, much faster.

The reason some files aren't compiled is that the main script, which you invoke with python main.py is recompiled every time you run the script. All imported scripts will be compiled and stored on the disk.

Important addition by Ben Blank:


  It's worth noting that while running a
  compiled script has a faster startup
  time (as it doesn't need to be
  compiled), it doesn't run any
  faster.

",Why compile Python code?,"Why would you compile a Python script? You can run them directly from the .py file and it works fine, so is there a performance advantage or something? 

I also notice that some files in my application get compiled into .pyc while others do not, why is this?
"
"Quoting Jacob Hallen:


  The proper use of __slots__ is to save space in objects. Instead of having
  a dynamic dict that allows adding attributes to objects at anytime,
  there is a static structure which does not allow additions after creation.
  This saves the overhead of one dict for every object that uses slots. While this is sometimes a useful optimization, it would be completely
  unnecessary if the Python interpreter was dynamic enough so that it would
  only require the dict when there actually were additions to the object.
  
  Unfortunately there is a side effect to slots. They change the behavior of
  the objects that have slots in a way that can be abused by control freaks
  and static typing weenies. This is bad, because the control freaks should
  be abusing the metaclasses and the static typing weenies should be abusing
  decorators, since in Python, there should be only one obvious way of doing something.
  
  Making CPython smart enough to handle saving space without __slots__ is a major
  undertaking, which is probably why it is not on the list of changes for P3k (yet).

",Usage of __slots__?,"What is the purpose of __slots__ in Python â especially with respect to when would I want to use it and when not?
"
"There are many fiddly things to take care of when becoming a well-behaved daemon process:


prevent core dumps (many daemons run as root, and core dumps can contain sensitive information)
behave correctly inside a chroot gaol
set UID, GID, working directory, umask, and other process parameters appropriately for the use case
relinquish elevated suid, sgid privileges
close all open file descriptors, with exclusions depending on the use case
behave correctly if started inside an already-detached context, such as init, inetd, etc.
set up signal handlers for sensible daemon behaviour, but also with specific handlers determined by the use case
redirect the standard streams stdin, stdout, stderr since a daemon process no longer has a controlling terminal
handle a PID file as a cooperative advisory lock, which is a whole can of worms in itself with many contradictory but valid ways to behave
allow proper cleanup when the process is terminated
actually become a daemon process without leading to zombies


Some of these are standard, as described in canonical Unix literature (Advanced Programming in the UNIX Environment, by the late W. Richard Stevens, Addison-Wesley, 1992). Others, such as stream redirection and PID file handling, are conventional behaviour most daemon users would expect but that are less standardised.

All of these are covered by the PEP 3143 âStandard daemon process libraryâ specification. The python-daemon reference implementation works on Python 2.7 or later, and Python 3.2 or later.
",How do you create a daemon in Python?,"Searching on Google reveals x2 code snippets. The first result is to this code recipe which has a lot of documentation and explanation, along with some useful discussion underneath. 

However, another code sample, whilst not containing so much documentation, includes sample code for passing commands such as start, stop and restart. It also creates a PID file which can be handy for checking if the daemon is already running etc.

These samples both explain how to create the daemon. Are there any additional things that need to be considered? Is one sample better than the other, and why?
"
"The exact same question that people at the old AudioScrobbler and currently at MusicBrainz have worked on since long ago. For the time being, the Python project that can aid in your quest, is Picard, which will tag audio files (not only MPEG 1 Layer 3 files) with a GUID (actually, several of them), and from then on, matching the tags is quite simple.

If you prefer to do it as a project of your own, libofa might be of help.
",Detect duplicate MP3 files with different bitrates and/or different ID3 tags?,"How could I detect (preferably with Python) duplicate MP3 files that can be encoded with different bitrates (but they are the same song) and ID3 tags that can be incorrect?

I know I can do an MD5 checksum of the files content but that won't work for different bitrates. And I don't know if ID3 tags have influence in generating the MD5 checksum. Should I re-encode MP3 files that have a different bitrate and then I can do the checksum? What do you recommend?
"
"There is a limit because it would take too much memory to store the complete state machine efficiently.  I'd say that if you have more than 100 groups in your re, something is wrong either in the re itself or in the way you are using them.  Maybe you need to split the input and work on smaller chunks or something.
",Python regular expressions with more than 100 groups?,"Is there any way to beat the 100-group limit for regular expressions in Python? Also, could someone explain why there is a limit. Thanks.
"
"The only way I can think of to do this amounts to giving the function a name:

fact = lambda x: 1 if x == 0 else x * fact(x-1)


or alternately, for earlier versions of python:

fact = lambda x: x == 0 and 1 or x * fact(x-1)


Update: using the ideas from the other answers, I was able to wedge the factorial function into a single unnamed lambda:

>>> map(lambda n: (lambda f, *a: f(f, *a))(lambda rec, n: 1 if n == 0 else n*rec(rec, n-1), n), range(10))
[1, 1, 2, 6, 24, 120, 720, 5040, 40320, 362880]


So it's possible, but not really recommended!
",Can a lambda function call itself recursively in Python?,"A regular function can contain a call to itself in its definition, no problem.  I can't figure out how to do it with a lambda function though for the simple reason that the lambda function has no name to refer back to.  Is there a way to do it?  How?
"
"Make sure you are not keeping global references to data. That prevents the python garbage collector from releasing the memory.

Don't use mod_python. It loads an interpreter inside apache. If you need to use apache, use mod_wsgi instead. It is not tricky to switch. It is very easy. mod_wsgi is way easier to configure for django than brain-dead mod_python.

If you can remove apache from your requirements, that would be even better to your memory. spawning seems to be the new fast scalable way to run python web applications.

EDIT: I don't see how switching to mod_wsgi could be ""tricky"". It should be a very easy task. Please elaborate on the problem you are having with the switch.
",Reducing Django Memory Usage. Low hanging fruit?,"My memory usage increases over time and restarting Django is not kind to users.

I am unsure how to go about profiling the memory usage but some tips on how to start measuring would be useful.

I have a feeling that there are some simple steps that could produce big gains. Ensuring 'debug' is set to 'False' is an obvious biggie.

Can anyone suggest others? How much improvement would caching on low-traffic sites?

In this case I'm running under Apache 2.x with mod_python. I've heard mod_wsgi is a bit leaner but it would be tricky to switch at this stage unless I know the gains would be significant.

Edit: Thanks for the tips so far. Any suggestions how to discover what's using up the memory? Are there any guides to Python memory profiling?

Also as mentioned there's a few things that will make it tricky to switch to mod_wsgi so I'd like to have some idea of the gains I could expect before ploughing forwards in that direction. 

Edit: Carl posted a slightly more detailed reply here that is worth reading: http://stackoverflow.com/questions/488864/django-deployment-cutting-apaches-overhead

Edit: Graham Dumpleton's article is the best I've found on the MPM and mod_wsgi related stuff. I am rather disappointed that no-one could provide any info on debugging the memory usage in the app itself though. 

Final Edit: Well I have been discussing this with Webfaction to see if they could assist with recompiling Apache and this is their word on the matter:

""I really don't think that you will get much of a benefit by switching to an MPM Worker + mod_wsgi setup.  I estimate that you might be able to save around 20MB, but probably not much more than that.""

So! This brings me back to my original question (which I am still none the wiser about). How does one go about identifying where the problems lies? It's a well known maxim that you don't optimize without testing to see where you need to optimize but there is very little in the way of tutorials on measuring Python memory usage and none at all specific to Django.

Thanks for everyone's assistance but I think this question is still open!

Another final edit ;-)

I asked this on the django-users list and got some very helpful replies

Honestly the last update ever!

This was just released. Could be the best solution yet: Profiling Django object size and memory usage with Pympler
"
"
  make them stick by committing them to
  the system?


I think you are a bit confused here.  There is no 'system' environment.  Each process has their own environment as part its memory. A process can only change its own environment.  A process can set the initial environment for processes it creates.

If you really do think you need to set environment variables for the system you will need to look at changing them in the location they get initially loaded from like the registry on windows or your shell configuration file on Linux.
",How do I make environment variable changes stick in Python?,"From what I've read, any changes to the environment variables in a Python instance are only available within that instance, and disappear once the instance is closed.  Is there any way to make them stick by committing them to the system?

The reason I need to do this is because at the studio where I work, tools like Maya rely heavily on environment variables to configure paths across multiple platforms.

My test code is

import os
os.environ['FAKE'] = 'C:\\'


Opening another instance of Python and requesting os.environ['FAKE'] yields a KeyError.

NOTE: Portability will be an issue, but the small API I'm writing will be able to check OS version and trigger different commands if necessary.

That said, I've gone the route of using the Windows registry technique and will simply write alternative methods that will call shell scripts on other platforms as they become requirements.
"
"# Over-explaining a bit:
def magic(numList):         # [1,2,3]
    s = map(str, numList)   # ['1','2','3']
    s = ''.join(s)          # '123'
    s = int(s)              # 123
    return s


# How I'd probably write it:
def magic(numList):
    s = ''.join(map(str, numList))
    return int(s)


# As a one-liner  
num = int(''.join(map(str,numList)))


# Functionally:
s = reduce(lambda x,y: x+str(y), numList, '')
num = int(s)


# Using some oft-forgotten built-ins:
s = filter(str.isdigit, repr(numList))
num = int(s)

",Convert list of ints to one number?,"I have a list of integers that I would like to convert to one number like:

numList = [1, 2, 3]
num = magic(numList)

print num, type(num)
>>> 123, 


What is the best way to implement the magic function?

EDIT 
I did find this, but it seems like there has to be a better way.
"
"The majority of this code is to set up the numwords dict, which is only done on the first call.

def text2int(textnum, numwords={}):
    if not numwords:
      units = [
        ""zero"", ""one"", ""two"", ""three"", ""four"", ""five"", ""six"", ""seven"", ""eight"",
        ""nine"", ""ten"", ""eleven"", ""twelve"", ""thirteen"", ""fourteen"", ""fifteen"",
        ""sixteen"", ""seventeen"", ""eighteen"", ""nineteen"",
      ]

      tens = ["""", """", ""twenty"", ""thirty"", ""forty"", ""fifty"", ""sixty"", ""seventy"", ""eighty"", ""ninety""]

      scales = [""hundred"", ""thousand"", ""million"", ""billion"", ""trillion""]

      numwords[""and""] = (1, 0)
      for idx, word in enumerate(units):    numwords[word] = (1, idx)
      for idx, word in enumerate(tens):     numwords[word] = (1, idx * 10)
      for idx, word in enumerate(scales):   numwords[word] = (10 ** (idx * 3 or 2), 0)

    current = result = 0
    for word in textnum.split():
        if word not in numwords:
          raise Exception(""Illegal word: "" + word)

        scale, increment = numwords[word]
        current = current * scale + increment
        if scale > 100:
            result += current
            current = 0

    return result + current

print text2int(""seven billion one hundred million thirty one thousand three hundred thirty seven"")
#7100031337

",Is there a way to convert number words to Integers?,"I need to convert one into 1, two into 2 and so on.

Is there a way to do this with a library or a class or anything?
"
"I would say, the standard practice to avoid this is to not write classes where you can be 1000 lines away from anything!

Seriously, that's way too much for just about any useful class, especially in a language that is as expressive as Python. Using more of what the Standard Library offers and abstracting away code into separate modules should help keeping your LOC count down.

The largest classes in the standard library have well below 100 lines! 
",What's a good way to keep track of class instance variables in Python?,"I'm a C++ programmer just starting to learn Python.  I'd like to know how you keep track of instance variables in large Python classes.  I'm used to having a .h file that gives me a neat list (complete with comments) of all the class' members.  But since Python allows you to add new instance variables on the fly, how do you keep track of them all?

I'm picturing a scenario where I mistakenly add a new instance variable when I already had one - but it was 1000 lines away from where I was working.  Are there standard practices for avoiding this?

Edit: It appears I created some confusion with the term ""member variable.""  I really mean instance variable, and I've edited my question accordingly.
"
"In any of your vim windows, type something like this:

for x in range(1,10):
    print '-> %d' % x


Visually select both of those lines (V to start visual mode), and type the following:

:!python


Because you pressed ':' in visual mode, that will end up looking like:

:'!python


Hit enter and the selection is replaced by the output of the print statements. You could easily turn it into a mapping:

:vnoremap  :!python

",How can you use Python in Vim?,"I waste a lot of time between Vim and Python. I find it too slow to manually copy-paste from Python to Vim and vice versa. A good broken example is:


  %!python for i in xrange(25); print 6*i \n     


How can you do such tweaks direcly in Vim?   [Solved]

[Clarification]  I need things to Vim, like printing sequences, arithmetics... - things I cannot do in Vim.

[?] Can someone elaborate this point:
""your script can read from stdin to operate directly on the lines given (., %, ...)."" 

[Further Clarification]

If I want to print 'Hello' to lines 4,5, 6 and 7, what is wrong:


  :4-7!python -c ""print 'hello'""


The dot . modifies the current line. Can I print on multiple lines 7, 32 and 99:


  :7,32,99!python -c ""print 'hello'""


Clearly not working. How?
"
"How about this:

import unicodedata
def strip_accents(s):
   return ''.join(c for c in unicodedata.normalize('NFD', s)
                  if unicodedata.category(c) != 'Mn')


This works on greek letters, too:

>>> strip_accents(u""A \u00c0 \u0394 \u038E"")
u'A A \u0394 \u03a5'
>>> 


The character category ""Mn"" stands for Nonspacing_Mark, which is similar to unicodedata.combining in MiniQuark's answer (I didn't think of unicodedata.combining, but it is probably the better solution, because it's more explicit).

And keep in mind, these manipulations may significantly alter the meaning of the text. Accents, Umlauts etc. are not ""decoration"".
",What is the best way to remove accents in a Python unicode string?,"I have a Unicode string in Python, and I would like to remove all the accents (diacritics).

I found on the Web an elegant way to do this in Java:


convert the Unicode string to its long normalized form (with a separate character for letters and diacritics)
remove all the characters whose Unicode type is ""diacritic"".


Do I need to install a library such as pyICU or is this possible with just the python standard library?  And what about python 3?

Important note: I would like to avoid code with an explicit mapping from accented characters to their non-accented counterpart.
"
"To write a lazy function, just use yield:

def read_in_chunks(file_object, chunk_size=1024):
    """"""Lazy function (generator) to read a file piece by piece.
    Default chunk size: 1k.""""""
    while True:
        data = file_object.read(chunk_size)
        if not data:
            break
        yield data


f = open('really_big_file.dat')
for piece in read_in_chunks(f):
    process_data(piece)




Another option would be to use iter and a helper function:

f = open('really_big_file.dat')
def read1k():
    return f.read(1024)

for piece in iter(read1k, ''):
    process_data(piece)




If the file is line-based, the file object is already a lazy generator of lines:

for line in open('really_big_file.dat'):
    process_data(line)

",Lazy Method for Reading Big File in Python?,"I have a very big file 4GB and when I try to read it my computer hangs.
So I want to read it piece by piece and after processing each piece store the processed piece into another file and read next piece.

Is there any method to yield these pieces ?

I would love to have a lazy method.
"
"What about using logging.disable?

I've also found I had to use logging.isEnabledFor if the logging message is expensive to create.
",How can I strip Python logging calls without commenting them out?,"Today I was thinking about a Python project I wrote about a year back where I used logging pretty extensively. I remember having to comment out a lot of logging calls in inner-loop-like scenarios (the 90% code) because of the overhead (hotshot indicated it was one of my biggest bottlenecks).

I wonder now if there's some canonical way to programmatically strip out logging calls in Python applications without commenting and uncommenting all the time. I'd think you could use inspection/recompilation or bytecode manipulation to do something like this and target only the code objects that are causing bottlenecks. This way, you could add a manipulator as a post-compilation step and use a centralized configuration file, like so:

[Leave ERROR and above]
my_module.SomeClass.method_with_lots_of_warn_calls

[Leave WARN and above]
my_module.SomeOtherClass.method_with_lots_of_info_calls

[Leave INFO and above]
my_module.SomeWeirdClass.method_with_lots_of_debug_calls


Of course, you'd want to use it sparingly and probably with per-function granularity -- only for code objects that have shown logging to be a bottleneck. Anybody know of anything like this?

Note: There are a few things that make this more difficult to do in a performant manner because of dynamic typing and late binding. For example, any calls to a method named debug may have to be wrapped with an if not isinstance(log, Logger). In any case, I'm assuming all of the minor details can be overcome, either by a gentleman's agreement or some run-time checking. :-)
"
"It's not about the language, it's about what you do with it. You can learn about virtually any CS concept in either Python or Java (or anything else), although there are definitely some concepts that are much better suited for one or another - for example, functional programming (e.g. the map and reduce functions) and metaclasses in Python, or graphics programming in Java. Having worked with both, I do think Python would give you an easier learning curve to programming in general, so I'd start with that, keeping in mind that it will be to your advantage to get experience in both Python and Java (and other languages, like C and/or C++) in the long run.
",Python or java which language will exposed a self taught programmer to more computer science concept?,"Of the two which one would exposed someone just learning to program to more
computer science concept/problems?
"
"Have a look at PyScripter, I haven't tried it extensively but heard good things about it.

It's not an addon to Visual Studio, it's an independent IDE.
",Python IDE built into Visual Studio 2008?,"Hi I develop in Visual Studio 2008 a lot and would like to find an addin like vsphp which  enables intellisense and debugging in Visual Studio. Is IronStudio what I am looking for? As far as I understand IronStudio is a Plugin for .NET.

If there is no Plugin for Visual Studio 2008 whats a great IDE for a python newbee who loves Visual Studio (hate netbeans and eclipse sorry just don't feel the love)

Also if IronPython Studio is an IDE do I want the Isolated or Integrated Version? I don't seem to understand the name.

I installed integrated and got this: http://dl.getdropbox.com/u/5910/Jing/2009-02-11_1750.png :( no console like here: http://www.codeplex.com/IronPythonStudio
"
"Well, there are separate implementations for separate operating systems. This means that if the logic to extract the extension of a file differs on Mac from that on Linux, this distinction will be handled by those things. I don't know of any such distinction so there might be none.



Edit: @Brian comments that an example like /directory.ext/file would of course not work with a simple .split('.') call, and you would have to know both that directories can use extensions, as well as the fact that on some operating systems, forward slash is a valid directory separator.

This just emphasizes the use a library routine unless you have a good reason not to part of my answer.

Thanks @Brian.



Additionally, where a file doesn't have an extension, you would have to build in logic to handle that case. And what if the thing you try to split is a directory name ending with a backslash? No filename nor an extension.

The rule should be that unless you have a specific reason not to use a library function that does what you want, use it. This will avoid you having to maintain and bugfix code others have perfectly good solutions to.
",Benefits of os.path.splitext over regular .split?,"In this other question, the votes clearly show that the os.path.splitext function is preferred over the simple .split('.')[-1] string manipulation. Does anyone have a moment to explain exactly why that is? Is it faster, or more accurate, or what? I'm willing to accept that there's something better about it, but I can't immediately see what it might be. Might importing a whole module to do this be overkill, at least in simple cases?

EDIT: The OS specificity is a big win that's not immediately obvious; but even I should've seen the ""what if there isn't a dot"" case! And thanks to everybody for the general comments on library usage.
"
"Short answer: no. 

Long answer: this is possible with some ugly hacks using traceback, inspect and the like, but it's generally probably not recommended for production code. For example see: 


http://groups.google.com/group/comp.lang.python/msg/237dc92f3629dd9a?pli=1
http://aspn.activestate.com/ASPN/Mail/Message/python-Tutor/330294


Perhaps you can use a workaround to translate the value back to a name/representational string. If you post some more sample code and details about what you're wanting this for maybe we can provide more in-depth assistance.
",Can I print original variable's name in Python?,"I have enum and use the variables like myEnum.SomeNameA, myEnum.SomeNameB, etc.  When I return one of these variables from a function, can I print their names (such as myEnum.SomeNameA) instead of the value they returned?
"
"One possible way would be:
sha1sum path/to/folder/* | sha1sum


If there is a whole directory tree, you're probably better off using find and xargs. One possible command would be 
find path/to/folder -type f -print0 | xargs -0 sha1sum | sha1sum


Edit: Good point, it's probably a good thing to sort the list of files, so:
find path/to/folder -type f -print0 | sort -z | xargs -0 sha1sum | sha1sum


And, finally, if you also need to take account of permissions and empty directories:

(find path/to/folder -type f -print0  | sort -z | xargs -0 sha1sum;
 find path/to/folder \( -type f -o -type d \) -print0 | sort -z | \
   xargs -0 stat -c '%n %a') \
| sha1sum


The arguments to stat will cause it to print the name of the file, followed by its octal permissions. The two finds will run one after the other, causing double the amount of disk IO, the first finding all file names and checksumming the contents, the second finding all file and directory names, printing name and mode. The list of ""file names and checksums"", followed by ""names and directories, with permissions"" will then be checksummed, for a smaller checksum.
",Linux: compute a single hash for a given folder & contents?,"Surely there must be a way to do this easily! 

I've tried the linux command-line apps sha1sum & md5sum but they seem only to be able to compute hashes of individual files and output a list of hash values, one for each file. 

I need to generate a single hash for the entire contents of a folder (not just the filenames).

I'd like to do something like

sha1sum /folder/of/stuff > singlehashvalue


Edit: to clarify, my files are at multiple levels in a directory tree, they're not all sitting in the same root folder.
"
"The biggest differences are that Python is duck typed, meaning that you won't need to plan out class hierarchies in as much detail as in Java, and has first class functions.  The strategy pattern, for example, becomes much simpler and more obvious when you can just pass a function in, rather than having to make interfaces, etc. just to simulate higher order functions.  More generally, Python has syntactic sugar for a lot of common design patterns, such as the iterator and the aforementioned strategy.  It might be useful to understand these patterns (I've read Head First and found it pretty useful), but think about Pythonic ways to implement them rather than just doing things the same way you would in Java.
",Do OO design principles apply to Python?,"It seems like many OO discussions use Java or C# as examples (e.g. Head First Design Patterns).

Do these patterns apply equally to Python?  Or if I follow the design patterns, will I just end up writing Java in Python (which apparently is a very bad thing)?
"
"I'm not sure what the point of that is.  Interfaces (of this form, anyway) are largely to work around the lack of multiple inheritance.  But Python has MI, so why not just make an abstract class?

class Something(object):
    def some_method(self):
        raise NotImplementedError()
    def some_other_method(self, some_argument):
        raise NotImplementedError()

","""Interfaces"" in Python: Yea or Nay?","So I'm starting a project using Python after spending a significant amount of time in static land.  I've seen some projects that make ""interfaces"" which are really just classes without any implementations.  Before, I'd scoff at the idea and ignore that section of those projects.  But now, I'm beginning to warm up to the idea.

Just so we're clear, an interface in Python would look something like this:

class ISomething(object):
    def some_method():
        pass
    def some_other_method(some_argument):
        pass


Notice that you aren't passing self to any of the methods, thus requiring that the method be overriden to be called.  I see this as a nice form of documentation and completeness testing.  

So what is everyone here's opinion on the idea?  Have I been brainwashed by all the C# programming I've done, or is this a good idea?
"
"This answer is similar in spirit to Douglas Leeder's, with the following changes:


It doesn't use actual Base64, so there's no padding characters
Instead of converting the number first to a byte-string (base 256), it converts it directly to base 64, which has the advantage of letting you represent negative numbers using a sign character.

import string
ALPHABET = string.ascii_uppercase + string.ascii_lowercase + \
           string.digits + '-_'
ALPHABET_REVERSE = dict((c, i) for (i, c) in enumerate(ALPHABET))
BASE = len(ALPHABET)
SIGN_CHARACTER = '$'

def num_encode(n):
    if n < 0:
        return SIGN_CHARACTER + num_encode(-n)
    s = []
    while True:
        n, r = divmod(n, BASE)
        s.append(ALPHABET[r])
        if n == 0: break
    return ''.join(reversed(s))

def num_decode(s):
    if s[0] == SIGN_CHARACTER:
        return -num_decode(s[1:])
    n = 0
    for c in s:
        n = n * BASE + ALPHABET_REVERSE[c]
    return n





    >>> num_encode(0)
    'A'
    >>> num_encode(64)
    'BA'
    >>> num_encode(-(64**5-1))
    '$_____'




A few side notes:


You could (marginally) increase the human-readibility of the base-64 numbers by putting string.digits first in the alphabet (and making the sign character '-'); I chose the order that I did based on Python's urlsafe_b64encode.
If you're encoding a lot of negative numbers, you could increase the efficiency by using a sign bit or one's/two's complement instead of a sign character.
You should be able to easily adapt this code to different bases by changing the alphabet, either to restrict it to only alphanumeric characters or to add additional ""URL-safe"" characters.
I would recommend against using a representation other than base 10 in URIs in most casesâit adds complexity and makes debugging harder without significant savings compared to the overhead of HTTPâunless you're going for something TinyURL-esque.

",How to convert an integer to the shortest url-safe string in Python?,"I want the shortest possible way of representing an integer in a URL. For example, 11234 can be shortened to '2be2' using hexadecimal. Since base64 uses is a 64 character encoding, it should be possible to represent an integer in base64 using even less characters than hexadecimal. The problem is I can't figure out the cleanest way to convert an integer to base64 (and back again) using Python.

The base64 module has methods for dealing with bytestrings - so maybe one solution would be to convert an integer to its binary representation as a Python string... but I'm not sure how to do that either.
"
"Building on Dana's answer, you might want to do this as a decorator:

def retry(howmany):
    def tryIt(func):
        def f():
            attempts = 0
            while attempts < howmany:
                try:
                    return func()
                except:
                    attempts += 1
        return f
    return tryIt


Then...

@retry(5)
def the_db_func():
    # [...]


Enhanced version that uses the decorator module

import decorator, time

def retry(howmany, *exception_types, **kwargs):
    timeout = kwargs.get('timeout', 0.0) # seconds
    @decorator.decorator
    def tryIt(func, *fargs, **fkwargs):
        for _ in xrange(howmany):
            try: return func(*fargs, **fkwargs)
            except exception_types or Exception:
                if timeout is not None: time.sleep(timeout)
    return tryIt


Then...

@retry(5, MySQLdb.Error, timeout=0.5)
def the_db_func():
    # [...]


To install the decorator module:

$ easy_install decorator

",is there a pythonic way to try something up to a maximum number of times?,"I have a python script which is querying a MySQL server on a shared linux host. For some reason, queries to MySQL often return a ""server has gone away"" error:

_mysql_exceptions.OperationalError: (2006, 'MySQL server has gone away')


If you try the query again immediately afterwards, it usually succeeds. So, I'd like to know if there's a sensible way in python to try to execute a query, and if it fails, to try again, up to a fixed number of tries. Probably I'd want it to try 5 times before giving up altogether.

Here's the kind of code I have:

conn = MySQLdb.connect(host, user, password, database)
cursor = conn.cursor()

try:
    cursor.execute(query)
    rows = cursor.fetchall()
    for row in rows:
        # do something with the data
except MySQLdb.Error, e:
    print ""MySQL Error %d: %s"" % (e.args[0], e.args[1])


Clearly I could do it by having another attempt in the except clause, but that's incredibly ugly, and I have a feeling there must be a decent way to achieve this.
"
"Sending signal 0 to a pid will raise an OSError exception if the pid is not running, and do nothing otherwise.

import os

def check_pid(pid):        
    """""" Check For the existence of a unix pid. """"""
    try:
        os.kill(pid, 0)
    except OSError:
        return False
    else:
        return True

",How to check if there exists a process with a given pid?,"Is there a way to check to see if a pid corresponds to a valid process? I'm getting a pid from a different source other than from os.getpid() and I need to check to see if a process with that pid doesn't exist on the machine. 

I need it to be available in Unix and Windows. I'm also checking to see if the PID is NOT in use.
"
"I'd parse the string if conversion fails:

>>> def convert(s):
    try:
        return float(s)
    except ValueError:
        num, denom = s.split('/')
        return float(num) / float(denom)
...

>>> convert(""0.1234"")
0.1234

>>> convert(""1/2"")
0.5


Generally using eval is a bad idea, since it's a security risk. Especially if the string being evaluated came from outside the system.
",How to convert rational and decimal number strings to floats in python?,"How can I convert strings which can denote decimal or rational numbers to floats

>>> [""0.1234"", ""1/2""]
['0.1234', '1/2']


I'd want [0.1234, 0.5].

eval is what I was thinking but no luck:

>>> eval(""1/2"")
0

"
"Actually, pywin32 and ctypes seem to be an overkill for this simple task. Tkinter is a cross-platform GUI framework, which ships with Python by default and has clipboard accessing methods along with other cool stuff.

If all you need is to put some text to system clipboard, this will do it:

from Tkinter import Tk
r = Tk()
r.withdraw()
r.clipboard_clear()
r.clipboard_append('i can has clipboardz?')
r.destroy()


And that's all, no need to mess around with platform-specific third-party libraries.
",How do I copy a string to the clipboard on Windows using Python?,"I'm kind of new to Python and I'm trying to make a basic Windows application that builds a string out of user input then adds it to the  clipboard. How do I copy a string to the clipboard using Python?
"
"Ah, the old "".5"" problem. Here's the answer:

If you're going to divide 10 things into two equal parts, you need 5 things in each part. 0 thru 4 in the first part, 5-9 in the second part. So...  is correct.
","When using random, which form returns an equal 50% chance?","I'm guessing that most built in random generators return something like this:

[0.0, 1.0)


so if I would like a 50% chance would I use something like this:

if random() < .5


or something like:

if random() <= .5


Thanks for the help.
"
"The idea behind this omission is that static variables are only useful in two situations: when you really should be using a class and when you really should be using a generator.

If you want to attach stateful information to a function, what you need is a class.  A trivially simple class, perhaps, but a class nonetheless:

def foo(bar):
    static my_bar # doesn't work

    if not my_bar:
        my_bar = bar

    do_stuff(my_bar)

foo(bar)
foo()

# -- becomes ->

class Foo(object):
    def __init__(self, bar):
        self.bar = bar

    def __call__(self):
        do_stuff(self.bar)

foo = Foo(bar)
foo()
foo()


If you want your function's behavior to change each time it's called, what you need is a generator:

def foo(bar):
    static my_bar # doesn't work

    if not my_bar:
        my_bar = bar

    my_bar = my_bar * 3 % 5

    return my_bar

foo(bar)
foo()

# -- becomes ->

def foogen(bar):
    my_bar = bar

    while True:
        my_bar = my_bar * 3 % 5
        yield my_bar

foo = foogen(bar)
foo.next()
foo.next()


Of course, static variables are useful for quick-and-dirty scripts where you don't want to deal with the hassle of big structures for little tasks.  But there, you don't really need anything more than global â it may seem a but kludgy, but that's okay for small, one-off scripts:

def foo():
    global bar
    do_stuff(bar)

foo()
foo()

",Why doesn't Python have static variables?,"There is a questions asking how to simulate static variables in python.

Also, on the web one can find many different solutions to create static variables. (Though I haven't seen one that I like yet.)

Why doesn't Python support static variables in methods? Is this considered unpythonic or has it something to do with Python's syntax?

Edit:

I asked specifically about the why of the design decision and I haven't provided any code example because I wanted to avoid explanation to simulate static variables.
"
"Do the getting started guide to scipy?

http://www.scipy.org/Getting_Started
",Python for mathematics students?,"I need to deliver one and half hour seminar on programming for students at the department of mathematics. 

I have chosen python  as language.


What should be content of my presentation ?
What are good resources available ?
What is necessity of programming for maths students?
How will knowledge of programming will help them?


Thank you !!!

NOTE: I know here is one post but it doesn't solve my problem.
"
"The way to go is wsgi.

WSGI is the Web Server Gateway Interface. It is a specification for web servers and application servers to communicate with web applications (though it can also be used for more than that). It is a Python standard, described in detail in PEP 333. 

All current frameworks support wsgi. A lot of webservers support it also (apache included, through mod_wsgi). It is the way to go if you want to write your own framework.

Here is hello world, written to wsgi directly:

def application(environ, start_response):
    status = '200 OK'
    response_headers = [('Content-type','text/plain')]
    start_response(status, response_headers)
    return ['Hello world!\n']


Put this in a file.py, point your mod_wsgi apache configuration to it, and it will run. Pure python. No imports. Just a python function.

If you are really writing your own framework, you could check werkzeug. It is not a framework, but a simple collection of various utilities for WSGI applications and has become one of the most advanced WSGI utility modules. It includes a powerful debugger, full featured request and response objects, HTTP utilities to handle entity tags, cache control headers, HTTP dates, cookie handling, file uploads, a powerful URL routing system and a bunch of community contributed addon modules. Takes the boring part out of your hands.
",How do I use python for web development without relying on a framework?,"I know the various frameworks have their benefits, but I personally want my web development in python to be as straight-forward as possible: less writing to the framework, more writing python.

The only thing I have found so far that lets me do this in the most obvious way possible is web.py but I have slight concerns on its performance.

For those of you using nginx(or another flavour)+mod_wsgi+web.py... how's performance? Can it be improved further?

For those of you who have used web.py, liked the idea and went on to write something better or found something better... care to point me to the source?

I'd like to hear about all the conspicuous, minimal yet powerful approaches.
"
"Okay, the simplest form of what you're looking for is the pipe command.  It allows you to run multiple cmdline commands on the same line.  In your case, the two commands are write \w\ and execute current file \! %:p\.  If you have a specific command you run for you current file, the second command becomes, e.g. \!python %:p\.  So, the simplest answer to you question becomes:

:w | ! %:p
 ^ ^ ^
 | | |--Execute current file
 | |--Chain two commands
 |--Save current file


One last thing to note is that not all commands can be chained.  According to the Vim docs, certain commands accept a pipe as an argument, and thus break the chain...
",VIM: Save and Run at the same time?,"I do a lot of Python quick simulation stuff and I'm constantly saving (:w) and then running (:!!).  I'm wondering, is there a way to combine these actions.  Maybe a ""save and run"" command.

Thanks for your help.
"
"One advantage I see in using the ""stock"" Python that's included with Mac OS X is that it makes deployment to other Macs a piece of cake. I don't know what your deployment scenario is, but for me this is important. My code has to run on any number of Macs at work, and I try to minimize the amount of work it takes to run my code on all of those systems.
",Recommendations for Python development on a Mac?,"I bought a low-end MacBook about a month ago and am finally getting around to configuring it for Python. I've done most of my Python work in Windows up until now, and am finding the choices for OS X a little daunting. It looks like there are at least five options to use for Python development:


""Stock"" Apple Python
MacPython
Fink
MacPorts
roll-your-own-from-source


I'm still primarily developing for 2.5, so the stock Python is fine from a functionality standpoint. What I want to know is: why should I choose one over the other?

Update:
To clarify, I am looking for a discussion of the various options, not links to the documentation. I've marked this as a Community Wiki question, as I don't feel there is a ""correct"" answer. Thanks to everyone who has already commented for their insight.
"
"A class may be a better fit here (and is usually a better fit for anything involving ""state""):

class Stateful(object):

    def __init__(self):
        self.state_var = 0

    def __call__(self):
        self.state_var = self.state_var + 1
        print self.state_var

foo = Stateful()
foo()
foo()

","Does Python have something like Perl 5.10's ""state"" variables?","In Perl 5.10, I can say:

sub foo () {
  state $x = 1;
  say $x++;
}

foo();
foo();
foo();


...and it will print out:

1
2
3


Does Python have something like this?
"
"Prior to Django 1.7

You can give your application a custom name by defining app_label in your model definition. But as django builds the admin page it will hash models by their app_label, so if you want them to appear in one application, you have to define this name in all models of your application.

class MyModel(models.Model):
        pass
    class Meta:
        app_label = 'My APP name'


Django 1.7+

As stated by rhunwicks' comment to OP, this is now possible out of the box since Django 1.7

Taken from the docs:



# in yourapp/apps.py
from django.apps import AppConfig

class YourAppConfig(AppConfig):
    name = 'yourapp'
    verbose_name = 'Fancy Title'


then set the default_app_config variable to YourAppConfig

# in yourapp/__init__.py
default_app_config = 'yourapp.apps.YourAppConfig'

",Can you give a Django app a verbose name for use throughout the admin?,"In the same way that you can give fields and models verbose names that appear in the Django admin, can you give an app a custom name?
"
"Well, I'm not much of a python programmer, but I'd say that the answer is 'YES'.

Any dynamic language that lets you create a variable with any name at any time, could use a 'strict' pragma.

Strict vars (one of the options for strict in Perl, 'use strict' turns them all on at once) in Perl requires that all variables are declared before they are used.  Which means that this code:

my $strict_is_good = 'foo';
$strict_iS_good .= 'COMPILE TIME FATAL ERROR';


Generates a fatal error at compile time.

I don't know of a way to get Python to reject this code at compile time:

strict_is_good = 'foo';
strict_iS_good += 'RUN TIME FATAL ERROR';


You will get a run-time exception that strict_iS_good is undefined.  But only when the code is executed.  If your test suite does not have 100% coverage, you can easily ship this bug.

Any time I work in a language that does not have this behavior (PHP for example), I get nervous.  I am not a perfect typist.  A simple, but hard to spot, typo can cause your code to fail in ways that may be hard to track down. 

So, to reiterate, YES Python could use a 'strict' pragma to turn on compile time checks for things that can be checked at compile time.  I can't think of any other checks to add, but a better Python programmer probably could think of some.  

Note I focus on the pragmatic effect of stict vars in Perl, and am glossing over some of the details.  If you really want to know all the details see the perldoc for strict.

Update: Responses to some comments

Jason Baker : Static checkers like pylint are useful.  But they represent an extra step that can be and often is skipped.  Building some basic checks into the compiler guarantees that these checks are performed consistently.  If these checks are controllable by a pragma, even the objection relating to the cost of the checks becomes moot.  

popcnt :  I know that python will generate a run time exception.  I said as much.  I advocate compile time checking where possible.  Please reread the post.

mpeters : No computer analysis of code can find all errors--this amounts to solving the halting problem.  Worse, to find typos in assignments, your compiler would need to know your intentions and find places where your intentions differ from your code.  This is pretty clearly impossible.

However this does not mean that no checking should be done.  If there are classes of problems that are easy to detect, then it makes sense to trap them.

I'm not familiar enough with pylint and pychecker to say what classes of errors they will catch.  As I said I am very inexperienced with python.

These static analysis programs are useful.  However, I believe that unless they duplicate the capabilities of the compiler, the compiler will always be in a position to ""know"" more about the program than any static checker could.  It seems wasteful not to take advantage of this to reduce errors where possible.

Update 2:

cdleary - In theory, I agree with you, a static analyzer can do any validation that the compiler can.  And in the case of Python, it should be enough.  

However, if your compiler is complex enough (especially if you have lots of pragmas that change how compilation occurs, or if like Perl, you can run code at compile time), then the static analyzer must approach the complexity of the compiler/interpreter to do the analysis.  

Heh, all this talk of complex compilers and running code at compile time shows my Perl background.

My understanding is that Python does not have pragmas and can not run arbitrary code at compile time.  So, unless I am wrong or these features are added, a relatively simple parser in the static analyzer should suffice.  It certainly would be helpful to force these checks at every execution.  Of course, the way I'd do this is with a pragma.

Once you add pragmas to the mix, you have started down a slippery slope and the complexity of you analyzer must grow in proportion to the power and flexibility you provide in your pragmas.  If you are not careful, you can wind up like Perl, and then ""only python can parse Python,"" a future I wouldn't want to see.

Maybe a command line switch would be a better way to add forced static analysis ;)

(In no way do intend to impugn Python's capabilities when I say that it can't futz with compile time behavior like Perl can.  I have a hunch  that this is a carefully considered design decision, and I can see the wisdom in it.  Perl's extreme flexibility at compile time is, IMHO, a great strength and a terrible weakness of the language; I see the wisdom in this approach as well.)
","Is there a need for a ""use strict"" Python compiler?","There exist static analysis tools for Python, but compile time checks tend to be diametrically opposed to the run-time binding philosophy that Python embraces. It's possible to wrap the standard Python interpreter with a static analysis tool to enforce some ""use strict""-like constraints, but we don't see any widespread adoption of such a thing.

Is there something about Python that makes ""use strict"" behavior unnecessary or especially undesirable?

Alternatively, is the ""use strict"" behavior unnecessary in Perl, despite its widespread adoption?

Note: By ""necessary"" I mean ""practically necessary"", not strictly necessary. Obviously you can write Perl without ""use strict,"" but (from what I've seen) most Perl programmers do use it.

Note: The Python interpreter-wrapper need not require ""use strict""-like constraints -- you could use a pseudo-pragma similar to ""use strict"" that would be ignored by the normal interpreter. I'm not talking about adding a language-level feature.



Update: Explaining what ""use strict"" does in Perl per comments. (Link to official docs is in the first paragraph.)

The ""use strict"" directive has three distinct components, only two of which are really interesting:


use strict vars: Statically checks lexically scoped variable usage in your program. (Keep in mind that, in Python, there is basically only global scope and local scope). Many Python linters check for this sort of thing. Since it's the only static analysis that they can do, the linters assume you use straightforward lexical scoping and warn you about things that appear wrong in that sense until you tell them to shut up; i.e.

FOO = 12
foo += 3


If you're not doing anything fancy with your namespaces this can be useful to check for typos.
use strict refs: Prevents symbolic namespace dereferencing. Python's closest analog is using locals() and globals() to do symbolic binding and identifier lookup.
use strict subs: No real analog in Python.

"
"I had this same issue before and found this snippet very useful:

class Tee(object):
    def __init__(self, name, mode):
        self.file = open(name, mode)
        self.stdout = sys.stdout
        sys.stdout = self
    def __del__(self):
        sys.stdout = self.stdout
        self.file.close()
    def write(self, data):
        self.file.write(data)
        self.stdout.write(data)


from: http://mail.python.org/pipermail/python-list/2007-May/438106.html
",How do I duplicate sys.stdout to a log file in python?,"Edit: Since it appears that there's either no solution, or I'm doing something so non-standard that nobody knows - I'll revise my question to also ask: What is the best way to accomplish logging when a python app is making a lot of system calls?

My app has two modes.  In interactive mode, I want all output to go to the screen as well as to a log file, including output from any system calls.  In daemon mode, all output goes to the log.  Daemon mode works great using os.dup2().  I can't find a way to ""tee"" all output to a log in interactive mode, without modifying each and every system call.



In other words, I want the functionality of the command line 'tee' for any output generated by a python app, including system call output.

To clarify: 

To redirect all output I do something like this, and it works great:

# open our log file
so = se = open(""%s.log"" % self.name, 'w', 0)

# re-open stdout without buffering
sys.stdout = os.fdopen(sys.stdout.fileno(), 'w', 0)

# redirect stdout and stderr to the log file opened above
os.dup2(so.fileno(), sys.stdout.fileno())
os.dup2(se.fileno(), sys.stderr.fileno())


The nice thing about this is that it requires no special print calls from the rest of the code.  The code also runs some shell commands, so it's nice not having to deal with each of their output individually as well.

Simply, I want to do the same, except duplicate instead of redirect.

At first blush, I thought that simply reversing the dup2's should work.  Why doesn't it?  Here's my test: 

import os, sys

### my broken solution:
so = se = open(""a.log"", 'w', 0)
sys.stdout = os.fdopen(sys.stdout.fileno(), 'w', 0)

os.dup2(sys.stdout.fileno(), so.fileno())
os.dup2(sys.stderr.fileno(), se.fileno())
###

print ""kljhf sdf""

os.spawnve(""P_WAIT"", ""/bin/ls"", [""/bin/ls""], {})
os.execve(""/bin/ls"", [""/bin/ls""], os.environ)


The file ""a.log"" should be identical to what was displayed on the screen.
"
"Apart from tuples being immutable there is also a semantic distinction that should guide their usage. Tuples are heterogeneous data structures (i.e., their entries have different meanings), while lists are homogeneous sequences. Tuples have structure, lists have order. 

Using this distinction makes code more explicit and understandable.

One example would be pairs of page and line number to reference locations in a book, e.g.:

my_location = (42, 11)  # page number, line number


You can then use this as a key in a dictionary to store notes on locations. A list on the other hand could be used to store multiple locations. Naturally one might want to add or remove locations from the list, so it makes sense that lists are mutable. On the other hand it doesn't make sense to add or remove items from an existing location - hence tuples are immutable.

There might be situations where you want to change items within an existing location tuple, for example when iterating through the lines of a page. But tuple immutability forces you to create a new location tuple for each new value. This seems inconvenient on the face of it, but using immutable data like this is a cornerstone of value types and functional programming techniques, which can have substantial advantages.

There are some interesting articles on this issue, e.g. ""Python Tuples are Not Just Constant Lists"" or ""Understanding tuples vs. lists in Python"". The official Python documentation also mentions this (""Tuples are immutable, and usually contain an heterogeneous sequence ..."").

In a statically typed language like Haskell the values in a tuple generally have different types and the length of the tuple must be fixed. In a list the values all have the same type and the length is not fixed. So the difference is very obvious.

Finally there is the namedtuple in Python, which makes sense because a tuple is already supposed to have structure. This underlines the idea that tuples are a light-weight alternative to classes and instances.
",What's the difference between list and tuples?,"What's the difference?

What are the advantages / disadvantages of tuples / lists?
"
"Perl is a very nice language and CPAN has a ton of mature modules that will save you a lot of time. Furthermore, Perl is really moving forwards nowadays with a lot of interesting projects (unlike what uninformed fanboys like to spread around). Even a Perl 6 implementation is by now releasing working Perl 6.

I you want to do OO, I would recommend Moose.
",Next step after PHP: Perl or Python?,"It might seem it has been asked numerous times, but in fact it hasn't. I did my research, and now I'm eager to hear others' opinions.

I have experience with PHP 5, both with functional and object oriented programming methods. I created a few feature-minimalistic websites.

Professionals may agree about PHP not being a programming language that encourages good development habits. (I believe it's not the task of the tool, but this doesn't matter.) Furthermore, its performance is also controversial and often said to be poor compared to competitors.

In the 42nd podcast at Stack Overflow blog a developer from Poland asked what language he should learn in order to improve his skills. Jeff and Joel suggested that every one of them would help, altough there are specific ones that are better in some ways.
Despite they made some great points, it didn't help me that much.

From a beginner point of view, there are not one may not see (correction suggested by S. Lott) many differences between Perl & Python. I would like You to emphasize their strenghts and weaknesses and name a few unique services.

Of course, this wouldn't be fair as I could also check both of them. So here's my wishlist and requirements to help You help me.

First of all, I'd like to follow OOP structures and use it fundamentally. I partly planned a multiuser CMS using MySQL and XML, so the greater the implementations are, the better. Due to its foreseen nature, string manipulation will be used intensively.

If there aren't great differences, comparisons should probably mention syntax and other tiny details that don't matter in the first place.

So, here's my question: which one should I try first -- Perl || Python?



Conclusion

Both Perl and Python have their own fans, which is great. I'd like to say I'm grateful for all participation -- there is no trace of any flame war.

I accepted the most valued answer, although there are many great mini-articles below. As suggested more often, I will go with Python first. Then I'll try Perl later on. Let me see which one fits my mind better.

During the development of my special CMS, I'm going to ask more regarding programming doubts -- because developers now can count on each other! Thank you.

Edit: There were some people suggesting to choose Ruby or Java instead. Java has actually disappointed me. Maybe it has great features, maybe it hasn't. I wouldn't enjoy using it.

In addition, I was told to use Ruby. So far, most of the developers I communicate with have quite bad opinion about Ruby. I'll see it myself, but that's the last element on my priority list.
"
"Another solution (not that pythonic, but very fast) is to use string.translate - though note that this will not work for unicode.  It's also worth noting that you can speed up Dana's code by moving the characters into a set (which looks up by hash, rather than performing a linear search each time).  Here are the timings I get for various of the solutions given:

import string, re, timeit

# Precomputed values (for str_join_set and translate)

letter_set = frozenset(string.ascii_lowercase + string.ascii_uppercase)
tab = string.maketrans(string.ascii_lowercase + string.ascii_uppercase,
                       string.ascii_lowercase * 2)
deletions = ''.join(ch for ch in map(chr,range(256)) if ch not in letter_set)

s=""A235th@#$&( er Ra{}|?>ndom""

# From unwind's filter approach
def test_filter(s):
    return filter(lambda x: x in string.ascii_lowercase, s.lower())

# using set instead (and contains)
def test_filter_set(s):
    return filter(letter_set.__contains__, s).lower()

# Tomalak's solution
def test_regex(s):
    return re.sub('[^a-z]', '', s.lower())

# Dana's
def test_str_join(s):
    return ''.join(c for c in s.lower() if c in string.ascii_lowercase)

# Modified to use a set.
def test_str_join_set(s):
    return ''.join(c for c in s.lower() if c in letter_set)

# Translate approach.
def test_translate(s):
    return string.translate(s, tab, deletions)


for test in sorted(globals()):
    if test.startswith(""test_""):
        assert globals()[test](s)=='atherrandom'
        print ""%30s : %s"" % (test, timeit.Timer(""f(s)"", 
              ""from __main__ import %s as f, s"" % test).timeit(200000))


This gives me:

               test_filter : 2.57138351271
           test_filter_set : 0.981806765698
                test_regex : 3.10069885233
             test_str_join : 2.87172979743
         test_str_join_set : 2.43197956381
            test_translate : 0.335367566218


[Edit] Updated with filter solutions as well.  (Note that using set.__contains__ makes a big difference here, as it avoids making an extra function call for the lambda.
",What is the most efficient way in Python to convert a string to all lowercase stripping out all non-ascii alpha characters?,"I have a simple task I need to perform in Python, which is to convert a string to all lowercase and strip out all non-ascii non-alpha characters. 

For example:

""This is a Test"" -> ""thisisatest""
""A235th@#$&( er Ra{}|?>ndom"" -> ""atherrandom""


I have a simple function to do this:

import string
import sys

def strip_string_to_lowercase(s):
    tmpStr = s.lower().strip()
    retStrList = []
    for x in tmpStr:
        if x in string.ascii_lowercase:
            retStrList.append(x)

    return ''.join(retStrList)


But I cannot help thinking there is a more efficient, or more elegant, way.

Thanks!



Edit:

Thanks to all those that answered. I learned, and in some cases re-learned, a good deal of python.
"
"int() is the Python standard built-in function to convert a string into an integer value. You call it with a string containing a number as the argument, and it returns the number converted to an actual integer:

print int(""1"") + 1


The above prints 2.

If you know the structure of your list (that it simply contains lists, only one level), you could do this:

T2 = [map(int, x) for x in T1]

",How to convert strings into integers in Python?,"I have a tuple of tuples from a MySQL query like this:

T1 = (('13', '17', '18', '21', '32'),
      ('07', '11', '13', '14', '28'),
      ('01', '05', '06', '08', '15', '16'))


I'd like to convert all the string elements into integers and put it back nicely to list of lists this time:

T2 = [[13, 17, 18, 21, 32], [7, 11, 13, 14, 28], [1, 5, 6, 8, 15, 16]]


I tried to achieve it with eval but didn't get any decent result yet.
"
"The reason is explained in the part of that section which I highlighted in bold:


  String quotes can be escaped with a
  backslash, but the backslash remains
  in the string; for example, r""\"""" is a
  valid string literal consisting of two
  characters: a backslash and a double
  quote; r""\"" is not a valid string
  literal (even a raw string cannot end
  in an odd number of backslashes).
  Specifically, a raw string cannot end
  in a single backslash (since the
  backslash would escape the following
  quote character). Note also that a
  single backslash followed by a newline
  is interpreted as those two characters
  as part of the string, not as a line
  continuation.


So raw strings are not 100% raw, there is still some rudimentary backslash-processing.
",Why can't Python's raw string literals end with a single backslash?,"Technically, any odd number of backslashes, as described in the docs.

>>> r'\'
  File """", line 1
    r'\'
       ^
SyntaxError: EOL while scanning string literal
>>> r'\\'
'\\\\'
>>> r'\\\'
  File """", line 1
    r'\\\'
         ^
SyntaxError: EOL while scanning string literal


It seems like the parser could just treat backslashes in raw strings as regular characters (isn't that what raw strings are all about?), but I'm probably missing something obvious. TIA!
"
"You can install them side-by-side. If you've encounter problems just set python 2.5 as the standard python and use e.g. python26 for a newer version.
",Which version of python is currently best for os x?,"After going through hell trying to install the latest version of postgresql and psycopg2 today I'm going for a complete reinstall of Leopard.

I've been sticking with macpython 2.5 for the past year but now I'm considering macports even 2.6

For me it's most important for Twisted, PIL and psycopg2 to be working without a problem.

Can anyone give some guidelines for what version I should choose, based on experience? 

Edit:

Ok I've decided to go without reinstalling the os. Hacked around to clean up the bad PostgresPlus installation and installed another one. The official python 2.6.1 package works great, no problem installing it alongside 2.5.2. Psycopg2 works. But as expected PIL wont compile. 

I guess I'll be switching between the 2.5 from macports and the official 2.6 for different tasks, since I know the macports python has it's issues with some packages.

Another Edit:

I've now compiled PIL. Had to hide the whole macports directory and half the xcode libraries, so it would find the right ones. It wouldn't accept the paths I was feeding it. PIL is notorious for this on leopard.
"
"Using keyword arguments with default values (as suggested by kquinn) is a good idea, but will require you to include the parenthesis:

@redirect_output()
def foo():
    ...


If you would like a version that works without the parenthesis on the decorator you will have to account both scenarios in your decorator code.

If you were using Python 3.0 you could use keyword only arguments for this:

def redirect_output(fn=None,*,destination=None):
  destination = sys.stderr if destination is None else destination
  def wrapper(*args, **kwargs):
    ... # your code here
  if fn is None:
    def decorator(fn):
      return functools.update_wrapper(wrapper, fn)
    return decorator
  else:
    return functools.update_wrapper(wrapper, fn)


In Python 2.x this can be emulated with varargs tricks:

def redirected_output(*fn,**options):
  destination = options.pop('destination', sys.stderr)
  if options:
    raise TypeError(""unsupported keyword arguments: %s"" % 
                    "","".join(options.keys()))
  def wrapper(*args, **kwargs):
    ... # your code here
  if fn:
    return functools.update_wrapper(wrapper, fn[0])
  else:
    def decorator(fn):
      return functools.update_wrapper(wrapper, fn)
    return decorator


Any of these versions would allow you to write code like this:

@redirected_output
def foo():
    ...

@redirected_output(destination=""somewhere.log"")
def bar():
    ...

",How to create a Python decorator that can be used either with or without parameters?,"I'd like to create a Python decorator that can be used either with parameters:

@redirect_output(""somewhere.log"")
def foo():
    ....


or without them (for instance to redirect the output to stderr by default):

@redirect_output
def foo():
    ....


Is that at all possible?

Note that I'm not looking for a different solution to the problem of redirecting output, it's just an example of the syntax I'd like to achieve.
"
">>> x = ""Hello World!""
>>> x[2:]
'llo World!'
>>> x[:2]
'He'
>>> x[:-2]
'Hello Worl'
>>> x[-2:]
'd!'
>>> x[2:-2]
'llo Worl'


Python calls this concept ""slicing"" and it works on more than just strings. Take a look here for a comprehensive introduction.
",Is there a way to substring a string in Python?,"Is there a way to substring a string in Python, to get a new string from the 3rd character to the end of the string?

Maybe like myString[2:end]?

If leaving the second part means 'till the end', if you leave the first part, does it start from the start?
"
"Will throw a NameError exception:

>>> val
Traceback (most recent call last):
  File """", line 1, in 
NameError: name 'val' is not defined


You can either catch that or use 'val' in dir(), i.e.:

try:
    val
except NameError:
    print(""val not set"")


or

if 'val' in dir():
    print('val set')
else:
    print('val not set')

",Uninitialized value in Python?,"What's the uninitialized value in Python, so I can compare if something is initialized, like:

val

if val == undefined ?


EDIT: added a pseudo keyword.

EDIT2: I think I didn't make it clear, but say val is already there, but nothing is assigned to it.

Duplicate: Just declaring a variable in Python?
"
"Why not just do this:

var = None


Python is dynamic, so you don't need to declare things; they exist automatically in the first scope where they're assigned.  So, all you need is a regular old assignment statement as above.

This is nice, because you'll never end up with an uninitialized variable.  But be careful -- this doesn't mean that you won't end up with incorrectly initialized variables.  If you init something to None, make sure that's what you really want, and assign something more meaningful if you can.
",Is it possible only to declare a variable without assigning any value in Python?,"Is it possible to declare a variable in Python, like so?:

var


so that it initialized to None? It seems like Python allows this, but as soon as you access it, it crashes. Is this possible? If not, why?

EDIT: I want to do this for cases like this:

value

for index in sequence:

   if value == None and conditionMet:
       value = index
       break


Duplicate


Uninitialised value in python (by same author)
Are there any declaration keywords in Python? (by the same author)


Related


Python: variable scope and function calls
Other languages have ""variables""

"
"Here's a one line answer

sortedLetters = sorted(d.iteritems(), key=lambda (k,v): (v,k))

",How to write a function that takes a string and prints the letters in decreasing order of frequency?,"I got this far:

def most_frequent(string):
    d = dict()
    for key in string:
        if key not in d:
            d[key] = 1
        else:
            d[key] += 1
    return d

print most_frequent('aabbbc')


Returning:

{'a': 2, 'c': 1, 'b': 3}


Now I need to:


reverse the pair
sort by number by decreasing order
only print the letters out


Should I convert this dictionary to tuples or list?
"
"Here the simplest algorithm, if you want just to drop messages when they arrive too quickly (instead of queuing them, which makes sense because the queue might get arbitrarily large):

rate = 5.0; // unit: messages
per  = 8.0; // unit: seconds
allowance = rate; // unit: messages
last_check = now(); // floating-point, e.g. usec accuracy. Unit: seconds

when (message_received):
  current = now();
  time_passed = current - last_check;
  last_check = current;
  allowance += time_passed * (rate / per);
  if (allowance > rate):
    allowance = rate; // throttle
  if (allowance < 1.0):
    discard_message();
  else:
    forward_message();
    allowance -= 1.0;


There are no datastructures, timers etc. in this solution and it works cleanly :) To see this, 'allowance' grows at speed 5/8 units per seconds at most, i.e. at most five units per eight seconds. Every message that is forwarded deducts one unit, so you can't send more than five messages per every eight seconds.

Note that rate should be an integer, i.e. without non-zero decimal part, or the algorithm won't work correctly (actual rate will not be rate/per). E.g. rate=0.5; per=1.0; does not work because allowance will never grow to 1.0. But rate=1.0; per=2.0; works fine.
",What's a good rate limiting algorithm?,"I could use some pseudo-code, or better, Python.  I am trying to implement a rate-limiting queue for a Python IRC bot, and it partially works, but if someone triggers less messages than the limit (e.g., rate limit is 5 messages per 8 seconds, and the person triggers only 4), and the next trigger is over the 8 seconds (e.g., 16 seconds later), the bot sends the message, but the queue becomes full and the bot waits 8 seconds, even though it's not needed since the 8 second period has lapsed.
"
"Here is an interesting piece of code. I didn't use it myself, but it looks nice ;)

https://github.com/facebook/tornado/blob/master/tornado/httpclient.py

Low level AsyncHTTPClient:

""An non-blocking HTTP client backed with pycurl. Example usage:""

import ioloop

def handle_request(response):
    if response.error:
        print ""Error:"", response.error
    else:
        print response.body
    ioloop.IOLoop.instance().stop()

http_client = httpclient.AsyncHTTPClient()
http_client.fetch(""http://www.google.com/"", handle_request)
ioloop.IOLoop.instance().start()


""
fetch() can take a string URL or an HTTPRequest instance, which offers more options, like executing POST/PUT/DELETE requests.

The keyword argument max_clients to the AsyncHTTPClient constructor determines the maximum number of simultaneous fetch() operations that can execute in parallel on each IOLoop.
""

There is also new implementation in progress:
https://github.com/facebook/tornado/blob/master/tornado/simple_httpclient.py
""Non-blocking HTTP client with no external dependencies. ... This class is still in development and not yet recommended for production use.""
",Python: simple async download of url content?,"I have a web.py server that responds to various user requests. One of these requests involves downloading and analyzing a series of web pages. 

Is there a simple way to setup an async / callback based url download mechanism in web.py? Low resource usage is particularly important as each user initiated request could result in download of multiple pages.

The flow would look like:

User request -> web.py -> Download 10 pages in parallel or asynchronously -> Analyze contents, return results

I recognize that Twisted would be a nice way to do this, but I'm already in web.py so I'm particularly interested in something that can fit within web.py .
"
"For CPAN offerings have a look at the following (in alphabetical order)...


Builder
HTML::AsSubs
HTML::Tiny
Markapl
Template::Declare
XML::Generator


Using the table part of the CL-WHO example provided (minus Roman numerals and s/background-color/color/ to squeeze code into screen width here!)....



Builder

use Builder;
my $builder = Builder->new;
my $h = $builder->block( 'Builder::XML' );

$h->table( { border => 0, cellpadding => 4 }, sub {
   for ( my $i = 1; $i < 25; $i += 5 ) {
       $h->tr( { align => 'right' }, sub {
           for my $j (0..4) {
               $h->td( { color => $j % 2 ? 'pink' : 'green' }, $i + $j );
           }
       });
   } 
});

say $builder->render;




HTML::AsSubs

use HTML::AsSubs;

my $td = sub {
    my $i = shift;
    return map { 
        td( { color => $_ % 2 ? 'pink' : 'green' }, $i + $_ )
    } 0..4;
};

say table( { border => 0, cellpadding => 4 },
    map { 
        &tr( { align => 'right' }, $td->( $_ ) ) 
    } loop( below => 25, by => 5 )
)->as_HTML;




HTML::Tiny

use HTML::Tiny;
my $h = HTML::Tiny->new;

my $td = sub {
    my $i = shift;
    return map { 
        $h->td( { 'color' => $_ % 2 ? 'pink' : 'green' }, $i + $_ )
    } 0..4;
};

say $h->table(
    { border => 0, cellpadding => 4 },
    [
        map { 
            $h->tr( { align => 'right' }, [ $td->( $_ ) ] )  
        } loop( below => 25, by => 5 )    
    ]
);




Markapl

use Markapl;

template 'MyTable' => sub {
    table ( border => 0, cellpadding => 4 ) {
       for ( my $i = 1; $i < 25; $i += 5 ) {
           row ( align => 'right' ) {
               for my $j ( 0.. 4 ) {
                   td ( color => $j % 2 ? 'pink' : 'green' ) { $i + $j }
               }
           }
       } 
    }
};

print main->render( 'MyTable' );




Template::Declare

package MyTemplates;
use Template::Declare::Tags;
use base 'Template::Declare';

template 'MyTable' => sub {
    table {
        attr { border => 0, cellpadding => 4 };
        for ( my $i = 1; $i < 25; $i += 5 ) {
            row  {
                attr { align => 'right' };
                    for my $j ( 0..4 ) {
                        cell {
                            attr { color => $j % 2 ? 'pink' : 'green' } 
                            outs $i + $j;
                        }
                    }
            }
        } 
    }
};

package main;
use Template::Declare;
Template::Declare->init( roots => ['MyTemplates'] );
print Template::Declare->show( 'MyTable' );




XML::Generator

use XML::Generator;
my $x = XML::Generator->new( pretty => 2 );

my $td = sub {
    my $i = shift;
    return map { 
        $x->td( { 'color' => $_ % 2 ? 'pink' : 'green' }, $i + $_ )
    } 0..4;
};

say $x->table(
    { border => 0, cellpadding => 4 },
    map { 
        $x->tr( { align => 'right' }, $td->( $_ ) )  
    } loop( below => 25, by => 5 )    
);



And the following can be used to produce the ""loop"" in HTML::AsSubs / HTML::Tiny / XML::Generator examples....

sub loop {
    my ( %p ) = @_;
    my @list;

    for ( my $i = $p{start} || 1; $i < $p{below}; $i += $p{by} ) {
        push @list, $i;
    }

    return @list;
}


/I3az/
",CL-WHO-like HTML templating for other languages?,"Common Lisp guys have their CL-WHO, which makes HTML templating integrated with the ""main"" language thus making the task easier. For those who don't know CL-WHO, it looks like this (example from CL-WHO's webpage):

(with-html-output (*http-stream*)
(:table :border 0 :cellpadding 4
  (loop for i below 25 by 5
     do (htm
         (:tr :align ""right""
          (loop for j from i below (+ i 5)
                do (htm
                    (:td :bgcolor (if (oddp j)
                                    ""pink""
                                    ""green"")
                         (fmt ""~@R"" (1+ j))))))))))


Do you know any libraries like this for other languages? The one I know about (that mimics CL-WHO) is BrevÃ© for Python. I'm particularly interested in Perl flavour, but it's interesting how other languages handle integrating HTML into their syntax.
"
"
  Use __new__ when you need to control
  the creation of a new instance. Use
  __init__ when you need to control initialization of a new instance.
  
  __new__ is the first step of instance creation.  It's called first, and is
  responsible for returning a new
  instance of your class.  In contrast,
  __init__ doesn't return anything; it's only responsible for initializing the
  instance after it's been created.
  
  In general, you shouldn't need to
  override __new__ unless you're
  subclassing an immutable type like
  str, int, unicode or tuple.


From: http://mail.python.org/pipermail/tutor/2008-April/061426.html

You should consider that what you are trying to do is usually done with a Factory and that's the best way to do it. Using __new__ is not a good clean solution so please consider the usage of a factory. Here you have a good factory example.
",Python's use of __new__ and __init__?,"I'm just trying to streamline one of my classes and have introduced some functionality in the same style as the flyweight design pattern.

However, I'm a bit confused as to why __init__ is always called after __new__. I wasn't expecting this. Can anyone tell me why this is happening and how I implement this functionality otherwise? (apart from putting the implementation into the __new__ which feels quite hacky).

Here's an example:

class A(object):
    _dict = dict()

    def __new__(cls):
    	if 'key' in A._dict:
    		print ""EXISTS""
    		return A._dict['key']
    	else:
    		print ""NEW""
    		return super(A, cls).__new__(cls)

    def __init__(self):
    	print ""INIT""
    	A._dict['key'] = self
    	print """"

a1 = A()
a2 = A()
a3 = A()


Outputs:

NEW
INIT

EXISTS
INIT

EXISTS
INIT


Why?
"
">>> d = { 'a': 1, 'b': 2, 'c': 3 }
>>> d.items()
[('a', 1), ('c', 3), ('b', 2)]
>>> [(v, k) for k, v in d.iteritems()]
[(1, 'a'), (3, 'c'), (2, 'b')]


It's not in the order you want, but dicts don't have any specific order anyway. Sort it or organize it as necessary.

See: items(), iteritems()



In Python 3.x, you would not use iteritems (which no longer exists), but instead use items, which now returns a ""view"" into the dictionary items. See the What's New document for Python 3.0, and the new documentation on views.
",How can I convert a Python dictionary to a list of tuples?,"If I have a dictionary like:

{ 'a': 1, 'b': 2, 'c': 3 }


How can I convert it to this?

[ ('a', 1), ('b', 2), ('c', 3) ]


And how can I convert it to this?

[ (1, 'a'), (2, 'b'), (3, 'c') ]

"
"Getting the name of the file without the extension :

import os
print(os.path.splitext(""path_to_file"")[0])


As for your import problem, you solve it this way :

from os.path import basename

# now you can call it directly with basename
print(basename(""/a/b/c.txt""))

",How to get the filename without the extension from a path in Python?,"How to get the filename without the extension from a path in Python?

I found out a method called os.path.basename to get the filename with extension. But even when I import os, I am not able to call it path.basename. Is it possible to call it as directly as basename?
"
"Actually None is much better for ""magic"" values:

class Cheese():
    def __init__(self, num_holes = None):
        if num_holes is None:
            ...


Now if you want complete freedom of adding more parameters:

class Cheese():
    def __init__(self, *args, **kwargs):
        #args -- tuple of anonymous arguments
        #kwargs -- dictionary of named arguments
        self.num_holes = kwargs.get('num_holes',random_holes())


To better explain the concept of *args and **kwargs (you can actually change these names):

def f(*args, **kwargs):
   print 'args: ', args, ' kwargs: ', kwargs

>>> f('a')
args:  ('a',)  kwargs:  {}
>>> f(ar='a')
args:  ()  kwargs:  {'ar': 'a'}
>>> f(1,2,param=3)
args:  (1, 2)  kwargs:  {'param': 3}


http://docs.python.org/reference/expressions.html#calls
","What is a clean, pythonic way to have multiple constructors in Python?","I can't find a definitive answer for this. AFAIK, you can't have multiple __init__ functions in a Python class. So what is a good way to solve this problem? 

Suppose I have an class called Cheese with the number_of_holes property. How can I have two ways of creating cheese-objects...


one that takes a number of holes like this: parmesan = Cheese(num_holes = 15)
and one that takes no arguments and just randomizes the number_of_holes property: gouda = Cheese()


I can think of only one way to do this, but that seems kinda clunky:

class Cheese():
    def __init__(self, num_holes = 0):
        if (num_holes == 0):
            # randomize number_of_holes
        else:
            number_of_holes = num_holes


What do you say? Is there a better way?
"
"How about pyjs?

From the above website:


  pyjs is a Rich Internet Application (RIA) Development Platform for both Web and Desktop. With pyjs you can write your JavaScript-powered web applications entirely in Python.

",Best way to integrate Python and JavaScript?,"Is it possible to integrate Python and JavaScript?  For example, imagine you wanted to be able to define classes in JavaScript and use them from Python (or vice versa).  If so, what's the best way?  I'm interested not only if this is possible but if anyone has done it within a ""serious"" project or product.

I'm guessing it would be possible using Jython and Rhino, for one example, but I'm curious whether or not anyone's ever actually done this, and if there are solutions for other platforms (especially CPython).
"
"""Reload is no longer a function in Python 3. Use imp.reload() instead"" copied from comments

Use the reload builtin function:

https://docs.python.org/2/library/functions.html#reload


  When reload(module) is executed:
  
  
  Python modulesâ code is recompiled and the module-level code reexecuted, defining a new set of objects which are bound to names in the moduleâs dictionary. The init function of extension modules is not called a second time.
  As with all other objects in Python the old objects are only reclaimed after their reference counts drop to zero.
  The names in the module namespace are updated to point to any new or changed objects.
  Other references to the old objects (such as names external to the module) are not rebound to refer to the new objects and must be updated in each namespace where they occur if that is desired.
  


Example:

# Make a simple function that prints ""version 1""
shell1$ echo 'def x(): print ""version 1""' > mymodule.py

# Run the module
shell2$ python
>>> import mymodule
>>> mymodule.x()
version 1

# Change mymodule to print ""version 2"" (without exiting the python REPL)
shell2$ echo 'def x(): print ""version 2""' > mymodule.py

# Back in that same python session
>>> reload(mymodule)

>>> mymodule.x()
version 2

",How to re import an updated package while in Python Interpreter?,"I often test my module in the Python Interpreter, and when I see an error, I quickly update the .py file. But how do I make it reflect on the Interpreter ? So, far I have been exiting and reentering the Interpreter because re importing the file again is not working for me.
"
"This code should work:

duplicates = set()
found = set()
for item in source:
    if item in found:
        duplicates.add(item)
    else:
        found.add(item)

","In Python, how do I take a list and reduce it to a list of duplicates?","I have a list of strings that should be unique. I want to be able to check for duplicates quickly. Specifically, I'd like to be able to take the original list and produce a new list containing any repeated items. I don't care how many times the items are repeated so it doesn't have to have a word twice if there are two duplicates.

Unfortunately, I can't think of a way to do this that wouldn't be clunky. Any suggestions?

EDIT:
Thanks for the answers and I thought I'd make a clarification. I'm not concerned with having a list of uniques for it's own sake. I'm generating the list based off of text files and I want to know what the duplicates are so I can go in the text files and remove them if any show up.
"
"Maybe Q objects could be of help for this problem. I've never used them but it seems they can be negated and combined much like normal python expressions.

Update: I Just tried it out, it seems to work pretty well:

>>> from myapp.models import Entry
>>> from django.db.models import Q

>>> Entry.objects.filter(~Q(id = 3))

[, , , ...]

",How do I do a not equal in Django queryset filtering?,"In Django model QuerySets, I see that there is a __gt and __lt for comparitive values, but is there a __ne/!=/ (not equals?)

I want to filter out using a not equals:

Example:

Model:
    bool a;
    int x;


I want

results = Model.objects.exclude(a=true, x!=5)


The != is not correct syntax. I tried __ne, .

I ended up using:

results = Model.objects.exclude(a=true, x__lt=5).exclude(a=true, x__gt=5)

"
"try python curses module , it is a command-line graphic operation library.
",How do I make a command line text editor?,"I have gotten to know my way around a few programming languages, and I'd like to try my hand at making a command-line text editor -- something that runs in the terminal, like vim/emacs/nano, but is pure text (no guis, please). Preferably, I'd like to do this in python. Where do I start? Are there any (python) libraries to do command-line applications?
"
"Another option is to use the built-in map function:

>>> my_list = [[1,2,3],[4,5,6],[7,8,9]]
>>> neg = lambda x: -x
>>> f = lambda x: map(neg, x)
>>> map(f, my_list)
[[-1, -2, -3], [-4, -5, -6], [-7, -8, -9]]

",Alter all values in a Python list of lists?,"Let's say I have a list like:

my_list = [[1,2,3],[4,5,6],[7,8,9]]


How do I alter every value in the list without doing?:

for x in range(0, 3):
    for y in range(0, 3):
        my_list[x][y] = -my_list[x][y]


I have tried to simplify this by doing

my_list = [[[-a, -b, -c] for [a, b, c] in d] for d in my_list]


but the values remain the same.
"
"Forget about mod_python, there is WSGI. 

I'd recommend Django. It runs on any WSGI server, there are a lot to choose from. There is mod_wsgi for Apache, wsgiref - reference implementation included in Python and many more. Also Google App Engine is WSGI, and includes Django.

Django is very popular and it's community is rapidly growing.
",Dilemma: Should I learn Seaside or a Python framework?,"I know it's kinda subjective but, if you were to put yourself in my shoes which would you invest the time in learning?

I want to write a web app which deals securely with relatively modest amounts of peoples private data, a few thousand records of a few Kb each but stuff that needs to be kept safe, addresses, phone numbers etc. I've done several web projects in PHP/MYSQL and have decided, handy though it is I really don't like PHP and don't want to do another large project in it...

As such I figure I'd best learn something new and so I am considering 2 options (although I'll happily entertain others if you have suggestions). I'm having terrible trouble deciding though. They both look quite involved so rather than just jump in and potentially waste days getting up to speed enough on both of them to make an informed choice I thought I'd come here and canvas some opinion.

So the two options I'm considering are...

One of the PYTHON Web frameworks - TurboGears seems well regarded?
Advantage: Of all the languages I ever tried Python is by far and away my favorite. There's loads of frameworks to choose from and I have done quite a lot of non web python coding over the last few years. 
Disadvantage: There's loads to choose from so it's hard to pick! Need to run single server process? or mod_python? which I don't like the sound of. What I do like is the notion of process separation and compartmentalization, i.e. if one users account is compromised it gives an attacker no leverage against the rest of the system. I'm not clear to what extent a python solution would handle that.

Writing it as a SEASIDE app Which I guess runs on a squeak app server?
Adv: From what I've heard it would permit good compartmentalization of users as each would have their own little private VM independent of all the systems other users which sounds wonderful from a security, scaling and redundancy standpoint.
Dis: I've not done any Smalltalk since Uni 15 years back and I never dug too deep into it then. I don't see much entry level help for seaside or that many projects using it. I suspect setting a server up to run it is hard for the same reason i.e. not because it's inherently hard but just cause there will be less help online and a presumption you are already rather au fait with Sqeak/Smalltalk.

So, what do people think? Would I be able to efficiently get the kind of strong separation and compartmentalization I'm after with a Python framework? Is Seaside as good as I think in terms of insulating users from each other? Might I be better off, security wise, sticking to the languages I'm most familiar with so I don't make any n00b mistakes or will Seaside be worth worth scaling the learning curve and prove more secure, comprehensible and maintainable in the long run? At the end of the day it's not a life or death decision and I can always bail if I start with one and then hate it so pls nobody get all holy language war and start flaming anyone! ;-)

Cheers for any replies this gets,

Roger :)
"
"For statements, use exec(string) (Python 2/3) or exec string (Python 2):

>>> mycode = 'print ""hello world""'
>>> exec(mycode)
Hello world


When you need the value of an expression, use eval(string):

>>> x = eval(""2+2"")
>>> x
4


However, the first step should be to ask yourself if you really need to.  Executing code should generally be the position of last resort: It's slow, ugly and dangerous if it can contain user-entered code.  You should always look at alternatives first, such as higher order functions, to see if these can better meet your needs.
",How do I execute a string containing Python code in Python?,"How do I execute a string containing Python code in Python?
"
"
  the religious debates between the Django and WSGI camps


It would seem as though you're a tad bit confused about what WSGI is and what Django is.  Saying that Django and WSGI are competing is a bit like saying that C and SQL are competing:  you're comparing apples and oranges.

Django is a framework, WSGI is a protocol (which is supported by Django) for how the server interacts with the framework.  Most importantly, learning to use WSGI directly is a bit like learning assembly.  It's a great learning experience, but it's not really something you should do for production code (nor was it intended to be).

At any rate, my advice is to figure it out for yourself.  Most frameworks have a ""make a wiki/blog/poll in an hour"" type exercise.  Spend a little time with each one and figure out which one you like best.  After all, how can you decide between different frameworks if you're not willing to try them out?
",Django vs other Python web frameworks?,"I've pretty much tried every Python web framework that exists, and it took me a long time to realize there wasn't a silver bullet framework, each had its own advantages and disadvantages. I started out with Snakelets and heartily enjoyed being able to control almost everything at a lower level without much fuss, but then I discovered TurboGears and I have been using it (1.x) ever since. Tools like Catwalk and the web console are invaluable to me.

But with TurboGears 2 coming out which brings WSGI support, and after reading up on the religious debates between the Django and WSGI camps, I'm really torn between ""doing it the right way"", e.g., learning WSGI, spending valuable time writing functionality that already exists in Django and other full-stack frameworks, as opposed to using Django or some high-level framework that does everything for me. The downsides with the latter that I can see are pretty obvious: 


I'm not learning anything in the process
If I ever need to do anything lower level it's going to be a pain
The overhead required for just a basic site which uses authentication is insane. (IMO)


So, I guess my question is, which is the better choice, or is it just a matter of opinion, and should I suck it up and use Django if it achieves what I want with minimal fuss (I want authentication and a CRUD interface to my database)? I tried Werkzeug, Glashammer, and friends, but AuthKit and Repoze scared me off, as well as the number of steps involved to just setup basic authentication. I looked at Pylons, but the documentation seems lacking, and when referencing simple features like authentication or a CRUD interface, various wiki pages and documentation seemed to contradict each other, with different hacks for versions and such. 



Thanks to S. Lott for pointing out that I wasn't clear enough. My question is: which of the following is worthwhile in the long run, but not painful in the short (e.g., some sort of middle ground, anyone?) - Learn WSGI, or stick with a ""batteries-included"" framework? If the latter, I would appreciate a suggestion as to whether I should give Django another try, stick with TurboGears 1.x, or venture into some other framework. 

Also, I have tried CherryPy, but couldn't seem to find a good enough CRUD application that I could plop in and use right away.
"
"Try GoFlow, a workflow engine for Django.
",Does anyone know about workflow frameworks/libraries in Python?,"I'm searching for a workflow library/framework for Python. I'm astonished that there I cannot find anything which is simple and not attached to Zope/Plone. 

Does anyone know of an open-source, simple workflow library/framework. It's preferred to support Django, but not required.
"
"isinstance()


In your case, isinstance(""this is a string"", str) will return True.

You may also want to read this: http://www.canonical.org/~kragen/isinstance/
",How to compare type of an object in Python?,"Basically I want to do this:

obj = 'str'
type ( obj ) == string


I tried:

type ( obj ) == type ( string )


and it didn't work.

Also, what about the other types? For example, I couldn't replicate NoneType.
"
"Don't walk, run to get a new host immediately.  If your host won't even get you the most basic of free databases, it's time for a change.  There are many fish in the sea.

At the very least I'd recommend an xml data store rather than a csv.  My blog uses an xml data provider and I haven't had any issues with performance at all.
",Using CSV as a mutable database?,"Yes, this is as stupid a situation as it sounds like.  Due to some extremely annoying hosting restrictions and unresponsive tech support, I have to use a CSV file as a database.  

While I can use MySQL with PHP, I can't use it with the Python backend of my program because of install issues with the host.  I can't use SQLite with PHP because of more install issues, but can use it as it's a Python builtin.

Anyways, now, the question: is it possible to update values SQL-style in a CSV database? Or should I keep on calling the help desk?
"
"json is simplejson, added to the stdlib. But since json was added in 2.6, simplejson has the advantage of working on more Python versions (2.4+). 

simplejson is also updated more frequently than Python, so if you need (or want) the latest version, it's best to use simplejson itself, if possible.

A good practice, in my opinion, is to use one or the other as a fallback.

try: import simplejson as json
except ImportError: import json

",What are the differences between json and simplejson Python modules?,"I have seen many projects using simplejson module instead of json module from the Standard Library. Also, there are many different simplejson modules. Why would use these alternatives, instead of the one in the Standard Library?
"
"You'll want to use the Python's standard logging module.

import logging

logging.info(""hello"")
logging.debug(""hi"") # this won't show up by default


To see calls to logging.debug() in the GoogleAppEngineLauncher Logs console, you have to first add the flag --dev_appserver_log_level=debug to your app. However, beware that you're going to see a lot of debug noise from the App Engine SDK itself. The full set of levels are:


debug
info
warning
error
critical


You can add the flag by double clicking the app and then dropping it into the Extra Flags field.


",How do I write to the console in Google App Engine?,"Often when I am coding I just like to print little things (mostly the current value of variables) out to console. I don't see anything like this for Google App Engine, although I note that the Google App Engine Launcher does have a Log terminal. Is there any way to write to said Terminal, or to some other terminal, using Google App Engine? 
"
"try:
  doSomething()
except: 
  pass


or

try:
  doSomething()
except Exception: 
  pass


The difference is, that the first one will also catch KeyboardInterrupt, SystemExit and stuff like that, which are derived directly from exceptions.BaseException, not exceptions.Exception. See documentation for details:


try statement — http://docs.python.org/reference/compound_stmts.html#try
exceptions — http://docs.python.org/library/exceptions

",Try/Except in Python: How do you properly ignore Exceptions?,"When you just want to do a try-except without handling the exception, how do you do it in Python?

Is the following the right way to do it?

try :
    shutil.rmtree ( path )
except :
    pass

"
"This question appears to have two things in it.


Presentation on the web.  This is easy to do in Python -- use Django or TurboGears or any Python-based web framework.
Refresh of the web page to show new data.  This can be done two ways.


Some fancy Javascript to refresh.
Some fancy HTML to refresh the page.  The meta refresh tag is what you want.  If you do this, you have an all-Python solution.


",What's easiest way to get Python script output on the web?,"I have a python script that runs continuously.  It outputs 2 lines of info every 30 seconds.  I'd like to be able to view this output on the web.  In particular, I'd like the site to auto-update (add the new output at the top of the page/site every 30 seconds without having to refresh the page).

I understand I can do this with javascript but is there a python only based solution?  Even if there is, is javascript the way to go?  I'm more than willing to learn javascript if needed but if not, I'd like to stay focused on python.

Sorry for the basic question but I'm still clueless when it comes to web programming.

Thx!
"
"""I checked it out and it looks good, but I also heard that processes, unlike threads, can't share a lot of information...""

This is only partially true.

Threads are part of a process -- threads share memory trivially.  Which is as much of a problem as a help -- two threads with casual disregard for each other can overwrite memory and create serious problems.

Processes, however, share information through a lot of mechanisms.  A Posix pipeline (a | b) means that process a and process b share information -- a writes it and b reads it.  This works out really well for a lot things.

The operating system will assign your processes to every available core as quickly as you create them.  This works out really well for a lot of things.

Stackless Python is unrelated to this discussion -- it's faster and has different thread scheduling.  But I don't think threads are the best route for this.

""I think my program will need to share a lot of information.""

You should resolve this first.  Then, determine how to structure processes around the flow of information.  A ""pipeline"" is very easy and natural to do; any shell will create the pipeline trivially.

A ""server"" is another architecture where multiple client processes get and/or put information into a central server.  This is a great way to share information.  You can use the WSGI reference implementation as a way to build a simple, reliable server.
",Multiprocessing or Multithreading?,"I'm making a program for running simulations in Python, with a wxPython interface. In the program, you can create a simulation, and the program renders (=calculates) it for you. Rendering can be very time-consuming sometimes.

When the user starts a simulation, and defines an initial state, I want the program to render the simulation continuously in the background, while the user may be doing different things in the program. Sort of like a YouTube-style bar that fills up: You can play the simulation only up to the point that was rendered.

Should I use multiple processes or multiple threads or what? People told me to use the multiprocessing package, I checked it out and it looks good, but I also heard that processes, unlike threads, can't share a lot of information (and I think my program will need to share a lot of information.) Additionally I also heard about Stackless Python: Is it a separate option? I have no idea.

Please advise.
"
"You can use the zfill() method to pad a string with zeros:

In [3]: str(1).zfill(2)
Out[3]: '01'

",Best way to format integer as string with leading zeros?,"I need to add leading zeros to integer to make a string with defined quantity of digits ($cnt).
What the best way to translate this simple function from PHP to Python:

function add_nulls($int, $cnt=2) {
    $int = intval($int);
    for($i=0; $i<($cnt-strlen($int)); $i++)
        $nulls .= '0';
    return $nulls.$int;
}


Is there a function that can do this?
"
"Or shorten David's answer with:

if 4 <= day <= 20 or 24 <= day <= 30:
    suffix = ""th""
else:
    suffix = [""st"", ""nd"", ""rd""][day % 10 - 1]

",Date Ordinal Output?,"I'm wondering if there is a quick and easy way to output ordinals given a number in python.

For example, given the number 1, I'd like to output ""1st"", the number 2, ""2nd"", et cetera, et cetera.

This is for working with dates in a breadcrumb trail

Home >  Venues >  Bar Academy >  2009 >  April >  01 


is what is currently shown

I'd like to have something along the lines of

Home >  Venues >  Bar Academy >  2009 >  April >  1st

"
">>> L1 = [2,3,4]
>>> L2 = [1,2]
>>> [i for i in L1 if i in L2]
[2]


>>> S1 = set(L1)
>>> S2 = set(L2)
>>> S1.intersection(S2)
set([2])


Both empty lists and empty sets are False, so you can use the value directly as a truth value.
",How to check if one of the following items is in a list?,"I'm trying to find a short way to see if any of the following items is in a list, but my first attempt does not work. Besides writing a function to accomplish this, is the any short way to check if one of multiple items is in a list.

>>> a = [2,3,4]
>>> print (1 or 2) in a
False
>>> print (2 or 1) in a
True

"
"I am not sure what you are trying to do. You can implement a do-while loop like this:

while True:
  stuff()
  if fail_condition:
    break


Or:

stuff()
while not fail_condition:
  stuff()


What are you doing trying to use a do while loop to print the stuff in the list? Why not just use:

for i in l:
  print i
print ""done""


Update:

So do you have a list of lines? And you want to keep iterating through it? How about: 

for s in l: 
  while True: 
    stuff() 
    # use a ""break"" instead of s = i.next()


Does that seem like something close to what you would want? With your code example, it would be:

for s in some_list:
  while True :
    if state is STATE_CODE :
      if ""//"" in s :
        tokens.add( TOKEN_COMMENT, s.split( ""//"" )[1] )
        state = STATE_COMMENT
      else :
        tokens.add( TOKEN_CODE, s )
    if state is STATE_COMMENT :
      if ""//"" in s :
        tokens.append( TOKEN_COMMENT, s.split( ""//"" )[1] )
        break # get next s
      else
        state = STATE_CODE
        # re-evaluate same line
        # continues automatically

",Emulate a do-while loop in Python?,"I need to emulate a do-while loop in a Python program. Unfortunately, the following straightforward code does not work:

l = [ 1, 2, 3 ]
i = l.__iter__()
s = None
while True :
  if s :
    print s
  try :
    s = i.next()
  except StopIteration :
    break
print ""done""


Instead of ""1,2,3,done"", it prints the following output:

[stdout:]1
[stdout:]2
[stdout:]3
None['Traceback (most recent call last):
', '  File ""test_python.py"", line 8, in 
    s = i.next()
', 'StopIteration
']


What can I do in order to catch the 'stop iteration' exception and break a while
loop properly?

An example of why such a thing may be needed is shown below as pseudocode.

State machine:

s = """"
while True :
  if state is STATE_CODE :
    if ""//"" in s :
      tokens.add( TOKEN_COMMENT, s.split( ""//"" )[1] )
      state = STATE_COMMENT
    else :
      tokens.add( TOKEN_CODE, s )
  if state is STATE_COMMENT :
    if ""//"" in s :
      tokens.append( TOKEN_COMMENT, s.split( ""//"" )[1] )
    else
      state = STATE_CODE
      # Re-evaluate same line
      continue
  try :
    s = i.next()
  except StopIteration :
    break

"
"As of June 2009 the originally cited blog post has a method to create animated GIFs in the comments.  Download the script images2gif.py (formerly images2gif.py, update courtesy of @geographika).

Then, to reverse the frames in a gif, for instance:

#!/usr/bin/env python

from PIL import Image, ImageSequence
import sys, os
filename = sys.argv[1]
im = Image.open(filename)
original_duration = im.info['duration']
frames = [frame.copy() for frame in ImageSequence.Iterator(im)]    
frames.reverse()

from images2gif import writeGif
writeGif(""reverse_"" + os.path.basename(filename), frames, duration=original_duration/1000.0, dither=0)

",Programmatically generate video or animated GIF in Python?,"I have a series of images that I want to create a video from.  Ideally I could specify a frame duration for each frame but a fixed frame rate would be fine too.  I'm doing this in wxPython, so I can render to a wxDC or I can save the images to files, like PNG.  Is there a Python library that will allow me to create either a video (AVI, MPG, etc) or an animated GIF from these frames?

Edit: I've already tried PIL and it doesn't seem to work.  Can someone correct me with this conclusion or suggest another toolkit?  This link seems to backup my conclusion regarding PIL: http://www.somethinkodd.com/oddthinking/2005/12/06/python-imaging-library-pil-and-animated-gifs/
"
"You can easily use a list to wrap the required object and that's all what django serializers need to correctly serialize it, eg.:

from django.core import serializers

# assuming obj is a model instance
serialized_obj = serializers.serialize('json', [ obj, ])

",How do you serialize a model instance in Django?,"There is a lot of documentation on how to serialize a Model QuerySet but how do you just serialize to JSON the fields of a Model Instance?
"
"A generator function would be neat:

def batch_gen(data, batch_size):
    for i in range(0, len(data), batch_size):
            yield data[i:i+batch_size]


Example use:

a = ""abcdef""
for i in batch_gen(a, 2): print i


prints:

ab
cd
ef

",Iterate over a python sequence in multiples of n?,"How do I process the elements of a sequence in batches, idiomatically?

For example, with the sequence ""abcdef"" and a batch size of 2, I would like to do something like the following:

for x, y in ""abcdef"":
    print ""%s%s\n"" % (x, y)
ab
cd
ef


Of course, this doesn't work because it is expecting a single element from the list which itself contains 2 elements.

What is a nice, short, clean, pythonic way to process the next n elements of a list in a batch, or sub-strings of length n from a larger string (two similar problems)?
"
"Since 2.5:

If you want to fall back only on None:

a = x if x is not None else y


If you want to fall back also on empty string, false, 0 etc.: 

a = x if x else y


or

a = x or y




As for undefined (as never defined, a.k.a. not bound):

try:
  a = x 
except NameError:
  a = y


or a bit more hackish (I'd not really recommend that, but it's short):

a = vars().get('x',y)

",What is the most Pythonic way to provide a fall-back value in an assignment?,"In Perl, it's often nice to be able to assign an object, but specify some fall-back value if the variable being assigned from is 'undef'.  For instance:

my $x = undef;
my $y = 2;
my $a = $x || $y;


After this,

$a == 2


Is there a concise way to achieve this in Python if the value x is None, or would a full-on ...

if x is not None
    a = x
else
    a = y


... be the most Pythonic way to achieve this?

EDIT: Apologies, as has been pointed out by several commenters, I wasn't really talking about the value being undefined, but 'undef' in Perl, which is not really the same thing.  But the question as originally worded didn't make this clear.
"
"Statements cannot go inside of expressions in Python; it was a complication that was deliberately designed out of the language.  For this problem, try using a complication that did make it into the language: generators.  Watch:

def total_and_item(sequence):
    total = 0
    for i in sequence:
        total += i
        yield (total, i)

list2 = list(total_and_item(list1))


The generator keeps a running tally of the items seen so far, and prefixes it to each item, just like it looks like you example tries to do.  Of course, a straightforward loop might be even simpler, that creates an empty list at the top and just calls append() a lot! :-)
",Multiple statements in list compherensions in Python?,"Is it possible to have something like:

list1 = ...

currentValue = 0
list2 = [currentValue += i, i for i in list1]


I tried that but didn't work? What's the proper syntax to write those?

EDIT: the print statement was an example. Actually I am incrementing a value outside the loop.
"
"If your wordlist is very long, might it be more efficient to generate all possible 1-letter-differences from 'word', then check which ones are in the list?  I don't know any Python but there should be a suitable data structure for the wordlist allowing for log-time lookups.

I suggest this because if your words are reasonable lengths (~10 letters), then you'll only be looking for 250 potential words, which is probably faster if your wordlist is larger than a few hundred words.
",How can I optimize this Python code to generate all words with word-distance 1?,"Profiling shows this is the slowest segment of my code for a little word game I wrote:

def distance(word1, word2):
    difference = 0
    for i in range(len(word1)):
        if word1[i] != word2[i]:
            difference += 1
    return difference

def getchildren(word, wordlist):
    return [ w for w in wordlist if distance(word, w) == 1 ]


Notes:


distance() is called over 5 million times, majority of which is from getchildren, which is supposed to get all words in the wordlist that differ from word by exactly 1 letter.
wordlist is pre-filtered to only have words containing the same number of letters as word so it's guaranteed that word1 and word2 have the same number of chars.
I'm fairly new to Python (started learning it 3 days ago) so comments on naming conventions or other style things also appreciated.
for wordlist, take the 12dict word list using the ""2+2lemma.txt"" file


Results:

Thanks everyone, with combinations of different suggestions I got the program running twice as fast now (on top of the optimizations I did on my own before asking, so 4 times speed increase approx from my initial implementation)

I tested with 2 sets of inputs which I'll call A and B

Optimization1: iterate over indices of word1,2 ... from

for i in range(len(word1)):
        if word1[i] != word2[i]:
            difference += 1
    return difference


to iterate on letter-pairs using zip(word1, word2)

for x,y in zip (word1, word2):
        if x != y:
            difference += 1
    return difference


Got execution time from 11.92 to 9.18 for input A, and 79.30 to 74.59 for input B

Optimization2:
Added a separate method for differs-by-one in addition to the distance-method (which I still needed elsewhere for the A* heuristics)

def is_neighbors(word1,word2):
    different = False
    for c1,c2 in zip(word1,word2):
        if c1 != c2:
            if different:
                return False
            different = True
    return different


Got execution time from 9.18 to 8.83 for input A, and 74.59 to 70.14 for input B

Optimization3:
Big winner here was to use izip instead of zip

Got execution time from 8.83 to 5.02 for input A, and 70.14 to 41.69 for input B

I could probably do better writing it in a lower level language, but I'm happy with this for now.  Thanks everyone!

Edit again: More results
Using Mark's method of checking the case where the first letter doesn't match got it down from 5.02 -> 3.59 and 41.69 -> 29.82

Building on that and incorporating izip instead of range, I ended up with this:

def is_neighbors(word1,word2):
    if word1[0] != word2[0]:
        return word1[1:] == word2[1:]
    different = False
    for x,y in izip(word1[1:],word2[1:]):
        if x != y:
            if different:
                return False
            different = True
    return different


Which squeezed a little bit more, bringing the times down from 3.59 -> 3.38 and 29.82 -> 27.88

Even more results!

Trying Sumudu's suggestion that I generate a list of all strings that are 1 letter off from ""word"" and then checking to see which ones were in the wordlist, instead of the is_neighbor function I ended up with this:

def one_letter_off_strings(word):
    import string
    dif_list = []
    for i in xrange(len(word)):
        dif_list.extend((word[:i] + l + word[i+1:] for l in string.ascii_lowercase if l != word[i]))
    return dif_list

def getchildren(word, wordlist):
    oneoff = one_letter_off_strings(word)
    return ( w for w in oneoff if w in wordlist )


Which ended up being slower (3.38 -> 3.74 and 27.88 -> 34.40) but it seemed promising.  At first I thought the part I'd need to optimize was ""one_letter_off_strings"" but profiling showed otherwise and that the slow part was in fact 

( w for w in oneoff if w in wordlist )


I thought if there'd be any difference if I switched ""oneoff"" and ""wordlist"" and did the comparison the other way when it hit me that I was looking for the intersection of the 2 lists.  I replace that with set-intersection on the letters:

return set(oneoff) & set(wordlist)


Bam! 3.74 -> 0.23 and 34.40 -> 2.25

This is truely amazing, total speed difference from my original naive implementation:
23.79 -> 0.23 and 180.07 -> 2.25, so approx 80 to 100 times faster than the original implementation.

If anyone is interested, I made blog post describing the program and describing the optimizations made including one that isn't mentioned here (because it's in a different section of code).

The Great Debate:

Ok, me and Unknown are having a big debate which you can read in the comments of his answer. He claims that it would be faster using the original method (using is_neighbor instead of using the sets) if it was ported to C.  I tried for 2 hours to get a C module I wrote to build and be linkable without much success after trying to follow this and this example, and it looks like the process is a little different in Windows? I don't know, but I gave up on that.  Anyway, here's the full code of the program, and the text file come from the 12dict word list using the ""2+2lemma.txt"" file.  Sorry if the code's a little messy, this was just something I hacked together.  Also I forgot to strip out commas from the wordlist so that's actually a bug that you can leave in for the sake of the same comparison or fix it by adding a comma to the list of chars in cleanentries.

from itertools import izip
def unique(seq):  
    seen = {} 
    result = [] 
    for item in seq: 
        if item in seen:
            continue 
        seen[item] = 1 
        result.append(item) 
    return result
def cleanentries(li):
    pass
    return unique( [w.strip('[]') for w in li if w != ""->""] )
def distance(word1, word2):
    difference = 0
    for x,y in izip (word1, word2):
        if x != y:
            difference += 1
    return difference
def is_neighbors(word1,word2):
    if word1[0] != word2[0]:
        return word1[1:] == word2[1:]
    different = False
    for x,y in izip(word1[1:],word2[1:]):
        if x != y:
            if different:
                return False
            different = True
    return different
def one_letter_off_strings(word):
    import string
    dif_list = []
    for i in xrange(len(word)):
        dif_list.extend((word[:i] + l + word[i+1:] for l in string.ascii_lowercase if l != word[i]))
    return dif_list

def getchildren(word, wordlist):
    oneoff = one_letter_off_strings(word)
    return set(oneoff) & set(wordlist)
def AStar(start, goal, wordlist):
    import Queue
    closedset = []
    openset = [start]
    pqueue = Queue.PriorityQueue(0)
    g_score = {start:0}         #Distance from start along optimal path.
    h_score = {start:distance(start, goal)}
    f_score = {start:h_score[start]}
    pqueue.put((f_score[start], start))
    parent_dict = {}
    while len(openset) > 0:
        x = pqueue.get(False)[1]
        if x == goal:
            return reconstruct_path(parent_dict,goal)
        openset.remove(x)
        closedset.append(x)
        sortedOpen = [(f_score[w], w, g_score[w], h_score[w]) for w in openset]
        sortedOpen.sort()
        for y in getchildren(x, wordlist):
            if y in closedset:
                continue
            temp_g_score = g_score[x] + 1
            temp_is_better = False
            appended = False
            if (not y in openset): 
                openset.append(y)
                appended = True
                h_score[y] = distance(y, goal)
                temp_is_better = True
            elif temp_g_score < g_score[y] :
                temp_is_better = True
            else :
                pass
            if temp_is_better:
                parent_dict[y] = x
                g_score[y] = temp_g_score
                f_score[y] = g_score[y] + h_score[y]
                if appended :
                    pqueue.put((f_score[y], y))
    return None


def reconstruct_path(parent_dict,node):
     if node in parent_dict.keys():
         p = reconstruct_path(parent_dict,parent_dict[node])
         p.append(node)
         return p
     else:
         return []        

wordfile = open(""2+2lemma.txt"")
wordlist = cleanentries(wordfile.read().split())
wordfile.close()
words = []
while True:
    userentry = raw_input(""Hello, enter the 2 words to play with separated by a space:\n "")
    words = [w.lower() for w in userentry.split()]
    if(len(words) == 2 and len(words[0]) == len(words[1])):
        break
print ""You selected %s and %s as your words"" % (words[0], words[1])
wordlist = [ w for w in wordlist if len(words[0]) == len(w)]
answer = AStar(words[0], words[1], wordlist)
if answer != None:
    print ""Minimum number of steps is %s"" % (len(answer))
    reply = raw_input(""Would you like the answer(y/n)? "")
    if(reply.lower() == ""y""):
        answer.insert(0, words[0])
        print ""\n"".join(answer)
    else:
        print ""Good luck!""
else:
    print ""Sorry, there's no answer to yours""
reply = raw_input(""Press enter to exit"")


I left the is_neighbors method in even though it's not used.  This is the method that is proposed to be ported to C.  To use it, just replace getchildren with this:

def getchildren(word, wordlist):
    return ( w for w in wordlist if is_neighbors(word, w))


As for getting it to work as a C module I didn't get that far, but this is what I came up with:

#include ""Python.h""

static PyObject *
py_is_neighbor(PyObject *self, Pyobject *args)
{
    int length;
    const char *word1, *word2;
    if (!PyArg_ParseTuple(args, ""ss"", &word1, &word2, &length))
        return NULL;

    int i;
    int different = 0;
    for (i =0; i < length; i++)
    {
        if (*(word1 + i) != *(word2 + i))
        {
            if (different)
            {
                return Py_BuildValue(""i"", different);
            }
            different = 1;
        }
    }
    return Py_BuildValue(""i"", different);
}

PyMethodDef methods[] = {
    {""isneighbor"", py_is_neighbor, METH_VARARGS, ""Returns whether words are neighbors""},
    {NULL, NULL, 0, NULL}
};

PyMODINIT_FUNC
initIsNeighbor(void)
{
    Py_InitModule(""isneighbor"", methods);
}


I profiled this using:


  python -m cProfile ""Wordgame.py""


And the time recorded was the total time of the AStar method call.  The fast input set was ""verse poets"" and the long input set was ""poets verse"".  Timings will obviously vary between different machines, so if anyone does end up trying this give result comparison of the program as is, as well as with the C module.
"
"EPOLLERR and EPOLLHUP never happens in the code pasted in the post is because they've always occurred in conjunction with an EPOLLIN or an EPOLLOUT (several of these can be set at once), so the if/then/else have always picked up an EPOLLIN or EPOLLOUT.                            

Experimenting I've found that EPOLLHUP only happens in conjunction with EPOLLERR, the reason for this may be the way python interfaces with epoll and lowlevel IO, normally recv would return a -1 and set errno to EAGAIN when nothing is available on a non-blocking recv, however python uses '' (nothing returned) to signal EOF.

Closing your telnet-session only closes that end of the tcp-connection, so it's still perfectly valid to call recv on your side, there may  be pending data in the tcp receive buffers which your application hasn't read yet so that won't trigger an error-condition.

It seems that EPOLLIN and a recv that returns an empty string is indicative of the other end having closed the connection, however, using an older version of python (before epoll were introduced) and plain select on a pipe, I've experienced that a read that returned '' did not indicate EOF just a lack of available data.
",How epoll detect clientside close in Python?,"Here is my server

""""""Server using epoll method""""""

import os
import select
import socket
import time

from oodict import OODict

addr = ('localhost', 8989)

s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
s.bind(addr)
s.listen(8)
s.setblocking(0) # Non blocking socket server
epoll = select.epoll()
epoll.register(s.fileno(), select.EPOLLIN) # Level triggerred

cs = {}
data = ''
while True:
    time.sleep(1)
    events = epoll.poll(1) # Timeout 1 second
    print 'Polling %d events' % len(events)
    for fileno, event in events:
        if fileno == s.fileno():
            sk, addr = s.accept()
            sk.setblocking(0)
            print addr
            cs[sk.fileno()] = sk
            epoll.register(sk.fileno(), select.EPOLLIN)

        elif event & select.EPOLLIN:
            data = cs[fileno].recv(4)
            print 'recv ', data
            epoll.modify(fileno, select.EPOLLOUT)
        elif event & select.EPOLLOUT:
            print 'send ', data
            cs[fileno].send(data)
            data = ''
            epoll.modify(fileno, select.EPOLLIN)

        elif event & select.EPOLLERR:
            print 'err'
            epoll.unregister(fileno)


client side input

ideer@ideer:/home/chenz/source/ideerfs$ telnet localhost 8989
Trying ::1...
Trying 127.0.0.1...
Connected to localhost.
Escape character is '^]'.
123456
123456
^]

telnet> q
Connection closed.


server side output

ideer@ideer:/chenz/source/ideerfs$ python epoll.py 
Polling 0 events
Polling 0 events
Polling 1 events
('127.0.0.1', 53975)
Polling 0 events
Polling 1 events
recv  1234
Polling 1 events
send  1234
Polling 1 events
recv  56

Polling 1 events
send  56

Polling 0 events
Polling 0 events
Polling 0 events
Polling 1 events
recv  
Polling 1 events
send  
Polling 1 events
recv  
Polling 1 events
send  
Polling 1 events
recv  
Polling 1 events
send  
Polling 1 events
recv  
^CTraceback (most recent call last):
  File ""epoll.py"", line 23, in 
    time.sleep(1)
KeyboardInterrupt


It's strange that after the client has closed the connection, epoll still can poll recv and send events! Why does EPOLLERR event never happen? it's the same if you use EPOLLHUP.

I notice that the EPOLLERR event only happens when you try to write a closed connection. 
Besides this, is there another way to tell that whether the connection has been closed or not?

Is it correct to treat the connection as closed if you get nothing in a EPOLLIN event?
"
"If you have spaces in the path, the easiest way I've found to get them interpreted properly is this.

subprocess.call('""""' + path + '""""')


I don't know why exactly it needs double double quotes, but that is what works.
",How to use subprocess when multiple arguments contain spaces?,"I'm working on a wrapper script that will exercise a vmware executable, allowing for the automation of virtual machine startup/shutdown/register/deregister actions.  I'm trying to use subprocess to handle invoking the executable, but the spaces in the executables path and in parameters of the executable are not being handled correctly by subprocess.  Below is a code fragment:

vmrun_cmd = r""c:/Program Files/VMware/VMware Server/vmware-cmd.bat""
def vm_start(target_vm):
    list_arg = ""start""
    list_arg2 = ""hard""
    if vm_list(target_vm):
            p = Popen([vmrun_cmd, target_vm, list_arg, list_arg2],   stdout=PIPE).communicate()[0]
            print p
    else:
            vm_register(target_vm)
            vm_start(target_vm)
def vm_list2(target_vm):
    list_arg = ""-l""
    p = Popen([vmrun_cmd, list_arg], stdout=PIPE).communicate()[0]
    for line in p.split('\n'):
            print line


If I call the vm_list2 function, I get the following output:

$ ./vmware_control.py --list                                                
C:\Virtual Machines\QAW2K3Server\Windows Server 2003 Standard Edition.vmx
C:\Virtual Machines\ubunturouter\Ubuntu.vmx
C:\Virtual Machines\vacc\vacc.vmx
C:\Virtual Machines\EdgeAS-4.4.x\Other Linux 2.4.x kernel.vmx
C:\Virtual Machines\UbuntuServer1\Ubuntu.vmx
C:\Virtual Machines\Other Linux 2.4.x kernel\Other Linux 2.4.x kernel.vmx
C:\Virtual Machines\QAClient\Windows XP Professional.vmx


If I call the vm_start function, which requires a path-to-vm parameter, I get the following output:

$ ./vmware_control.py --start ""C:\Virtual Machines\ubunturouter\Ubuntu.vmx""
'c:\Program' is not recognized as an internal or external command,
operable program or batch file.


Apparently, the presence of a second parameter with embedded spaces is altering the way that subprocess is interpreting the first parameter.  Any suggestions on how to resolve this?

python2.5.2/cygwin/winxp
"
"Yes, but only with new-style classes.  Use the super() function:

class Foo(Bar):
    def baz(self, arg):
        return super(Foo, self).baz(arg)

",Call a parent class's method from child class in Python?,"When creating a simple object hierarchy in Python, I'd like to be able to invoke methods of the parent class from a derived class.  In Perl and Java, there is a keyword for this (super).  In Perl, I might do this:

package Foo;

sub frotz {
    return ""Bamf"";
}

package Bar;
@ISA = qw(Foo);

sub frotz {
   my $str = SUPER::frotz();
   return uc($str);
}


In python, it appears that I have to name the parent class explicitly from the child.
In the example above, I'd have to do something like Foo::frotz().  

This doesn't seem right, since this behavior makes it hard to make deep hierarchies.  If children need to know what class defined an inherited method, then all sorts of information pain is created.  

Is this an actual limitation in python, a gap in my understanding or both?
"
"Starting from Python 3.2 there is a built-in decorator:

@functools.lru_cache(maxsize=100, typed=False)


Decorator to wrap a function with a memoizing callable that saves up to the maxsize most recent calls. It can save time when an expensive or I/O bound function is periodically called with the same arguments.


Example of an LRU cache for computing Fibonacci numbers:

@lru_cache(maxsize=None)
def fib(n):
    if n < 2:
        return n
    return fib(n-1) + fib(n-2)

>>> print([fib(n) for n in range(16)])
[0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610]

>>> print(fib.cache_info())
CacheInfo(hits=28, misses=16, maxsize=None, currsize=16)




If you are stuck with Python 2.x, here's a list of other compatible memoization libraries:


functools32 | PyPI | Source code
repoze.lru | PyPI | Source code
pylru | PyPI | Source code
backports.functools_lru_cache | PyPI | Source code

",Is there a decorator to simply cache function return values?,"Consider the following:

@property
def name(self):

    if not hasattr(self, '_name'):

    	# expensive calculation
    	self._name = 1 + 1

    return self._name


I'm new, but I think the caching could be factored out into a decorator. Only I didn't find one like it ;)

PS the real calculation doesn't depend on mutable values
"
"Without using any external libraries, if that matters to you:

import string
from ctypes import windll

def get_drives():
    drives = []
    bitmask = windll.kernel32.GetLogicalDrives()
    for letter in string.uppercase:
        if bitmask & 1:
            drives.append(letter)
        bitmask >>= 1

    return drives

if __name__ == '__main__':
    print get_drives()     # On my PC, this prints ['A', 'C', 'D', 'F', 'H']

",Is there a way to list all the available drive letters in python?,"More or less what it says on the tin: is there an (easy) way in Python to list all the currently in-use drive letters in a windows system?

(My google-fu seems to have let me down on this one.)

Related:


Enumerating all available drive letters in Windows (C++ / Win32)

"
"Here's the complete regexp to parse a URL.

(?:http://(?:(?:(?:(?:(?:[a-zA-Z\d](?:(?:[a-zA-Z\d]|-)*[a-zA-Z\d])?)\.
)*(?:[a-zA-Z](?:(?:[a-zA-Z\d]|-)*[a-zA-Z\d])?))|(?:(?:\d+)(?:\.(?:\d+)
){3}))(?::(?:\d+))?)(?:/(?:(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F
\d]{2}))|[;:@&=])*)(?:/(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{
2}))|[;:@&=])*))*)(?:\?(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{
2}))|[;:@&=])*))?)?)|(?:ftp://(?:(?:(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?
:%[a-fA-F\d]{2}))|[;?&=])*)(?::(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-
fA-F\d]{2}))|[;?&=])*))?@)?(?:(?:(?:(?:(?:[a-zA-Z\d](?:(?:[a-zA-Z\d]|-
)*[a-zA-Z\d])?)\.)*(?:[a-zA-Z](?:(?:[a-zA-Z\d]|-)*[a-zA-Z\d])?))|(?:(?
:\d+)(?:\.(?:\d+)){3}))(?::(?:\d+))?))(?:/(?:(?:(?:(?:[a-zA-Z\d$\-_.+!
*'(),]|(?:%[a-fA-F\d]{2}))|[?:@&=])*)(?:/(?:(?:(?:[a-zA-Z\d$\-_.+!*'()
,]|(?:%[a-fA-F\d]{2}))|[?:@&=])*))*)(?:;type=[AIDaid])?)?)|(?:news:(?:
(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))|[;/?:&=])+@(?:(?:(
?:(?:[a-zA-Z\d](?:(?:[a-zA-Z\d]|-)*[a-zA-Z\d])?)\.)*(?:[a-zA-Z](?:(?:[
a-zA-Z\d]|-)*[a-zA-Z\d])?))|(?:(?:\d+)(?:\.(?:\d+)){3})))|(?:[a-zA-Z](
?:[a-zA-Z\d]|[_.+-])*)|\*))|(?:nntp://(?:(?:(?:(?:(?:[a-zA-Z\d](?:(?:[
a-zA-Z\d]|-)*[a-zA-Z\d])?)\.)*(?:[a-zA-Z](?:(?:[a-zA-Z\d]|-)*[a-zA-Z\d
])?))|(?:(?:\d+)(?:\.(?:\d+)){3}))(?::(?:\d+))?)/(?:[a-zA-Z](?:[a-zA-Z
\d]|[_.+-])*)(?:/(?:\d+))?)|(?:telnet://(?:(?:(?:(?:(?:[a-zA-Z\d$\-_.+
!*'(),]|(?:%[a-fA-F\d]{2}))|[;?&=])*)(?::(?:(?:(?:[a-zA-Z\d$\-_.+!*'()
,]|(?:%[a-fA-F\d]{2}))|[;?&=])*))?@)?(?:(?:(?:(?:(?:[a-zA-Z\d](?:(?:[a
-zA-Z\d]|-)*[a-zA-Z\d])?)\.)*(?:[a-zA-Z](?:(?:[a-zA-Z\d]|-)*[a-zA-Z\d]
)?))|(?:(?:\d+)(?:\.(?:\d+)){3}))(?::(?:\d+))?))/?)|(?:gopher://(?:(?:
(?:(?:(?:[a-zA-Z\d](?:(?:[a-zA-Z\d]|-)*[a-zA-Z\d])?)\.)*(?:[a-zA-Z](?:
(?:[a-zA-Z\d]|-)*[a-zA-Z\d])?))|(?:(?:\d+)(?:\.(?:\d+)){3}))(?::(?:\d+
))?)(?:/(?:[a-zA-Z\d$\-_.+!*'(),;/?:@&=]|(?:%[a-fA-F\d]{2}))(?:(?:(?:[
a-zA-Z\d$\-_.+!*'(),;/?:@&=]|(?:%[a-fA-F\d]{2}))*)(?:%09(?:(?:(?:[a-zA
-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))|[;:@&=])*)(?:%09(?:(?:[a-zA-Z\d$
\-_.+!*'(),;/?:@&=]|(?:%[a-fA-F\d]{2}))*))?)?)?)?)|(?:wais://(?:(?:(?:
(?:(?:[a-zA-Z\d](?:(?:[a-zA-Z\d]|-)*[a-zA-Z\d])?)\.)*(?:[a-zA-Z](?:(?:
[a-zA-Z\d]|-)*[a-zA-Z\d])?))|(?:(?:\d+)(?:\.(?:\d+)){3}))(?::(?:\d+))?
)/(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))*)(?:(?:/(?:(?:[a-zA
-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))*)/(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(
?:%[a-fA-F\d]{2}))*))|\?(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]
{2}))|[;:@&=])*))?)|(?:mailto:(?:(?:[a-zA-Z\d$\-_.+!*'(),;/?:@&=]|(?:%
[a-fA-F\d]{2}))+))|(?:file://(?:(?:(?:(?:(?:[a-zA-Z\d](?:(?:[a-zA-Z\d]
|-)*[a-zA-Z\d])?)\.)*(?:[a-zA-Z](?:(?:[a-zA-Z\d]|-)*[a-zA-Z\d])?))|(?:
(?:\d+)(?:\.(?:\d+)){3}))|localhost)?/(?:(?:(?:(?:[a-zA-Z\d$\-_.+!*'()
,]|(?:%[a-fA-F\d]{2}))|[?:@&=])*)(?:/(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(
?:%[a-fA-F\d]{2}))|[?:@&=])*))*))|(?:prospero://(?:(?:(?:(?:(?:[a-zA-Z
\d](?:(?:[a-zA-Z\d]|-)*[a-zA-Z\d])?)\.)*(?:[a-zA-Z](?:(?:[a-zA-Z\d]|-)
*[a-zA-Z\d])?))|(?:(?:\d+)(?:\.(?:\d+)){3}))(?::(?:\d+))?)/(?:(?:(?:(?
:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))|[?:@&=])*)(?:/(?:(?:(?:[a-
zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))|[?:@&=])*))*)(?:(?:;(?:(?:(?:[
a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))|[?:@&])*)=(?:(?:(?:[a-zA-Z\d
$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))|[?:@&])*)))*)|(?:ldap://(?:(?:(?:(?:
(?:(?:[a-zA-Z\d](?:(?:[a-zA-Z\d]|-)*[a-zA-Z\d])?)\.)*(?:[a-zA-Z](?:(?:
[a-zA-Z\d]|-)*[a-zA-Z\d])?))|(?:(?:\d+)(?:\.(?:\d+)){3}))(?::(?:\d+))?
))?/(?:(?:(?:(?:(?:(?:(?:[a-zA-Z\d]|%(?:3\d|[46][a-fA-F\d]|[57][Aa\d])
)|(?:%20))+|(?:OID|oid)\.(?:(?:\d+)(?:\.(?:\d+))*))(?:(?:%0[Aa])?(?:%2
0)*)=(?:(?:%0[Aa])?(?:%20)*))?(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F
\d]{2}))*))(?:(?:(?:%0[Aa])?(?:%20)*)\+(?:(?:%0[Aa])?(?:%20)*)(?:(?:(?
:(?:(?:[a-zA-Z\d]|%(?:3\d|[46][a-fA-F\d]|[57][Aa\d]))|(?:%20))+|(?:OID
|oid)\.(?:(?:\d+)(?:\.(?:\d+))*))(?:(?:%0[Aa])?(?:%20)*)=(?:(?:%0[Aa])
?(?:%20)*))?(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))*)))*)(?:(
?:(?:(?:%0[Aa])?(?:%20)*)(?:[;,])(?:(?:%0[Aa])?(?:%20)*))(?:(?:(?:(?:(
?:(?:[a-zA-Z\d]|%(?:3\d|[46][a-fA-F\d]|[57][Aa\d]))|(?:%20))+|(?:OID|o
id)\.(?:(?:\d+)(?:\.(?:\d+))*))(?:(?:%0[Aa])?(?:%20)*)=(?:(?:%0[Aa])?(
?:%20)*))?(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))*))(?:(?:(?:
%0[Aa])?(?:%20)*)\+(?:(?:%0[Aa])?(?:%20)*)(?:(?:(?:(?:(?:[a-zA-Z\d]|%(
?:3\d|[46][a-fA-F\d]|[57][Aa\d]))|(?:%20))+|(?:OID|oid)\.(?:(?:\d+)(?:
\.(?:\d+))*))(?:(?:%0[Aa])?(?:%20)*)=(?:(?:%0[Aa])?(?:%20)*))?(?:(?:[a
-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))*)))*))*(?:(?:(?:%0[Aa])?(?:%2
0)*)(?:[;,])(?:(?:%0[Aa])?(?:%20)*))?)(?:\?(?:(?:(?:(?:[a-zA-Z\d$\-_.+
!*'(),]|(?:%[a-fA-F\d]{2}))+)(?:,(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-f
A-F\d]{2}))+))*)?)(?:\?(?:base|one|sub)(?:\?(?:((?:[a-zA-Z\d$\-_.+!*'(
),;/?:@&=]|(?:%[a-fA-F\d]{2}))+)))?)?)?)|(?:(?:z39\.50[rs])://(?:(?:(?
:(?:(?:[a-zA-Z\d](?:(?:[a-zA-Z\d]|-)*[a-zA-Z\d])?)\.)*(?:[a-zA-Z](?:(?
:[a-zA-Z\d]|-)*[a-zA-Z\d])?))|(?:(?:\d+)(?:\.(?:\d+)){3}))(?::(?:\d+))
?)(?:/(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))+)(?:\+(?:(?:
[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))+))*(?:\?(?:(?:[a-zA-Z\d$\-_
.+!*'(),]|(?:%[a-fA-F\d]{2}))+))?)?(?:;esn=(?:(?:[a-zA-Z\d$\-_.+!*'(),
]|(?:%[a-fA-F\d]{2}))+))?(?:;rs=(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA
-F\d]{2}))+)(?:\+(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))+))*)
?))|(?:cid:(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))|[;?:@&=
])*))|(?:mid:(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))|[;?:@
&=])*)(?:/(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))|[;?:@&=]
)*))?)|(?:vemmi://(?:(?:(?:(?:(?:[a-zA-Z\d](?:(?:[a-zA-Z\d]|-)*[a-zA-Z
\d])?)\.)*(?:[a-zA-Z](?:(?:[a-zA-Z\d]|-)*[a-zA-Z\d])?))|(?:(?:\d+)(?:\
.(?:\d+)){3}))(?::(?:\d+))?)(?:/(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a
-fA-F\d]{2}))|[/?:@&=])*)(?:(?:;(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a
-fA-F\d]{2}))|[/?:@&])*)=(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d
]{2}))|[/?:@&])*))*))?)|(?:imap://(?:(?:(?:(?:(?:(?:(?:[a-zA-Z\d$\-_.+
!*'(),]|(?:%[a-fA-F\d]{2}))|[&=~])+)(?:(?:;[Aa][Uu][Tt][Hh]=(?:\*|(?:(
?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))|[&=~])+))))?)|(?:(?:;[
Aa][Uu][Tt][Hh]=(?:\*|(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2
}))|[&=~])+)))(?:(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))|[
&=~])+))?))@)?(?:(?:(?:(?:(?:[a-zA-Z\d](?:(?:[a-zA-Z\d]|-)*[a-zA-Z\d])
?)\.)*(?:[a-zA-Z](?:(?:[a-zA-Z\d]|-)*[a-zA-Z\d])?))|(?:(?:\d+)(?:\.(?:
\d+)){3}))(?::(?:\d+))?))/(?:(?:(?:(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:
%[a-fA-F\d]{2}))|[&=~:@/])+)?;[Tt][Yy][Pp][Ee]=(?:[Ll](?:[Ii][Ss][Tt]|
[Ss][Uu][Bb])))|(?:(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))
|[&=~:@/])+)(?:\?(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))|[
&=~:@/])+))?(?:(?:;[Uu][Ii][Dd][Vv][Aa][Ll][Ii][Dd][Ii][Tt][Yy]=(?:[1-
9]\d*)))?)|(?:(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))|[&=~
:@/])+)(?:(?:;[Uu][Ii][Dd][Vv][Aa][Ll][Ii][Dd][Ii][Tt][Yy]=(?:[1-9]\d*
)))?(?:/;[Uu][Ii][Dd]=(?:[1-9]\d*))(?:(?:/;[Ss][Ee][Cc][Tt][Ii][Oo][Nn
]=(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))|[&=~:@/])+)))?))
)?)|(?:nfs:(?:(?://(?:(?:(?:(?:(?:[a-zA-Z\d](?:(?:[a-zA-Z\d]|-)*[a-zA-
Z\d])?)\.)*(?:[a-zA-Z](?:(?:[a-zA-Z\d]|-)*[a-zA-Z\d])?))|(?:(?:\d+)(?:
\.(?:\d+)){3}))(?::(?:\d+))?)(?:(?:/(?:(?:(?:(?:(?:[a-zA-Z\d\$\-_.!~*'
(),])|(?:%[a-fA-F\d]{2})|[:@&=+])*)(?:/(?:(?:(?:[a-zA-Z\d\$\-_.!~*'(),
])|(?:%[a-fA-F\d]{2})|[:@&=+])*))*)?)))?)|(?:/(?:(?:(?:(?:(?:[a-zA-Z\d
\$\-_.!~*'(),])|(?:%[a-fA-F\d]{2})|[:@&=+])*)(?:/(?:(?:(?:[a-zA-Z\d\$\
-_.!~*'(),])|(?:%[a-fA-F\d]{2})|[:@&=+])*))*)?))|(?:(?:(?:(?:(?:[a-zA-
Z\d\$\-_.!~*'(),])|(?:%[a-fA-F\d]{2})|[:@&=+])*)(?:/(?:(?:(?:[a-zA-Z\d
\$\-_.!~*'(),])|(?:%[a-fA-F\d]{2})|[:@&=+])*))*)?)))


Given its complexibility, I think you should go the urlparse way.

For completeness, here's the pseudo-BNF of the above regex (as a documentation):

; The generic form of a URL is:

genericurl     = scheme "":"" schemepart

; Specific predefined schemes are defined here; new schemes
; may be registered with IANA

url            = httpurl | ftpurl | newsurl |
                 nntpurl | telneturl | gopherurl |
                 waisurl | mailtourl | fileurl |
                 prosperourl | otherurl

; new schemes follow the general syntax
otherurl       = genericurl

; the scheme is in lower case; interpreters should use case-ignore
scheme         = 1*[ lowalpha | digit | ""+"" | ""-"" | ""."" ]
schemepart     = *xchar | ip-schemepart


; URL schemeparts for ip based protocols:

ip-schemepart  = ""//"" login [ ""/"" urlpath ]

login          = [ user [ "":"" password ] ""@"" ] hostport
hostport       = host [ "":"" port ]
host           = hostname | hostnumber
hostname       = *[ domainlabel ""."" ] toplabel
domainlabel    = alphadigit | alphadigit *[ alphadigit | ""-"" ] alphadigit
toplabel       = alpha | alpha *[ alphadigit | ""-"" ] alphadigit
alphadigit     = alpha | digit
hostnumber     = digits ""."" digits ""."" digits ""."" digits
port           = digits
user           = *[ uchar | "";"" | ""?"" | ""&"" | ""="" ]
password       = *[ uchar | "";"" | ""?"" | ""&"" | ""="" ]
urlpath        = *xchar    ; depends on protocol see section 3.1

; The predefined schemes:

; FTP (see also RFC959)

ftpurl         = ""ftp://"" login [ ""/"" fpath [ "";type="" ftptype ]]
fpath          = fsegment *[ ""/"" fsegment ]
fsegment       = *[ uchar | ""?"" | "":"" | ""@"" | ""&"" | ""="" ]
ftptype        = ""A"" | ""I"" | ""D"" | ""a"" | ""i"" | ""d""

; FILE

fileurl        = ""file://"" [ host | ""localhost"" ] ""/"" fpath

; HTTP

httpurl        = ""http://"" hostport [ ""/"" hpath [ ""?"" search ]]
hpath          = hsegment *[ ""/"" hsegment ]
hsegment       = *[ uchar | "";"" | "":"" | ""@"" | ""&"" | ""="" ]
search         = *[ uchar | "";"" | "":"" | ""@"" | ""&"" | ""="" ]

; GOPHER (see also RFC1436)

gopherurl      = ""gopher://"" hostport [ / [ gtype [ selector
                 [ ""%09"" search [ ""%09"" gopher+_string ] ] ] ] ]
gtype          = xchar
selector       = *xchar
gopher+_string = *xchar

; MAILTO (see also RFC822)

mailtourl      = ""mailto:"" encoded822addr
encoded822addr = 1*xchar               ; further defined in RFC822

; NEWS (see also RFC1036)

newsurl        = ""news:"" grouppart
grouppart      = ""*"" | group | article
group          = alpha *[ alpha | digit | ""-"" | ""."" | ""+"" | ""_"" ]
article        = 1*[ uchar | "";"" | ""/"" | ""?"" | "":"" | ""&"" | ""="" ] ""@"" host

; NNTP (see also RFC977)

nntpurl        = ""nntp://"" hostport ""/"" group [ ""/"" digits ]

; TELNET

telneturl      = ""telnet://"" login [ ""/"" ]

; WAIS (see also RFC1625)

waisurl        = waisdatabase | waisindex | waisdoc
waisdatabase   = ""wais://"" hostport ""/"" database
waisindex      = ""wais://"" hostport ""/"" database ""?"" search
waisdoc        = ""wais://"" hostport ""/"" database ""/"" wtype ""/"" wpath
database       = *uchar
wtype          = *uchar
wpath          = *uchar

; PROSPERO

prosperourl    = ""prospero://"" hostport ""/"" ppath *[ fieldspec ]
ppath          = psegment *[ ""/"" psegment ]
psegment       = *[ uchar | ""?"" | "":"" | ""@"" | ""&"" | ""="" ]
fieldspec      = "";"" fieldname ""="" fieldvalue
fieldname      = *[ uchar | ""?"" | "":"" | ""@"" | ""&"" ]
fieldvalue     = *[ uchar | ""?"" | "":"" | ""@"" | ""&"" ]

; Miscellaneous definitions

lowalpha       = ""a"" | ""b"" | ""c"" | ""d"" | ""e"" | ""f"" | ""g"" | ""h"" |
                 ""i"" | ""j"" | ""k"" | ""l"" | ""m"" | ""n"" | ""o"" | ""p"" |
                 ""q"" | ""r"" | ""s"" | ""t"" | ""u"" | ""v"" | ""w"" | ""x"" |
                 ""y"" | ""z""
hialpha        = ""A"" | ""B"" | ""C"" | ""D"" | ""E"" | ""F"" | ""G"" | ""H"" | ""I"" |
                 ""J"" | ""K"" | ""L"" | ""M"" | ""N"" | ""O"" | ""P"" | ""Q"" | ""R"" |
                 ""S"" | ""T"" | ""U"" | ""V"" | ""W"" | ""X"" | ""Y"" | ""Z""
alpha          = lowalpha | hialpha
digit          = ""0"" | ""1"" | ""2"" | ""3"" | ""4"" | ""5"" | ""6"" | ""7"" |
                 ""8"" | ""9""
safe           = ""$"" | ""-"" | ""_"" | ""."" | ""+""
extra          = ""!"" | ""*"" | ""'"" | ""("" | "")"" | "",""
national       = ""{"" | ""}"" | ""|"" | ""\"" | ""^"" | ""~"" | ""["" | ""]"" | ""`""
punctuation    = """" | ""#"" | ""%"" | 


reserved       = "";"" | ""/"" | ""?"" | "":"" | ""@"" | ""&"" | ""=""
hex            = digit | ""A"" | ""B"" | ""C"" | ""D"" | ""E"" | ""F"" |
                 ""a"" | ""b"" | ""c"" | ""d"" | ""e"" | ""f""
escape         = ""%"" hex hex

unreserved     = alpha | digit | safe | extra
uchar          = unreserved | escape
xchar          = unreserved | reserved | escape
digits         = 1*digit

",How do you validate a URL with a regular expression in Python?,"I'm building an app on Google App Engine. I'm incredibly new to Python and have been beating my head against the following problem for the past 3 days.

I have a class to represent an RSS Feed and in this class I have a method called setUrl. Input to this method is a URL. 

I'm trying to use the re python module to validate off of the RFC 3986 Reg-ex (http://www.ietf.org/rfc/rfc3986.txt)

Below is a snipped which should work? 

p = re.compile('^(([^:/?#]+):)?(//([^/?#]*))?([^?#]*)(\?([^#]*))?(#(.*))?')
m = p.match(url)
if m:
  self.url = url
  return url

"
"Look at getpass module

import getpass
getpass.getuser()
'kostya'


Availability: Unix, Windows



p.s. Per comment below ""this function looks at the values of various environment variables to determine the user name. Therefore, this function should not be relied on for access control purposes (or possibly any other purpose, since it allows any user to impersonate any other).""
",Is there a portable way to get the current username in Python?,"Is there a portable way to get the current user's username in Python (i.e., one that works under both Linux and Windows, at least).  It would work like os.getuid:

>>> os.getuid()
42
>>> os.getusername()
'slartibartfast'


I googled around and was surprised not to find a definitive answer (although perhaps I was just googling poorly).  The pwd module provides a relatively easy way to achieve this under, say, Linux, but it is not present on Windows.  Some of the search results suggested that getting the username under Windows can be complicated in certain circumstances (e.g., running as a Windows service), although I haven't verified that.
"
"I would go with Qt. It works on all the major platforms, and it's being continually improved. You can also get started really fast.
There are bindings for Java, Ruby and Python.
Plus it's free if you're writing open source programs.
",Practical GUI toolkit?,"I am thinking about cross-platform with nice programming language bindings (Java, Ruby and Python).  What would be the ""flattest"" learning curve but yet enough powers to perform most of the standard GUI features? What would you guys/gals recommend; FOX, wx, Tk or Qt?
"
"Neither one is more accurate, they both diverge from the actual answer in equal parts:

>>> (8885558**0.5)**2
8885557.9999999981
>>> sqrt(8885558)**2
8885558.0000000019

>>> 2**1023.99999999999
1.7976931348498497e+308

>>> (sqrt(2**1023.99999999999))**2
1.7976931348498495e+308
>>> ((2**1023.99999999999)**0.5)**2
1.7976931348498499e+308

>>> ((2**1023.99999999999)**0.5)**2 - 2**1023.99999999999
1.9958403095347198e+292
>>> (sqrt(2**1023.99999999999))**2 - 2**1023.99999999999
-1.9958403095347198e+292


http://mail.python.org/pipermail/python-list/2003-November/238546.html


  The math module wraps the platform C
  library math functions of the same
  names; math.pow() is most useful if
  you need (or just want) high
  compatibility with C extensions
  calling C's pow().
  
  __builtin__.pow() is the implementation of Python's infix **
  operator, and deals with complex
  numbers, unbounded integer powers, and
  modular exponentiation too (the C
  pow() doesn't handle any of those).


** is more complete. math.sqrt is probably just the C implementation of sqrt which is probably related to pow.
","Which is more accurate, x**.5 or math.sqrt(x)?","I recently discovered that x**.5 and math.sqrt(x) do not always produce the same result in Python:

Python 2.6.1 (r261:67517, Dec 4 2008, 16:51:00) [MSC v.1500 32 bit (Intel)]
on win32
>>> 8885558**.5 - math.sqrt(8885558)
-4.5474735088646412e-13


Checking all integers below 10**7, the two methods produced different results for almost exactly 0.1% of the samples, with the size of the error increasing (slowly) for larger numbers.

So the question is, which method is more accurate?
"
"To check the existence of a local variable:

if 'myVar' in locals():
  # myVar exists.


To check the existence of a global variable:

if 'myVar' in globals():
  # myVar exists.


To check if an object has an attribute:

if hasattr(obj, 'attr_name'):
  # obj.attr_name exists.

",How do I check if a variable exists?,"I want to check if a variable exists. Now I'm doing something like this:

try:
   myVar
except NameError:
   # Do something.


Are there other ways without exceptions?
"
"If you need efficient vector arithmetic, try Numpy.

>>> import numpy
>>> a=numpy.array([0,1,2])
>>> b=numpy.array([3,4,5])
>>> a+b
array([3, 5, 7])
>>>


Or (thanks, Andrew Jaffe), 

>>> a += b
>>> a
array([3, 5, 7])
>>>

",Concise vector adding in Python?,"I often do vector addition of Python lists.

Example: I have two lists like these:

a = [0.0, 1.0, 2.0]
b = [3.0, 4.0, 5.0]


I now want to add b to a to get the result a = [3.0, 5.0, 7.0].

Usually I end up doing like this:

a[0] += b[0]
a[1] += b[1]
a[2] += b[2]


Is there some efficient, standard way to do this with less typing?

UPDATE: It can be assumed that the lists are of length 3 and contain floats.
"
"You could chain your queries as follows:

values = [1,2,3]

# Turn list of values into list of Q objects
queries = [Q(pk=value) for value in values]

# Take one Q object from the list
query = queries.pop()

# Or the Q object with the ones remaining in the list
for item in queries:
    query |= item

# Query the model
Article.objects.filter(query)

",How to dynamically compose an OR query filter in Django?,"From an example you can see a multiple OR query filter:

Article.objects.filter(Q(pk=1) | Q(pk=2) | Q(pk=3))


For example, this results in:

[, , ]


However, I want to create this query filter from a list. How to do that?

e.g. [1, 2, 3] -> Article.objects.filter(Q(pk=1) | Q(pk=2) | Q(pk=3))
"
"If you want something that will both 


find duplicates and 
handle nested lists (lists of lists of lists of ...)


you can do something like the following:

def get_positions(xs, item):
    if isinstance(xs, list):
        for i, it in enumerate(xs):
            for pos in get_positions(it, item):
                yield (i,) + pos
    elif xs == item:
        yield ()


Testing this:

>>> xs = [['1', '2', '4', '6'],
...       ['7', '0', '1', '4'],
...       [ [ '0', '1', '1'], ['1']]
...       ]
>>> print list(get_positions(xs, '1'))
[(0, 0), (1, 2), (2, 0, 1), (2, 0, 2), (2, 1, 0)]

",How can I find the locations of an item in a Python list of lists?,"I want to find the location(s) of a specific item in a list of lists.  It should return a list of tuples, where each tuple represents the indexes for a specific instance of the item.  For example:

list = [['1', '2', '4', '6'], ['7', '0', '1', '4']]
getPosition('1')  #returns [(0, 0), (1, 2)]
and getPosition('7') #returns [(1,0)]

"
"On Linux, MDBTools is your only chance as of now. [disputed]

On Windows, you can deal with mdb files with pypyodbc.

To create an Access mdb file:

import pypyodbc
pypyodbc.win_create_mdb( ""D:\\Your_MDB_file_path.mdb"" )


Here is an Hello World script that fully demostate pypyodbc's Access support functions.

Disclaimer: I'm the developer of pypyodbc.
",What do I need to read Microsoft Access databases using Python?,"How can I access Microsoft Access databases in Python? With SQL?

I'd prefere a solution that works with Linux, but I could also settle for Windows.

I only require read access.
"
"Here are a couple of links to give you an idea on what you're up against:


How can I run an untrusted Python script safely (i.e. Sandbox)
Capabilities for Python? by Guido himself


There is also a dead google code project at http://code.google.com/p/sandbox-python/
","Is there a ""safe"" subset of Python for use as an embedded scripting language?","In the many Python applications I've created, I often create simple modules containing nothing but constants to be used as config files.  Additionally, because the config file is actually a Python code file, I can add simple logic for changing variables depending on a debug level, etc.

While this works great for internal applications, I'd be wary about releasing such applications into the wild for fear of someone either accidentally, or maliciously, adding destructive code to the file.  The same would hold true for using Python as an embedded scripting language.

Is there a subset of Python that is deemed ""safe"" for embedding? I realize how safe it can be considered is fairly subjective.  However, Java Applets and Flash both have their security sandbox well defined.  I'm wondering if there's a version of Python that has similar rules?

EDIT: I'm asking not so much because of the config file approach, but because I'm interested in implementing some scripting/plugin mechanisms into a newer app and don't want a plugin or script to be able to, say, delete files.  That goes beyond the scope of what the application should be able to do.
"
"There are several different answers I can give here, from your specific question to more general concerns. so from most specific to most general:

Q. Can you put multiple statements in a lambda?

A. No.  But you don't actually need to use a lambda.  You can put the statements in a def instead. ie:

def second_lowest(l):
    l.sort()
    return l[1]

map(second_lowest, lst)


Q. Can you get the second lowest item from a lambda by sorting the list?

A. Yes.  As alex's answer poinst out, sorted() is a version of sort that creates a new list, rather than sorting in-place, and can be chained.  Note that this is probably what you should be using - it's bad practice for your map to have side effects on the original list.

Q. How should I get the second lowest item from each list in a sequence of lists.

A. sorted(l)[1] is not actually the best way for this.  It has O(N log(N)) complexity, while an O(n) solution exists.  This can be found in the heapq module.

>>> import  heapq
>>> l = [5,2,6,8,3,5]
>>> heapq.nsmallest(l, 2)
[2, 3]


So just use:

map(lambda x: heapq.nsmallest(x,2)[1],  list_of_lists)


It's also usually considered clearer to use a list comprehension, which avoids the lambda altogether:

[heapq.nsmallest(x,2)[1] for x in list_of_lists]

",Is it possible to have multiple statements in a python lambda expression?,"I am a python newbie trying to achieve the following:

I have a list of lists:

lst = [[567,345,234],[253,465,756, 2345],[333,777,111, 555]]


I want map lst into another list containing only the second smallest number from each sublist. So the result should be:

[345, 465, 333]


For example if I were just interested in the smallest number, I could do:

map(lambda x: min(x),lst)


I wish I could do this:

map(lambda x: sort(x)[1],lst)


but sort does not chain. (returns None)

neither is something like this allowed:

map(lambda x: sort(x); x[1],lst) #hence the multiple statement question


Is there a way to do this with map in python but without defining a named function? (it is easy with anonymous blocks in ruby, for example)
"
"I would strongly recommend ack, a grep substitute, ""aimed at programmers with large trees of heterogeneous source code"" (from the website)
",How do you grep through code that lives in many different directories?,"I'm working on a Python program that makes heavy use of eggs (Plone). That means there are 198 directories full of Python code I might want to search through while debugging. Is there a good way to search only the .py files in only those directories, avoiding unrelated code and large binary files?
"
"S.Lott has obviously seen some bad code out there. Haven't we all? I do not consider else harmful, though I've seen it used to write bad code. In those cases, all the surrounding code has been bad as well, so why blame poor else?
","""else"" considered harmful in Python?","In an answer (by S.Lott) to a question about Python's try...else statement:


  Actually, even on an if-statement, the
  else: can be abused in truly terrible
  ways creating bugs that are very hard
  to find. [...]
  
  Think twice about else:. It is
  generally a problem. Avoid it except
  in an if-statement and even then
  consider documenting the else-
  condition to make it explicit.


Is this a widely held opinion? Is else considered harmful?

Of course you can write confusing code with it but that's true of any other language construct. Even Python's for...else seems to me a very handy thing to have (less so for try...else). 
"
"Try range(100,-1,-1), the 3rd argument being the increment to use (documented here).
",Loop backwards using indices in Python?,"I am trying to loop from 100 to 0. How do I do this in Python?

for i in range (100,0) doesn't work.
"
"If you are looking for efficiency. Using the translate function is the fastest you can get.

It can be used to quickly replace characters and/or delete them.

import string
delete_table  = string.maketrans(
    string.ascii_lowercase, ' ' * len(string.ascii_lowercase)
)
table = string.maketrans('', '')

""Agh#$%#%2341- -!zdrkfd"".translate(table, delete_table)


In python 2.6: you don't need the second table anymore

import string
delete_table  = string.maketrans(
    string.ascii_lowercase, ' ' * len(string.ascii_lowercase)
)
""Agh#$%#%2341- -!zdrkfd"".translate(None, delete_table)


This is method is way faster than any other. Of course you need to store the delete_table somewhere and use it. But even if you don't store it and build it every time, it is still going to be faster than other suggested methods so far.

To confirm my claims here are the results:

for i in xrange(10000):
    ''.join(c for c in s if c.islower())

real    0m0.189s
user    0m0.176s
sys 0m0.012s


While running the regular expression solution:

for i in xrange(10000):
    re.sub(r'[^a-z]', '', s)

real    0m0.172s
user    0m0.164s
sys 0m0.004s


[Upon request] If you pre-compile the regular expression:

r = re.compile(r'[^a-z]')
for i in xrange(10000):
    r.sub('', s)

real    0m0.166s
user    0m0.144s
sys 0m0.008s


Running the translate method the same number of times took:

real    0m0.075s
user    0m0.064s
sys 0m0.012s

","In Python, How Do You Filter a String Such That Only Characters in Your List Are Returned?","Imagine a string, like 'Agh#$%#%2341-   -!zdrkfd' and I only wish to perform some operating on it such that only the lowercase letters are returned (as an example), which in this case would bring 'ghzdrkfd'.

How do you do this in Python?  The obvious way would be to create a list, of characters, 'a' through 'z', then iterate over the characters in my string and build a new string, character by character, of those in my list only.  This seems primitive.

I was wondering if regular expressions are appropriate.  Replacing unwanted characters seems problematic and I tend to prefer whitelisting over blacklisting.  The .match function does not seem appropriate.  I have looked over the appropriate page on the Python site, but have not found a method which seems to fit.

If regular expressions are not appropriate and the correct approach is looping, is there a simple function which ""explodes"" a string into a list?  Or am I just hitting another for loop there?
"
"I was getting the same error message. What was causing the problem for me was that I named one of my scripts 'string.py'. Every time I tried to run a script with 'string.py' in the same directory this happened.
",Python IDLE subprocess error?,"
  IDLE's subprocess didn't make
  connection. Either IDLE can't start a
  subprocess or personal firewall
  software is blocking the connection.


Don't think this has been asked-how come this comes up occasionally when running very simple programs-I then have to go to Task Manager & stop all Pythonw processes to get it to work again?

It seems to happen randomnly on different bits of code-here is the one I'm doing at the moment-

f = open('money.txt')
currentmoney = float(f.readline())
print(currentmoney, end='')
howmuch = (float(input('How much did you put in or take out?:')))
now = currentmoney + howmuch
print(now)
f.close()
f = open('money.txt', 'w')
f.write(str(now))
f.close()


Sometimes it works, sometimes it doesn't!
"
"If dateutil is missing install it via:

pip install python-dateutil


Or on Ubuntu:

sudo apt-get install python-dateutil

",How to install python-dateutil on Windows?,"I'm trying to convert some date/times to UTC, which I thought would be dead simple in Python - batteries included, right? Well, it would be simple except that Python (2.6) doesn't include any tzinfo classes. No problem, a quick search turns up python-dateutil which should do exactly what I need.

The problem is that I need to install it on Windows. I was able to upack the .tar.gz2 distribution using 7-zip, but now I'm left with a collection of files and no guidance on how to proceed. When I try to run setup.py I get the error ""No module named setuptools"".
"
"Fortunately this is not something that you have to write yourself; the testfixtures package provides a context manager that captures all logging output that occurs in the body of the with statement. You can find the package here:

http://pypi.python.org/pypi/testfixtures

And here are its docs about how to test logging:

http://testfixtures.readthedocs.org/en/latest/logging.html
",How should I verify a log message when testing Python code under nose?,"I'm trying to write a simple unit test that will verify that, under a certain condition, a class in my application will log an error via the standard logging API.  I can't work out what the cleanest way to test this situation is.

I know that nose already captures logging output through it's logging plugin, but this seems to be intended as a reporting and debugging aid for failed tests.  

The two ways to do this I can see are:


Mock out the logging module, either in a piecemeal way (mymodule.logging = mockloggingmodule) or with a proper mocking library.
Write or use an existing nose plugin to capture the output and verify it.


If I go for the former approach, I'd like to know what the cleanest way to reset the global state to what it was before I mocked out the logging module.

Looking forward to your hints and tips on this one...
"
"Try this,

settings.py

# typically, os.path.join(os.path.dirname(__file__), 'media')
MEDIA_ROOT = '/media'
MEDIA_URL = '/media/'


urls.py

urlpatterns = patterns('',
               (r'^media/(?P.*)$', 'django.views.static.serve',
                 {'document_root': settings.MEDIA_ROOT}),
              )


.html

/"" />


Caveat

Beware! using Context() will yield you an empty value for {{MEDIA_URL}}. You must use RequestContext(), instead. 

I hope, this will help.
",How do I include image files in Django templates?,"I'm new to Django and I'm trying to learn it through a simple project I'm developing called 'dubliners' and an app called 'book'. The directory structure is like this:

dubliners/book/  [includes models.py, views.py, etc.]
dubliners/templates/book/


I have a JPG file that needs to be displayed in the header of each Web page. Where should I store the file? Which path should I use for the  tag to display it using a template? I've tried various locations and paths, but nothing is working so far.

...

Thanks for the answer posted below. However, I've tried both relative and absolute paths to the image, and I still get a broken image icon displayed in the Web page. For example, if I have an image in my home directory and use this tag in my template: 




The image doesn't display. If I save the Web page as a static HTML file, however, the images display, so the path is correct. Maybe the default Web server that comes with Django will display images only if they're on a particular path?
"
">>> import numpy as np
>>> A = np.array([[1,2,3,4],[5,6,7,8]])

>>> A
array([[1, 2, 3, 4],
    [5, 6, 7, 8]])

>>> A[:,2] # returns the third columm
array([3, 7])


See also: ""numpy.arange"" and ""reshape"" to allocate memory

Example: (Allocating a array with shaping of matrix (3x4))

nrows = 3
ncols = 4
my_array = numpy.arange(nrows*ncols, dtype='double')
my_array = my_array.reshape(nrows, ncols)

",How do you extract a column from a multi-dimensional array?,"Does anybody know how to extract a column from a multi-dimensional array in Python?
"
"Actually I had the same problem and I realized that, if you add a hyphen between the % and the letter, you can remove the leading zero.

For example %Y/%-m/%-d.

Only works on Unix (Linux, OS X). Doesn't work in Windows (including Cygwin).
",Python strftime - date without leading 0?,"When using Python strftime, is there a way to remove the first 0 of the date if it's before the 10th, ie. so 01 is 1? Can't find a %thingy for that?

Thanks!
"
"Yes. How it will perform is another question.

A good development pattern would be to develop it in pure python, and then profile it, and rewrite performance-critical bottlenecks, either in C/C++/Cython or even python itself but with more efficient code.
",Would it be possible to write a 3D game as large as World of Warcraft in pure Python?,"Would it be possible to write a 3D game as large as World of Warcraft in pure Python?
Assuming the use of DirectX / D3D bindings or OpenGL bindings.

If not, what would be the largest hold-up to doing such a project in Python? I know games tend to fall into the realm of C and C++ but sometimes people do things out of habit!

Any information would help satisfy my curiosity.

Edit:

Would the GIL post a major issue on 3d client performance? And what is the general performance penalty for using say, OpenGL or DirectX bindings vs natively using the libraries?
"
"You can write a little function for that

def maplist(func, values):
    return [map(func, values[i:]) for i in xrange(len(values))]

>>> maplist(lambda a: a* 2, [1,2,3])
[[2, 4, 6], [4, 6], [6]]


[Edit]

if you want to apply the function on the sublists you can change the function to this:

def maplist(func, values):
    return [func(values[i:]) for i in xrange(len(values))]

>>> maplist(lambda l: list(reversed(l)), [1,2,3])
[[3, 2, 1], [3, 2], [3]]

",Python equivalent of maplist?,"What's the best Python equivalent of Common Lisp's maplist function?  From the maplist documentation:


  maplist is like mapcar except that
  function is applied to successive
  sublists of the lists. function is
  first applied to the lists themselves,
  and then to the cdr of each list, and
  then to the cdr of the cdr of each
  list, and so on.


Example (pseudoy-code, not tested):

>>> def p(x): return x
>>> maplist(p, [1,2,3])
[[1, 2, 3], [2, 3], [3]]


Note: the arguments passed to p in the example above would be the lists [1, 2, 3], [2, 3], [3]; i.e., p is not applied to the elements of those lists.  E.g.:

>>> maplist(lambda l: list(reversed(l)), [1,2,3])
[[3, 2, 1], [3, 2], [3]]

"
"class Foo(models.Model):
    a = models.CharField(max_length=42)

class Bar(models.Model):
    b = models.CharField(max_length=42)
    a = models.ForeignKey(Foo, default=lambda: Foo.objects.get(id=1) )

",How do you specify a default for a Django ForeignKey Model or AdminModel field?,"How can I set a default value on a ForeignKey field in a django Model or AdminModel?

Something like this (but of course this doesn't work)...

created_by = models.ForeignKey(User, default=request.user)


I know I can 'trick' it in the view, but in terms of the AdminModel it doesn't seem possible.
"
"math.isnan()


  Checks if the float x is a NaN (not a number). NaNs are part of the IEEE 754 standards. Operation like but not limited to inf * 0, inf / inf or any operation involving a NaN, e.g. nan * 1, return a NaN.
  
  New in version 2.6.


>>> import math
>>> x=float('nan')
>>> math.isnan(x)
True
>>>

",How to check for NaN in python?,"float('nan') results in a thingy simply called nan. But how do I check for it? Should be very easy, but i cannot find it.
"
"How about this?

>>> tuple_list = [(""pineapple"", 5), (""cherry"", 7), (""kumquat"", 3), (""plum"", 11)]
>>> [x for x, y in enumerate(tuple_list) if y[1] == 7]
[1]
>>> [x for x, y in enumerate(tuple_list) if y[0] == 'kumquat']
[2]


As pointed out in the comments, this would get all matches. To just get the first one, you can do:

>>> [y[0] for y in tuple_list].index('kumquat')
2


There is a good discussion in the comments as to the speed difference between all the solutions posted. I may be a little biased but I would personally stick to a one-liner as the speed we're talking about is pretty insignificant versus creating functions and importing modules for this problem, but if you are planning on doing this to a very large amount of elements you might want to look at the other answers provided, as they are faster than what I provided.
",Using Python's list index() method on a list of tuples or objects?,"Python's list type has an index() method that takes one parameter and returns the index of the first item in the list matching the parameter.  For instance:

>>> some_list = [""apple"", ""pear"", ""banana"", ""grape""]
>>> some_list.index(""pear"")
1
>>> some_list.index(""grape"")
3


Is there a graceful (idiomatic) way to extend this to lists of complex objects, like tuples?  Ideally, I'd like to be able to do something like this:

>>> tuple_list = [(""pineapple"", 5), (""cherry"", 7), (""kumquat"", 3), (""plum"", 11)]
>>> some_list.getIndexOfTuple(1, 7)
1
>>> some_list.getIndexOfTuple(0, ""kumquat"")
2


getIndexOfTuple() is just a hypothetical method that accepts a sub-index and a value, and then returns the index of the list item with the given value at that sub-index.  I hope

Is there some way to achieve that general result, using list comprehensions or lambas or something ""in-line"" like that?  I think I could write my own class and method, but I don't want to reinvent the wheel if Python already has a way to do it.
"
"IPython is extremely useful if you like using interactive sessions. For example for your usecase there is the %save magic command, you just input %save my_useful_session 10-20 23 to save input lines 10 to 20 and 23 to my_useful_session.py. (to help with this, every line is prefixed by its number)

Look at the videos on the documentation page to get a quick overview of the features.
",How to save a Python interactive session?,"I find myself frequently using Python's interpreter to work with databases, files, etc -- basically a lot of manual formatting of semi-structured data.  I don't properly save and clean up the useful bits as often as I would like.  Is there a way to save my input into the shell (db connections, variable assignments, little for loops and bits of logic) -- some history of the interactive session?  If I use something like script I get too much stdout noise.  I don't really need to pickle all the objects -- though if there is a solution that does that, it would be OK.  Ideally I would just be left with a script that ran as the one I created interactively, and I could just delete the bits I didn't need.  Is there a package that does this, or a DIY approach?

UPDATE:  I am really amazed at the quality and usefulness of these packages.  For those with a similar itch:


IPython -- should have been using this for ages, kind of what I had in mind
reinteract -- very impressive, I want to learn more about visualization and this seems like it will shine there.  Sort of a gtk/gnome desktop app that renders graphs inline.  Imagine a hybrid shell + graphing calculator + mini eclipse.  Source distribution here: http://www.reinteract.org/trac/wiki/GettingIt . Built fine on Ubuntu, integrates into gnome desktop, Windows and Mac installers too.
bpython -- extremely cool, lots of nice features, autocomplete(!), rewind, one keystroke save to file, indentation, well done.  Python source distribution, pulled a couple of dependencies from sourceforge.


I am converted, these really fill a need between interpreter and editor.
"
"whereis locates man pages, which locates binaries. So try which dot.
","How do I run ""dot"" as a command from Python?","I am using Python on Mac OSX Leopard.

I am trying to run the program 'dot' (part of Graphviz) from Python:

# -*- coding: utf-8 -*-
import os

print os.environ['PATH']
print os.system(""ls >> a.txt"")
print os.system(""dot -o9.png -Tpng ./6.dot"")


The command ""ls"" is there just to make sure that python is in the correct directory. It is. The result that I get is:


  /usr/bin:/bin:/usr/sbin:/sbin
  0
  32512


My understanding is that 32512 error means that python could not find the file, and since the file 6.dot is there (If I run ""dot -o9.png -Tpng ./6.dot"" from the terminal I receive no error, and 9.png gets produced), I assume Python can't find the dot file.

I probably need to add the dot file to the path. But I don't know where is it. If I run: 

whereis dot


I receive no answer.

How can I find the dot executable?
Alternatively, can I run the dot program as a command from inside Python?
"
"Simply use:

MyModel.objects.order_by('?').first()


It is documented in QuerySet API.
",How to pull a random record using Django's ORM?,"I have a model that represents paintings I present on my site. On the main webpage I'd like to show some of them: newest, one that was not visited for most time, most popular one and a random one. 

I'm using Django 1.0.2.

While first 3 of them are easy to pull using django models, last one (random) causes me some trouble. I can ofc code it in my view, to something like this:

number_of_records = models.Painting.objects.count()
random_index = int(random.random()*number_of_records)+1
random_paint = models.Painting.get(pk = random_index)


It doesn't look like something I'd like to have in my view tho - this is entirely part of database abstraction and should be in the model. Also, here I need to take care of removed records (then number of all records won't cover me all the possible key values) and probably lots of other things.

Any other options how I can do it, preferably somehow inside the model abstraction?
"
"You can use BeautifulSoup with this (and other) methods:

soup = BeautifulSoup(source.lower())
to_extract = soup.findAll('script')
for item in to_extract:
    item.extract()


This actually removes the nodes from the HTML.  If you wanted to leave the empty  tags you'll have to work with the item attributes rather than just extracting it from the soup.
",how to remove text between <script> and </script> using python?,"how to remove text between  and  using python?
"
"As many have said, there is no ""offical"" way.  There are, however, many choices.  There was a talk at PyCon this year about many of the available options.
",What's the official way of storing settings for python programs?,"Django uses real Python files for settings, Trac uses a .ini file, and some other pieces of software uses XML files to hold this information.

Are one of these approaches blessed by Guido and/or the Python community more than another?
"
"1) Loop through every line in the log

    a)If line matches appropriate Regex:

      Display/Store Next Line as the item title.
      Look for the next line containing ""Result 
      XXXX."" and parse out that result for 
      including in the result set.


EDIT: added a bit more now that I see the result you're looking for.
",How would I go about parsing the following log?,"I need to parse a log in the following format:

===== Item 5483/14800  =====
This is the item title
Info: some note
===== Item 5483/14800 (Update 1/3) =====
This is the item title
Info: some other note
===== Item 5483/14800 (Update 2/3) =====
This is the item title
Info: some more notes
===== Item 5483/14800 (Update 3/3) =====
This is the item title
Info: some other note
Test finished. Result Foo. Time 12 secunds.
Stats: CPU 0.5 MEM 5.3
===== Item 5484/14800  =====
This is this items title
Info: some note
Test finished. Result Bar. Time 4 secunds.
Stats: CPU 0.9 MEM 4.7
===== Item 5485/14800  =====
This is the title of this item
Info: some note
Test finished. Result FooBar. Time 7 secunds.
Stats: CPU 2.5 MEM 2.8


I only need to extract each item's title (next line after ===== Item 5484/14800  =====) and the result.
So i need to keep only the line with the item title and the result for that title and discard everything else.
The issue is that sometimes a item has notes (maxim 3) and sometimes the result is displayed without additional notes so this makes it tricky.
Any help would be appreciated. I'm doing the parser in python but don't need the actual code but some pointing in how could i achive this?

LE: The result I'm looking for is to discard everything else and get something like:

('This is the item title','Foo')
then
('This is this items title','Bar')

"
"First off -- measure.  Don't just assume that one is better or worse than the other.

Second, if you really don't want to measure, I'd guess the database is a bit faster (assuming the database is relatively local compared to the web service).  Network latency usually is more than parse time unless we're talking a really complex database or really complex XML.
",Is it more efficient to parse external XML or to hit the database?,"I was wondering when dealing with a web service API that returns XML, whether it's better (faster) to just call the external service each time and parse the XML (using ElementTree) for display on your site or to save the records into the database (after parsing it once or however many times you need to each day) and make database calls instead for that same information.
"
"Keeping your data lying around in a header makes it trickier to get at using other programs like Perl. Another approach you might consider is to keep this data in a database or another file and regenerate your header file as-needed, maybe even as part of your build system. The reason for this is that generating C is much easier than parsing C, it's trivial to write a script that parses a text file and makes a header for you, and such a script could even be invoked from your build system. 

Assuming that you want to keep your data in a C header file, you will need one of two things to solve this problem:


a quick one-off script to parse exactly (or close to exactly) the input you describe. 
a general, well-written script that can parse arbitrary C and work generally on to lots of different headers. 


The first case seems more common than the second to me, but it's hard to tell from your question if this is better solved by a script that needs to parse arbitrary C or a script that needs to parse this specific file. For code that works on your specific case, the following works for me on your input:

#!/usr/bin/perl -w

use strict;

open FILE, ""<header.h"" or die $!;
my @file = ;
close FILE or die $!;

my $in_block = 0;
my $regex = 'Some_Idx\[\]';
my $byte_line = '';
my @byte_entries;
foreach my $line (@file) {
    chomp $line;

    if ( $line =~ /$regex.*\{(.*)/ ) {
    	$in_block = 1;
    	my @digits = @{ match_digits($1) };
    	push @digits, @byte_entries;
    	next;
    }

    if ( $in_block ) {
    	my @digits = @{ match_digits($line) };
    	push @byte_entries, @digits;
    }

    if ( $line =~ /\}/ ) {
    	$in_block = 0;
    }
}

print ""const BYTE Some_Idx_Mod_mul_2[] = {\n"";
print join "","", map { $_ * 2 } @byte_entries;
print ""};\n"";

sub match_digits {
    my $text = shift;
    my @digits;
    while ( $text =~ /(\d+),*/g ) {
    	push @digits, $1;
    }

    return \@digits;
}


Parsing arbitrary C is a little tricky and not worth it for many applications, but maybe you need to actually do this. One trick is to let GCC do the parsing for you and read in GCC's parse tree using a CPAN module named GCC::TranslationUnit. 
Here's the GCC command to compile the code, assuming you have a single file named test.c:

gcc -fdump-translation-unit -c test.c 

Here's the Perl code to read in the parse tree:

  use GCC::TranslationUnit;

  # echo '#include ' > stdio.c
  # gcc -fdump-translation-unit -c stdio.c
  $node = GCC::TranslationUnit::Parser->parsefile('stdio.c.tu')->root;

  # list every function/variable name
  while($node) {
    if($node->isa('GCC::Node::function_decl') or
       $node->isa('GCC::Node::var_decl')) {
      printf ""%s declared in %s\n"",
        $node->name->identifier, $node->source;
    }
  } continue {
    $node = $node->chain;
  }

",How can I parse a C header file with Perl?,"I have a header file in which there is a large struct. I need to read this structure using some program and make some operations on each member of the structure and write them back.

For example I have some structure like 

const BYTE Some_Idx[] = {
4,7,10,15,17,19,24,29,
31,32,35,45,49,51,52,54,
55,58,60,64,65,66,67,69,
70,72,76,77,81,82,83,85,
88,93,94,95,97,99,102,103,
105,106,113,115,122,124,125,126,
129,131,137,139,140,149,151,152,
153,155,158,159,160,163,165,169,
174,175,181,182,183,189,190,193,
197,201,204,206,208,210,211,212,
213,214,215,217,218,219,220,223,
225,228,230,234,236,237,240,241,
242,247,249};


Now, I need to read this and apply some operation on each of the member variable and create a new structure with different order, something like:

const BYTE Some_Idx_Mod_mul_2[] = {
8,14,20, ...
...
484,494,498};


Is there any Perl library already available for this? If not Perl, something else like Python is also OK.

Can somebody please help!!!
"
"You have a few options:


Run the program from an already-open terminal. Open a command prompt and type:

python myscript.py


For that to work you need the python executable in your path. Just check on how to edit environment variables on Windows, and add C:\PYTHON26 (or whatever directory you installed python to).

When the program ends, it'll drop you back to the cmd prompt instead of closing the window.
Add code to wait at the end of your script. Adding ...

raw_input()


... at the end of the script makes it wait for the Enter key. That method is annoying because you have to modify the script, and have to remember removing it when you're done. Specially annoying when testing other people's scripts.
Use an editor that pauses for you. Some editors prepared for python will automatically pause for you after execution. Other editors allow you to configure the command line it uses to run your program. I find it particularly useful to configure it as ""python -i myscript.py"" when running. That drops you to a python shell after the end of the program, with the program environment loaded, so you may further play with the variables and call functions and methods.

",How to keep a Python script output window open?,"I have just started with Python. When I execute a python script file on Windows, the output window appears but instantaneously goes away. I need it to stay there so I can analyze my output. How can I keep it open?
"
"You don't need regular expressions, Python has a string method that does what you need:

mystring.replace ("" "", ""_"")

",How do I replace whitespaces with underscore and vice versa?,"I want to replace whitespace with underscore in a string to create nice URLs. So that for example:

""This should be connected"" becomes ""This_should_be_connected""


I am using Python with Django. Can this be solved using regular expressions?  
"
"Funny that after all these hours nobody's yet given a solution to the problem as actually phrased (as @John Machin points out in a comment) -- remove just the leading marker (if followed by another such marker 3 lines down), not the whole line containing it. It's not hard, of course -- here's a tiny mod as needed of @truppo's fun solution, for example:

from itertools import izip, chain
f = ""foo.txt""
for third, line in izip(chain(""   "", open(f)), open(f)):
    if third.startswith(""@STRING_A"") and line.startswith(""@STRING_A""):
        line = line[len(""@STRING_A""):]
    print line,


Of course, in real life, one would use an iterator.tee instead of reading the file twice, have this code in a function, not repeat the marker constant endlessly, &c;-).
",Bash or Python to go backwards?,"I have a text file which a lot of random occurrences of the string @STRING_A, and I would be interested in writing a short script which removes only some of them. Particularly one that scans the file and once it finds a line which starts with this string like

@STRING_A


then checks if 3 lines backwards there is another occurrence of a line starting with the same string, like

@STRING_A


@STRING_A


and if it happens, to delete the occurrence 3 lines backward. I was thinking about bash, but I do not know how to ""go backwards"" with it. So I am sure that this is not possible with bash. I also thought about python, but then I should store all information in memory in order to go backwards and then, for long files it would be unfeasible. 

What do you think? Is it possible to do it in bash or python?

Thanks
"
"Python uses spacing at the start of the line to determine when code blocks start and end. Errors you can get are:

Unexpected indent. This line of code has more spaces at the start than the one before, but the one before is not the start of a subblock (e.g. if/while/for statement). All lines of code in a block must start with exactly the same string of whitespace. For instance:

>>> def a():
...   print ""foo""
...     print ""bar""
IndentationError: unexpected indent


This one is especially common when running python interactively: make sure you don't put any extra spaces before your commands. (Very annoying when copy-and-pasting example code!)

>>>   print ""hello""
IndentationError: unexpected indent


Unindent does not match any outer indentation level. This line of code has fewer spaces at the start than the one before, but equally it does not match any other block it could be part of. Python cannot decide where it goes. For instance, in the following, is the final print supposed to be part of the if clause, or not?

>>> if user == ""Joey"":
...     print ""Super secret powers enabled!""
...   print ""Revealing super secrets""
IndendationError: unindent does not match any outer indentation level


Expected an indented block. This line of code has the same number of spaces at the start as the one before, but the last line was expected to start a block (e.g. if/while/for statement, function definition).

>>> def foo():
... print ""Bar""
IndentationError: expected an indented block


If you want a function that doesn't do anything, use the ""no-op"" command pass:

>>> def foo():
...     pass


Mixing tabs and spaces is allowed (at least on my version of Python), but Python assumes tabs are 8 characters long, which may not match your editor. Just say ""no"" to tabs. Most editors allow them to be automatically replaced by spaces.

The best way to avoid these issues is to always use a consistent number of spaces when you indent a subblock, and ideally use a good IDE that solves the problem for you. This will also make your code more readable.
","What to do with ""Unexpected indent"" in python?","How do I rectify the error ""unexpected indent"" in python?
"
"The question you reference asks which languages promote both OO and functional programming. Python does not promote functional programming even though it works fairly well.

The best argument against functional programming in Python is that imperative/OO use cases are carefully considered by Guido, while functional programming use cases are not. When I write imperative Python, it's one of the prettiest languages I know. When I write functional Python, it becomes as ugly and unpleasant as your average language that doesn't have a BDFL.

Which is not to say that it's bad, just that you have to work harder than you would if you switched to a language that promotes functional programming or switched to writing OO Python.

Here are the functional things I miss in Python:


Pattern matching
Tail recursion
Large library of list functions
Functional dictionary class
Automatic currying
Concise way to compose functions
Lazy lists
Simple, powerful expression syntax (Python's simple block syntax prevents Guido from adding it)





No pattern matching and no tail recursion mean your basic algorithms have to be written imperatively. Recursion is ugly and slow in Python.
A small list library and no functional dictionaries mean that you have to write a lot of stuff yourself. 
No syntax for currying or composition means that point-free style is about as full of punctuation as explicitly passing arguments.
Iterators instead of lazy lists means that you have to know whether you want efficiency or persistence, and to scatter calls to list around if you want persistence. (Iterators are use-once)
Python's simple imperative syntax, along with its simple LL1 parser, mean that a better syntax for if-expressions and lambda-expressions is basically impossible. Guido likes it this way, and I think he's right.

",Why isn't Python very good for functional programming?,"I have always thought that functional programming can be done in Python. Thus, I was surprised that Python didn't get much of a mention in this question, and when it was mentioned, it normally wasn't very positive. However, not many reasons were given for this (lack of pattern matching and algebraic data types were mentioned). So my question is: why isn't Python very good for functional programming? Are there more reasons than its lack of pattern matching and algebraic data types? Or are these concepts so important to functional programming that a language that doesn't support them can only be classed as a second rate functional programming language? (Keep in mind that my experience with functional programming is quite limited.)
"
"You are referring to the run-time duck-typing as ""overriding"" inheritance, however I believe inheritance has its own merits as a design and implementation approach, being an integral part of object oriented design. In my humble opinion, the question of whether you can achieve something otherwise is not very relevant, because actually you could code Python without classes, functions and more, but the question is how well-designed, robust and readable your code will be.

I can give two examples for where inheritance is the right approach in my opinion, I'm sure there are more. 

First, if you code wisely, your makeSpeak function may want to validate that its input is indeed an Animal, and not only that ""it can speak"", in which case the most elegant method would be to use inheritance. Again, you can do it in other ways, but that's the beauty of object oriented design with inheritance - your code will ""really"" check whether the input is an ""animal"".

Second, and clearly more straightforward, is Encapsulation - another integral part of object oriented design. This becomes relevant when the ancestor has data members and/or non-abstract methods. Take the following silly example, in which the ancestor has a function (speak_twice) that invokes a then-abstract function:

class Animal(object):
    def speak(self):
        raise NotImplementedError()

    def speak_twice(self):
        self.speak()
        self.speak()

class Dog(Animal):
    def speak(self):
        print ""woff!""

class Cat(Animal):
    def speak(self):
        print ""meow""


Assuming ""speak_twice"" is an important feature, you don't want to code it in both Dog and Cat, and I'm sure you can extrapolate this example. Sure, you could implement a Python stand-alone function that will accept some duck-typed object, check whether it has a speak function and invoke it twice, but that's both non-elegant and misses point number 1 (validate it's an Animal). Even worse, and to strengthen the Encapsulation example, what if a member function in the descendant class wanted to use ""speak_twice""?

It gets even clearer if the ancestor class has a data member, for example ""number_of_legs"" that is used by non-abstract methods in the ancestor like ""print_number_of_legs"", but is initiated in the descendant class' constructor (e.g. Dog would initialize it with 4 whereas Snake would initialize it with 0). 

Again, I'm sure there are endless more examples, but basically every (large enough) software that is based on solid object oriented design will require inheritance.
",Whatâs the point of inheritance in Python?,"Suppose you have the following situation

#include 

class Animal {
public:
    virtual void speak() = 0;
};

class Dog : public Animal {
    void speak() { std::cout << ""woff!"" <<std::endl; }
};

class Cat : public Animal {
    void speak() { std::cout << ""meow!"" <<std::endl; }
};

void makeSpeak(Animal &a) {
    a.speak();
}

int main() {
    Dog d;
    Cat c;
    makeSpeak(d);
    makeSpeak(c);
}


As you can see, makeSpeak is a routine that accepts a generic Animal object. In this case, Animal is quite similar to a Java interface, as it contains only a pure virtual method. makeSpeak does not know the nature of the Animal it gets passed. It just sends it the signal âspeakâ and leaves the late binding to take care of which method to call: either Cat::speak() or Dog::speak(). This means that, as far as makeSpeak is concerned, the knowledge of which subclass is actually passed is irrelevant.

But what about Python? Letâs see the code for the same case in Python. Please note that I try to be as similar as possible to the C++ case for a moment:

class Animal(object):
    def speak(self):
        raise NotImplementedError()

class Dog(Animal):
    def speak(self):
        print ""woff!""

class Cat(Animal):
    def speak(self):
        print ""meow""

def makeSpeak(a):
    a.speak()

d=Dog()
c=Cat()
makeSpeak(d)
makeSpeak(c)


Now, in this example you see the same strategy. You use inheritance to leverage the hierarchical concept of both Dogs and Cats being Animals. 
But in Python, thereâs no need for this hierarchy. This works equally well

class Dog:
    def speak(self):
        print ""woff!""

class Cat:
    def speak(self):
        print ""meow""

def makeSpeak(a):
    a.speak()

d=Dog()
c=Cat()
makeSpeak(d)
makeSpeak(c)


In Python you can send the signal âspeakâ to any object you want. If the object is able to deal with it, it will be executed, otherwise it will raise an exception. Suppose you add a class Airplane to both codes, and submit an Airplane object to makeSpeak. In the C++ case, it wonât compile, as Airplane is not a derived class of Animal. In the Python case, it will raise an exception at runtime, which could even be an expected behavior.

On the other side, suppose you add a MouthOfTruth class with a method speak(). In the C++ case, either you will have to refactor your hierarchy, or you will have to define a different makeSpeak method to accept MouthOfTruth objects, or in java you could extract the behavior into a CanSpeakIface and implement the interface for each. There are many solutions...

What Iâd like to point out is that I havenât found a single reason yet to use inheritance in Python (apart of frameworks and trees of exceptions, but I guess that alternative strategies exist). you donât need to implement a base-derived hierarchy to perform polymorphically. If you want to use inheritance to reuse implementation, you can accomplish the same through containment and delegation, with the added benefit that you can alter it at runtime, and you clearly define the interface of the contained, without risking unintended side effects.

So, in the end, the question stands: what's the point of inheritance in Python?

Edit: thanks for the very interesting answers. Indeed you can use it for code reuse, but I am always careful when reusing implementation. In general, I tend to do very shallow inheritance trees or no tree at all, and if a functionality is common I refactor it out as a common module routine and then call it from each object. I do see the advantage of having one single point of change (eg. instead of adding to Dog, Cat, Moose and so on, I just add to Animal, which is the basic advantage of inheritance), but you can achieve the same with a delegation chain (eg. a la JavaScript). I'm not claiming it's better though, just another way.

I also found a similar post on this regard.
"
">>> d = {'key':'value'}
>>> print d
{'key': 'value'}
>>> d['mynewkey'] = 'mynewvalue'
>>> print d
{'mynewkey': 'mynewvalue', 'key': 'value'}

",Add key to a dictionary in Python?,"Is it possible to add a key to a Python dictionary after it has been created? It doesn't seem to have an .add() method.
"
"res = dict((v,k) for k,v in a.iteritems())

",Python: Best Way to Exchange Keys with Values in a Dictionary?,"I receive a dictionary as input, and would like to to return a dictionary whose keys will be the input's values and whose value will be the corresponding input keys. Values are unique.

For example, say my input is:

a = dict()
a['one']=1
a['two']=2


I would like my output to be:

{1: 'one', 2: 'two'}


To clarify I would like my result to be the equivalent of the following:

res = dict()
res[1] = 'one'
res[2] = 'two'


Any neat Pythonian way to achieve this?

Thanks
"
"I think efficient way if dict is too large would be

countMap = {}
for v in a.itervalues():
    countMap[v] = countMap.get(v,0) + 1
uni = [ k for k, v in a.iteritems() if countMap[v] == 1]

",Python: finding keys with unique values in a dictionary?,"I receive a dictionary as input, and want to return a list of keys for which the dictionary values are unique in the scope of that dictionary.

I will clarify with an example. Say my input is dictionary a, constructed as follows:

a = dict()
a['cat'] =      1
a['fish'] =     1
a['dog'] =      2  # <-- unique
a['bat'] =      3
a['aardvark'] = 3
a['snake'] =    4  # <-- unique
a['wallaby'] =  5
a['badger'] =   5


The result I expect is ['dog', 'snake'].

There are obvious brute force ways to achieve this, however I wondered if there's a neat Pythonian way to get the job done.
"
"def xstr(s):
    return '' if s is None else str(s)

",Python: most idiomatic way to convert None to empty string?,"What is the most idiomatic way to do the following?

def xstr(s):
    if s is None:
        return ''
    else:
        return s

s = xstr(a) + xstr(b)


update: I'm incorporating Tryptich's suggestion to use str(s), which makes this routine work for other types besides strings.  I'm awfully impressed by Vinay Sajip's lambda suggestion, but I want to keep my code relatively simple.

def xstr(s):
    if s is None:
        return ''
    else:
        return str(s)

"
"Try:

2**3*2


and

2*3*2


to see the difference.

** is the operator for ""power of"". In your particular operation, 2 to the power of 2 yields the same as 2 times 2. 
","What's the difference between ""2*2"" and ""2**2"" in Python?","What is the difference between the following codes?

code1:

var=2**2*3


code2:

var2=2*2*3


I see no difference. 
This raises the following question.

Why is the code1 used if we can use code2?
"
"Quote: ""If it doesn't break, don't fix it.""

Unless your company is moving towards .NET and/or there are no more qualified Python developer available anymore, then don't.
",Is there any good reason to convert an app written in python to c#?,"I have written several Python tools for my company.  Is there any good reason to convert them from Python to C# now that their usefulness has been proven?  Would I be better off just leaving them in Python?
"
"correct for most circumstances

The runtime/language/compiler will abstract those details unless you are dealing directly with word sizes or binary at a low level.

Even byteorder is abstracted by the NIC/Network stack in the kernel. It is translated for you. When programming sockets in C, you do sometimes have to deal with byte ordering for the network when sending data ... but that doesn't concern 32 or 64 bit differences.

When dealing with blobs of binary data, mapping them from one architecture to another (as an overlay to a C struct for example) can cause problems as others have mentioned, but this is why we develop architecture independent protocols based on characters and so on.

In-fact things like Java run in a virtual machine that abstracts the machine another step!

Knowing a bit about the instruction set of the architecture, and how the syntax is compiled to that can help you understand the platform and write cleaner, tighter code. I know I grimace at some old C code after studying compilers!
",Would one have to know the machine architecture to write code?,"Let's say I'm programming in Java or Python or C++ for a simple problem, could be to build an TCP/UDP echo server or computation of factorial. Do I've to bother about the architecture details, i.e., if it is 32 or 64-bit?

IMHO, unless I'm programming something to do with fairly low-level stuff then I don't have to bother if its 32 or 64 bit. Where am I going wrong? Or am I correct???
"
"This is almost the exact same algorithm described in Anurag Uniyal's answer, except using the file as an iterator instead of readline():

from collections import defaultdict
try:
  from io import StringIO # 2.6+, 3.x
except ImportError:
  from StringIO import StringIO # 2.5

data = defaultdict(int)

#with open(""filename"", ""r"") as f: # if a real file
with StringIO(""10\n5\n-1\n-1\n-1\n1\n1\n0\n2"") as f:
  for line in f:
    data[int(line)] += 1

for number, count in data.iteritems():
  print number, ""was found"", count, ""times""

",How to use dict in python?,"10
5
-1
-1
-1
1
1
0
2
...


If I want to count the number of occurrences of each number in a file, how do I use python to do it?
"
"First, use a logging library like SLF4J/Logback that allows you to make this decision dynamically.  Then you can tweak a configuration file and route some or all of your log messages to each of several different destinations.

Be very careful before logging to your application database, you can easily overwhelm it if you're logging a lot of stuff and volume starts to get high.  And if your application is running close to full capacity or in a failure mode, the log messages may be inaccessible and you'll be flying blind.  Probably the only messages that should go to your application database are high-level application-oriented events (a type of application data).

It's much better to ""log to the file system"" (which for a large production environment includes logging to a multicast address read by redundant log aggregation servers).  

Log files can be read into special analytics databases where you could use eg, Hadoop to do map/reduce analyses of log data.
",Server Logging - in Database or Logfile?,"I've been working on a server and I'm starting to implement logging.  However, I'm not sure whether I should use the db for logging, or just a plaintext file.

I'm planning on logging some basic information for every request (what type of request, ip address of request, session tracking).  For some requests there will be extended information present (details on what type of request was made), and if there are any errors I will log those, too.

On the one hand, putting the logs into the db means I could run queries on the logged data.  On the other hand, I'm not sure if this would be putting unnecessary strain on the db.  Of course, I could also use both the db and a log file for logging.  What are people's thoughts on proper logging?

(If it makes a difference, I'm using mod_python on an Apache server with a MySQL db.  So I'd either be using the logging library or just creating some logging tables in the db.)
"
"The answer by Ber - storing it in threadlocals - is a very bad idea. There's absolutely no reason to do it this way.

A much better way is to override the form's __init__ method to take an extra keyword argument, request. This stores the request in the form, where it's required, and from where you can access it in your clean method.

class MyForm(forms.Form):

    def __init__(self, *args, **kwargs):
        self.request = kwargs.pop('request', None)
        super(MyForm, self).__init__(*args, **kwargs)


    def clean(self):
        ... access the request object via self.request ...


and in your view:

myform = MyForm(request.POST, request=request)

",How do I access the request object or any other variable in a form's clean() method?,"I am trying to request.user for a form's clean method, but how can I access the request object? Can I modify the clean method to allow variables input?
"
"To run only a single specific test you can use:

$ python -m unittest test_module.TestClass.test_method


More information here
",Python unittest: how to run only part of a test file?,"I have a test file that contains tests taking quite a lot of time (they send calculations to a cluster and wait for the result). All of these are in specific TestCase class.

Since they take time and furthermore are not likely to break, I'd want to be able to choose whether this subset of tests does or doesn't run (the best way would be with a command-line argument, ie ""./tests.py --offline"" or something like that), so I could run most of the tests often and quickly and the whole set once in a while, when I have time.

For now, I just use unittest.main() to start the tests.

Thanks.
"
"You can have nested iterations in a single list comprehension:

[filename for path in dirs for filename in os.listdir(path)]

",python list comprehensions; compressing a list of lists?,"guys. I'm trying to find the most elegant solution to a problem and wondered if python has anything built-in for what I'm trying to do. 

What I'm doing is this. I have a list, A, and I have a function f which takes an item and returns a list. I can use a list comprehension to convert everything in A like so;

[f(a) for a in A]


But this return a list of lists;

[a1,a2,a3] => [[b11,b12],[b21,b22],[b31,b32]]


What I really want is to get the flattened list;

[b11,b12,b21,b22,b31,b32]


Now, other languages have it; it's traditionally called flatmap in functional programming languages, and .Net calls it SelectMany. Does python have anything similar? Is there a neat way to map a function over a list and flatten the result?

The actual problem I'm trying to solve is this; starting with a list of directories, find all the subdirectories. so;

import os
dirs = [""c:\\usr"", ""c:\\temp""]
subs = [os.listdir(d) for d in dirs]
print subs


currentliy gives me a list-of-lists, but I really want a list.
"
"You could make your own ""each"" function:



def each(fn, items):
    for item in items:
        fn(item)


# called thus
each(lambda x: installWow(x, 'installed by me'), wowList)



Basically it's just map, but without the results being returned.  By using a function you'll ensure that the ""item"" variable doesn't leak into the current scope.
",Is there a map without result in python?,"Sometimes, I just want to execute a function for a list of entries -- eg.:

for x in wowList:
   installWow(x, 'installed by me')


Sometimes I need this stuff for module initialization, so I don't want to have a footprint like x in global namespace. One solution would be to just use map together with lambda:

map(lambda x: installWow(x, 'installed by me'), wowList)


But this of course creates a nice list [None, None, ...] so my question is, if there is a similar function without a return-list -- since I just don't need it.

(off course I can also use _x and thus not leaving visible footprint -- but the map-solution looks so neat ...)
"
"eval and exec are handy quick-and-dirty way to get some source code dynamically, maybe munge it a bit, and then execute it -- but they're hardly ever the best way, especially in production code as opposed to ""quick-and-dirty"" prototypes &c.

For example, if I had to deal with such dynamic Python sources, I'd reach for the ast module -- ast.literal_eval is MUCH safer than eval (you can call it directly on a string form of the expression, if it's a one-off and relies on simple constants only, or do node = ast.parse(source) first, then keep the node around, perhaps munge it with suitable visitors e.g. for variable lookup, then literal_eval the node) -- or, once having put the node in proper shape and vetted it for security issues, I could compile it (yielding a code object) and build a new function object out of that. Far less simple (except that ast.literal_eval is just as simple as eval for the simplest cases!) but safer and preferable in production-quality code.

For many tasks I've seen people (ab-)use exec and eval for, Python's powerful built-ins, such as getattr and setattr, indexing into globals(), &c, provide preferable and in fact often simpler solutions. For specific uses such as parsing JSON, library modules such as json are better (e.g. see SilentGhost's comment on tinnitus' answer to this very question). Etc, etc...
",Use of eval in Python?,"There is an eval() function in Python I stumbled upon while playing around. I cannot think of a case when this function is needed, except maybe as syntactic sugar. Can anyone give an example?
"
"FTP is quite a rudimentary protocol and there's no built-in protocol query allowing you to get the type (file, dir) of each node, so a heuristic like the one you found is the only solution.

If getting the size of each node doesn't work, perhaps you should consider calling FTP.nlst() on each of those nodes: those that error out will be files rather than dirs.
",ftplib checking if a file is a folder?,"How can i check if a file on a remote ftp is a folder or not using ftplib?

Best way i have right now is to do a nlst, and iterate through calling size on each of the files, if the file errors out then it is a folder?

Is there a better way? I cannot parse the output of list, since there is about a dozen different ftp servers(many extremely old.)

What should i do?
"
"Unless you really need the features of an integer (that is, the ability to do arithmetic), then it is probably better for you to store the product IDs as strings. You will never need to do anything like add two product IDs together, or compute the average of a group of product IDs, so there is no need for an actual numeric type.

It is unlikely that storing product IDs as strings will cause a measurable difference in performance. While there will be a slight increase in storage size, the size of a product ID string is likely to be much smaller than the data in the rest of your database row anyway.

Storing product IDs as strings today will save you much pain in the future if the data provider decides to start using alphabetic or symbol characters. There is no real downside.
",Any drawbacks to storing an integer as a string in a database?,"I have id values for products that I need store. Right now they are all integers, but I'm not sure if the data provider in the future will introduce letters or symbols into that mix, so I'm debating whether to store it now as integer or string.

Are there performance or other disadvantages to saving the values as strings?
"
"This information is available in the sys.version string in the sys module:

>>> import sys


Human readable:

>>> print (sys.version) #parentheses necessary in python 3.       
2.5.2 (r252:60911, Jul 31 2008, 17:28:52) 
[GCC 4.2.3 (Ubuntu 4.2.3-2ubuntu7)]


For further processing:

>>> sys.version_info
(2, 5, 2, 'final', 0)
# or
>>> sys.hexversion
34014192


To ensure a script runs with a minimal version requirement of the Python interpreter add this to your code:

assert sys.version_info >= (2,5)


This compares major and minor version information. Add micro (=0, 1, etc) and even releaselevel (='alpha','final', etc) to the tuple as you like. Note however, that it is almost always better to ""duck"" check if a certain feature is there, and if not, workaround (or bail out). Sometimes features go away in newer releases, being replaced by others.
",How do I check what version of Python is running my script?,"How can I check what version of the Python Interpreter is interpreting my script?
"
"Addressing the above ""too small a task to require a library"" issue by a straightforward implementation:

def sizeof_fmt(num, suffix='B'):
    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:
        if abs(num) < 1024.0:
            return ""%3.1f%s%s"" % (num, unit, suffix)
        num /= 1024.0
    return ""%.1f%s%s"" % (num, 'Yi', suffix)


Supports:


all currently known binary prefixes
negative and positive numbers
numbers larger than 1000 Yobibytes
arbitrary units (maybe you like to count in Gibibits!)


Example:

>>> sizeof_fmt(168963795964)
'157.4GiB'


by Fred Cirera
",Reusable library to get human readable version of file size?,"There are various snippets on the web that would give you a function to return human readable size from bytes size:

>>> human_readable(2048)
'2 kilobytes'
>>>


But is there a Python library that provides this?
"
"IBM's ICU library does that (and a lot more). It has Python bindings: PyICU. 

Update: The core difference in sorting between ICU and locale.strcoll is that ICU uses the full Unicode Collation Algorithm while strcoll uses ISO 14651.

The differences between those two algorithms are briefly summarized here: http://unicode.org/faq/collation.html#13. These are rather exotic special cases, which should rarely matter in practice.

>>> import icu # pip install PyICU
>>> sorted(['a','b','c','Ã¤'])
['a', 'b', 'c', 'Ã¤']
>>> collator = icu.Collator.createInstance(icu.Locale('de_DE.UTF-8'))
>>> sorted(['a','b','c','Ã¤'], key=collator.getSortKey)
['a', 'Ã¤', 'b', 'c']

",How do I sort unicode strings alphabetically in Python?,"Python sorts by byte value by default, which means Ã© comes after z and other equally funny things. What is the best way to sort alphabetically in Python?

Is there a library for this? I couldn't find anything. Preferrably sorting should have language support so it understands that Ã¥Ã¤Ã¶ should be sorted after z in Swedish, but that Ã¼ should be sorted by u, etc. Unicode support is thereby pretty much a requirement.

If there is no library for it, what is the best way to do this? Just make a mapping from letter to a integer value and map the string to a integer list with that?
"
"""Premature optimization is the root of all evil.""

With that firmly in mind, let's do this! Once your apps hit a certain point, denormalizing data is very common. Done correctly, it can save numerous expensive database lookups at the cost of a little more housekeeping.

To return a list of friend names we'll need to create a custom Django Field class that will return a list when accessed.

David Cramer posted a guide to creating a SeperatedValueField on his blog. Here is the code:

from django.db import models

class SeparatedValuesField(models.TextField):
    __metaclass__ = models.SubfieldBase

    def __init__(self, *args, **kwargs):
        self.token = kwargs.pop('token', ',')
        super(SeparatedValuesField, self).__init__(*args, **kwargs)

    def to_python(self, value):
        if not value: return
        if isinstance(value, list):
            return value
        return value.split(self.token)

    def get_db_prep_value(self, value):
        if not value: return
        assert(isinstance(value, list) or isinstance(value, tuple))
        return self.token.join([unicode(s) for s in value])

    def value_to_string(self, obj):
        value = self._get_val_from_obj(obj)
        return self.get_db_prep_value(value)


The logic of this code deals with serializing and deserializing values from the database to Python and vice versa. Now you can easily import and use our custom field in the model class:

from django.db import models
from custom.fields import SeparatedValuesField 

class Person(models.Model):
    name = models.CharField(max_length=64)
    friends = SeparatedValuesField()

",What is the most efficent way to store a list in the Django models?,"Currently I have a lot of python objects in my code similar to the following:

class MyClass():
  def __init__(self, name, friends):
      self.myName = name
      self.myFriends = [str(x) for x in friends]


Now I want to turn this into a Django model, where self.myName is a string field, and self.myFriends is a list of strings.

from django.db import models

class myDjangoModelClass():
    myName = models.CharField(max_length=64)
    myFriends = ??? # what goes here?


Since the list is such a common data structure in python, I sort of expected there to be a Django model field for it. I know I can use a ManyToMany or OneToMany relationship, but I was hoping to avoid that extra indirection in the code.

Edit:

I added this related question, which people may find useful.
"
"Whatever language you know better. I think this should be the first criterion.
",How do Python and PHP compare for ecommerce?,"If I were to start an ecommerce store, which language would you suggest I start with?  Python or PHP?

And would it be wise to use Python for an ecommerce site in favor of PHP?  PHP has lots of shopping carts, both open source and commercial.  

Is Python the future of Web Development ?

Edit:

I would like to clear out that i am not asking for Shopping carts solutions and links to them.
"
"Code is usually read many times, and it is written only once.
Saving writing time at the expense of readability is not usually a good choice, unless you are doing some throw-away code.

The second version is less explicit, and you need some time to understand what the code is doing. And we are simply talking about variable instantiation, not about algorithms!
",Is it acceptable to use tricks to save programmer when putting data in your code?,"Example: It's really annoying to type a list of strings in python:

[""January"", ""February"", ""March"", ""April"", ...]


I often do something like this to save me having to type quotation marks all over the place:

""January February March April May June July August ..."".split()


Those took the same amount of time, and I got 2x the # of months typed in. Another example:

[('a', '9'), ('4', '3'), ('z', 'x')...]


instead of:

map(tuple, ""a9 43 zx"".split())


which took much less time.
"
"There is an ipdb project which embeds iPython into the standard pdb, so you can just do:

import ipdb; ipdb.set_trace()


It's installable via the usual easy_install ipdb.

ipdb is pretty short, so instead of easy_installing you can also create a file ipdb.py somewhere on your Python path and paste the following into the file:

import sys
from IPython.Debugger import Pdb
from IPython.Shell import IPShell
from IPython import ipapi

shell = IPShell(argv=[''])

def set_trace():
    ip = ipapi.get()
    def_colors = ip.options.colors
    Pdb(def_colors).set_trace(sys._getframe().f_back)

",Is it possible to go into ipython from code?,"For my debugging needs, pdb is pretty good. However, it would be much cooler (and helpful) if I could go into ipython. Is this thing possible?
"
"I don't think it's trivial.  I don't want to have to sprinkle a redundant conditional around my code if I'm writing code like that often.

This is slightly odd, but you can do this with an iterator:

import re

def rematch(pattern, inp):
    matcher = re.compile(pattern)
    matches = matcher.match(inp)
    if matches:
        yield matches

if __name__ == '__main__':
    for m in rematch(""(\d+)g"", ""123g""):
        print(m.group(1))


The odd thing is that it's using an iterator for something that isn't iterating--it's closer to a conditional, and at first glance it might look like it's going to yield multiple results for each match.

It does seem odd that a context manager can't cause its managed function to be skipped entirely; while that's not explicitly one of the use cases of ""with"", it seems like a natural extension.
",Alternative to the `match = re.match(); if match: ...` idiom?,"If you want to check if something matches a regex, if so, print the first group, you do..

import re
match = re.match(""(\d+)g"", ""123g"")
if match is not None:
    print match.group(1)


This is completely pedantic, but the intermediate match variable is a bit annoying..

Languages like Perl do this by creating new $1..$9 variables for match groups, like..

if($blah ~= /(\d+)g/){
    print $1
}


From this reddit comment,

with re_context.match('^blah', s) as match:
    if match:
        ...
    else:
        ...


..which I thought was an interesting idea, so I wrote a simple implementation of it:

#!/usr/bin/env python2.6
import re

class SRE_Match_Wrapper:
    def __init__(self, match):
        self.match = match

    def __exit__(self, type, value, tb):
        pass

    def __enter__(self):
        return self.match

    def __getattr__(self, name):
        if name == ""__exit__"":
            return self.__exit__
        elif name == ""__enter__"":
            return self.__name__
        else:
            return getattr(self.match, name)

def rematch(pattern, inp):
    matcher = re.compile(pattern)
    x = SRE_Match_Wrapper(matcher.match(inp))
    return x
    return match

if __name__ == '__main__':
    # Example:
    with rematch(""(\d+)g"", ""123g"") as m:
        if m:
            print(m.group(1))

    with rematch(""(\d+)g"", ""123"") as m:
        if m:
            print(m.group(1))


(This functionality could theoretically be patched into the _sre.SRE_Match object)

It would be nice if you could skip the execution of the with statement's code block, if there was no match, which would simplify this to..

with rematch(""(\d+)g"", ""123"") as m:
    print(m.group(1)) # only executed if the match occurred


..but this seems impossible based of what I can deduce from PEP 343

Any ideas? As I said, this is really trivial annoyance, almost to the point of being code-golf..
"
"This tries to be a little more race-free than the other solutions.  (The with keyword is new in Python 2.5.)

import os
def touch(fname, times=None):
    with open(fname, 'a'):
        os.utime(fname, times)


Roughly equivalent to this.

import os
def touch(fname, times=None):
    fhandle = open(fname, 'a')
    try:
        os.utime(fname, times)
    finally:
        fhandle.close()


Now, to really make it race-free, you need to use futimes and change the timestamp of the open filehandle, instead of opening the file and then changing the timestamp on the filename (which may have been renamed).  Unfortunately, Python doesn't seem to provide a way to call futimes without going through ctypes or similar...



EDIT

As noted by Nate Parsons, Python 3.3 will add specifying a file descriptor (when os.supports_fd) to functions such as os.utime, which will use the futimes syscall instead of the utimes syscall under the hood.  In other words:

import os
def touch(fname, mode=0o666, dir_fd=None, **kwargs):
    flags = os.O_CREAT | os.O_APPEND
    with os.fdopen(os.open(fname, flags=flags, mode=mode, dir_fd=dir_fd)) as f:
        os.utime(f.fileno() if os.utime in os.supports_fd else fname,
            dir_fd=None if os.supports_fd else dir_fd, **kwargs)

",Implement touch using Python?,"touch is a Unix utility that sets the modification and access times of files to the current time of day.  If the file doesn't exist, it is created with default permissions.

How would you implement it as a Python function? Try to be cross platform and complete.

(Current Google results for ""python touch file"" are not that great, but point to os.utime.)
"
"If it's OK for you, there is a Django application ready, doing exactly what you want:
https://github.com/sorl/sorl-thumbnail
",Image resizing with django?,"I'm new to Django (and Python) and I have been trying to work out a few things myself, before jumping into using other people's apps. I'm having trouble understanding where things 'fit' in the Django (or Python's) way of doing things. What I'm trying to work out is how to resize an image, once it's been uploaded. I have my model setup nicely and plugged into the admin, and the image uploads fine to the directory:

from django.db import models

# This is to list all the countries
# For starters though, this will be just United Kingdom (GB)
class Country(models.Model):
    name = models.CharField(max_length=120, help_text=""Full name of country"")
    code = models.CharField(max_length=2, help_text=""This is the ISO 3166 2-letter country code (see: http://www.theodora.com/country_digraphs.html)"")
    flag = models.ImageField(upload_to=""images/uploaded/country/"", max_length=150, help_text=""The flag image of the country."", blank=True)

    class Meta:
        verbose_name_plural = ""Countries""

    def __unicode__(self):
        return self.name


The thing I'm now having trouble with is taking that file and making a new file into a thumbnail. Like I say, I'd like to know how to do it without using others' apps (for now). I have got this code from DjangoSnippets:

from PIL import Image
import os.path
import StringIO

def thumbnail(filename, size=(50, 50), output_filename=None):
    image = Image.open(filename)
    if image.mode not in ('L', 'RGB'):
        image = image.convert('RGB')
    image = image.resize(size, Image.ANTIALIAS)

    # get the thumbnail data in memory.
    if not output_filename:
        output_filename = get_default_thumbnail_filename(filename)
    image.save(output_filename, image.format) 
    return output_filename

def thumbnail_string(buf, size=(50, 50)):
    f = StringIO.StringIO(buf)
    image = Image.open(f)
    if image.mode not in ('L', 'RGB'):
        image = image.convert('RGB')
    image = image.resize(size, Image.ANTIALIAS)
    o = StringIO.StringIO()
    image.save(o, ""JPEG"")
    return o.getvalue()

def get_default_thumbnail_filename(filename):
    path, ext = os.path.splitext(filename)
    return path + '.thumb.jpg'


...but this has ultimately confused me... As I don't know how this 'fits in' to my Django app? And really, is it the best solution for simply making a thumbnail of an image that has been successfully uploaded? Can anyone possibly show me a good, solid, decent way that a beginner like me can learn to do this properly? As in, knowing where to put that sort of code (models.py? forms.py? ...) and how it would work in context? ... I just need a bit of help understanding and working this problem out.

Thank you!
"
"The answer is to use Welford's algorithm, which is very clearly defined after the ""naive methods"" in:


Wikipedia: Algorithms for calculating variance


It's more numerically stable than either the two-pass or online simple sum of squares collectors suggested in other responses.  The stability only really matters when you have lots of values that are close to each other as they lead to what is known as ""catastrophic cancellation"" in the floating point literature.

You might also want to brush up on the difference between dividing by the number of samples (N) and N-1 in the variance calculation (squared deviation).  Dividing by N-1 leads to an unbiased estimate of variance from the sample, whereas dividing by N on average underestimates variance (because it doesn't take into account the variance between the sample mean and the true mean).

I wrote two blog entries on the topic which go into more details, including how to delete previous values online:


Computing Sample Mean and Variance Online in One Pass
Deleting Values in Welfordâs Algorithm for Online Mean and Variance


You can also take a look at my Java implement; the javadoc, source, and unit tests are all online:


Javadoc: stats.OnlineNormalEstimator
Source: stats.OnlineNormalEstimator.java
JUnit Source: test.unit.stats.OnlineNormalEstimatorTest.java
LingPipe Home Page

",How to efficiently calculate a running standard deviation?,"I have an array of lists of numbers, e.g.:

[0] (0.01, 0.01, 0.02, 0.04, 0.03)
[1] (0.00, 0.02, 0.02, 0.03, 0.02)
[2] (0.01, 0.02, 0.02, 0.03, 0.02)
     ...
[n] (0.01, 0.00, 0.01, 0.05, 0.03)


What I would like to do is efficiently calculate the mean and standard deviation at each index of a list, across all array elements.

To do the mean, I have been looping through the array and summing the value at a given index of a list. At the end, I divide each value in my ""averages list"" by n.

To do the standard deviation, I loop through again, now that I have the mean calculated.

I would like to avoid going through the array twice, once for the mean and then once for the SD (after I have a mean). 

Is there an efficient method for calculating both values, only going through the array once? Any code in an interpreted language (e.g. Perl or Python) or pseudocode is fine.
"
"This could work:

import sys

def str_to_class(str):
    return getattr(sys.modules[__name__], str)

",Convert string to Python class object?,"Given a string as user input to a python function, I'd like to get a class object out of it if there's a class with that name in the currently defined namespace. Essentially, I want the implementation for a function which will produce this kind of result:

class Foo:
    pass

str_to_class(""Foo"")
==> 


Is this possible?
"
"Whitespace on the both sides:

s = ""  \t a string example\t  ""
s = s.strip()


Whitespace on the right side:

s = s.rstrip()


Whitespace on the left side:

s = s.lstrip()


As thedz points out, you can provide an argument to strip arbitrary characters to any of these functions like this:

s = s.strip(' \t\n\r')


This will strip any space, \t, \n, or \r characters from the left-hand side, right-hand side, or both sides of the string. 

The examples above only remove strings from the left-hand and right-hand sides of strings. If you want to also remove characters from the middle of a string, try re.sub:

import re
print re.sub('[\s+]', '', s)


That should print out:

astringexample

",How to trim whitespace (including tabs)?,"Is there a function that will trim not only spaces for whitespace, but also tabs?
"
"If you are posting JSON to Django, I think you want request.body (request.raw_post_data on Django 

Here is an example using JavaScript, jQuery, jquery-json and Django.

JavaScript:

var myEvent = {id: calEvent.id, start: calEvent.start, end: calEvent.end,
               allDay: calEvent.allDay };
$.ajax({
    url: '/event/save-json/',
    type: 'POST',
    contentType: 'application/json; charset=utf-8',
    data: $.toJSON(myEvent),
    dataType: 'text',
    success: function(result) {
        alert(result.Result);
    }
});


Django:

def save_events_json(request):
    if request.is_ajax():
        if request.method == 'POST':
            print 'Raw Data: ""%s""' % request.body   
    return HttpResponse(""OK"")


Django 

  def save_events_json(request):
    if request.is_ajax():
        if request.method == 'POST':
            print 'Raw Data: ""%s""' % request.raw_post_data
    return HttpResponse(""OK"")

",Where's my JSON data in my incoming Django request?,"I'm trying to process incoming JSON/Ajax requests with Django/Python.

request.is_ajax() is True on the request, but I have no idea where the payload is with the JSON data.

request.POST.dir contains this:

['__class__', '__cmp__', '__contains__', '__copy__', '__deepcopy__', '__delattr__',
 '__delitem__', '__dict__', '__doc__', '__eq__', '__ge__', '__getattribute__',
'__getitem__', '__gt__', '__hash__', '__init__', '__iter__', '__le__', '__len__',
 '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', 
'__setattr__', '__setitem__', '__str__', '__weakref__', '_assert_mutable', '_encoding', 
'_get_encoding', '_mutable', '_set_encoding', 'appendlist', 'clear', 'copy', 'encoding', 
'fromkeys', 'get', 'getlist', 'has_key', 'items', 'iteritems', 'iterkeys', 'itervalues', 
'keys', 'lists', 'pop', 'popitem', 'setdefault', 'setlist', 'setlistdefault', 'update', 
'urlencode', 'values']


There are apparently no keys in the request post keys.

When I look at the POST in Firebug, there is JSON data being sent up in the request.
"
"The most popular way to manage python packages (if you're not using your system package manager) is to use setuptools and easy_install. It is probably already installed on your system. Use it like this:

easy_install django


easy_install uses the Python Package Index  which is an amazing resource for python developers. Have a look around to see what packages are available.

A better option is pip, which is gaining traction, as it attempts to fix a lot of the problems associated with easy_install. Pip uses the same package repository as easy_install, it just works better. Really the only time use need to use easy_install is for this command:

easy_install pip


After that, use:

pip install django


At some point you will probably want to learn a bit about virtualenv. If you do a lot of python development on projects with conflicting package requirements, virtualenv is a godsend. It will allow you to have completely different versions of various packages, and switch between them easily depending your needs.

Regarding which python to use, sticking with Apple's python will give you the least headaches, but If you need a newer version (Leopard is 2.5.1 I believe), I would go with the macports python 2.6.
",What is the most compatible way to install python modules on a Mac?,"I'm starting to learn python and loving it. I work on a Mac mainly as well as Linux. I'm finding that on Linux (Ubuntu 9.04 mostly) when I install a python module using apt-get it works fine. I can import it with no trouble.

On the Mac, I'm used to using Macports to install all the Unixy stuff. However, I'm finding that most of the python modules I install with it are not being seen by python. I've spent some time playing around with PATH settings and using python_select . Nothing has really worked and at this point I'm not really understanding, instead I'm just poking around.

I get the impression that Macports isn't universally loved for managing python modules. I'd like to start fresh using a more ""accepted"" (if that's the right word) approach. 

So, I was wondering, what is the method that Mac python developers use to manage their modules?

Bonus questions: 

Do you use Apple's python, or some other version?
Do you compile everything from source or is there a package manger that works well (Fink?).

Any tips or suggestions here are greatly appreciated. Thanks for your time. :)
"
"pip, an alternative to setuptools/easy_install, provides an ""uninstall"" command. 

Install pip according to the installation instructions:

$ wget https://bootstrap.pypa.io/get-pip.py
$ python get-pip.py


Then you can use pip uninstall to remove packages installed with easy_install
",How do I remove packages installed with Python's easy_install?,"Python's easy_install makes installing new packages extremely convenient. However, as far as I can tell, it doesn't implement the other common features of a dependency manager - listing and removing installed packages.

What is the best way of finding out what's installed, and what is the preferred way of removing installed packages? Are there any files that need to be updated if I remove packages manually (e.g. by rm /usr/local/lib/python2.6/dist-packages/my_installed_pkg.egg or similar)?
"
"What about something like

import threading

thr = threading.Thread(target=foo, args=(), kwargs={})
thr.start() # will run ""foo""
....
thr.is_alive() # will return whether foo is running currently
....
thr.join() # will wait till ""foo"" is done


See the docs at https://docs.python.org/2/library/threading.html#module-threading for more details; this code should work for python 3 as well.
",Asynchronous method call in Python?,"I was wondering if there's any library for asynchronous method calls in Python. It would be great if you could do something like

@async
def longComputation():
    


token = longComputation()
token.registerCallback(callback_function)
# alternative, polling
while not token.finished():
    doSomethingElse()
    if token.finished():
        result = token.result()


Or to call a non-async routine asynchronously

def longComputation()
    

token = asynccall(longComputation())


It would be great to have a more refined strategy as native in the language core. Was this considered?
"
"EUREKA: I found the way to use the bulkloader.py tool without having to manually enter login credentials.

Here are the 2 steps:



Set your app.yaml file up. Example:

- url: /remote_api
  script: $PYTHON_LIB/google/appengine/ext/remote_api/handler.py
  login: admin


You should put it BEFORE your - url: .* line in app.yaml, otherwise you will never access the /remote_api url.

Note that I've left the login: admin part, as removing it is a VERY BAD practice, since you might deploy that into production...



2 Launch this command (adapt it to your needs).

echo 'XX' | python2.5 ../google_appengine/bulkloader.py --dump --kind=NAMEOFMODEL --url=http://localhost:8080/remote_api --filename=FILENAME --app_id=APPID --email=foobar@nowhere.com --passin .


The trick is to use the combination of those 2 parameters:


--email= (you can put whichever email address you want, I use foobar@nowhere.com)
--passin


Specifying --email= will suppress the ""enter credentials"" prompt, and --passin will allow to read the password from stdin (that's where the echo 'XX' | comes into play!)



Enjoy!

P.S.: Don't forget to vote so that Google can provide an easier to use way to do that: Issue 2440.
",Which credentials should I put in for Google App Engine BulkLoader at development server?,"I would like to ask which kind of credentials do I need to put on for importing data using the Google App Engine BulkLoader class

appcfg.py upload_data --config_file=models.py --filename=listcountries.csv --kind=CMSCountry --url=http://localhost:8178/remote_api vit/


And then it asks me for credentials:


  Please enter login credentials for
  localhost


Here is an extraction of the content of the models.py, I use this listcountries.csv file

class CMSCountry(db.Model):
  sortorder = db.StringProperty()
  name = db.StringProperty(required=True)
  formalname = db.StringProperty()
  type = db.StringProperty()
  subtype = db.StringProperty()
  sovereignt = db.StringProperty()
  capital = db.StringProperty()
  currencycode = db.StringProperty()
  currencyname = db.StringProperty()
  telephonecode = db.StringProperty()
  lettercode = db.StringProperty()
  lettercode2 = db.StringProperty()
  number = db.StringProperty()
  countrycode = db.StringProperty()

class CMSCountryLoader(bulkloader.Loader):
  def __init__(self):
    bulkloader.Loader.__init__(self, 'CMSCountry',
                           [('sortorder', str),
                            ('name', str),
                            ('formalname', str),
                            ('type', str),
                            ('subtype', str),
                            ('sovereignt', str),
                            ('capital', str),
                            ('currencycode', str),
                            ('currencyname', str),
                            ('telephonecode', str),
                            ('lettercode', str),
                            ('lettercode2', str),
                            ('number', str),
                            ('countrycode', str)
                            ])
loaders = [CMSCountryLoader]


Every tries to enter the email and password result in ""Authentication Failed"", so I could not import the data to the development server.    

I don't think that I have any problem with my files neither my models because I have successfully uploaded the data to the appspot.com application.
So what should I put in for localhost credentials?
I also tried to use Eclipse with Pydev but I still got the same message :(
Here is the output:

Uploading data records.
[INFO    ] Logging to bulkloader-log-20090820.121659
[INFO    ] Opening database: bulkloader-progress-20090820.121659.sql3
[INFO    ] [Thread-1] WorkerThread: started
[INFO    ] [Thread-2] WorkerThread: started
[INFO    ] [Thread-3] WorkerThread: started
[INFO    ] [Thread-4] WorkerThread: started
[INFO    ] [Thread-5] WorkerThread: started
[INFO    ] [Thread-6] WorkerThread: started
[INFO    ] [Thread-7] WorkerThread: started
[INFO    ] [Thread-8] WorkerThread: started
[INFO    ] [Thread-9] WorkerThread: started
[INFO    ] [Thread-10] WorkerThread: started
Password for foobar@nowhere.com: [DEBUG   ] Configuring remote_api. url_path = /remote_api, servername = localhost:8178

[DEBUG   ] Bulkloader using app_id: abc
[INFO    ] Connecting to /remote_api
[ERROR   ] Exception during authentication
Traceback (most recent call last):
  File ""D:\Projects\GoogleAppEngine\google_appengine\google\appengine\tools\bulkloader.py"", line 2802, in Run
request_manager.Authenticate()
  File ""D:\Projects\GoogleAppEngine\google_appengine\google\appengine\tools\bulkloader.py"", line 1126, in Authenticate
remote_api_stub.MaybeInvokeAuthentication()
  File ""D:\Projects\GoogleAppEngine\google_appengine\google\appengine\ext\remote_api\remote_api_stub.py"", line 488, in MaybeInvokeAuthentication
datastore_stub._server.Send(datastore_stub._path, payload=None)
  File ""D:\Projects\GoogleAppEngine\google_appengine\google\appengine\tools\appengine_rpc.py"", line 344, in Send
f = self.opener.open(req)
  File ""C:\Python25\lib\urllib2.py"", line 381, in open
response = self._open(req, data)
  File ""C:\Python25\lib\urllib2.py"", line 399, in _open
'_open', req)
  File ""C:\Python25\lib\urllib2.py"", line 360, in _call_chain
result = func(*args)
  File ""C:\Python25\lib\urllib2.py"", line 1107, in http_open
return self.do_open(httplib.HTTPConnection, req)
  File ""C:\Python25\lib\urllib2.py"", line 1082, in do_open
raise URLError(err)
URLError: 
[INFO    ] Authentication Failed


Thank you!  
"
"with positive integers you could use .isdigit:

>>> '16'.isdigit()
True


it doesn't work with negative integers though. suppose you could try the following:

>>> s = '-17'
>>> s.startswith('-') and s[1:].isdigit()
True


it won't work with '16.0' format, which is similar to int casting in this sense.

edit:

def check_int(s):
    if s[0] in ('-', '+'):
    	return s[1:].isdigit()
    return s.isdigit()

","Python: Check if a string represents an int, Without using Try/Except?","Is there any way to tell whether a string represents an integer (e.g., '3', '-17' but not '3.14' or 'asfasfas') Without using a try/except mechanism?

is_int('3.14') = False
is_int('-7')   = True

"
"This should be the most efficent and shortest:

import operator
filter(operator.isNumberType, list_1)


Edit: this in python 3000:

import numbers
[x for x in list_1 if isinstance(x, numbers.Number)]

",Is there a way to output the numbers only from a python list?,"Simple Question:

list_1 = [ 'asdada', 1, 123131.131, 'blaa adaraerada', 0.000001, 34.12451235265, 'stackoverflow is awesome' ]


I want to create a list_2 such that it only contains the numbers:

list_2 = [ 1, 123131.131, 0.000001, 34.12451235265 ]


Is there simplistic way of doing this, or do I have to resort to checking the variable type of each list item and only output the numerical ones?
"
"If you're frequently iterating over a Cartesian product like in your example, you might want to investigate Python 2.6's itertools.product -- or write your own if you're in an earlier Python.

from itertools import product
for y, x in product(range(3), repeat=2):
  do_something()
  for y1, x1 in product(range(3), repeat=2):
    do_something_else()

",In python is there an easier way to write 6 nested for loops?,"This problem has been getting at me for a while now. Is there an easier way to write nested for loops in python? For example if my code went something like this:

  for y in range(3):
    for x in range(3):
      do_something()
      for y1 in range(3):
        for x1 in range(3):
          do_something_else()


would there be an easier way to do this? I know that this code works but when you indent instead of using 2 spaces, like me, it can get to be a problem.

Oh in the example there were only 4 nested for loops to make things easier.
"
"Well, you could do this:

>>> if all (k in foo for k in (""foo"",""bar"")):
...     print ""They're there!""
...
They're there!

",python: How do I check that multiple keys are in a dict in one go?,"I want to do something like:

foo = {'foo':1,'zip':2,'zam':3,'bar':4}

if (""foo"",""bar"") in foo:
    #do stuff


I'm not sure if its possible but would like to know.  :-)
"
"I put the following in my settings.py to distinguish between the standard dev server and production:

import sys
RUNNING_DEVSERVER = (len(sys.argv) > 1 and sys.argv[1] == 'runserver')


This also relies on convention, however.  

(Amended per Daniel Magnusson's comment)
",How can I tell whether my Django application is running on development server or not?,"How can I be certain that my application is running on development server or not? I suppose I could check value of settings.DEBUG and assume if DEBUG is True then it's running on development server, but I'd prefer to know for sure than relying on convention.
"
"Why do you have to convince your boss to use Django?

Your boss should understand that it's in his best interest to work in what the people he'll be employing know best. 

But, how can you tell that Django is really the best suit all things considered? 

For example:


Are the servers in-house? do the sysadmins know how to maintain servers for Django? 
Are the servers in a webhost, do you know how much does it cost to have a Django webhost versus a PHP one?
Are the rest of the team familiarized with Django/Python? If you are a one man team, what if your boss wants to make the team bigger, will he be able to? At what cost? PHP devs abound.
Given the PHP framework of choice, can you honestly give some criteria that will translate to dollars (or whatever your currency is) giving Django the advantage? Say, time to market, or some features that will be used and come for free in Django but not in the other alternative? Don't forget that if you are a good programmer you can create good programs in any language.


This are just some things you have to consider before presenting with your boss with a ""PHP sucks, let's use Python instead"" speech. I understand the feeling but it really might not make sense in the long run in certain cases. If, after all these things are answered (and some more), you can still present a good case for Django, then you should do so. Just don't do what sounds to a business man like fanboy speech.

UPDATE: If the only thing stopping you from doing in Django is your boss' fear and you both know that you can make it work at a comparable cost in infrastructure, then the only way to alleviate that fear is to jump in and do something like it. You might get authorization for a prototype, for example. No amount of talking will relieve him from his fear, he'll need to see something. You should also tutor him (if possible) on how Python works while you go at it, so he can appreciate the beauty of the beast.
",How to convince my boss to use Django?,"I have an unusual problem: I have to convince my superiors to use Django for our new project. Alternative is some PHP framework. I've programmed in PHP for 2 years and then switched to Python and have about 3 years of experience in it. However I'm not too good in business speech. 

I know all the technical pros and cons but when it comes to discussing business issues things blur a bit.

EDIT:

Reasons I want to use Python + Django:


experience in Django
beauty of pythonic code (and all it's benefits)
lots of third party libraries
efficiency
less code = less bugs


Reasons why my new boss wants to use PHP:


he knows it
he can estimate on his own
he doesn't know Python


@Vinko Vrsalovic:
 All requirements for both technologies are met.


we have both our own servers and external Python hosting
PHP costs of course less, however the difference is really tiny in comparison to support cost
we have suitable resources for both PHP and Python projects


I think problem is with my PM: he is afraid of new technologies. For him it's something new. So quoting the basic question from Robertos answer ""why can't we just use the old system?"".

I think I'm just too old :D to write a prototype in my free time. However this had worked a few times in past.
"
"Python's GIL is intended to serialize access to interpreter internals from different threads. On multi-core systems, it means that multiple threads can't effectively make use of multiple cores. (If the GIL didn't lead to this problem, most people wouldn't care about the GIL - it's only being raised as an issue because of the increasing prevalence of multi-core systems.) If you want to understand it in detail, you can view this video or look at this set of slides. It might be too much information, but then you did ask for details :-)

Note that Python's GIL is only really an issue for CPython, the reference implementation. Jython and IronPython don't have a GIL. As a Python developer, you don't generally come across the GIL unless you're writing a C extension. C extension writers need to release the GIL when their extensions do blocking I/O, so that other threads in the Python process get a chance to run.

Update: Updated link to video to point to Youtube, as the earlier blip.tv link had rotted.
",What is a global interpreter lock (GIL)?,"What is a global interpreter lock and why is that an issue?

A lot noise has been made around removing the GIL from Python, and I'd like to understand why that is so important. I have never written a compiler nor an interpreter myself, so don't be frugal with details, I'll probably need them to understand.
"
"You might want to consider Simon Willison's library:


djngâa Django powered microframework


From the readme:


  djng is a micro-framework that depends on a macro-framework (Django).
  
  My definition of a micro-framework: something that lets you create an entire
  Python web application in a single module:

import djng

def index(request):
    return djng.Response('Hello, world')

if __name__ == '__main__':
    djng.serve(index, '0.0.0.0', 8888)

  
  [...]

",How do I write a single-file Django application?,"I want to write a very small Django application in a single file, requiring all the appropriate modules and stuff, and then be able to run that as a normal Python script, like this:

$ python myapp.py


You can assume I won't render HTML, so I don't need templates (I'll return JSON or some other auto-generated string).
"
"Python 2

Use isinstance(obj, basestring) for an object-to-test obj.

Docs.
",How to find out if a Python object is a string?,"How can I check if a Python object is a string (either regular or Unicode)?
"
">>> a = set('abcde')
>>> l = ['f', 'g']
>>> a |= set(l)
>>> a
set(['a', 'c', 'b', 'e', 'd', 'g', 'f'])


The union operator is much faster than add anyway.

edit: If you want the list itself and not its members, then you must use a tuple, unfortunately. Set members must be hashable.
",Python: Add list to set?,"Tested on Python 2.6 interpreter:

>>> a=set('abcde')
>>> a
set(['a', 'c', 'b', 'e', 'd'])
>>> l=['f','g']
>>> l
['f', 'g']
>>> a.add(l)
Traceback (most recent call last):
  File """", line 1, in 
    a.add(l)
TypeError: list objects are unhashable


I think that I can't add the list to the set because there's no way Python can tell If I have added the same list twice. Is there a workaround?

EDIT: I want to add the list itself, not its elements. 
"
"text[0] fails if text is an empty string:

IronPython 2.6 Alpha (2.6.0.1) on .NET 4.0.20506.1
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> text = """"
>>> print(text.startswith(""a""))
False
>>> print(text[0]=='a')
Traceback (most recent call last):
  File """", line 1, in 
IndexError: index out of range: 0


EDIT: You say you ""know"" that text is not empty... how confident are you of that, and what would you want to happen if it is empty in reality? If a failure is appropriate (e.g. it means a bug in your code) that would encourage the use of text[0]=='a'.

Other questions:


How concerned are you about the performance of this? If this is performance critical, then benchmark it on your particular Python runtime. I wouldn't be entirely surprised to find that (say) one form was faster on IronPython and a different one faster on CPython.
Which do you (and your team) find more readable?

",How good is startswith?,"Is  

text.startswith('a')


better than  

text[0]=='a'


?

Knowing text is not empty and we are only interested in the first character of it.  
"
"You may be interested in this: An optimization anecdote by Guido.  Although it is worth remembering also that this is an old article and it predates the existence of things like ''.join (although I guess string.joinfields is more-or-less the same)

On the strength of that, the array module may be fastest if you can shoehorn your problem into it.  But ''.join is probably fast enough and has the benefit of being idiomatic and thus easier for other python programmers to understand.

Finally, the golden rule of optimization: don't optimize unless you know you need to, and measure rather than guessing.

You can measure different methods using the timeit module. That can tell you which is fastest, instead of random strangers on the internet making guesses.
",What is the most efficient string concatenation method in python?,"Is there any efficient mass string concatenation method in Python (like StringBuilder in C# or StringBuffer in Java)? I found following methods here:


Simple concatenation using +
Using string list and join method
Using UserString from MutableString module
Using character array and the array module 
Using cStringIO from StringIO module


But what do you experts use or suggest, and why? 

[A related question here]
"
"Such lookups are implemented in django.views.generic.date_based as follows:

{'date_time_field__range': (datetime.datetime.combine(date, datetime.time.min),
                            datetime.datetime.combine(date, datetime.time.max))} 


Because it is quite verbose there are plans to improve the syntax using __date operator. Check ""#9596 Comparing a DateTimeField to a date is too hard"" for more details.
",How can I filter a date of a DateTimeField in Django?,"I am trying to filter a DateTimeField comparing with a date. I mean:

MyObject.objects.filter(datetime_attr=datetime.date(2009,8,22))


I get an empty queryset list as an answer because (I think) I am not considering time, but I want ""any time"".

Is there an easy way in Django for doing this?

I have the time in the datetime setted, it is not 00:00.
"
"in is definitely more pythonic.

In fact has_key() was removed in Python 3.x.
",'has_key()' or 'in'?,"I wonder what is better to do:

d = {'a': 1, 'b': 2}
'a' in d
True


or:

d = {'a': 1, 'b': 2}
d.has_key('a')
True

"
"I've been working on a library called Pyth, which can do this:

http://pypi.python.org/pypi/pyth/

Converting an RTF file to plaintext looks something like this:

from pyth.plugins.rtf15.reader import Rtf15Reader
from pyth.plugins.plaintext.writer import PlaintextWriter

doc = Rtf15Reader.read(open('sample.rtf'))

print PlaintextWriter.write(doc).getvalue()


Pyth can also generate RTF files, read and write XHTML, generate documents from Python markup a la Nevow's stan, and has limited experimental support for latex and pdf output. Its RTF support is pretty robust -- we use it in production to read RTF files generated by various versions of Word, OpenOffice, Mac TextEdit, EIOffice, and others.
",Is there a Python module for converting RTF to plain text?,"Ideally, I'd like a module or library that doesn't require superuser access to install; I have limited privileges in my working environment.
"
"def removeNonAscii(s): return """".join(filter(lambda x: ord(x)<128, s))


edit: my first impulse is always to use a filter, but the generator expression is more memory efficient (and shorter)...

def removeNonAscii(s): return """".join(i for i in s if ord(i)<128)


Keep in mind that this is guaranteed to work with UTF-8 encoding (because all bytes in multi-byte characters have the highest bit set to 1).
",How to make the python interpreter correctly handle non-ASCII characters in string operations?,"I have a string that looks like so:

6ÃÂ 918ÃÂ 417ÃÂ 712


The clear cut way to trim this string (as I understand Python) is simply to say the string is in a variable called s, we get:

s.replace('Ã ', '')


That should do the trick. But of course it complains that the non-ASCII character '\xc2' in file blabla.py is not encoded.

I never quite could understand how to switch between different encodings.

Here's the code, it really is just the same as above, but now it's in context. The file is saved as UTF-8 in notepad and has the following header:

#!/usr/bin/python2.4
# -*- coding: utf-8 -*-


The code:

f = urllib.urlopen(url)

soup = BeautifulSoup(f)

s = soup.find('div', {'id':'main_count'})

#making a print 's' here goes well. it shows 6Ã 918Ã 417Ã 712

s.replace('Ã ','')

save_main_count(s)


It gets no further than s.replace...
"
">>> import datetime
>>> a = datetime.datetime.now()
>>> b = datetime.datetime.now()
>>> c = b - a
datetime.timedelta(0, 8, 562000)
>>> divmod(c.days * 86400 + c.seconds, 60)
(0, 8)      # 0 minutes, 8 seconds

",How do I find the time difference between two datetime objects in python?,"How do I tell the time difference in minutes between two datetime objects?
"
"Some of us Python committers, I believe mostly Rigo and Hettinger, went out of their way (on the way to 2.5 I believe) to optimize some special cases of the alas-far-too-common s += something blight, arguing that it was proven that beginners will never be covinced that ''.join is the right way to go and the horrible slowness of the += might be giving Python a bad name. Others of us weren't that hot, because they just couldn't possibly optimize every occurrence (or even just a majority of them) to decent performance; but we didn't feel hotly enough on the issue to try and actively block them.

I believe this thread proves we should have opposed them more sternly. As it is now, they optimized += in a certain hard-to-predict subset of cases to where it can be maybe 20% faster for particular stupid cases than the proper way (which IS still ''.join) -- just a perfect way to trap beginners into pursuing those irrelevant 20% gains by using the wrong idiom... at the cost, once in a while and from their POV out of the blue, of being hit with a performance loss of 200% (or more, since non-linear behavior IS still lurking there just outside of the corners that Hettinger and Rigo prettied up and put flowers in;-) -- one that MATTERS, one that WILL make them miserable.  This goes against the grain of Python's ""ideally only one obvious way to do it"" and it feels to me like we, collectively, have lain a trap for beginners -- the best kind, too... those who don't just accept what they're told by their ""betters"", but inquisitively go and question and explore.

Ah well -- I give up.  OP, @mshsayem, go ahead, use += everywhere, enjoy your irrelevant 20% speedups in trivial, tiny, irrelevant cases, and you'd better enjoy them to the hilt -- because one day, when you can't see it coming, on an IMPORTANT, LARGE operation, you'll be hit smack in the midriff by the oncoming trailer truck of a 200% slowdown (unless you get unlucky and it's a 2000% one;-).  Just remember: if you ever feel that ""Python is horribly slow"", REMEMBER, more likely than not it's one of your beloved loops of += turning around and biting the hand that feeds it.

For the rest of us -- those who understand what it means to say We should forget about small efficiencies, say about 97% of the time, I'll keep heartily recommending ''.join, so we all can sleep in all tranquility and KNOW we won't be hit with a superlinear slowdown when we least expect and least can afford you. But for you, Armin Rigo, and Raymond Hettinger (the last two, dear personal friends of mine, BTW, not just co-commiters;-) -- may your += be smooth and your big-O's never worse than N!-)

So, for the rest of us, here's a more meaningful and interesting set of measurements:

$ python -mtimeit -s'r=[str(x)*99 for x in xrange(100,1000)]' 's="""".join(r)'
1000 loops, best of 3: 319 usec per loop


900 strings of 300 chars each, joining the list directly is of course fastest, but the OP is terrified about having to do appends before then. But:

$ python -mtimeit -s'r=[str(x)*99 for x in xrange(100,1000)]' 's=""""' 'for x in r: s+=x'
1000 loops, best of 3: 779 usec per loop
$ python -mtimeit -s'r=[str(x)*99 for x in xrange(100,1000)]' 'z=[]' 'for x in r: z.append(x)' '"""".join(z)'
1000 loops, best of 3: 538 usec per loop


...with a semi-important amount of data (a very few 100's of KB -- taking a measurable fraction of a millisecond every which way), even plain good old .append is alread superior. In addition, it's obviously and trivially easy to optimize:

$ python -mtimeit -s'r=[str(x)*99 for x in xrange(100,1000)]' 'z=[]; zap=z.append' 'for x in r: zap(x)' '"""".join(z)'
1000 loops, best of 3: 438 usec per loop


shaving another tenths of a millisecond over the average looping time.  Everybody (at least everybody who's totally obsessed abound performance) obviously knows that HOISTING (taking OUT of the inner loop a repetitive computation that would be otherwise performed over and over) is a crucial technique in optimization -- Python doesn't hoist on your behalf, so you have to do your own hoisting in those rare occasions where every microsecond matters.
","Python string 'join' is faster (?) than '+', but what's wrong here?","I asked the most efficient method for mass dynamic string concatenation in an earlier post and I was suggested to use the join method, the best, simplest and fastest method to do so (as everyone said that). But while I was playing with string concatenations, I found some weird(?) results. I'm sure something is going on but I can't not get it quite. Here is what I did:

I defined these functions:

import timeit
def x():
    s=[]
    for i in range(100):
        # Other codes here...
        s.append(""abcdefg""[i%7])
    return ''.join(s)

def y():
    s=''
    for i in range(100):
        # Other codes here...
        s+=""abcdefg""[i%7]
    return s

def z():
    s=''
    for i in range(100):
        # Other codes here...
        s=s+""abcdefg""[i%7]
    return s

def p():
    s=[]
    for i in range(100):
        # Other codes here...
        s+=""abcdefg""[i%7]
    return ''.join(s)

def q():
    s=[]
    for i in range(100):
        # Other codes here...
        s = s + [""abcdefg""[i%7]]
    return ''.join(s)


I have tried to keep other things (except the concatenation) almost same throughout the functions. Then I tested with the following with results in comment (using Python 3.1.1 IDLE on Windows 32 bit machine):

timeit.timeit(x) # 31.54912480500002
timeit.timeit(y) # 23.533029429999942 
timeit.timeit(z) # 22.116181330000018
timeit.timeit(p) # 37.718607439999914
timeit.timeit(q) # 108.60377576499991


That means it shows that strng = strng + dyn_strng is the fastest. Though the difference in times are not that significant (except the last one), but I wanna know why this is happening. Is that because I am using Python 3.1.1 and that provides '+' as most efficient? Should I use '+' as an alternative to join? Or, have I done something extremely silly? Or what? Please explain clearly.
"
"In some projects, I use the following helper function to accomplish something akin to Python's repr for strings:

private static final char CONTROL_LIMIT = ' ';
private static final char PRINTABLE_LIMIT = '\u007e';
private static final char[] HEX_DIGITS = new char[] { '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f' };

public static String toPrintableRepresentation(String source) {

    if( source == null ) return null;
    else {

        final StringBuilder sb = new StringBuilder();
        final int limit = source.length();
        char[] hexbuf = null;

        int pointer = 0;

        sb.append('""');

        while( pointer < limit ) {

            int ch = source.charAt(pointer++);

            switch( ch ) {

            case '\0': sb.append(""\\0""); break;
            case '\t': sb.append(""\\t""); break;
            case '\n': sb.append(""\\n""); break;
            case '\r': sb.append(""\\r""); break;
            case '\""': sb.append(""\\\""""); break;
            case '\\': sb.append(""\\\\""); break;

            default:
                if( CONTROL_LIMIT <= ch && ch <= PRINTABLE_LIMIT ) sb.append((char)ch);
                else {

                    sb.append(""\\u"");

                    if( hexbuf == null ) 
                        hexbuf = new char[4];

                    for( int offs = 4; offs > 0; ) {

                        hexbuf[--offs] = HEX_DIGITS[ch & 0xf];
                        ch >>>= 4; 
                    }

                    sb.append(hexbuf, 0, 4);
                }
            }
        }

        return sb.append('""').toString();
    }
}


Its main advantage over many of the other solutions given here is, that it does not filter only a limited set of non-printable characters (like those replace-based solutions), but simply all non-printable ASCII characters. Some of it could have been written slightly nicer, but it actually does its job...

Note, that like the Python function, this one will surround the string with quotes. If you do not want that, you will have to eliminate the append('""') calls before and after the while loop.
",Java equivalent of Python repr()?,"Is there a Java method that works like Python's repr? For example, assuming the function were named repr,

""foo\n\tbar"".repr()


would return

""foo\n\tbar""

not

foo
        bar 

as toString does.
"
"My answer to that would be :


  We should forget about small
  efficiencies, say about 97% of the
  time: premature optimization is the
  root of all evil.


(Quoting Knuth, Donald. Structured Programming with go to Statements, ACM Journal Computing Surveys, Vol 6, No. 4, Dec. 1974. p.268)


If your application is doing anything like a query to the database, that one query will take more time than anything you can gain with those kind of small optimizations, anyway...

And if running after performances like that, why not code in assembly language, afterall ? Because Python is easier/faster to write and maintain ? Well, if so, you are right :-)

The most important thing is that your code is easy to maintain ; not a couple micro-seconds of CPU-time !
Well, maybe except if you have thousands of servers -- but is it your case ?
",Should I optimise my python code like C++? Does it matter?,"I had an argument with a colleague about writing python efficiently. He claimed that though you are programming python you still have to optimise the little bits of your software as much as possible, as if you are writing an efficient algorithm in C++.

Things like:


In an if statement with an or always put the condition most likely to fail first, so the second will not be checked.
Use the most efficient functions for manipulating strings in common use. Not code that grinds strings, but simple things like doing joins and splits, and finding substrings.
Call as less functions as possible, even if it comes on the expense of readability, because of the overhead this creates.


I say, that in most cases it doesn't matter. I should also say that context of the code is not a super-efficient NOC or missile-guidance systems. We're mostly writing tests in python.

What's your view of the matter?
"
"Existing answers do a good job of showing you how to get the ATTRIBUTES of an object, but do not precisely answer the question you posed -- how to get the METHODS of an object. Python objects have a unified namespace (differently from Ruby, where methods and attributes use different namespaces).  Consider for example:

>>> class X(object):
...   @classmethod
...   def clame(cls): pass
...   @staticmethod
...   def stame(): pass
...   def meth(self): pass
...   def __init__(self):
...     self.lam = lambda: None
...     self.val = 23
... 
>>> x = X()
>>> dir(x)
['__class__', '__delattr__', '__dict__', '__doc__', '__format__',
 '__getattribute__', '__hash__', '__init__', '__module__',
 '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__',
 '__sizeof__', '__str__', '__subclasshook__', '__weakref__',
 'clame', 'lam', 'meth', 'stame', 'val']


((output split for readability)).

As you see, this is giving you the names of all attributes -- including plenty of special methods that are just inherited from object, special data attributes such as __class__, __dict__ and __doc__, per-instance data attributes (val), per-instance executable attributes (lam), as well as actual methods.

If and when you need to be more selective, try:

>>> import inspect
>>> [n for n, v in inspect.getmembers(x, inspect.ismethod)]
['__init__', 'clame', 'meth']


Standard library module inspect is the best way to do introspection in Python: it builds on top of the built-in introspection hooks (such as dir and more advanced ones) to offer you useful, rich, and simple introspection services. Here, for example, you see that only instance and class methods specifically designed by this class are shown -- not static methods, not instance attributes whether callable or not, not special methods inherited from object. If your selectivity needs are slightly different, it's easy to build your own tweaked version of ismethod and pass it as the second argument of getmembers, to tailor the results to your precise, exact needs.
",list of methods for python shell?,"You'd have already found out by my usage of terminology that I'm a python n00b.

straight forward question:

How can i see a list of methods for a particular object in an interactive python shell like i can in ruby (you can do that in ruby irb with a '.methods' after the object)?
"
"I had  a problem like this, until I realized that (long before I had discovered virtualenv), I had gone adding directories to the PYTHONPATH in my .bashrc file. As it had been over a year beforehand, I didn't think of that straight away.  
",virtualenv --no-site-packages and pip still finding global packages?,"I was under the impression that virtualenv --no-site-packages would create a completely separate and isolated Python environment, but it doesn't seem to.

For example, I have python-django installed globally, but wish to create a virtualenv with a different Django version.

$ virtualenv --no-site-packages foo       
New python executable in foo/bin/python
Installing setuptools............done.
$ pip -E foo install Django
Requirement already satisfied: Django in /usr/share/pyshared
Installing collected packages: Django
Successfully installed Django


From what I can tell, the pip -E foo install above is supposed to re-install a new version of Django.  Also, if I tell pip to freeze the environment, I get a whole lot of packages.  I would expect that for a fresh environment with --no-site-packages this would be blank?

$ pip -E foo freeze
4Suite-XML==1.0.2
BeautifulSoup==3.1.0.1
Brlapi==0.5.3
BzrTools==1.17.0
Django==1.1
... and so on ...


Am I misunderstanding how --no-site-packages is supposed to work?  
"
"Edit: extended the solution to honor default arguments also

Here is the complete solution:

from functools import wraps
import inspect


def initializer(func):
    """"""
    Automatically assigns the parameters.

    >>> class process:
    ...     @initializer
    ...     def __init__(self, cmd, reachable=False, user='root'):
    ...         pass
    >>> p = process('halt', True)
    >>> p.cmd, p.reachable, p.user
    ('halt', True, 'root')
    """"""
    names, varargs, keywords, defaults = inspect.getargspec(func)

    @wraps(func)
    def wrapper(self, *args, **kargs):
        for name, arg in list(zip(names[1:], args)) + list(kargs.items()):
            setattr(self, name, arg)

        for name, default in zip(reversed(names), reversed(defaults)):
            if not hasattr(self, name):
                setattr(self, name, default)

        func(self, *args, **kargs)

    return wrapper




Edit: Adam asked me to extend the solution to support keyword arguments

from functools import wraps
import inspect

def initializer(fun):
   names, varargs, keywords, defaults = inspect.getargspec(fun)
   @wraps(fun)
   def wrapper(self, *args, **kargs):
       for name, arg in zip(names[1:], args) + kargs.items():
           setattr(self, name, arg)
       fun(self, *args, **kargs)
   return wrapper




You can use a decorator:

from functools import wraps
import inspect

def initializer(fun):
    names, varargs, keywords, defaults = inspect.getargspec(fun)
    @wraps(fun)
    def wrapper(self, *args):
        for name, arg in zip(names[1:], args):
            setattr(self, name, arg)
        fun(self, *args)
    return wrapper

class process:
    @initializer
    def __init__(self, PID, PPID, cmd, FDs, reachable, user):
        pass


Output:

>>> c = process(1, 2, 3, 4, 5, 6)
>>> c.PID
1
>>> dir(c)
['FDs', 'PID', 'PPID', '__doc__', '__init__', '__module__', 'cmd', 'reachable', 'user'

",Python: Automatically initialize instance variables?,"I have a python class that looks like this:

class Process:
    def __init__(self, PID, PPID, cmd, FDs, reachable, user):


followed by:

        self.PID=PID
        self.PPID=PPID
        self.cmd=cmd
        ...


Is there any way to autoinitialize these instance variables, like C++'s initialization list? It would spare lots of redundant code.
"
"I can reproduce this on my Q6600 (Python 2.6.2); increasing the range to 100000000:

('+=', 11.370000000000001)
('-=', 10.769999999999998)


First, some observations:


This is 5% for a trivial operation.  That's significant.
The speed of the native addition and subtraction opcodes is irrelevant.  It's in the noise floor, completely dwarfed by the bytecode evaluation.  That's talking about one or two native instructions around thousands.
The bytecode generates exactly the same number of instructions; the only difference is INPLACE_ADD vs. INPLACE_SUBTRACT and +1 vs -1.


Looking at the Python source, I can make a guess.  This is handled in ceval.c, in PyEval_EvalFrameEx.  INPLACE_ADD has a significant extra block of code, to handle string concatenation.  That block doesn't exist in INPLACE_SUBTRACT, since you can't subtract strings.  That means INPLACE_ADD contains more native code.  Depending (heavily!) on how the code is being generated by the compiler, this extra code may be inline with the rest of the INPLACE_ADD code, which means additions can hit the instruction cache harder than subtraction.  This could be causing extra L2 cache hits, which could cause a significant performance difference.

This is heavily dependent on the system you're on (different processors have different amounts of cache and cache architectures), the compiler in use, including the particular version and compilation options (different compilers will decide differently which bits of code are on the critical path, which determines how assembly code is lumped together), and so on.

Also, the difference is reversed in Python 3.0.1 (+: 15.66, -: 16.71); no doubt this critical function has changed a lot.
",Why is subtraction faster than addition in Python?,"I was optimising some Python code, and tried the following experiment:

import time

start = time.clock()
x = 0
for i in range(10000000):
    x += 1
end = time.clock()

print '+=',end-start

start = time.clock()
x = 0
for i in range(10000000):
    x -= -1
end = time.clock()

print '-=',end-start


The second loop is reliably faster, anywhere from a whisker to 10%, depending on the system I run it on. I've tried varying the order of the loops, number of executions etc, and it still seems to work.

Stranger,

for i in range(10000000, 0, -1):


(ie running the loop backwards) is faster than

for i in range(10000000):


even when loop contents are identical.

What gives, and is there a more general programming lesson here?
"
"Use numpy.linalg.norm:

dist = numpy.linalg.norm(a-b)

",How can the euclidean distance be calculated with numpy?,"I have two points in 3D:

(xa, ya, za)
(xb, yb, zb)


And I want to calculate the distance:

dist = sqrt((xa-xb)^2 + (ya-yb)^2 + (za-zb)^2)


What's the best way to do this with Numpy, or with Python in general?  I have:

a = numpy.array((xa ,ya, za))
b = numpy.array((xb, yb, zb))

"
"Did you install libjpeg after PIL was already compiled/installed on the system? Maybe it can't find the decoder properly?

Here's one set of instructions I found on getting libjpeg and PIL playing nicely on MacOS (see towards the end; looks like you may need to explicitly set the dir of the decoder):

http://djangodays.com/2008/09/03/django-imagefield-validation-error-caused-by-incorrect-pil-installation-on-mac/
",Why can't I upload jpg files to my Django app via admin/?,"I'm trying to add images to my models in my Django app.

models.py

class ImageMain(models.Model):
  product = models.ForeignKey(Product)
  photo = models.ImageField(upload_to='products')


In development mode, every time I try to upload the image via Django admin, I keep getting:


  Upload a valid image. The file you uploaded was either not an image or
  a corrupted image.


I installed libjpeg via fink and then installed PIL 1.1.6 on ox X 10.5.7

from PIL import Image
file = open('/Users/Bryan/work/review_app/media/lcdtvs/samsung_UN46B6000_front.jpg', 'r')
trial_image = Image.open(file)
trial_image.verify()


It seems that the jpg is valid based on that session. However, it does not load.
I have tried other jpgs, they don't work either.

What could be going wrong?

I was able to successfully upload a png file.
"
"UPDATED:
One way is to look at sys.maxsize as documented here:

$ python-32 -c 'import sys;print(""%x"" % sys.maxsize, sys.maxsize > 2**32)'
('7fffffff', False)
$ python-64 -c 'import sys;print(""%x"" % sys.maxsize, sys.maxsize > 2**32)'
('7fffffffffffffff', True)


sys.maxsize was introduced in Python 2.6.  If you need a test for older systems, this slightly more complicated test should work on all Python 2 and 3 releases:

$ python-32 -c 'import struct;print( 8 * struct.calcsize(""P""))'
32
$ python-64 -c 'import struct;print( 8 * struct.calcsize(""P""))'
64


BTW, you might be tempted to use platform.architecture() for this.  Unfortunately, its results are not always reliable, particularly in the case of OS X universal binaries.

$ arch -x86_64 /usr/bin/python2.6 -c 'import sys,platform; print platform.architecture()[0], sys.maxsize > 2**32'
64bit True
$ arch -i386 /usr/bin/python2.6 -c 'import sys,platform; print platform.architecture()[0], sys.maxsize > 2**32'
64bit False

",How do I determine if my python shell is executing in 32bit or 64bit mode on OS X?,"I need a way to tell what mode the shell is in from within the shell.  

I've tried looking at the platform module but it seems only to tell you about ""about the bit architecture and the linkage format used for the executable"": the binary is compiled as 64bit though (I'm running on OS X 10.6) so it seems to always report 64bit even though I'm using the methods described here to force 32bit mode).
"
"Invoke â Fabric without the SSH dependencies.

The Fabric roadmap discusses that Fabric 1.x will be split into three portions:


Invoke â The non-SSH task execution.
Fabric 2.x â The remote execution and deployment library that utilizes Invoke.
Patchwork âÂ The ""common deployment/sysadmin operations, built on Fabric.""


Invoke is a Python (2.6+ and 3.3+) task execution tool & library, drawing inspiration from various sources to arrive at a powerful & clean feature set.

Below are a few descriptive statements from Invoke's website:


  
  Invoke is a Python (2.6+ and 3.3+) task execution tool & library, drawing inspiration from various sources to arrive at a powerful & clean feature set.
  Like Rubyâs Rake tool and Invokeâs own predecessor Fabric 1.x, it provides a clean, high level API for running shell commands and defining/organizing task functions from a tasks.py file.
  

",Is there a Rake equivalent in Python?,"Rake is a software build tool written in Ruby (like ant or make), and so all its files are written in this language. Does something like this exist in Python?
"
"With Python and PIL:

from PIL import Image
gif = Image.open('path.gif')
try:
    gif.seek(1)
except EOFError:
    isanimated = False
else:
    isanimated = True

",How do I programmatically check whether a GIF image is animated?,"Here is a link to another question I asked concerning the same project I am working on. I think that bit of background will be helpful. 

For those that are too lazy to open a new tab to that question, I'll summarize what I'm trying to do here: I've downloaded about 250,000 images from 4scrape and I want to go through the GIFs and find which ones are animated or not. I need to do this programmatically, because I really don't feel my soul (or my relationship with my girlfriend) could use looking at a couple thousand GIFs from 4chan to see if they are animated or not. If you know the nature of 4chan, then you know the nature of the images (i.e. ""tits or GTFO"").

I know PHP and Python, but would be willing to explore other solutions. A stand-alone piece of software that works on Windows would also work.

Thanks a lot!
"
"There are a few options:


You could use Selenium Grid so that the browser is opened on a completely different machine (or virtual machine) that you can then connect to via VNC or Remote Desktop Connection if you wanted to see the browser.   Also, another option: if you run a Jenkins foreground process on that remote server, it can execute your test project on the desktop.
You can run Selenium 'headless' on Linux in XVFB. I've never tried doing this and doubt it's really worth the effort. http://www.alittlemadness.com/2008/03/05/running-selenium-headless/
You can wrap Selenium RC in a Windows service. http://support.microsoft.com/kb/137890 . Except that permissions constraints on later versions of windows will probably prevent Selenium from accessing the desktop like Windows 2000 used to allow us to do.
Another option would be to use something like WebDriver HTMLUnitDriver, which doesn't launch a 'real' browser. http://code.google.com/p/webdriver/  .  Also there is a PhantomJS option as well as a 'headless Chrome' that you could use.
Of course there's also the option of using a service like SauceLabs, where you can get your tests to be run in the cloud. After your tests have completed you can watch a video of them running.

",Is it possible to hide the browser in Selenium RC?,"I am using Selenium RC to automate some browser operations but I want the browser to be invisible. Is this possible? How? What about Selenium Grid? Can I hide the Selenium RC window also?
"
"Here is the tale of my rambling experience with this problem.  Would love to see it edited or generalised if you have better experience of the issue... apply a bit of that SO magic.

Note: Comments in next paragraph applied to Snow Leopard, but not to Lion, which appears to require 64-bit MySQL

First off, the author (still?) of MySQLdb says here that one of the most pernicious problems is that OS X comes installed with a 32 bit version of Python, but most average joes (myself included) probably jump to install the 64 bit version of MySQL.  Bad move... remove the 64 bit version if you have installed it (instructions on this fiddly task are available on SO here), then download and install the 32 bit version (package here)

There are numerous step-by-steps on how to build and install the MySQLdb libraries.  They often have subtle differences.  This seemed the most popular to me, and provided the working solution.  I've reproduced it with a couple of edits below

Step 0:
Before I start, I assume that you have MySQL, Python, and GCC installed on the mac.

Step 1:
Download the latest MySQL for Python adapter from SourceForge.

Step 2:
Extract your downloaded package:

tar xzvf MySQL-python-1.2.2.tar.gz


Step 3:
Inside the folder, clean the package:

sudo python setup.py clean


COUPLE OF EXTRA STEPS, (from this comment)

Step 3b: 
Remove everything under your MySQL-python-1.2.2/build/* directory -- don't trust the ""python setup.py clean"" to do it for you

Step 3c: 
Remove the egg under Users/$USER/.python-eggs

Step 4: 
Originally required editing _mysql.c, but is now NO LONGER NECESSARY.  MySQLdb community seem to have fixed this bug now.

Step 5:
Create a symbolic link under lib to point to a sub-directory called mysql. This is where it looks for during compilation.

sudo ln -s /usr/local/mysql/lib /usr/local/mysql/lib/mysql


Step 6:
Edit the setup_posix.py and change the following

mysql_config.path = ""mysql_config""

to

mysql_config.path = ""/usr/local/mysql/bin/mysql_config""

Step 7:
In the same directory, rebuild your package (ignore the warnings that comes with it)

sudo python setup.py build


Step 8:
Install the package and you are done.

sudo python setup.py install


Step 9:
Test if it's working. It works if you can import MySQLdb.

python


>>> import MySQLdb

Step 10:
If upon trying to import you receive an error complaining that Library not loaded: libmysqlclient.18.dylib ending with: Reason: image not found you need to create one additional symlink which is:

sudo ln -s /usr/local/mysql/lib/libmysqlclient.18.dylib /usr/lib/libmysqlclient.18.dylib


You should then be able to import MySQLdb without any errors.

One final hiccup though is that if you start Python from the build directory you will get this error:

/Library/Python/2.5/site-packages/MySQL_python-1.2.3c1-py2.5-macosx-10.5-i386.egg/_mysql.py:3: UserWarning: Module _mysql was already imported from /Library/Python/2.5/site-packages/MySQL_python-1.2.3c1-py2.5-macosx-10.5-i386.egg/_mysql.pyc, but XXXX/MySQL-python-1.2.3c1 is being added to sys.path

This is pretty easy to Google, but to save you the trouble you will end up here (or maybe not... not a particularly future-proof URL) and figure out that you need to cd .. out of build directory and the error should disappear.

As I wrote at the top, I'd love to see this answer generalised, as there are numerous other specific experiences of this horrible problem out there. Edit away, or provide your own, better answer.
",How to install MySQLdb (Python data access library to MySQL) on Mac OS X?,"I'm a Python newbie, but I've just spent a day working out how to get MySQLdb working properly, and the universe according to google includes numerous references to what a PITA it is, and an inordinate number of guides that seem to be outdated.  Given that this site is intended to address these sorts of problems, and I know that I'm going to need a reference to the solution in future, I'm going to ask the question, provide my answer and see what else floats to the surface.

So the question is how to get MySQLdb working on Mac OS X?
"
"For Debian distros I fixed this problem with

sudo apt-get install libsqlite3-dev

",How to install pysqlite?,"I am trying to install pysqlite (Python interface to the SQLite). I downloaded the file with the package (pysqlite-2.5.5.tar.gz). And I did the following:

gunzip pysqlite-2.5.5.tar.gz
tar xvf pysqlite-2.5.5.tar
\cd pysqlite-2.5.5
python setup.py install


At the last step I have a problem. I get the following error message:

error: command 'gcc' failed with exit status 1


I found that other peoples also had this problem.

As far as I understood in the person had a problem because sqlite2 was not installed. But in my case, I have sqlite3 (I can run it from command line).

May be I should change some paths in ""setup.cfg""? At the moment I have there:

#define=
#include_dirs=/usr/local/include
#library_dirs=/usr/local/lib
libraries=sqlite3
define=SQLITE_OMIT_LOAD_EXTENSION


And if I type ""which sqlite3"" I get:

/usr/bin/sqlite3


I saw a similar question here. The answer was ""you need sqlite3-dev"". But, even if it is the case, how to check if I have sqlite3-dev. And if I do not have it how to get it?

Can anybody pleas help me with that problem.

Thank you in advance. 
"
"The Python itertools page has exactly a powerset recipe for this:

def powerset(iterable):
    ""powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)""
    s = list(iterable)
    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))


Output:

>>> list(powerset(""abcd""))
[(), ('a',), ('b',), ('c',), ('d',), ('a', 'b'), ('a', 'c'), ('a', 'd'), ('b', 'c'), ('b', 'd'), ('c', 'd'), ('a', 'b', 'c'), ('a', 'b', 'd'), ('a', 'c', 'd'), ('b', 'c', 'd'), ('a', 'b', 'c', 'd')]


If you don't like that empty tuple at the beginning, you can just change the range statement to range(1, len(s)+1) to avoid a 0-length combination.
",what's a good way to combinate through a set?,"Given a set {a,b,c,d}, what's a good way to produce {a,b,c,d,ab,ac,ad,bc,bd,cd,abc,abd,abcd}?
"
"Did we forget why ""multiple exit points"" was considered harmful in the first place?  Back in the day (before widespread access to good exception handling and finally constructs, or managing objects like auto_ptr that do cleanup when they leave scope), this was the problem that haunted many multi-exit functions:

int function blah(arg1, arg2)
    allocate resource

    if early failure detection
        return failure_status

    ... much later...

    release resource // oh rats! resource didn't release
    return success_status


If the resource is memory, this creates a memory leak.  If it's a database transaction, we are heading for bad database contention or deadlock.  For that matter, with the advent of more exception support, we implicitly add many potential exits from a method (by virtue of an unhandled exception).  In my C++ days, I developed the habit of never calling delete, but instead using auto_ptr, so that allocated memory was cleaned up when the auto_ptr exited its scope, even if some unexpected exception reared its head.

In our garbage collected Python world, we can still have this issue, even though many of our objects, such as files, or locks, have improved self-cleaning behavior.  But in implementations other than CPython (jython and IronPython to name two), there is no guarantee just when a destructor will get called, so something more proactive needs to be built into your method.  The first mechanism for this purpose was try/finally:

int function blah(arg1, arg2)
    allocate resource
    try:

        if early failure detection
            return failure_status

        ... much later...
        return success_status

    finally:
        release resource // always releases no matter what


But now Python has context managers, in conjunction with the new 'with' syntax:

int function blah(arg1, arg2)
    allocate resource
    with context_manager(resource): // releases on exit from 'with'

        if early failure detection
            return failure_status

        ... much later...
        return success_status


So let's be sure that we tell the whole story, that the reason we can discard this old chestnut is that newer coding practices make it unnecessary.
",When is it advisable to use a ret_val variable?,"I have seen conflicting advice on whether the following code is better

def function():
    ret_val = 0
    if some_condition():
        ret_val = 2
    else:
        ret_val = 3
    return ret_val


or whether this is better:

def function():
    if some_condition():
        return 2
    else:
        return 3


This is a simple example, and I've written it in python-style, but what I'm looking for is a general principle as to when to use some ""accumulator"" variable to keep track of the return value, or whether to use multiple exit points.  I know different languages might have different reasons for using one style over the other, so I'd appreciate differing viewpoints for why a particular language might stick with a particular style. (Specifically in the past I've heard that structured programming in C avoids having multiple exit points for a function.)
"
"Edit: Here, I wrote a module for you.  Use it. http://code.activestate.com/recipes/576918/



Counting up from 1 will guarantee short, unique URLS. /1, /2, /3 ... etc.

Adding uppercase and lowercase letters to your alphabet will give URLs like those in your question.  And you're just counting in base-62 instead of base-10.

Now the only problem is that the URLs come consecutively.  To fix that, read my answer to this question here:

http://stackoverflow.com/questions/1051949/map-incrementing-integer-range-to-six-digit-base-26-max-but-unpredictably/1052896#1052896

Basically the approach is to simply swap bits around in the incrementing value to give the appearance of randomness while maintaining determinism and guaranteeing that you don't have any collisions.
",How to make unique short URL with Python?,"How can I make unique URL in Python a la http://imgur.com/gM19g or http://tumblr.com/xzh3bi25y
When using uuid from python I get a very large one. I want something shorter for URLs.
"
"Subversion includes the svnversion tool for exactly this purpose. A working copy may actually have local modifications, or may consist of a mix of revisions. svnversion knows how to handle that; see the examples in the linked documentation.

You can invoke svnversion from python like this:

import subprocess

def svnversion():
    p = subprocess.Popen(""svnversion"", stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    (stdout, stderr) = p.communicate()
    return stdout

",How to programmatically get SVN revision number?,"Like this question, but without the need to actually query the SVN server. This is a web-based project, so I figure I'll just use the repository as the public view (unless someone can advise me why this is a bad idea). I assume this info is in a file in the .svn folder somewhere, but where, and how do I parse it? I want to do something like what SO does, having the revision in the bottom-right corner.

Code in Python or PHP appreciated if you have it on hand, or just a point in the right direction.
"
"is is identity testing, == is equality testing. what happens in your code would be emulated in the interpreter like this:

>>> a = 'pub'
>>> b = ''.join(['p', 'u', 'b'])
>>> a == b
True
>>> a is b
False


so, no wonder they're not the same, right?

In other words: is is the id(a) == id(b)
",Why does comparing strings in Python using either '==' or 'is' sometimes produce a different result?,"I've got a Python program where two variables are set to the value 'public'. In a conditional expression I have the comparison var1 is var2 which fails, but if I change it to var1 == var2 it returns True.

Now if I open my Python interpreter and do the same ""is"" comparison, it succeeds.

>>> s1 = 'public'
>>> s2 = 'public'
>>> s2 is s1
True


What am I missing here?
"
"variable = []


Now variable refers to an empty list*.

Of course this is an assignment, not a declaration. There's no way to say in Python ""this variable should never refer to anything other than a list"", since Python is dynamically typed.



*The default built-in Python type is called a list, not an array. It is an ordered container of arbitrary length that can hold a heterogenous collection of objects (their types do not matter and can be freely mixed). This should not be confused with the array module, which offers a type closer to the C array type; the contents must be homogenous (all of the same type), but the length is still dynamic.
",How to declare an array in Python?,"How do I declare an array in Python?

I can't find any reference to arrays in the documentation. 
"
"def fivetimes(anylist):
  return anylist * 5


As you see, if you're given a list argument, there's no need for any assignment whatsoever in order to ""multiply it a given number of times and return the output"".  You talk about a given list; how is it given to you, if not (the most natural way) as an argument to your function?  Not that it matters much -- if it's a global variable, a property of the object that's your argument, and so forth, this still doesn't necessitate any assignment.

If you were ""homeworkically"" forbidden from using the * operator of lists, and just required to implement it yourself, this would require assignment, but no declaration:

def multiply_the_hard_way(inputlist, multiplier):
    outputlist = []
    for i in range(multiplier):
        outputlist.extend(inputlist)
    return outputlist


You can simply make the empty list ""magicaly appear"": there's no need to ""declare"" it as being anything whatsoever, it's an empty list and the Python compiler knows it as well as you or any reader of your code does.  Binding it to the name outputlist doesn't require you to perform any special ritual either, just the binding (aka assignment) itself: names don't have types, only objects have types... that's Python!-)

Edit: OP now says output must not be a list, but rather int, float, or maybe string, and he is given no indication of what.  I've asked for clarification -- multiplying a list ALWAYS returns a list, so clearly he must mean something different from what he originally said, that he had to multiply a list.  Meanwhile, here's another attempt at mind-reading. Perhaps he must return a list where EACH ITEM of the input list is multiplied by the same factor (whether that item is an int, float, string, list, ...).  Well then:

define multiply_each_item(somelist, multiplier):
  return [item * multiplier for item in somelist]


Look ma, no hands^H^H^H^H^H assignment.  (This is known as a ""list comprehension"", btw).

Or maybe (unlikely, but my mind-reading hat may be suffering interference from my tinfoil hat, will need to go to the mad hatter's shop to have them tuned) he needs to (say) multiply each list item as if they were the same type as the first item, but return them as their original type, so that for example

>>> mystic(['zap', 1, 23, 'goo'], 2)
['zapzap', 11, 2323, 'googoo']
>>> mystic([23, '12', 15, 2.5], 2)
[46, '24', 30, 4.0]


Even this highly-mystical spec COULD be accomodated...:

>>> def mystic(alist, mul):
...   multyp = type(alist[0])
...   return [type(x)(mul*multyp(x)) for x in alist]
...


...though I very much doubt it's the spec actually encoded in the mysterious runes of that homework assignment. Just about ANY precise spec can be either implemented or proven to be likely impossible as stated (by requiring you to solve the Halting Problem or demanding that P==NP, say;-).  That may take some work (""prove the 4-color theorem"", for example;-)... but still less than it takes to magically divine what the actual spec IS, from a collection of mutually contradictory observations, no examples, etc.  Though in our daily work as software developer (ah for the good old times when all we had to face was homework!-) we DO meet a lot of such cases of course (and have to solve them to earn our daily bread;-).

EditEdit: finally seeing a precise spec I point out I already implemented that one, anyway, here it goes again:

def multiplyItemsByFour(argsList):
  return [item * 4 for item in argsList]


EditEditEdit: finally/finally seeing a MORE precise spec, with (luxury!-) examples:

Input: ('a','b') Output: 'aaaabbbb' Input: (2,3,4) Output: 36


So then what's wanted it the summation (and you can't use sum as it wouldn't work on strings) of the items in the input list, each multiplied by four.  My preferred solution:

def theFinalAndTrulyRealProblemAsPosed(argsList):
  items = iter(argsList)
  output = next(items, []) * 4
  for item in items:
    output += item * 4
  return output


If you're forbidden from using some of these constructs, such as built-ins items and iter, there are many other possibilities (slightly inferior ones) such as:

def theFinalAndTrulyRealProblemAsPosed(argsList):
  if not argsList: return None
  output = argsList[0] * 4
  for item in argsList[1:]:
    output += item * 4
  return output


For an empty argsList, the first version returns [], the second one returns None -- not sure what you're supposed to do in that corner case anyway.
",Declaring Unknown Type Variable in Python?,"I have a situation in Python(cough, homework) where I need to multiply EACH ELEMENT in a given list of objects a specified number of times and return the output of the elements.  The problem is that the sample inputs given are of different types.  For example, one case may input a list of strings whose elements I need to multiply while the others may be ints.  So my return type needs to vary.  I would like to do this without having to test what every type of object is.  Is there a way to do this?  I know in C# i could just use ""var"" but I don't know if such a thing exists in Python?

I realize that variables don't have to be declared, but in this case I can't see any way around it.  Here's the function I made:

def multiplyItemsByFour(argsList):

output = ????

for arg in argsList:
        output += arg * 4

return output


See how I need to add to the output variable.  If I just try to take away the output assignment on the first line, I get an error that the variable was not defined.  But if I assign it a 0 or a """" for an empty string, an exception could be thrown since you can't add 3 to a string or ""a"" to an integer, etc...  

Here are some sample inputs and outputs:

Input:  ('a','b')  Output:  'aaaabbbb'
Input:  (2,3,4)    Output:  36


Thanks!
"
"Unofficial 64-bit installers for NumPy and SciPy are available at http://www.lfd.uci.edu/~gohlke/pythonlibs/
",How do I install SciPy on 64 bit Windows?,"How do I install SciPy on my system?

For the NumPy part (that SciPy depends on) there is actually an installer for 64 bit Windows: numpy-1.3.0.win-amd64-py2.6.msi (is direct download URL, 2310144 bytes).

Running the SciPy superpack installer results in this
message in a dialog box:


  Cannot install. Python version 2.6 required, which was not found in the registry.


I already have Python 2.6.2 installed (and a working Django installation
in it), but I don't know about any Registry story.

The registry entries seem to already exist:

REGEDIT4

[HKEY_LOCAL_MACHINE\SOFTWARE\Python]

[HKEY_LOCAL_MACHINE\SOFTWARE\Python\PythonCore]

[HKEY_LOCAL_MACHINE\SOFTWARE\Python\PythonCore\2.6]

[HKEY_LOCAL_MACHINE\SOFTWARE\Python\PythonCore\2.6\Help]

[HKEY_LOCAL_MACHINE\SOFTWARE\Python\PythonCore\2.6\Help\Main Python Documentation]
@=""D:\\Python262\\Doc\\python262.chm""

[HKEY_LOCAL_MACHINE\SOFTWARE\Python\PythonCore\2.6\InstallPath]
@=""D:\\Python262\\""

[HKEY_LOCAL_MACHINE\SOFTWARE\Python\PythonCore\2.6\InstallPath\InstallGroup]
@=""Python 2.6""

[HKEY_LOCAL_MACHINE\SOFTWARE\Python\PythonCore\2.6\Modules]

[HKEY_LOCAL_MACHINE\SOFTWARE\Python\PythonCore\2.6\PythonPath]
@=""D:\\Python262\\Lib;D:\\Python262\\DLLs;D:\\Python262\\Lib\\lib-tk""




What I have done so far:

Step 1

Downloaded the NumPy superpack installer
numpy-1.3.0rc2-win32-superpack-python2.6.exe
(direct download URL, 4782592 bytes). Running this installer
resulted in the same message, ""Cannot install. Python
version 2.6 required, which was not found in the registry."".
Update: there is actually an installer for NumPy that works - see beginning of the question.

Step 2

Tried to install NumPy in another way. Downloaded the zip
package numpy-1.3.0rc2.zip (direct download URL, 2404011 bytes),
extracted the zip file in a normal way to a temporary
directory, D:\temp7\numpy-1.3.0rc2 (where setup.py and
README.txt is). I then opened a command line window and:

d:
cd D:\temp7\numpy-1.3.0rc2
setup.py install


This ran for a long time and also included use of cl.exe
(part of Visual Studio). Here is a nearly 5000 lines long
transcript (230 KB).

This seemed to work. I can now do this in Python:

import numpy as np
np.random.random(10)


with this result:

array([ 0.35667511,  0.56099423,  0.38423629,  0.09733172,  0.81560421,
        0.18813222,  0.10566666,  0.84968066,  0.79472597,  0.30997724])


Step 3

Downloaded the SciPy superpack installer, scipy-0.7.1rc3-
win32-superpack-python2.6.exe (direct download URL, 45597175
bytes). Running this installer resulted in the message
listed in the beginning

Step 4

Tried to install SciPy in another way. Downloaded the zip
package scipy-0.7.1rc3.zip (direct download URL, 5506562
bytes), extracted the zip file in a normal way to a
temporary directory, D:\temp7\scipy-0.7.1 (where setup.py
and README.txt is). I then opened a command line window and:

d:
cd D:\temp7\scipy-0.7.1
setup.py install


This did not achieve much - here is a transcript (about 95
lines).

And it fails:

>>> import scipy as sp2
Traceback (most recent call last):
  File """", line 1, in 
ImportError: No module named scipy




Platform: Python 2.6.2 installed in directory D:\Python262,
Windows XP 64 bit SP2, 8 GB RAM, Visual Studio 2008
Professional Edition installed.

The startup screen of the installed Python is:

Python 2.6.2 (r262:71605, Apr 14 2009, 22:46:50) [MSC v.1500 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>>


Value of PATH, result from SET in a command line window:

Path=D:\Perl64\site\bin;D:\Perl64\bin;C:\Program Files (x86)\PC Connectivity Solution\;D:\Perl\site\bin;D:\Perl\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;d:\Program Files (x86)\WinSCP\;D:\MassLynx\;D:\Program Files (x86)\Analyst\bin;d:\Python262;d:\Python262\Scripts;D:\Program Files (x86)\TortoiseSVN\bin;D:\Program Files\TortoiseSVN\bin;C:\WINDOWS\system32\WindowsPowerShell\v1.0;D:\Program Files (x86)\IDM Computer Solutions\UltraEdit\

"
"Simple:

l = ['exiv2-devel', 'mingw-libs', 'tcltk-demos', 'fcgi', 'netcdf', 
    'pdcurses-devel',     'msvcrt', 'gdal-grass', 'iconv', 'qgis-devel', 
    'qgis1.1', 'php_mapscript']

if len(l) % 2 != 0:
    l.append("" "")

split = len(l)/2
l1 = l[0:split]
l2 = l[split:]
for key, value in zip(l1,l2):
    print '%-20s %s' % (key, value)         #python <2.6
    print ""{0:<20s} {1}"".format(key, value) #python 2.6+

",How to print a list more nicely?,"This is similar to How to print a list in Python ânicelyâ, but I would like to print the list even more nicely -- without the brackets and apostrophes and commas, and even better in columns.

foolist = ['exiv2-devel', 'mingw-libs', 'tcltk-demos', 'fcgi', 'netcdf', 
    'pdcurses-devel',     'msvcrt', 'gdal-grass', 'iconv', 'qgis-devel', 
    'qgis1.1', 'php_mapscript']

evenNicerPrint(foolist)


Desired result:

exiv2-devel       msvcrt        
mingw-libs        gdal-grass    
tcltk-demos       iconv         
fcgi              qgis-devel    
netcdf            qgis1.1       
pdcurses-devel    php_mapscript 


thanks!
"
"There is an usage scenario where you might need this. I'm not implying there are not better ways or achieving the same functionality.

This would be useful in order to 'dump' an arbitrary list of dictionaries in case of error, in debug modes and other similar situations.

What would be needed, is the reverse of the eval() function:

get_indentifier_name_missing_function()


which would take an identifier name ('variable','dictionary',etc) as an argument, and return a 
string containing the identifierâs name.



Consider the following current state of affairs:

random_function(argument_data)


If one is passing an identifier name ('function','variable','dictionary',etc) argument_data to a random_function() (another identifier name), one actually passes an identifier (e.g.: ) to another identifier  (e.g.: ):

()


From my understanding, only the memory address is passed to the function:

()


Therefore, one would need to pass a string as an argument to random_function() in order for that function to have the argument's identifier name:

random_function('argument_data')


Inside the random_function()

def random_function(first_argument):


, one would use the already supplied string 'argument_data' to:


serve as an 'identifier name' (to display, log, string split/concat, whatever)
feed the eval() function in order to get a reference to the actual identifier, and therefore, a reference to the real data:

print(""Currently working on"", first_argument)
some_internal_var = eval(first_argument)
print(""here comes the data: "" + str(some_internal_var))



Unfortunately, this doesn't work in all cases. It only works if the random_function() can resolve the 'argument_data' string to an actual identifier. I.e. If argument_data identifier name is available in the random_function()'s namespace.

This isn't always the case:

# main1.py
import some_module1

argument_data = 'my data'

some_module1.random_function('argument_data')


# some_module1.py
def random_function(first_argument):
    print(""Currently working on"", first_argument)
    some_internal_var = eval(first_argument)
    print(""here comes the data: "" + str(some_internal_var))
######


Expected results would be:

Currently working on: argument_data
here comes the data: my data


Because argument_data identifier name is not available in the random_function()'s namespace, this would yield instead:

Currently working on argument_data
Traceback (most recent call last):
  File ""~/main1.py"", line 6, in 
    some_module1.random_function('argument_data')
  File ""~/some_module1.py"", line 4, in random_function
    some_internal_var = eval(first_argument)
  File """", line 1, in 
NameError: name 'argument_data' is not defined




Now, consider the hypotetical usage of a get_indentifier_name_missing_function() which would behave as described above.

Here's a dummy Python 3.0 code: .

# main2.py
import some_module2
some_dictionary_1       = { 'definition_1':'text_1',
                            'definition_2':'text_2',
                            'etc':'etc.' }
some_other_dictionary_2 = { 'key_3':'value_3',
                            'key_4':'value_4', 
                            'etc':'etc.' }
#
# more such stuff
#
some_other_dictionary_n = { 'random_n':'random_n',
                            'etc':'etc.' }

for each_one_of_my_dictionaries in ( some_dictionary_1,
                                     some_other_dictionary_2,
                                     ...,
                                     some_other_dictionary_n ):
    some_module2.some_function(each_one_of_my_dictionaries)


# some_module2.py
def some_function(a_dictionary_object):
    for _key, _value in a_dictionary_object.items():
        print( get_indentifier_name_missing_function(a_dictionary_object)    +
               ""    "" +
               str(_key) +
               ""  =  "" +
               str(_value) )
######


Expected results would be:

some_dictionary_1    definition_1  =  text_1
some_dictionary_1    definition_2  =  text_2
some_dictionary_1    etc  =  etc.
some_other_dictionary_2    key_3  =  value_3
some_other_dictionary_2    key_4  =  value_4
some_other_dictionary_2    etc  =  etc.
......
......
......
some_other_dictionary_n    random_n  =  random_n
some_other_dictionary_n    etc  =  etc.


Unfortunately, get_indentifier_name_missing_function() would not see the 'original' identifier names (some_dictionary_,some_other_dictionary_2,some_other_dictionary_n). It would only see the a_dictionary_object identifier name.

Therefore the real result would rather be:

a_dictionary_object    definition_1  =  text_1
a_dictionary_object    definition_2  =  text_2
a_dictionary_object    etc  =  etc.
a_dictionary_object    key_3  =  value_3
a_dictionary_object    key_4  =  value_4
a_dictionary_object    etc  =  etc.
......
......
......
a_dictionary_object    random_n  =  random_n
a_dictionary_object    etc  =  etc.


So, the reverse of the eval() function won't be that useful in this case.



Currently, one would need to do this:

# main2.py same as above, except:

    for each_one_of_my_dictionaries_names in ( 'some_dictionary_1',
                                               'some_other_dictionary_2',
                                               '...',
                                               'some_other_dictionary_n' ):
        some_module2.some_function( { each_one_of_my_dictionaries_names :
                                     eval(each_one_of_my_dictionaries_names) } )


    # some_module2.py
    def some_function(a_dictionary_name_object_container):
        for _dictionary_name, _dictionary_object in a_dictionary_name_object_container.items():
            for _key, _value in _dictionary_object.items():
                print( str(_dictionary_name) +
                       ""    "" +
                       str(_key) +
                       ""  =  "" +
                       str(_value) )
    ######




In conclusion:


Python passes only memory addresses as arguments to functions.
Strings representing the name of an identifier, can only be referenced back to the actual identifier by the eval() function if the name identifier is available in the current namespace.
A hypothetical reverse of the eval() function, would not be useful in cases where the identifier name is not 'seen' directly by the calling code. E.g. inside any called function.
Currently one needs to pass to a function:

the string representing the identifier name
the actual identifier (memory address)



This can be achieved by passing both the 'string' and eval('string') to the called function at the same time. I think this is the most 'general' way of solving this egg-chicken problem across arbitrary functions, modules, namespaces, without using corner-case solutions. The only downside is the use of the eval() function which may easily lead to unsecured code. Care must be taken to not feed the eval() function with just about anything, especially unfiltered external-input data.
",Convert Variable Name to String?,"I would like to convert a python variable name into the string equivalent as shown. Any ideas how?

var = {}
print ???  # Would like to see 'var'
something_else = 3
print ???  # Would print 'something_else'

"
"Objects do not necessarily have names in python, so you can't get the name.
It's not unusual for objects to have a __name__ attribute in those cases that they do have a name, but this is not a part of standard python, and most built in types do not have one.

When you create a variable, like the x, y, z above then those names just act as ""pointers"" or ""references"" to the objects. The objects itself do not know what names you are using for it, and you can not easily (if at all) get the names of all references to an object.

Update: However, functions do have a __name__ (unless they are lambdas) so, in this case you can do:

dict([(t.__name__, t) for t in fun_list])

",How can I get the name of an object in Python?,"Is there any way to get the name of an object in Python?  For instance:

my_list = [x, y, z] # x, y, z have been previously defined

for bla in my_list:
    print ""handling object "", name(bla) # <--- what would go instead of `name`?
    # do something to bla


Edit: Some context:

What I'm actually doing is creating a list of functions that I can specify by the command line.

I have:

def fun1:
    pass
def fun2
    pass
def fun3:
    pass

fun_dict = {'fun1': fun1,
            'fun2': fun2,
            'fun3': fun3}


I get the name of the function from the commandline and I want to call the relevant function:

func_name = parse_commandline()

fun_dict[func_name]()


And the reason I want to have the name of the function is because I want to create fun_dict without writing the names of the functions twice, since that seems like a good way to create bugs.  What I want to do is:

fun_list = [fun1, fun2, fun3] # and I'll add more as the need arises

fun_dict = {}
[fun_dict[name(t) = t for t in fun_list] # <-- this is where I need the name function


This way I only need to write the function names once.
"
"Another possibility is going the other way around, instead of generating substrings from a string, grab all your candidate words and match them against your string. 

You can store as a result (start,end) pairs of indexes of the words in the original string.

This could be easily done in regex, or, if not performant enough, with str.find(), or if even not performant enough with more complex dictionary index schemes or smarts about what can and can't match (see Gregg's answer for ideas)

Here you have a sample of what I mean

candidate = ""thingsandstuffmydarlingpretty""
words = file('/usr/share/dict/words').read()
#This generator calls find twice, it should be rewritten as a normal loop
generate_matches = ((candidate.find(word),word) for word in words.split('\n')
                     if candidate.find(word) != -1 and word != '')

for match in generate_matches:
    print ""Found %s at (%d,%d)"" % (match[1],match[0],match[0] + len(match[1]))

",How to sort all possible words out of a string?,"I'm wondering how to proceed with this task, take this string for example ""thingsandstuff"".

How could I generate all possible strings out of this string as to look them up individually against an english dictionary?

The goal is to find valid english words in a string that does not contain space.

Thanks
"
"The .title() method of a string (either ASCII or Unicode is fine) does this:

>>> ""hello world"".title()
'Hello World'
>>> u""hello world"".title()
u'Hello World'


However, look out for strings with embedded apostrophes, as noted in the docs.


  The algorithm uses a simple language-independent definition of a word as groups of consecutive letters. The definition works in many contexts but it means that apostrophes in contractions and possessives form word boundaries, which may not be the desired result:

>>> ""they're bill's friends from the UK"".title()
""They'Re Bill'S Friends From The Uk""


",How to capitalize the first letter of each word in a string (Python)?,"s = 'the brown fox'


...do something here...

s should be :

'The Brown Fox'


What's the easiest way to do this?
"
"Yes, there is. Or, write your own and tailor it to your needs.



The function (as the blog author deleted it).

def pretty_date(time=False):
    """"""
    Get a datetime object or a int() Epoch timestamp and return a
    pretty string like 'an hour ago', 'Yesterday', '3 months ago',
    'just now', etc
    """"""
    from datetime import datetime
    now = datetime.now()
    if type(time) is int:
        diff = now - datetime.fromtimestamp(time)
    elif isinstance(time,datetime):
        diff = now - time
    elif not time:
        diff = now - now
    second_diff = diff.seconds
    day_diff = diff.days

    if day_diff < 0:
        return ''

    if day_diff == 0:
        if second_diff < 10:
            return ""just now""
        if second_diff < 60:
            return str(second_diff) + "" seconds ago""
        if second_diff < 120:
            return ""a minute ago""
        if second_diff < 3600:
            return str(second_diff / 60) + "" minutes ago""
        if second_diff < 7200:
            return ""an hour ago""
        if second_diff < 86400:
            return str(second_diff / 3600) + "" hours ago""
    if day_diff == 1:
        return ""Yesterday""
    if day_diff < 7:
        return str(day_diff) + "" days ago""
    if day_diff < 31:
        return str(day_diff / 7) + "" weeks ago""
    if day_diff < 365:
        return str(day_diff / 30) + "" months ago""
    return str(day_diff / 365) + "" years ago""

",User-friendly time format in Python?,"Python: I need to show file modification times in the ""1 day ago"", ""two hours ago"", format.

Is there something ready to do that? It should be in English.
"
"Because ""append"" existed long before ""pop"" was thought of. Python 0.9.1 supported list.append in early 1991. By comparison, here's part of a discussion on comp.lang.python about adding pop in 1997. Guido wrote:


  To implement a stack, one would need
  to add a list.pop() primitive  (and
  no, I'm not against this particular
  one on the basis of any  principle). 
  list.push() could be added for
  symmetry with list.pop()  but I'm not
  a big fan of multiple names for the
  same operation --  sooner or later
  you're going to read code that uses
  the other one, so  you need to learn
  both, which is more cognitive load.


You can also see he discusses the idea of if push/pop/put/pull should be at element [0] or after element [-1] where he posts a reference to Icon's list:


  I stil think that all this is best
  left out of the list object 
  implementation -- if you need a stack,
  or a queue, with particular 
  semantics, write a little class that
  uses a lists


In other words, for stacks implemented directly as Python lists, which already supports fast append(), and del list[-1], it makes sense that list.pop() work by default on the last element. Even if other languages do it differently.

Implicit here is that most people need to append to a list, but many fewer have occasion to treat lists as stacks, which is why list.append came in so much earlier.
","Why is Python's ""append"" not ""push""?","Does anyone know why Python's list.append function is not called list.push given that there's already a list.pop that removes and returns the last element (that indexed at -1) and list.append semantic is consistent with that use?
"
"As noone has added it, it should be noted that going forward from Python 2.6+ the recommended way to do string formating is with format, to get ready for Python 3+.

print [""{0:0.2f}"".format(i) for i in a]


The new string formating syntax is not hard to use, and yet is quite powerfull.

I though that may be pprint could have something, but I haven't found anything.
",Easy pretty printing of floats in python?,"I have a list of floats. If I simply print it, it shows up like this:

[9.0, 0.052999999999999999, 0.032575399999999997, 0.010892799999999999, 0.055702500000000002, 0.079330300000000006]


I could use print ""%.2f"", which would require a for loop to traverse the list, but then it wouldn't work for more complex data structures.
I'd like something like (I'm completely making this up)

>>> import print_options
>>> print_options.set_float_precision(2)
>>> print [9.0, 0.052999999999999999, 0.032575399999999997, 0.010892799999999999, 0.055702500000000002, 0.079330300000000006]
[9.0, 0.05, 0.03, 0.01, 0.06, 0.08]

"
"If you don't care about the order in which items are processed, I'd try a subclass of Queue that uses set internally:

class SetQueue(Queue):

    def _init(self, maxsize):
        self.maxsize = maxsize
        self.queue = set()

    def _put(self, item):
        self.queue.add(item)

    def _get(self):
        return self.queue.pop()


As Paul McGuire pointed out, this would allow adding a duplicate item after it's been removed from the ""to-be-processed"" set and not yet added to the ""processed"" set. To solve this, you can store both sets in the Queue instance, but since you are using the larger set for checking if the item has been processed, you can just as well go back to queue which will order requests properly.

class SetQueue(Queue):

    def _init(self, maxsize):
        Queue._init(self, maxsize) 
        self.all_items = set()

    def _put(self, item):
        if item not in self.all_items:
            Queue._put(self, item) 
            self.all_items.add(item)


The advantage of this, as opposed to using a set separately, is that the Queue's methods are thread-safe, so that you don't need additional locking for checking the other set.
",How check if a task is already in python Queue?,"I'm writing a simple crawler in Python using the threading and Queue modules. I fetch a page, check links and put them into a queue, when a certain thread has finished processing page, it grabs the next one from the queue. I'm using an array for the pages I've already visited to filter the links I add to the queue, but if there are more than one threads and they get the same links on different pages, they put duplicate links to the queue. So how can I find out whether some url is already in the queue to avoid putting it there again?
"
"What you can do is to wrap the invocation into a function of its own.

So that

foo()

def foo():
    print ""Hi!""


will break, but

def bar():
    foo()

def foo():
    print ""Hi!""

bar()


will be working properly.

General rule in Python is not that function should be defined higher in the code (as in Pascal), but that it should be defined before its usage.

Hope that helps.  
",Is it possible to forward-declare a function in Python?,"Is it possible to forward-declare a function in Python?  I want to sort a list using my own cmp function before it is declared.  

print ""\n"".join([str(bla) for bla in sorted(mylist, cmp = cmp_configs)])


I've organized my code to put the definition of cmp_configs method after the invocation.  It fails with this error:

NameError: name 'cmp_configs' is not defined


Is there any way to ""declare"" cmp_configs method before it's used?  It would make my code look cleaner?

I assume that some people will be tempted to tell me that I should just reorganize my code so that I don't have this problem.  However, there are cases when this is probably unavoidable, for instance when implementing some forms of recursion.  If you don't like this example, assume that I have a case in which it's really necessary to forward declare a function.

Consider this case where forward-declaring a function would be necessary in Python:

def spam():
    if end_condition():
        return end_result()
    else:
        return eggs()

def eggs():
    if end_condition():
        return end_result()
    else:
        return spam()


Where end_condition and end_result have been previously defined.

Is the only solution to reorganize the code and always put definitions before invocations?
"
"The use of ""super"" (see Python Built-in, super) may be a slightly better method of calling the parent for initialization:

# Initialize using Parent
#
class MySubClass(MySuperClass):
    def __init__(self):
        MySuperClass.__init__(self)

# Better initialize using Parent (less redundant).
#
class MySubClassBetter(MySuperClass):
    def __init__(self):
        super(MySubClassBetter, self).__init__()

",Python: How do I make a subclass from a superclass?,"In Python, how do you make a subclass from a superclass?
"
"XML::Twig is very nice, especially because itâs not as awfully verbose as some of the other options.
",Parsing XML - right scripting languages / packages for the job?,"I know that any language is capable of parsing XML; I'm really just looking for advantages or drawbacks that you may have come across in your own experiences.  Perl would be my standard go to here, but I'm open to suggestions.

Thanks!

UPDATE: I ended up going with XML::Simple which did a nice job, but I have one piece of advice if you plan to use it--research the forcearray option first.  I had to rewrite a bunch of statements after learning that it is usually best practice to set forcearray.  This page had the clearest explanation that I could find. Frankly, I'm surprised this isn't the default behavior.
"
"I wanted a Log viewer as a list only.

I got it working like this:

class LogEntryAdmin(ModelAdmin):
    actions = None
    list_display = (
        'action_time', 'user',
        'content_type', 'object_repr', 
        'change_message')

    search_fields = ['=user__username', ]
    fieldsets = [
        (None, {'fields':()}), 
        ]

    def __init__(self, *args, **kwargs):
        super(LogEntryAdmin, self).__init__(*args, **kwargs)
        self.list_display_links = (None, )


It is kind of a mix between both answers.

If you just do self.list_display_links = () it will show the link, Anyway because the template-tag code (templatetags/admin_list.py) checks again to see if the list is empty.
",Disable link to edit object in django's admin (display list only)?,"In Django's admin, I want disable the links provided on the ""select item to change"" page so that users cannot go anywhere to edit the item.  (I am going to limit what the users can do with this list to a set of drop down actions - no actual editing of fields).

I see that Django has the ability to choose which fields display the link, however, I can't see how I can have none of them.  

class HitAdmin(admin.ModelAdmin):
    list_display = ('user','ip','user_agent','hitcount')
    search_fields = ('ip','user_agent')
    date_hierarchy = 'created'
    list_display_links = [] # doesn't work, goes to default


Any ideas how to get my object list without any links to edit?
"
"This is a typical job for NumPy, which is very fast for these kinds of operations:

array_np = numpy.asarray(array)
low_values_indices = array_np < lowValY  # Where values are low
array_np[low_values_indices] = 0  # All low values set to 0


Now, if you only need the highCountX largest elements, you can even ""forget"" the small elements (instead of setting them to 0 and sorting them) and only sort the list of large elements:

array_np = numpy.asarray(array)
print numpy.sort(array_np[array_np >= lowValY])[-highCountX:]


Of course, sorting the whole array if you only need a few elements might not be optimal.  Depending on your needs, you might want to consider the standard heapq module.
",Fastest way to zero out low values in array?,"So, lets say I have 100,000 float arrays with 100 elements each.  I need the highest X number of values, BUT only if they are greater than Y.  Any element not matching this should be set to 0.   What would be the fastest way to do this in Python?  Order must be maintained.  Most of the elements are already set to 0.

sample variables:

array = [.06, .25, 0, .15, .5, 0, 0, 0.04, 0, 0]
highCountX = 3
lowValY = .1


expected result:

array = [0, .25, 0, .15, .5, 0, 0, 0, 0, 0]

"
"Most of the times it is easier (and cheaper) to make the first iteration the special case instead of the last one:

first = True
for data in data_list:
    if first:
        first = False
    else:
        between_items()

    item()


This will work for any iterable, even for those that have no len():

file = open('/path/to/file')
for line in file:
    process_line(line)

    # No way of telling if this is the last line!


Apart from that, I don't think there is a generally superior solution as it depends on what you are trying to do. For example, if you are building a string from a list, it's naturally better to use str.join() than using a for loop âwith special caseâ.



Using the same principle but more compact:

for i, line in enumerate(data_list):
    if i > 0:
        between_items()
    item()


Looks familiar, doesn't it? :)



For @ofko, and others who really need to find out if the current value of an iterable without len() is the last one, you will need to look ahead:

def lookahead(iterable):
    """"""Pass through all values from the given iterable, augmented by the
    information if there are more values to come after the current one
    (True), or if it is the last value (False).
    """"""
    # Get an iterator and pull the first value.
    it = iter(iterable)
    last = next(it)
    # Run the iterator to exhaustion (starting from the second value).
    for val in it:
        # Report the *previous* value (more to come).
        yield last, True
        last = val
    # Report the last value.
    yield last, False


Then you can use it like this:

>>> for i, has_more in lookahead(range(3)):
...     print(i, has_more)
0 True
1 True
2 False

",What is the pythonic way to detect the last element in a python 'for' loop?,"I'd like to know the best way (more compact and ""pythonic"" way) to do a special treatment for the last element in a for loop. There is a piece of code that should be called only between elements, being suppressed in the last one.

Here is how I currently do it:

for i, data in enumerate(data_list):
    code_that_is_done_for_every_element
    if i != len(data_list) - 1:
        code_that_is_done_between_elements


Is there any better way?

Note: I don't want to make it with hacks such as using reduce ;)
"
"You can't undo one graphic written over the top of another graphic any more than you can undo one chalk illustration drawn over the top of another chalk illustration on the same board.

What is typically done in graphics is what you'd do with the chalkboard - clear the whole lot, and next time only redraw what you want to keep.
","Is there any way to ""clear"" a surface?","Is there any way to clear a surface from anything that has been blitted to it?
"
"EasyGUI is a single file, and provides a simple way to work with Tkinter dialogs, but they're still ugly non-native Tkinter dialogs.

from easygui import msgbox
msgbox('Stuff')





Apparently it is now abandonware, but there's also a fork called EasyGuiTtk, obtainable via pip install https://github.com/Who8MyLunch/EasyGuiTtk/archive/master.zip


",What's the simplest cross-platform way to pop up graphical dialogs in Python?,"I want the simplest possible way to pop up simple dialogs in Python scripts.  Ideally, the solution would:


Work on Windows, OS X, Gnome, KDE
Look like a native dialog on any OS
Require minimal code


To pop up a simple standard dialog should require only minimal code.  Essentially you're just saying ""Pop up a standard dialog with this text"", or ""Pop up a dialog with question x and feed response into variable y"".

This is for simple scripts that would otherwise run on the command line.  I don't want to know about GUI frameworks or have to set up code that says ""start a GUI thread, register an event handler, configure some window properties, run a loop"", etc.  I don't want to have to set up a window or close the window afterward.  I give it the text to put in the window and/or buttons and/or checkboxes, it returns what the user clicked on.  Everything else should be taken care of automatically.  For example:

message_box('File conversion complete')


for a standard dialog box with an ""Ok"" button, or

balloon_tip('File conversion complete')


for a system tray popup balloon, or

format = button_box('Which file format do you want?', 'JPG', 'PNG')


and they press one of the two buttons, and then format equals 'JPG', or

response = text_query('What would you like to name the file?')


and after they type in the box and press Ok, response now equals 'bananas.txt'.  No other code required.  No ugly command line prompts for the poor user.

I've listed Zenity and EasyGUI as example answers, since they're similar to what I want, but not perfect.

[Previously asked on Python Forum]
"
"You could try to encapsulate this in a struct:

typedef struct s_generator {
    int current;
    int (*func)(int);
} generator;

int next(generator* gen) {
    int result = gen->current;
    gen->current = (gen->func)(gen->current);
    return result;
}


Then you define you multiples with:

int next_multiple(int current) { return 2 + current; }
generator multiples_of_2 = {0, next_multiple};


You get the next multiple by calling

next(&multiples_of_2);

",How would one implement Lazy Evaluation in C?,"Take for example,

The follow python code:

def multiples_of_2():
  i = 0
  while True:
    i = i + 2
    yield i


How do we translate this into C code?

Edit: I am looking to translate this python code into a similar generator in C, with next() function. What I am not looking for is how to create a function in C to output multiples of 2. Multiples of 2 is merely an example to illustrate the problem of lazy eval generators in C.
"
"def in_list(small, big):
    l_sml = len(small)
    l_big = len(big)
    return any((big[i:i+l_sml]==small for i in xrange(l_big-l_sml+1)))

print in_list([4,2,1], [1,2,3,4,2,1,0,5]) # True
print in_list([1,2,3], [1,2,4])           # False

",Is there a way to know if a list of elements is on a larger list without using 'in' keyword?,"I want to do this. I have two python lists, one larger than the other and I want to know is there is a way to check if the elements of the smaller list are in the big list in the exact same order for example:

small_list = [4,2,5]
big_list = [1,2,5,7,2,4,2,5,67,8,5,13,45]


I tried using the in keyword but It did not worked :'(
"
"One way to do it is to use findall with a regex that greedily matches things that can go between separators. eg:

>>> s = ""Wilbur Smith (Billy, son of John), Eddie Murphy (John), Elvis Presley, Jane Doe (Jane Doe)""
>>> r = re.compile(r'(?:[^,(]|\([^)]*\))+')
>>> r.findall(s)
['Wilbur Smith (Billy, son of John)', ' Eddie Murphy (John)', ' Elvis Presley', ' Jane Doe (Jane Doe)']


The regex above matches one or more:


non-comma, non-open-paren characters
strings that start with an open paren, contain 0 or more non-close-parens, and then a close paren


One quirk about this approach is that adjacent separators are treated as a single separator. That is, you won't see an empty string. That may be a bug or a feature depending on your use-case.

Also note that regexes are not suitable for cases where nesting is a possibility. So for example, this would split incorrectly:

""Wilbur Smith (son of John (Johnny, son of James), aka Billy), Eddie Murphy (John)""


If you need to deal with nesting your best bet would be to partition the string into parens, commas, and everthing else (essentially tokenizing it -- this part could still be done with regexes) and then walk through those tokens reassembling the fields, keeping track of your nesting level as you go (this keeping track of the nesting level is what regexes are incapable of doing on their own).
",How to split a string by commas positioned outside of parenthesis?,"I got a string of such format: 

""Wilbur Smith (Billy, son of John), Eddie Murphy (John), Elvis Presley, Jane Doe (Jane Doe)""


so basicly it's list of actor's names (optionally followed by their role in parenthesis). The role itself can contain comma (actor's name can not, I strongly hope so).

My goal is to split this string into a list of pairs - (actor name, actor role). 

One obvious solution would be to go through each character, check for occurances of '(', ')' and ',' and split it whenever a comma outside occures. But this seems a bit heavy...

I was thinking about spliting it using a regexp: first split the string by parenthesis:

import re
x = ""Wilbur Smith (Billy, son of John), Eddie Murphy (John), Elvis Presley, Jane Doe (Jane Doe)""
s = re.split(r'[()]', x) 
# ['Wilbur Smith ', 'Billy, son of John', ', Eddie Murphy ', 'John', ', Elvis Presley, Jane Doe ', 'Jane Doe', '']


The odd elements here are actor names, even are the roles. Then I could split the names by commas and somehow extract the name-role pairs. But this seems even worse then my 1st approach.

Are there any easier / nicer ways to do this, either with a single regexp or a nice piece of code? 
"
"I used Python with wxPython for quite a while and found it very easy to use. I now use Java with both Swing and SWT.

I prefer Java but that's just a personal preference so you shouldn't let that sway you.

I didn't find the transition from Python to Java that difficult. In terms of GUI, they both have the layout manager paradigm - the managers are different but not so different you'll have trouble switching.

Java has an absolute huge class library to the point where you probably don't need to write your own version of anything, just string together the components. I never really got that deep into Python but it may well be similar. One thing I did notice is that all the really good stuff I used in Python (e.g., s[-4:-1]) could still be done quite easily in Java. Both languages were a step up from C where I had to manage strings with my own libraries.

If you think wxPython is limited on MacOS, you should try Java. I run my Java code on Windows, Linux and other UNIXes without compatibility problems. Sadly, not Mac, so I can't really advise you there.

My advice, pick a smallish project - do it in both Python and Java - see how it runs on all the platforms you're interested in.
",Cross-Platform Programming Language with a decent gui toolkit?,"For the program idea I have, it requires that the software be written in one binary that is executeable by all major desktop platforms, meaning it needs an interpreted language or a language within a JVM. Either is fine with me, but the programming language has to balance power & simplicity (e.g. Python)

I know of wxPython but I have read that it's support on Mac OS X is fairly limited

Java sounds good & it looks good but it seems almost too difficult to program in

Any help?
"
"There is an ordered set recipe for this which is referred to from the Python 2 Documentation. This runs on Py2.6 or later and 3.0 or later without any modifications. The interface is almost exactly the same as a normal set, except that initialisation should be done with a list.

OrderedSet([1, 2, 3])


This is a MutableSet, so the signature for .union doesn't match that of set, but since it includes __or__ something similar can easily be added:

@staticmethod
def union(*sets):
    union = OrderedSet()
    union.union(*sets)
    return union

def union(self, *sets):
    for set in sets:
        self |= set

",Does Python have an ordered set?,"Python has an ordered dictionary, what about an ordered set?
"
"Probably not exactly what you were thinking, but...

q = request.GET.get('q')
if q:
    print q


this?
",How to avoid writing request.GET.get() twice in order to print it?,"I come from a PHP background and would like to know if there's a way to do this in Python. 

In PHP you can kill 2 birds with one stone like this:

Instead of:

if(getData()){
    $data = getData();
    echo $data;
}


I can do this:

if($data = getData()){
    echo $data;
}


You check to see if getData() exists AND if it does, you assign it to a variable in one statement.

I wanted to know if there's a way to do this in Python? So instead of doing this:

if request.GET.get('q'):
    q = request.GET.get('q')
    print q


avoid writing request.GET.get('q') twice.
"
"As others have pointed out, there is no built-in mount function.  However, it is easy to create one using ctypes, and this is a bit lighter weight and more reliable than using a shell command:

import ctypes
import os

def mount(source, target, fs, options=''):
  ret = ctypes.CDLL('libc.so.6', use_errno=True).mount(source, target, fs, 0, options)
  if ret < 0:
    errno = ctypes.get_errno()
    raise RuntimeError(""Error mounting {} ({}) on {} with options '{}': {}"".
     format(source, fs, target, options, os.strerror(errno)))

mount('/dev/sdb1', '/mnt', 'ext4', 'rw')

",How do I mount a filesystem using Python?,"I'm sure this is a easy question, my Google-fu is obviously failing me.

How do I mount a filesystem using Python, the equivalent of running the shell command mount ...?

Obviously I can use os.system to run the shell command, but surely there is a nice tidy, Python interface to the mount system call.

I can't find it. I thought it would just be a nice, easy os.mount().
"
"
  Or we can store the dict string
  directly to DB without serializing.


There is no such thing as ""the dict string"".  There are many ways to serialize a dict into a string; you may be thinking of repr, possibly as eval as the way to get the dict back (you mention exec, but that's simply absurd: what statement would you execute...?!  I think you probably mean eval).  They're different serialization methods with their tradeoffs, and in many cases the tradeoffs tend to favor pickling (cPickle, for speed, with protocol -1 meaning ""the best you can do"", usually).

Performance is surely an issue, e.g., in terms of size of what you're storing...:

$ python -c 'import cPickle; d=dict.fromkeys(range(99), ""banana""); print len(repr(d))'
1376
$ python -c 'import cPickle; d=dict.fromkeys(range(99), ""banana""); print len(cPickle.dumps(d,-1))'
412


...why would you want to store 1.4 KB rather than 0.4 KB each time you serialize a dict like this one...?-)

Edit: since some suggest Json, it's worth pointing out that json takes 1574 bytes here -- even bulkier than bulky repr!

As for speed...

$ python -mtimeit -s'import cPickle; d=dict.fromkeys(range(99), ""chocolate"")' 'eval(repr(d))'
1000 loops, best of 3: 706 usec per loop
$ python -mtimeit -s'import cPickle; d=dict.fromkeys(range(99), ""chocolate"")' 'cPickle.loads(cPickle.dumps(d, -1))'
10000 loops, best of 3: 70.2 usec per loop


...why take 10 times longer?  What's the upside that would justify paying such a hefty price?

Edit: json takes 2.7 milliseconds -- almost forty times slower than cPickle.

Then there's generality -- not every serializable object can properly round-trip with repr and eval, while pickling is much more general.  E.g.:

$ python -c'def f(): pass
d={23:f}
print d == eval(repr(d))'
Traceback (most recent call last):
  File """", line 3, in 
  File """", line 1
    {23: }
         ^
SyntaxError: invalid syntax


vs

$ python -c'import cPickle
def f(): pass
d={""x"":f}
print d == cPickle.loads(cPickle.dumps(d, -1))'
True


Edit: json is even less general than repr in terms of round-trips.

So, comparing the two serialization approaches (pickling vs repr/eval), we see: pickling is way more general, it can be e.g. 10 times faster, and take up e.g. 3 times less space in your database.

What compensating advantages do you envisage for repr/eval...?

BTW, I see some answers mention security, but that's not a real point: pickling is insecure too (the security issue with eval`ing untrusted strings may be more obvious, but unpickling an untrusted string is also insecure, though in subtler and darker ways).

Edit: json is more secure.  Whether that's worth the huge cost in size, speed and generality, is a tradeoff worth pondering.  In most cases it won't be.
",Why we should perfer to store the serialized data not the raw code to DB?,"If we have some code(a data structure) which should be stored in DB, someone always suggests us to store the serialized data not the raw code string.

So I'm not so sure why we should prefer the serialized data.

Give a simple instance(in python):

we've got a field which will store a dict of python, like 

{ ""name"" : ""BMW"", ""category"":""car"", ""cost"" : ""200000""}


so we can serialize it using pickle(a python module) and then store the pickled data to db field.

Or we can store the dict string directly to DB without serializing. 

Since we need to convert the string to python data back, two approaches are both easy to do, by using pickle.loads and exec respectively.

So which should be preferred? And why? Is it because exec is much slower than pickle? or some other reasons?

Thanks.
"
"import os, threading, Queue

def idmaker(aqueue):
  while True:
    u = hexlify(os.urandom(8)).decode('ascii')
    aqueue.put(u)

idqueue = Queue.Queue(2)

t = threading.Thread(target=idmaker, args=(idqueue,))
t.daemon = True
t.start()

def idgetter():
  return idqueue.get()


Queue is often the best way to synchronize threads in Python -- that's frequent enough that when designing a multi-thread system your first thought should be ""how could I best do this with Queues"".  The underlying idea is to dedicate a thread to entirely ""own"" a shared resource or subsystem, and have all other ""worker"" threads access the resource only by gets and/or puts on Queues used by that dedicated thread (Queue is intrinsically threadsafe).

Here, we make an idqueue with a length of only 2 (we don't want the id generation to go wild, making a lot of ids beforehand, which wastes memory and exhausts the entropy pool -- not sure if 2 is optimal, but the sweet spot is definitely going to be a pretty small integer;-), so the id generator thread will block when trying to add the third one, and wait until some space opens in the queue.  idgetter (which could also be simply defined by a top-level assignment, idgetter = idqueue.get) will normally find an id already there and waiting (and make space for the next one!) -- if not, it intrinsically blocks and waits, waking up as soon as the id generator has placed a new id in the queue.
",How do you generate random unique identifiers in a multi process and multi thread environment?,"Every solution I come up with is not thread save.

def uuid(cls,db):
    u = hexlify(os.urandom(8)).decode('ascii')
    db.execute('SELECT sid FROM sessions WHERE sid=?',(u,))
    if db.fetch(): u=cls.uuid(db)
    else: db.execute('INSERT INTO sessions (sid) VALUES (?)',(u,))
    return u

"
"I would go for option three.


First option: (Not safe)


  The code opens âHKEY_CURRENT_USER\Software\Python\PythonCoreâ, if the key exists it will get the path from the first child key of this key.


Check if this key exists, and if does not, you could try creating it.
Second option:

Use a batch script that runs the Python script and then create a shortcut to that from Notepad++.

As explained here: http://it-ride.blogspot.com/2009/08/notepad-and-python.html
Third option: (The easiest one)

Open Notepad++. On the menu go to: Run -> Run.. (F5). Type in:

C:\Python26\python.exe ""$(FULL_CURRENT_PATH)""


Note: If you have Python 3.1: type in Python31 instead of Python26

Note: Add -i if you want the command line window to stay open after the script has finished

Now, instead of pressing run, press save to create a shortcut for it.

",How to Execute a Python File in Notepad ++?,"I prefer using Notepad ++ for developing,

How do I execute the files in Python through Notepad++?
"
"Well, the simplest way would be to constantly read from the file, check what's new and test for hits.

import time

def watch(fn, words):
    fp = open(fn, 'r')
    while True:
        new = fp.readline()
        # Once all lines are read this just returns ''
        # until the file changes and a new line appears

        if new:
            for word in words:
                if word in new:
                    yield (word, new)
        else:
            time.sleep(0.5)

fn = 'test.py'
words = ['word']
for hit_word, hit_sentence in watch(fn, words):
    print ""Found %r in line: %r"" % (hit_word, hit_sentence)


This solution with readline works if you know your data will appear in lines. 

If the data is some sort of stream you need a buffer, larger than the largest word you're looking for, and fill it first. It gets a bit more complicated that way...
",How to implement a pythonic equivalent of tail -F?,"What is the pythonic way of watching the tail end of a growing file for the occurrence of certain keywords?

In shell I might say:

tail -f ""$file"" | grep ""$string"" | while read hit; do
    #stuff
done

"
"for line in open(name, ""r""):
    line = line.replace('""', '').strip()
    a, b, c, d = map(float, line.split())


This is kind of bare-bones, and will raise exceptions if (for example) there aren't four values on the line, etc.
","Can Python remove double quotes from a string, when reading in text file?","I have some text file like this, with several 5000 lines:

5.6  4.5  6.8  ""6.5"" (new line)
5.4  8.3  1.2  ""9.3"" (new line)


so the last term is a number between double quotes.

What I want to do is, using Python (if possible), to assign the four columns to double variables. But the main problem is the last term, I found no way of removing the double quotes to the number, is it possible in linux?

This is what I tried:

#!/usr/bin/python

import os,sys,re,string,array

name=sys.argv[1]
infile = open(name,""r"")

cont = 0
while 1:
         line = infile.readline()
         if not line: break
         l = re.split(""\s+"",string.strip(line)).replace('\""','')
     cont = cont +1
     a = l[0]
     b = l[1]
     c = l[2]
     d = l[3]

"
"Although an answer has been given for C++, it looks from your description (""[You] don't want to measure anything within the loop"") like you're trying to measure the time which it takes a program to iterate over an empty loop.

Please take care here: not only will it take varying times from different platforms and processors, but many compilers will optimise away such loops, effectively rendering the answer as ""0"" for any loop size.
",How can I measure the execution time of a for loop?,"I want to measure the execution time of for loops on various platforms like php, c, python, Java, javascript... How can i measure it?

I know these platforms so i am talking about these:

 for (i = 0; i < 1000000; i++)
 {

 }


I don't want to measure anything within the loop.

Little bit modification:

@all Some of the friends of mine are saying compiler will optimize this code making this loop a useless loop.  I agree with this. we can add a small statement like some incremental statement, but the fact is I just want to calculate the execution time of per iteration in a loop in various languages.  By adding a incremental statement will add up the execution time and that will effect the results, cause on various platforms, execution time for incrementing a value also differ and that will make a result useless.
In short, in better way I should ask:

I WANT TO CALCULATE THE EXECUTION TIME OF PER ITERATION IN A LOOP on Various PLATFORMS..HOW CAN DO THIS???

edit---

I came to know about  Python Profilers
Profiler modules ...which evaluate cpu time... absolute time.. Any suggestions???Meanwhile i am working on this...
"
"TextMate is a great general-purpose editor for mac. Used by the Rails community a lot, but it's great with python too.
",Native Python Editor for Mac?,"I'm currently using IDLE, its decent, but I'd like to know if there're better lightweight IDEs built especially for Mac âÂ free or commercial. 
"
"I encountered the same ImportError. Somehow the setuptools package had been deleted in my Python environment.

To fix the issue, run the setup script for setuptools:

curl https://bitbucket.org/pypa/setuptools/raw/bootstrap/ez_setup.py | python


If you have any version of distribute, or any setuptools below 0.6, you will have to uninstall it first.*

See Installation Instructions for further details.



* If you already have a working distribute, upgrading it to the ""compatibility wrapper"" that switches you over to setuptools is easier. But if things are already broken, don't try that.
",What is causing ImportError: No module named pkg_resources after upgrade of Python on os X?,"I just updated Python to 2.6.4 on my Mac. 
I installed from the dmg package.

The binary did not seem to correctly set my Python path, so I added '/usr/local/lib/python2.6/site-packages' in .bash_profile

>>> pprint.pprint(sys.path)  
['',
'/Users/Bryan/work/django-trunk', 
'/usr/local/lib/python2.6/site-packages',  
'/Library/Frameworks/Python.framework/Versions/2.6/lib/python26.zip',  
'/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6',  
'/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/plat-darwin',  
'/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/plat-mac',  
'/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/plat-mac/lib-scriptpackages',  
'/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/lib-tk',  
'/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/lib-old',  
'/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/lib-dynload',  
'/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/site-packages']


Apparently that is not all the required paths because I can't run iPython.

$ ipython  
Traceback (most recent call last):  
  File ""/usr/local/bin/ipython"", line 5, in   
  from pkg_resources import load_entry_point  
ImportError: No module named `pkg_resources`


I've done Google searches and I can't really figure out how to install pkg_resources or make sure it's on the path.

What do I need to do to fix this?
"
"For me its the flexibility and elegance, but there are a handful of things I wish could be pulled in from other languages though (better threading, more robust expressions).

In typical I can write a little bit of code in python and do a lot more than the same amount of lines in many other languages.  Also, in python code form is of utmost importance and the syntax lends its self to highly readable, clean looking code.  That of course helps out with maintenance. 

I love having a command line interpreter that I can quickly prototype an algorithm in rather than having to start up a new project, code, compile, test, repeat.  Not to mention the fact I can use it to help me automate my server maintenance as well (I double as a SA for my company).

The last thing that comes to mind immediately is the vast amounts of libraries.  There are a lot of things already solved out there, the built-in library has a lot to offer, and the third party ones are many times very good (not always though).
",What Python features will excite the interest of a C# developer?,"For someone whoâs been happily programming in C# for quite some time now and planning to learn a new language I find the Python community more closely knit than many others.  

Personally dynamic typing puts me off, but I am fascinated by the way the Python community rallies around it. There are a lot of other things I expect I would miss in Python (LINQ, expression trees, etc.)  

What are the good things about Python that developers love? Stuff thatâll excite me more than C#.
"
"This isn't pythonic, but it is language neutral. Often val = 1 - val is simplest.
",Swapping 1 with 0 and 0 with 1 in a pythonic way?,"In some part of my Python program I have a val variable that can be 1 or 0. If it's 1 I must change to 0, if it's 0 I must change to 1.

How do you do it in a Pythonic way?

if val == 1:
    val = 0
elif val == 0:
    val = 1


it's too long!

I did:

swap = {0: 1, 1:0}


So I can use it:

swap[val]


Other ideas?
"
"Some Python limits :

- Python is slow. It can be improved in many ways (see other answers) but the bare bone cPython is 100 times slower that C/C++. 

This problem is getter more and more mitigated. With Numpy, Pypy and asyncio, most performance problems are not covered, and only very specific use cases are a bottleneck in Python anymore.

- Python is opened to anything. It's really hard to protect / obfuscate / limit Python code. 

- Python is not hype. Unlike Ruby, there is no ""cool wave"" around Python, and it's still much harder to find a experienced Python coder, than, let's say, a Java or a PHP pro.

- After using Python, a lot of languages seems to be a pain to use. You'd think it's good, but believe me, not always. When you have to go Javascript after a Python project, your eyes are in tears for at least 3 days. Really hard to get started.

- It's harder to find web hosting than for popular solutions, such as PHP.

- As a dynamic language, you don't have the very handy refactoring tools you could get with Java and Eclipse or C# and VS. 

- For the same reason, you can't rely on type checking as a safety net. This is why pythonistas tend to follow best practice and write unit tests more often than others. 

- It seems I just can't find an IDE with a decent code completion. PyDev, Gedit, Komodo, SPE, etc. just don't do it as good as it could be.

With Python 3 types hints and tools like PyCharm or Sublime Text+Anaconda, the situation has changed a lot.

- The best docs are still in English only. Some people don't deal well with it.

- You have to get use to the syntax. Not only you get spaces and line breaks instead of bracets, but you can forget about long lambdas, --i, and ternary operation.

Now, to me, these are not reasons to not learn a tool that will make you produce more while having more fun. But maybe it's just me :-)

Honestly, given that :


C++ much harder to learn;
You can do pretty much any thing you want with Python;
You will get quicker result with Python in your projects.


Unless you have professional issues involving C++, you'd better learn Python first, it's more motivating. You still can learn C++ later, it's a useful language for system programming, embedded devices and such.

Don't try to learn both at the same times, multitasking rarely ends well.
",What are the limits of Python?,"I spent a few days reading about C++ and Python and I found that Python is so much simpler and easy to learn. 

So I wonder does it really worth spending time learning it? Or should I invest that time learning C++ instead?

What can C++ do and Python can't ?
"
"I would add a docstring which explains what it compares, as you did in your question.
",Python: Can you make this __eq__ easy to understand?,"I have another question for you.

I have a python class with a list 'metainfo'. This list contains variable names that my class might contain. I wrote a __eq__ method that returns True if the both self and other have the same variables from metainfo and those variables have the same value.

Here is my implementation:

 def __eq__(self, other):
    for attr in self.metainfo:
      try:
        ours = getattr(self, attr) 
        try:
          theirs = getattr(other, attr)
          if ours != theirs:
            return False
        except AttributeError:
          return False
      except AttributeError:
        try:
          theirs = getattr(other, attr)
          return False
        except AttributeError:
          pass
    return True


Does anyone have any suggestions as to how I can make this code easier on the eye? Be as ruthless as you please.
"
"Several reasons:


faster development loop, write-test vs write-compile-link-test
easier to arrange for dynamic behavior (reflection, metaprogramming)
makes the whole system portable (just recompile the underlying C code and you are good to go on a new platform)


Think of what would happen if the system was not interpreted. Say you used translation-to-C as the mechanism. The compiled code would periodically have to check if it had been superseded by metaprogramming. A similar situation arises with eval()-type functions.  In those cases, it would have to run the compiler again, an outrageously slow process, or it would have to also have the interpreter around at run-time anyway. 

The only alternative here is a JIT compiler. These systems are highly complex and sophisticated and have even bigger run-time footprints than all the other alternatives. They start up very slowly, making them impractical for scripting. Ever seen a Java script? I haven't.

So, you have two choices:


all the disadvantages of both a compiler and an interpreter
just the disadvantages of an interpreter


It's not surprising that generally the primary implementation just goes with the second choice. It's quite possible that some day we may see secondary implementations like compilers appearing. Ruby 1.9 and Python have bytecode VM's; those are ½-way there. A compiler might target just non-dynamic code, or it might have various levels of language support declarable as options. But since such a thing can't be the primary implementation, it represents a lot of work for a very marginal benefit. Ruby already has 200,000 lines of C in it...

I suppose I should add that one can always add a compiled C (or, with some effort, any other language) extension. So, say you have a slow numerical operation. If you add, say Array#newOp with a C implementation then you get the speedup, the program stays in Ruby (or whatever) and your environment gets a new instance method. Everybody wins! So this reduces the need for a problematic secondary implementation.
",Why is (python|ruby) interpreted?,"What are the technical reasons why languages like Python and Ruby are interpreted (out of the box) instead of compiled? It seems to me like it should not be too hard for people knowledgeable in this domain to make these languages not be interpreted like they are today, and we would see significant performance gains. So certainly I am missing something. 
"
"maybe something like this (2.6+)

from fractions import Fraction
float(sum(Fraction(s) for s in '1 2/3'.split()))

",Convert fraction to float?,"Kind of like this question, but in reverse.

Given a string like 1, 1/2, or 1 2/3, what's the best way to convert it into a float? I'm thinking about using regexes on a case-by-case basis, but perhaps someone knows of a better way, or a pre-existing solution. I was hoping I could just use eval, but I think the 3rd case prevents that.
"
"Those whitespaces can really be a bother:-(.  Try os.chdir('C:/Documents\ and\ Settings/') followed by relative paths for os.system, subprocess methods, or whatever...

If best-effort attempts to bypass the whitespaces-in-path hurdle keep failing, then my next best suggestion is to avoid having blanks in your crucial paths.  Couldn't you make a blanks-less directory, copy the crucial .exe file there, and try that?  Are those havoc-wrecking space absolutely essential to your well-being...?
",running an outside program (executable) in python?,"I just started working on python and I have been trying to run an outside executable form python.
I have an executable for a program written in Fortran. Lets say the name for the executable is flow.exe. And my executable is lacated in C:\Documents and Settings\flow_model
I tried both os.system and popen commands but so far couldnt make it work.
The following code seems like opens the command window but wouldnt execute the model.

# Import system modules
import sys, string, os, arcgisscripting
os.system(""C:/Documents and Settings/flow_model/flow.exe"")


Any suggestions out there? Any help would be greatly appreciated.
"
"I think you're looking for Python, because you can:


Focus on the algorithms themselves and not have to worry about other detail like memory management.  
Do more with less code
The syntax is almost like working with pseudo code.
There is great built in language support for lists, tuples, list comprehensions, etc...


But more specifically...


If by better you mean speed of development, then chose Python.
If by better you mean sheer execution speed, then chose C++.

",which is a better language (C++ or Python) for  complex problem solving exercises (ex. Graphs)?,"I am trying to work on some problems and algorithms. I know C++ but a friend told me that it would be better if done with Python.As it would be much faster to develop and less time is spent in programming details which does not actually earn anything solution wise.

EDIT 2: I plan to use python-graph lib from Google-codes, Please provide example codes if you have used it.

EDIT 1: faster  - less time && less work to code the solution

Thank you all for your help !
"
"You're not going to be able to do what you want without storing the information somewhere external to the two instances of the interpreter.
If it's just simple variables you want, you can easily dump a python dict to a file with the pickle module in script one and then re-load it in script two.
Example:

one.py

import pickle

shared = {""Foo"":""Bar"", ""Parrot"":""Dead""}
fp = open(""shared.pkl"",""w"")
pickle.dump(shared, fp)


two.py

import pickle

fp = open(""shared.pkl"")
shared = pickle.load(fp)
print shared[""Foo""]

",How to share variables across scripts in python?,"The following does not work

one.py

import shared
shared.value = 'Hello'
raw_input('A cheap way to keep process alive..')


two.py

import shared
print shared.value


run on two command lines as:

>>python one.py
>>python two.py


(the second one gets an attribute error, rightly so).

Is there a way to accomplish this, that is, share a variable between two scripts?
"
"Quoting Wikipedia:


  Jython, successor of JPython, is an implementation of the Python programming language written in Java.


As for what uses it may have:


  Jython programs can seamlessly import and use any Java class. Except for some standard modules, Jython programs use Java classes instead of Python modules.


Performance measurements of Jython, IronPython and CPython show that both Jython and IronPython outperform CPython for some cases with large datasets.
",What is Jython and is it useful at all?,"I know Python. When will I need Jython?  What are the drawbacks. I assume it is slow? Please detail it out! thanks.
"
"from collections import OrderedDict
OrderedDict((word, True) for word in words)


contains 

OrderedDict([('He', True), ('will', True), ('be', True), ('the', True), ('winner', True)])


If the values are True (or any other immutable object), you can also use:

OrderedDict.fromkeys(words, True)

","Python dictionary, how to keep keys/values in same order as declared?","new to Python and had a question about dictionaries. I have a dictionary that I declared in a particular order and want to keep it in that order all the time. The keys/values can't really be kept in order based on their value, I just want it in the order that I declared it.

So if I have the dictionary:

d = {'ac':33, 'gw':20, 'ap':102, 'za':321, 'bs':10}


It isn't in that order if I view it or iterate through it, is there any way to make sure Python will keep the explicit order that I declared the keys/values in?

Using Python 2.6
"
"The first argument for a python class method is the self variable. If you call classInstance.method(parameter), the method is invoked as method(self, parameter).

So, when you're defining your class, do something like this: 

class MyClass(Object): 
    def my_method(self, parameter): 
        print parameter


You might want to read through the Python tutorial.
",Why does my Python class claim that I have 2 arguments instead of 1?,"#! /usr/bin/env python
import os
import stat
import sys
class chkup:

        def set(file):
                filepermission = os.stat(file)
                user_read()
                user_write()
                user_exec()

        def user_read():
                """"""Return True if 'file' is readable by user 
            """"""
            # Extract the permissions bits from the file's (or
            # directory's) stat info.
                b = bool(filepermission.st_mode & stat.S_IRUSR)
                print b
            return b

        def user_write():
                """"""Return True if 'file' is readable by user 
            """"""
            # Extract the permissions bits from the file's (or
            # directory's) stat info.
                b = bool(filepermission.st_mode & stat.S_WRUSR)
                print b
            return b

        def user_exec():
                """"""Return True if 'file' is readable by user 
            """"""
            # Extract the permissions bits from the file's (or
            # directory's) stat info.
                b = bool(filepermission.st_mode & stat.S_IXUSR)
                print b
            return b

def main():
        i = chkup()
        place = '/net/home/f08/itsrsw1/ScriptingWork/quotacheck'
        i.set(place)

if __name__ == '__main__':
        main()


With that code I receive

> Traceback (most recent call last):
  File ""chkup.py"", line 46, in 
    main()
  File ""chkup.py"", line 43, in main
    i.set(place)
TypeError: set() takes exactly 1 argument (2 given)


Any thoughts?
"
"This limitation of the standard shutil.copytree seems arbitrary and annoying. Workaround:

def copytree(src, dst, symlinks=False, ignore=None):
    for item in os.listdir(src):
        s = os.path.join(src, item)
        d = os.path.join(dst, item)
        if os.path.isdir(s):
            shutil.copytree(s, d, symlinks, ignore)
        else:
            shutil.copy2(s, d)


Note that it's not entirely consistent with the standard copytree:


it doesn't honor symlinks and ignore parameters for the root directory of the src tree;
it doesn't raise shutil.Error for errors at the root level of src;
in case of errors during copying of a subtree, it will raise shutil.Error for that subtree instead of trying to copy other subtrees and raising single combined shutil.Error.

",How do I copy an entire directory of files into an existing directory using Python?,"Run the following code from a directory that contains a directory named bar (containing one or more files) and a directory named baz (also containing one or more files).  Make sure there is not a directory named foo.

import shutil
shutil.copytree('bar', 'foo')
shutil.copytree('baz', 'foo')


It will fail with:

$ python copytree_test.py 
Traceback (most recent call last):
  File ""copytree_test.py"", line 5, in 
    shutil.copytree('baz', 'foo')
  File ""/System/Library/Frameworks/Python.framework/Versions/2.5/lib/python2.5/shutil.py"", line 110, in copytree
  File ""/System/Library/Frameworks/Python.framework/Versions/2.5/lib/python2.5/os.py"", line 172, in makedirs
OSError: [Errno 17] File exists: 'foo'


I want this to work the same way as if I had typed:

$ mkdir foo
$ cp bar/* foo/
$ cp baz/* foo/


Do I need to use shutil.copy() to copy each file in baz into foo? (After I've already copied the contents of 'bar' into 'foo' with shutil.copytree()?)  Or is there an easier/better way?
"
"I am not sure this question is solved already or not, but let me paste what I have done for reference.

First, your JSON has nested objects, so it normally cannot be directly converted to CSV.
You need to change that to something like this:

{
    ""pk"": 22,
    ""model"": ""auth.permission"",
    ""codename"": ""add_logentry"",
    ""content_type"": 8,
    ""name"": ""Can add log entry""
},
......]


Here is my code to generate CSV from that:

import csv
import json

x = """"""[
    {
        ""pk"": 22,
        ""model"": ""auth.permission"",
        ""fields"": {
            ""codename"": ""add_logentry"",
            ""name"": ""Can add log entry"",
            ""content_type"": 8
        }
    },
    {
        ""pk"": 23,
        ""model"": ""auth.permission"",
        ""fields"": {
            ""codename"": ""change_logentry"",
            ""name"": ""Can change log entry"",
            ""content_type"": 8
        }
    },
    {
        ""pk"": 24,
        ""model"": ""auth.permission"",
        ""fields"": {
            ""codename"": ""delete_logentry"",
            ""name"": ""Can delete log entry"",
            ""content_type"": 8
        }
    }
]""""""

x = json.loads(x)

f = csv.writer(open(""test.csv"", ""wb+""))

# Write CSV Header, If you dont need that, remove this line
f.writerow([""pk"", ""model"", ""codename"", ""name"", ""content_type""])

for x in x:
    f.writerow([x[""pk""],
                x[""model""],
                x[""fields""][""codename""],
                x[""fields""][""name""],
                x[""fields""][""content_type""]])


You will get output as:

pk,model,codename,name,content_type
22,auth.permission,add_logentry,Can add log entry,8
23,auth.permission,change_logentry,Can change log entry,8
24,auth.permission,delete_logentry,Can delete log entry,8

",How can I convert JSON to CSV?,"I have a JSON file that I want to covert to a CSV file. How can I do this with Python?

I tried:

import json
import csv

f = open('data.json')
data = json.load(f)
f.close()
f = open('data.csv')
csv_file = csv.writer(f)
for item in data:
    f.writerow(item)

f.close()


However, it did not work. I am using Django and the error I received is:

file' object has no attribute 'writerow'


So, then I tried the following:

import json
import csv

f = open('data.json')
data = json.load(f)
f.close()

f = open('data.csv')
csv_file = csv.writer(f)
for item in data:
    csv_file.writerow(item)

f.close()


I then get the error:

sequence expected


Sample json file:

[
  {
    ""pk"": 22,
    ""model"": ""auth.permission"",
    ""fields"": {
      ""codename"": ""add_logentry"",
      ""name"": ""Can add log entry"",
      ""content_type"": 8
    }
  },
  {
    ""pk"": 23,
    ""model"": ""auth.permission"",
    ""fields"": {
      ""codename"": ""change_logentry"",
      ""name"": ""Can change log entry"",
      ""content_type"": 8
    }
  },
  {
    ""pk"": 24,
    ""model"": ""auth.permission"",
    ""fields"": {
      ""codename"": ""delete_logentry"",
      ""name"": ""Can delete log entry"",
      ""content_type"": 8
    }
  },
  {
    ""pk"": 4,
    ""model"": ""auth.permission"",
    ""fields"": {
      ""codename"": ""add_group"",
      ""name"": ""Can add group"",
      ""content_type"": 2
    }
  },
  {
    ""pk"": 10,
    ""model"": ""auth.permission"",
    ""fields"": {
      ""codename"": ""add_message"",
      ""name"": ""Can add message"",
      ""content_type"": 4
    }
  }
]

"
"You can always pass a dictionary as an argument to a function. For instance, 

dict = {'a':1, 'b':2}
def myFunc( a=0,b=0,c=0 ):
  print a,b,c
myFunc(**dict)

","""unpacking"" a passed dictionary into the function's name space in Python?","In the work I do, I often have parameters that I need to group into subsets for convenience:

d1 = {'x':1,'y':2}
d2 = {'a':3,'b':4}


I do this by passing in multiple dictionaries.  Most of the time I use the passed dictionary directly, i.e.:

def f(d1,d2):
    for k in d1:
        blah( d1[k] )


In some functions I need to access the variables directly, and things become cumbersome; I really want those variables in the local name space.  I want to be able to do something like:

def f(d1,d2)
    locals().update(d1)
    blah(x)
    blah(y)


but the updates to the dictionary that locals() returns aren't guaranteed to actually update the namespace.

Here's the obvious manual way:

def f(d1,d2):
    x,y,a,b = d1['x'],d1['y'],d2['a'],d2['b']
    blah(x)
    return {'x':x,'y':y}, {'a':a,'b':b}


This results in three repetitions of the parameter list per function.  This can be automated with a decorator:

def unpack_and_repack(f):
    def f_new(d1, d2):
        x,y,a,b = f(d1['x'],d1['y'],d2['a'],d3['b'])
        return {'x':x,'y':y}, {'a':a,'b':b}
    return f_new
@unpack
def f(x,y,a,b):
    blah(x)
    blah(y)
    return x,y,a,b


This results in three repetitions for the decorator, plus two per function, so it's better if you have a lot of functions.

Is there a better way?  Maybe something using eval?  Thanks!
"
"There are two options I'm aware of.

One, change the PYTHONPATH environment variable to include the directory above your module.

Alternatively, edit ~/.pylintrc to include the directory above your module, like this:

[General]
init-hook='import sys; sys.path.append(""/path/to/root"")'


(Or in other version of pylint, the init-hook requires you to change [General] to [MASTER])

Both of these options ought to work.

Hope that helps.
","PyLint ""Unable to import"" error - how to set PYTHONPATH?","I'm running PyLint from inside Wing IDE on Windows. I have a sub-directory (package) in my project and inside the package I import a module from the top level, ie.

__init__.py
myapp.py
one.py
subdir\
    __init__.py
    two.py


Inside two.py I have import one and this works fine at runtime, because the top-level directory (from which myapp.py is run) is in the Python path. However, when I run PyLint on two.py it gives me an error:

F0401: Unable to import 'one'


How do I fix this?
"
"I suggest ElementTree.  There are other compatible implementations of the same API, such as lxml, and cElementTree in the Python standard library itself; but, in this context, what they chiefly add is even more speed -- the ease of programming part depends on the API, which ElementTree defines.

After building an Element instance e from the XML, e.g. with the XML function, or by parsing a file with something like

import xml.etree.ElementTree
e = xml.etree.ElementTree.parse('thefile.xml').getroot()


or any of the many other ways shown at ElementTree, you just do something like:

for atype in e.findall('type'):
    print(atype.get('foobar'))


and similar, usually pretty simple, code patterns.
",How do I parse XML in Python?,"I have many rows in a database that contains xml and I'm trying to write a Python script that will go through those rows and count how many instances of a particular node attribute show up. For instance, my tree looks like:


   
      
      
   



How can I access the attributes 1 and 2 in the XML using Python?
"
"Bloomier filters - space-efficient associative array

From the Wikipedia:


  Chazelle et al. (2004) designed a
  generalization of Bloom filters that
  could associate a value with each
  element that had been inserted,
  implementing an associative array.
  Like Bloom filters, these structures
  achieve a small space overhead by
  accepting a small probability of false
  positives. In the case of ""Bloomier
  filters"", a false positive is defined
  as returning a result when the key is
  not in the map. The map will never
  return the wrong value for a key that
  is in the map.

",What is a hashtable/dictionary implementation for Python that doesn't store the keys?,"I'm storing millions, possibly billions of 4 byte values in a hashtable and I don't want to store any of the keys. I expect that only the hashes of the keys and the values will have to be stored. This has to be fast and all kept in RAM. The entries would still be looked up with the key, unlike set()'s.

What is an implementation of this for Python? Is there a name for this?

Yes, collisions are allowed and can be ignored.

(I can make an exception for collisions, the key can be stored for those. Alternatively, collisions can just overwrite the previously stored value.)
"
"mydict = {""&y"":""\033[0;30m"",
          ""&c"":""\033[0;31m"",
          ""&b"":""\033[0;32m"",
          ""&Y"":""\033[0;33m"",
          ""&u"":""\033[0;34m""}
mystr = ""The &yquick &cbrown &bfox &Yjumps over the &ulazy dog""

for k, v in mydict.iteritems():
    mystr = mystr.replace(k, v)

print mystr
The â[0;30mquick â[0;31mbrown â[0;32mfox â[0;33mjumps over the â[0;34mlazy dog


I took the liberty of comparing a few solutions:

mydict = dict([('&' + chr(i), str(i)) for i in list(range(65, 91)) + list(range(97, 123))])

# random inserts between keys
from random import randint
rawstr = ''.join(mydict.keys())
mystr = ''
for i in range(0, len(rawstr), 2):
    mystr += chr(randint(65,91)) * randint(0,20) # insert between 0 and 20 chars

from time import time

# How many times to run each solution
rep = 10000

print 'Running %d times with string length %d and ' \
      'random inserts of lengths 0-20' % (rep, len(mystr))

# My solution
t = time()
for x in range(rep):
    for k, v in mydict.items():
        mystr.replace(k, v)
    #print(mystr)
print '%-30s' % 'Tor fixed & variable dict', time()-t

from re import sub, compile, escape

# Peter Hansen
t = time()
for x in range(rep):
    sub(r'(&[a-zA-Z])', r'%(\1)s', mystr) % mydict
print '%-30s' % 'Peter fixed & variable dict', time()-t

# Claudiu
def multiple_replace(dict, text): 
    # Create a regular expression  from the dictionary keys
    regex = compile(""(%s)"" % ""|"".join(map(escape, dict.keys())))

    # For each match, look-up corresponding value in dictionary
    return regex.sub(lambda mo: dict[mo.string[mo.start():mo.end()]], text)

t = time()
for x in range(rep):
    multiple_replace(mydict, mystr)
print '%-30s' % 'Claudio variable dict', time()-t

# Claudiu - Precompiled
regex = compile(""(%s)"" % ""|"".join(map(escape, mydict.keys())))

t = time()
for x in range(rep):
    regex.sub(lambda mo: mydict[mo.string[mo.start():mo.end()]], mystr)
print '%-30s' % 'Claudio fixed dict', time()-t

# Andrew Y - variable dict
def mysubst(somestr, somedict):
  subs = somestr.split(""&"")
  return subs[0] + """".join(map(lambda arg: somedict[""&"" + arg[0:1]] + arg[1:], subs[1:]))

t = time()
for x in range(rep):
    mysubst(mystr, mydict)
print '%-30s' % 'Andrew Y variable dict', time()-t

# Andrew Y - fixed
def repl(s):
  return mydict[""&""+s[0:1]] + s[1:]

t = time()
for x in range(rep):
    subs = mystr.split(""&"")
    res = subs[0] + """".join(map(repl, subs[1:]))
print '%-30s' % 'Andrew Y fixed dict', time()-t


Results in Python 2.6

Running 10000 times with string length 490 and random inserts of lengths 0-20
Tor fixed & variable dict      1.04699993134
Peter fixed & variable dict    0.218999862671
Claudio variable dict          2.48400020599
Claudio fixed dict             0.0940001010895
Andrew Y variable dict         0.0309998989105
Andrew Y fixed dict            0.0310001373291


Both claudiu's and andrew's solutions kept going into 0, so I had to increase it to 10 000 runs.

I ran it in Python 3 (because of unicode) with replacements of chars from 39 to 1024 (38 is ampersand, so I didn't wanna include it). String length up to 10.000 including about 980 replacements with variable random inserts of length 0-20. The unicode values from 39 to 1024 causes characters of both 1 and 2 bytes length, which could affect some solutions.

mydict = dict([('&' + chr(i), str(i)) for i in range(39,1024)])

# random inserts between keys
from random import randint
rawstr = ''.join(mydict.keys())
mystr = ''
for i in range(0, len(rawstr), 2):
    mystr += chr(randint(65,91)) * randint(0,20) # insert between 0 and 20 chars

from time import time

# How many times to run each solution
rep = 10000

print('Running %d times with string length %d and ' \
      'random inserts of lengths 0-20' % (rep, len(mystr)))

# Tor Valamo - too long
#t = time()
#for x in range(rep):
#    for k, v in mydict.items():
#        mystr.replace(k, v)
#print('%-30s' % 'Tor fixed & variable dict', time()-t)

from re import sub, compile, escape

# Peter Hansen
t = time()
for x in range(rep):
    sub(r'(&[a-zA-Z])', r'%(\1)s', mystr) % mydict
print('%-30s' % 'Peter fixed & variable dict', time()-t)

# Peter 2
def dictsub(m):
    return mydict[m.group()]

t = time()
for x in range(rep):
    sub(r'(&[a-zA-Z])', dictsub, mystr)
print('%-30s' % 'Peter fixed dict', time()-t)

# Claudiu - too long
#def multiple_replace(dict, text): 
#    # Create a regular expression  from the dictionary keys
#    regex = compile(""(%s)"" % ""|"".join(map(escape, dict.keys())))
#
#    # For each match, look-up corresponding value in dictionary
#    return regex.sub(lambda mo: dict[mo.string[mo.start():mo.end()]], text)
#
#t = time()
#for x in range(rep):
#    multiple_replace(mydict, mystr)
#print('%-30s' % 'Claudio variable dict', time()-t)

# Claudiu - Precompiled
regex = compile(""(%s)"" % ""|"".join(map(escape, mydict.keys())))

t = time()
for x in range(rep):
    regex.sub(lambda mo: mydict[mo.string[mo.start():mo.end()]], mystr)
print('%-30s' % 'Claudio fixed dict', time()-t)

# Separate setup for Andrew and gnibbler optimized dict
mydict = dict((k[1], v) for k, v in mydict.items())

# Andrew Y - variable dict
def mysubst(somestr, somedict):
  subs = somestr.split(""&"")
  return subs[0] + """".join(map(lambda arg: somedict[arg[0:1]] + arg[1:], subs[1:]))

def mysubst2(somestr, somedict):
  subs = somestr.split(""&"")
  return subs[0].join(map(lambda arg: somedict[arg[0:1]] + arg[1:], subs[1:]))

t = time()
for x in range(rep):
    mysubst(mystr, mydict)
print('%-30s' % 'Andrew Y variable dict', time()-t)
t = time()
for x in range(rep):
    mysubst2(mystr, mydict)
print('%-30s' % 'Andrew Y variable dict 2', time()-t)

# Andrew Y - fixed
def repl(s):
  return mydict[s[0:1]] + s[1:]

t = time()
for x in range(rep):
    subs = mystr.split(""&"")
    res = subs[0] + """".join(map(repl, subs[1:]))
print('%-30s' % 'Andrew Y fixed dict', time()-t)

# gnibbler
t = time()
for x in range(rep):
    myparts = mystr.split(""&"")
    myparts[1:]=[mydict[x[0]]+x[1:] for x in myparts[1:]]
    """".join(myparts)
print('%-30s' % 'gnibbler fixed & variable dict', time()-t)


Results:

Running 10000 times with string length 9491 and random inserts of lengths 0-20
Tor fixed & variable dict      0.0 # disqualified 329 secs
Peter fixed & variable dict    2.07799983025
Peter fixed dict               1.53100013733 
Claudio variable dict          0.0 # disqualified, 37 secs
Claudio fixed dict             1.5
Andrew Y variable dict         0.578000068665
Andrew Y variable dict 2       0.56299996376
Andrew Y fixed dict            0.56200003624
gnibbler fixed & variable dict 0.530999898911


(** Note that gnibbler's code uses a different dict, where keys don't have the '&' included. Andrew's code also uses this alternate dict, but it didn't make much of a difference, maybe just 0.01x speedup.)
",Mass string replace in python?,"Say I have a string that looks like this:

str = ""The &yquick &cbrown &bfox &Yjumps over the &ulazy dog""


You'll notice a lot of locations in the string where there is an ampersand, followed by a character (such as ""&y"" and ""&c"").  I need to replace these characters with an appropriate value that I have in a dictionary, like so:

dict = {""&y"":""\033[0;30m"",
        ""&c"":""\033[0;31m"",
        ""&b"":""\033[0;32m"",
        ""&Y"":""\033[0;33m"",
        ""&u"":""\033[0;34m""}


What is the fastest way to do this?  I could manually find all the ampersands, then loop through the dictionary to change them, but that seems slow.  Doing a bunch of regex replaces seems slow as well (I will have a dictionary of about 30-40 pairs in my actual code).

Any suggestions are appreciated, thanks.

Edit:

As has been pointed out in comments throught this question, my dictionary is defined before runtime, and will never change during the course of the applications life cycle.  It is a list of ANSI escape sequences, and will have about 40 items in it.  My average string length to compare against will be about 500 characters, but there will be ones that are up to 5000 characters (although, these will be rare).  I am also using Python 2.6 currently.

Edit #2
I accepted Tor Valamos answer as the correct one, as it not only gave a valid solution (although it wasn't the best solution), but took all others into account and did a tremendous amount of work to compare all of them.  That answer is one of the best, most helpful answers I have ever come across on StackOverflow.  Kudos to you.
"
"Just for information, In python 2.7+, we can use Counter

import collections

x=[1, 2, 3, 5, 6, 7, 5, 2]

>>> x
[1, 2, 3, 5, 6, 7, 5, 2]

>>> y=collections.Counter(x)
>>> y
Counter({2: 2, 5: 2, 1: 1, 3: 1, 6: 1, 7: 1})


Unique List

>>> list(y)
[1, 2, 3, 5, 6, 7]


Items found more than 1 time

>>> [i for i in y if y[i]>1]
[2, 5]


Items found only one time

>>> [i for i in y if y[i]==1]
[1, 3, 6, 7]

",How to find duplicate elements in array using for loop in Python?,"I have a list with duplicate elements:

 list_a=[1,2,3,5,6,7,5,2]

 tmp=[]

 for i in list_a:
     if tmp.__contains__(i):
         print i
     else:
         tmp.append(i)


I have used the above code to find the duplicate elements in the list_a. I don't want to remove the elements from list.

But I want to use for loop here.
Normally C/C++ we use like this I guess:

 for (int i=0;i<=list_a.length;i++)
     for (int j=i+1;j<=list_a.length;j++)
         if (list_a[i]==list_a[j])
             print list_a[i]


how do we use like this in Python?

for i in list_a:
    for j in list_a[1:]:
    ....


I tried the above code. But it gets solution wrong. I don't know how to increase the value for j.
"
"I prefer the anonymous dict option.

I don't like the dict() option for the same reason I don't like:

 i = int(""1"")


With the dict() option you're needlessly calling a function which is adding overhead you don't need:

>>> from timeit import Timer
>>> Timer(""mydict = {'a' : 1, 'b' : 2, 'c' : 'three'}"").timeit()
0.91826782454194589
>>> Timer(""mydict = dict(a=1, b=2, c='three')"").timeit()
1.9494664824719337

","In Python, use ""dict"" with keywords or anonymous dictionaries?","Say you want to pass a dictionary of values to a function, or otherwise want to work with a short-lived dictionary that won't be reused. There are two easy ways to do this:

Use the dict() function to create a dictionary:

foo.update(dict(bar=42, baz='qux'))


Use an anonymous dictionary:

foo.update({'bar': 42, 'baz': 'qux'})


Which do you prefer? Are there reasons other than personal style for choosing one over the other?
"
"There are often clearer, more direct ways to get the same effect. If you build a complex string and pass it to exec, the code is difficult to follow, and difficult to test. 

Example: I wrote code that read in string keys and values and set corresponding fields in an object. It looked like this: 

for key, val in values:
    fieldName = valueToFieldName[key]
    fieldType = fieldNameToType[fieldName]
    if fieldType is int:
        s = 'object.%s = int(%s)' % (fieldName, fieldType) 
    #Many clauses like this...

exec(s)


That code isn't too terrible for simple cases, but as new types cropped up it got more and more complex. When there were bugs they always triggered on the call to exec, so stack traces didn't help me find them. Eventually I switched to a slightly longer, less clever version that set each field explicitly. 

The first rule of code clarity is that each line of your code should be easy to understand by looking only at the lines near it. This is why goto and global variables are discouraged. exec and eval make it easy to break this rule badly.
",Why should exec() and eval() be avoided?,"I've seen this multiple times in multiple places, but never have found a satisfying explanation as to why this should be the case. 

So, hopefully, one will be presented here. Why should we (at least, generally) not use exec() and eval()?

EDIT: I see that people are assuming that this question pertains to web servers âÂ it doesn't. I can see why an unsanitized string being passed to exec could be bad. Is it bad in non-web-applications?
"
"if foo: #{
    print ""it's true""
#}
else: #{
    print ""it's false!""
#}


(Obviously, this is a joke.)
",Is it true that I can't use curly braces in Python?,"I was reading that Python does all it's ""code blocks"" by indentation, rather than with curly braces. Is that right? So functions, if's and stuff like that all appear without surrounding their block with curly braces?
"
"First, lose that absurd call to int -- which is taking you farther from what you want, so, what ever possessed you to put it in?!  Change:

inp = int(input(""Enter a number:""))


to the simpler

inp = input(""Enter a number:"")


so that inp is a string of digits and you can indeed loop over it, digit by digit.

Next, assign some initial value to n -- as you code stands right now, you'll get a NameError since you never initialize it.  Presumably you want n = 0 before the for loop.

Next, consider the difference between a character and an integer again.  You now have:

n = n + i;


which, besides the utterly absurd (but innocuous) semicolon, is trying to sum the character i to the  integer n -- that won't work!  So, this becomes

n = n + int(i)


to turn character '7' into integer 7, and so forth.
",int object is not iterable?,"inp = int(input(""Enter a number:""))

for i in inp:
    n = n + i;
    print (n)


... throws an error: 'int' object is not iterable

I wanted to find out the total by adding each digit, for eg, 110. 1 + 1 + 0 = 2. How do I do that?

Thanks
"
"Classic Example: You want to store point value as tuple of  (x, y) 
",In what case would I use a tuple as a dictionary key?,"I was studying the difference between lists and tuples (in Python). An obvious one is that tuples are immutable (the values cannot be changed after initial assignment), while lists are mutable.

A sentence in the article got me: 


  Only immutable elements can be used as
  dictionary keys, and hence only tuples
  and not lists can be used as keys.


I have a hard time thinking of a situation where I would like to use a tuple as a dictionary key. Can you provide an example problem where this would be the natural, efficient, elegant, or obvious solution?

Edit:

Thanks for your examples. So far I take that a very important application is the caching of function values.
"
"Warning: a Cython core developer's opinion ahead.

I almost always recommend Cython over ctypes. The reason is that it has a much smoother upgrade path. If you use ctypes, many things will be simple at first, and it's certainly cool to write your FFI code in plain Python, without compilation, build dependencies and all that. However, at some point, you will almost certainly find that you have to call into your C library a lot, either in a loop or in a longer series of interdependent calls, and you would like to speed that up. That's the point where you'll notice that you can't do that with ctypes. Or, when you need callback functions and you find that your Python callback code becomes a bottleneck, you'd like to speed it up and/or move it down into C as well. Again, you cannot do that with ctypes. So you have to switch languages at that point and start rewriting parts of your code, potentially reverse engineering your Python/ctypes code into plain C, thus spoiling the whole benefit of writing your code in plain Python in the first place.

With Cython, OTOH, you're completely free to make the wrapping and calling code as thin or thick as you want. You can start with simple calls into your C code from regular Python code, and Cython will translate them into native C calls, without any additional calling overhead, and with an extremely low conversion overhead for Python parameters. When you notice that you need even more performance at some point where you are making too many expensive calls into your C library, you can start annotating your surrounding Python code with static types and let Cython optimise it straight down into C for you. Or, you can start rewriting parts of your C code in Cython in order to avoid calls and to specialise and tighten your loops algorithmically. And if you need a fast callback, just write a function with the appropriate signature and pass it into the C callback registry directly. Again, no overhead, and it gives you plain C calling performance. And in the much less likely case that you really cannot get your code fast enough in Cython, you can still consider rewriting the truly critical parts of it in C (or C++ or Fortran) and call it from your Cython code naturally and natively. But then, this really becomes the last resort instead of the only option.

So, ctypes is nice to do simple things and to quickly get something running. However, as soon as things start to grow, you'll most likely come to the point where you notice that you'd better used Cython right from the start.
","Wrapping a C library in Python: C, Cython or ctypes?","I want to call a C library from a Python application. I don't want to wrap the whole API, only the functions and datatypes that are relevant to my case. As I see it, I have three choices:


Create an actual extension module in C. Probably overkill, and I'd also like to avoid the overhead of learning extension writing.
Use Cython to expose the relevant parts from the C library to Python.
Do the whole thing in Python, using ctypes to communicate with the external library.


I'm not sure whether 2) or 3) is the better choice. The advantage of 3) is that ctypes is part of the standard library, and the resulting code would be pure Python – although I'm not sure how big that advantage actually is.

Are there more advantages / disadvantages with either choice? Which approach do you recommend?



Edit: Thanks for all your answers, they provide a good resource for anyone looking to do something similar. The decision, of course, is still to be made for the single case—there's no one ""This is the right thing"" sort of answer. For my own case, I'll probably go with ctypes, but I'm also looking forward to trying out Cython in some other project.

With there being no single true answer, accepting one is somewhat arbitrary; I chose FogleBird's answer as it provides some good insight into ctypes and it currently also is the highest-voted answer. However, I suggest to read all the answers to get a good overview.

Thanks again.
"
"The latter strings shouldn't start with a slash. If they start with a slash, then they're considered an ""absolute path"" and everything before them is discarded.

Quoting the Python docs for os.path.join:


  If any component is an absolute path, all previous components (on Windows, including the previous drive letter, if there was one) are thrown away, and joining continues. 

",Why doesn't os.path.join() work in this case?,"The below code will not join, when debugged the command does not store the whole path but just the last entry.

os.path.join('/home/build/test/sandboxes/', todaystr, '/new_sandbox/')


When I test this it only stores the /new_sandbox/ part of the code.
"
"Python has a construct that is sort of like the ternary operator in C, et al. It works something like this:

my_var = ""Retired"" if age > 65 else ""Working""


and is equivalent to this C code:

my_var = age > 65 ? ""Retired"" : ""Working"";


As for how the code you posted works, let's step through it:

(""Working"",""Retired"")


creates a 2-tuple (an immutable list) with the element ""Working"" at index 0, and ""Retired"" at index 1.

var>65


returns True if var is greater than 65, False if not. When applied to an index, it is converted into 1 (True) or 0 (False). Thus, this boolean value provides an index into the tuple created on the same line.

Why hasn't Python always had a ternary operator? The simple answer is that Guido van Rossum, the author of Python, didn't like/didn't want it, apparently believing that it was an unnecessary construct that could lead to confusing code (and anyone who's seen massively-nested ternary operators in C can probably agree). But for Python 2.5, he relented and added the grammar seen above.
",How does the Python conditional operator workaround work?,"From what I have read, I found that a built-in ternary operator does not exist (I will be happy to know more about it.).

I found the following code as a substitute:

def val():
    var = float(raw_input(""Age:""))
    status = (""Working"",""Retired"")[var>65]
    print ""You should be:"",status


I couldn't understand how this code works; can anyone explain me how actually the code is working? I am also interested to know why the ternary operator doesn't exist; any references or links about this will be ore useful. 

I'm running Python 2.6.4 on Windows Vista.
"
"
Checking for __iter__ works on sequence types, but it would fail on e.g. strings. I would like to know the right answer too, until then, here is one possibility (which would work on strings, too):

try:
    some_object_iterator = iter(some_object)
except TypeError, te:
    print some_object, 'is not iterable'


The iter built-in checks for the __iter__ method or in the case of strings the __getitem__ method. To check if an object is ""list like"" and not ""string like"" then the key is the attributes __getitem__ and __iter__:


 In [9]: hasattr([1,2,3,4], '__iter__')
 Out[9]: True
 In [11]: hasattr((1,2,3,4), '__iter__')
 Out[11]: True
 In [12]: hasattr(u""hello"", '__iter__')
 Out[12]: False
 In [14]: hasattr(u""hello"", '__getitem__')
 Out[14]: True


Another general pythonic approach is to assume an iterable, then fail gracefully if it does not work on the given object. The Python glossary:


  Pythonic programming style that determines an object's type by inspection of its method or attribute signature rather than by explicit relationship to some type object (""If it looks like a duck and quacks like a duck, it must be a duck."") By emphasizing interfaces rather than specific types, well-designed code improves its flexibility by allowing polymorphic substitution. Duck-typing avoids tests using type() or isinstance(). Instead, it typically employs the EAFP (Easier to Ask Forgiveness than Permission) style of programming.
  
  ...

try:
   _ = (e for e in my_object)
except TypeError:
   print my_object, 'is not iterable'


The collections module provides some abstract base classes, which allow to ask classes or instances if they provide particular functionality, for example:

import collections

if isinstance(e, collections.Iterable):
    # e is iterable


","In Python, how do I determine if an object is iterable?","Is there a method like isiterable? The only solution I have found so far is to call

hasattr(myObj, '__iter__')


But I am not sure how fool-proof this is.
"
"I think Compiling Python Code would be a good place to start:


  Python source code is automatically
  compiled into Python byte code by the
  CPython interpreter. Compiled code is
  usually stored in PYC (or PYO) files,
  and is regenerated when the source is
  updated, or when otherwise necessary.
  
  To distribute a program to people who
  already have Python installed, you can
  ship either the PY files or the PYC
  files. In recent versions, you can
  also create a ZIP archive containing
  PY or PYC files, and use a small
  âbootstrap scriptâ to add that ZIP
  archive to the path.
  
  To âcompileâ a Python program into an
  executable, use a bundling tool, such
  as Gordon McMillanâs installer
  (alternative download)
  (cross-platform), Thomas Hellerâs
  py2exe (Windows), Anthony Tuiningaâs
  cx_Freeze (cross-platform), or Bob
  Ippolitoâs py2app (Mac). These tools
  puts your modules and data files in
  some kind of archive file, and creates
  an executable that automatically sets
  things up so that modules are imported
  from that archive. Some tools can
  embed the archive in the executable
  itself.

",Is it possible to compile a program written in Python?,"I am new to the Python programming language. I was wondering if it is possible to compile a program written in Python.
"
"It should be enough to create an empty virtualenv and then copy the contents of the .../site-packages/PyQt4 directories into it.

I suggest to install PyQt4 once globally, make a copy of the directory, uninstall it and then use this trick to create VEs.
",Is it possible to add PyQt4/PySide packages on a Virtualenv sandbox?,"I'm using Virtualenv with profit on my development environment with web.py, simplejson and other web oriented packages.
I'm going to develop a simple python client using Qt to reuse some Api developed with web.py.  

Does anybody here had succesfully installed PyQt4 with Virtualenv?
Is it possible?

I've downloaded all the binaries and have PyQt4 installed globally on my python2.6 directory.
If I don't use --no-site--packages option, Virtualenv correctly includes PyQt4 in my new sandbox but, obviously, with all the global packages that I don't need.

Is there a clean way to prepare a new sandbox with --no-site--packages option and then add PyQt4 or PySide using pip, easy_install or some other magic trick?
"
"Here's some good advice on Python idioms from this page:



Catch errors rather than avoiding them to avoid cluttering your code with special cases. This idiom is called EAFP ('easier to ask forgiveness than permission'), as opposed to LBYL ('look before you leap'). This often makes the code more readable. For example:

Worse:

#check whether int conversion will raise an error
if not isinstance(s, str) or not s.isdigit:
    return None
elif len(s) > 10:    #too many digits for int conversion
    return None
else:
    return int(str)


Better:

try:
    return int(str)
except (TypeError, ValueError, OverflowError): #int conversion failed
    return None


(Note that in this case, the second version is much better, since it correctly handles leading + and -, and also values between 2 and 10 billion (for 32-bit machines). Don't clutter your code by anticipating all the possible failures: just try it and use appropriate exception handling.) 
",Should I make my python code less fool-proof to improve readability?,"I try to make my code fool-proof, but I've noticed that it takes a lot of time to type things out and it takes more time to read the code.

Instead of:

class TextServer(object):
    def __init__(self, text_values):
        self.text_values = text_values
        # 
    # 


I tend to write this:

class TextServer(object):
    def __init__(self, text_values):
        for text_value in text_values:
            assert isinstance(text_value, basestring), u'All text_values should be str or unicode.'
            assert 2 <= len(text_value), u'All text_values should be at least two characters long.'
        self.__text_values = frozenset(text_values) # 
        # 
    @property
    def text_values(self):
        # 
        return self.__text_values
    # 


Is my python coding style too paranoid? Or is there a way to improve readability while keeping it fool-proof?


Note 1: I've added the comments between  and > just for clarification.
Note 2: The main fool I try to prevent to abuse my code is my future self.

"
"There's an alternative to the StopIteration by using next(iterator, default_value).

For exapmle:

>>> a = iter('hi')
>>> print next(a, None)
h
>>> print next(a, None)
i
>>> print next(a, None)
None


So you can detect for None or other pre-specified value for end of the iterator if you don't want the exception way.
",hasNext in Python iterators?,"Haven't Python iterators got a hasNext method?
"
"Python requires specifying self.  The result is there's never any confusion over what's a member and what's not, even without the full class definition visible.  This leads to useful properties, such as: you can't add members which accidentally shadow non-members and thereby break code.

One extreme example: you can write a class without any knowledge of what base classes it might have, and always know whether you are accessing a member or not:

class A(some_function()):
  def f(self):
    self.member = 42
    self.method()


That's the complete code!  (some_function returns the type used as a base.)

Another, where the methods of a class are dynamically composed:

class B(object):
  pass

print B()
# 

def B_init(self):
  self.answer = 42
def B_str(self):
  return """" % self.answer
# notice these functions require no knowledge of the actual class
# how hard are they to read and realize that ""members"" are used?

B.__init__ = B_init
B.__str__ = B_str

print B()
# 


Remember, both of these examples are extreme and you won't see them every day, nor am I suggesting you should often write code like this, but they do clearly show aspects of self being explicitly required.
",How to avoid explicit 'self' in Python?,"I have been learning Python by following some pygame tutorials.

Therein I found extensive use of the keyword self, and coming from a primarily Java background, I find that I keep forgetting to type self.  For example, instead of self.rect.centerx I would type rect.centerx, because, to me, rect is already a member variable of the class.

The Java parallel I can think of for this situation is having to prefix all references to member variables with this.

Am I stuck prefixing all member variables with self, or is there a way to declare them that would allow me to avoid having to do so?

Even if what I am suggesting isn't pythonic, I'd still like to know if it is possible.

I have taken a look at these related SO questions, but they don't quite answer what I am after:


Python - why use âselfâ in a class?  
Why do you need explicitly have the âselfâ argument into a Python method?

"
"EDIT:

Indeed there was a patch which included sign() in math, but it wasn't accepted, because they didn't agree on what it should return in all the edge cases (+/-0, +/-nan, etc)

So they decided to implement only copysign, which (although more verbose) can be used to delegate to the end user the desired behavior for edge cases - which sometimes might require the call to cmp(x,0).



I don't know why it's not a built-in, but I have some thoughts.

copysign(x,y):
Return x with the sign of y.


Most importantly, copysign is a superset of sign!  Calling copysign with x=1 is the same as a sign function.  So you could just use copysign and forget about it.

>>> math.copysign(1, -4)
-1.0
>>> math.copysign(1, 3)
1.0


If you get sick of passing two whole arguments, you can implement sign this way, and it will still be compatible with the IEEE stuff mentioned by others:

>>> sign = functools.partial(math.copysign, 1) # either of these
>>> sign = lambda x: math.copysign(1, x) # two will work
>>> sign(-4)
-1.0
>>> sign(3)
1.0
>>> sign(0)
1.0
>>> sign(-0.0)
-1.0
>>> sign(float('nan'))
-1.0


Secondly, usually when you want the sign of something, you just end up multiplying it with another value.  And of course that's basically what copysign does.

So, instead of:

s = sign(a)
b = b * s


You can just do:

b = copysign(b, a)


And yes, I'm surprised you've been using Python for 7 years and think cmp could be so easily removed and replaced by sign!  Have you never implemented a class with a __cmp__ method?  Have you never called cmp and specified a custom comparator function?

In summary, I've found myself wanting a sign function too, but copysign with the first argument being 1 will work just fine.  I disagree that sign would be more useful than copysign, as I've shown that it's merely a subset of the same functionality.
",Why doesn't Python have a sign function?,"I can't understand why Python doesn't have a sign function. It has an abs builtin (which I consider sign's sister), but no sign.

In python 2.6 there is even a copysign function (in math), but no sign. Why bother to write a copysign(x,y) when you could just write a sign and then get the copysign directly from abs(x) * sign(y)? The latter would be much more clear: x with the sign of y, whereas with copysign you have to remember if it's x with the sign of y or y with the sign of x!

Obviously sign(x) does not provide anything more than cmp(x,0), but it would be much more readable that this too (and for a greatly readable language like python, this would have been a big plus). 

If I were a python designer, I would been the other way arond: no cmp builtin, but a sign. When you need cmp(x,y), you could just do a sign(x-y) (or, even better for non-numerical stuff, just a x>y - of course this should have required sorted accepting a boolean instead of an integer comparator). This would also be more clear: positive when x>y (whereas with cmp you have to remember the convention positive when the first is bigger, but it could be the other way around). Of course cmp makes sense in its own for other reasons (e.g. when sorting non-numerical things, or if you want the sort to be stable, which is not possible using with simply a boolean)

So, the question is: why did the Python designer(s) decide to leave the sign function out of the language? Why the heck bother with copysign and not its parent sign?

Am I missing something?

EDIT - after Peter Hansen comment. 
Fair enough that you didn't use it, but you didn't say what you use python for. In 7 years that I use python, I needed it countless times, and the last is the straw that broke the camel's back!

Yes, you can pass cmp around, but 90% of the times that I needed to pass it was in an idiom like 
lambda x,y: cmp(score(x),score(y)) that would have worked with sign just fine.

Finally, I hope you agree that sign would be more useful than copysign, so even if I bought your view, why bother about defining that in math, instead of sign? How can copysign be so much useful than sign?
"
"Memoization effectively refers to remembering (""memoization"" -> ""memorandum"" -> to be remembered) results of method calls based on the method inputs and then returning the remembered result rather than computing the result again. You can think of it as a cache for method results. For further details, see page 387 for the definition in Introduction To Algorithms (3e), Cormen et al.

A simple example for computing factorials using memoization in Python would be something like this:

factorial_memo = {}
def factorial(k):
    if k < 2: return 1
    if k not in factorial_memo:
        factorial_memo[k] = k * factorial(k-1)
    return factorial_memo[k]


You can get more complicated and encapsulate the memoization process into a class

class Memoize:
    def __init__(self, f):
        self.f = f
        self.memo = {}
    def __call__(self, *args):
        if not args in self.memo:
            self.memo[args] = self.f(*args)
        return self.memo[args]


Then:

def factorial(k):
    if k < 2: return 1
    return k * factorial(k - 1)

factorial = Memoize(factorial)

",What is memoization and how can I use it in Python?,"I just started Python and I've got no idea what memoization is and how to use it. Also, may I have a simplified example?
"
"You want to do non-blocking I/O with the select module.

There are a couple of different specific techniques.  select.select should work for every major platform.  There are other variations that are more efficient (and could matter if you are checking tens of thousands of connections simultaneously) but you will then need to write the code for you specific platform.
",A programming strategy to bypass the os thread limit?,"The scenario: We have a python script that checks thousands of proxys simultaneously.
The program uses threads, 1 per proxy, to speed the process. When it reaches the 1007 thread, the script crashes because of the thread limit.
My solution is: A global variable that gets incremented when a thread spawns and decrements when a thread finishes. The function which spawns the threads monitors the variable so that the limit is not reached.
What will your solution be, friends?

Thanks for the answers.
"
"Exceptions are just a specific example of a more general case of advanced non-local flow control constructs. Other examples are:


notifications (a generalization of exceptions, originally from some old Lisp object system, now implemented in e.g. CommonLisp and Ioke), 
continuations (a more structured form of GOTO, popular in high-level, higher-order languages), 
coroutines (a generalization of subroutines, popular especially in Lua), 
generators Ã  la Python (essentially a restricted form of coroutines), 
fibers (cooperative light-weight threads) and of course the already mentioned 
GOTO.


(I'm sure there's many others I missed.)

An interesting property of these constructs is that they are all roughly equivalent in expressive power: if you have one, you can pretty easily build all the others.

So, how you best implement exceptions depends on what other constructs you have available: 


Every CPU has GOTO, therefore you can always fall back to that, if you must.
C has setjmp/longjmp which are basically MacGyver continuations (built out of duct-tape and toothpicks, not quite the real thing, but will at least get you out of the immediate trouble if you don't have something better available). 
The JVM and CLI have exceptions of their own, which means that if the exception semantics of your language match Java's/C#'s, you are home free (but if not, then you are screwed). 
The Parrot VM as both exceptions and continuations. 
Windows has its own framework for exception handling, which language implementors can use to build their own exceptions on top.


A very interesting use case, both of the usage of exceptions and the implementation of exceptions is Microsoft Live Lab's Volta Project. (Now defunct.) The goal of Volta was to provide architectural refactoring for Web applications at the push of a button. So, you could turn your one-tier web application into a two- or three-tier application just by putting some [Browser] or [DB] attributes on your .NET code and the code would then automagically run on the client or in the DB. In order to do that, the .NET code had to be translated to JavaScript source code, obviously.

Now, you could just write an entire VM in JavaScript and run the bytecode unmodified. (Basically, port the CLR from C++ to JavaScript.) There are actually projects that do this (e.g. the HotRuby VM), but this is both inefficient and not very interoperable with other JavaScript code.

So, instead, they wrote a compiler which compiles CIL bytecode to JavaScript sourcecode. However, JavaScript lacks certain features that .NET has (generators, threads, also the two exception models aren't 100% compatible), and more importantly it lacks certain features that compiler writers love (either GOTO or continuations) and that could be used to implement the above-mentioned missing features.

However, JavaScript does have exceptions. So, they used JavaScript Exceptions to implement Volta Continuations and then they used Volta Continuations to implement .NET Exceptions, .NET Generators and even .NET Managed Threads(!!!)

So, to answer your original question:


  How are exceptions implemented under the hood?


With Exceptions, ironically! At least in this very specific case, anyway.

Another great example is some of the exception proposals on the Go mailing list, which implement exceptions using Goroutines (something like a mixture of concurrent coroutines ans CSP processes). Yet another example is Haskell, which uses Monads, lazy evaluation, tail call optimization and higher-order functions to implement exceptions. Some modern CPUs also support basic building blocks for exceptions (for example the Vega-3 CPUs that were specifically designed for the Azul Systems Java Compute Accelerators).
",How are exceptions implemented under the hood?,"Just about everyone uses them, but many, including me simply take it for granted that they just work.

I am looking for high-quality material. Languages I use are: Java, C, C#, Python, C++, so these are of most interest to me.

Now, C++ is probably a good place to start since you can throw anything in that language. 

Also, C is close to assembly. How would one emulate exceptions using pure C constructs and no assembly?

Finally, I heard a rumor that Google employees do not use exceptions for some projects due to speed considerations. Is this just a rumor? How can anything substantial be accomplished without them?

Thank you.
"
"I would pay a reasonable amount for a Django-tailored IDE or plug-in. I don't know what I mean by reasonable, but maye it helps to know that I would not pay more than $75, and I would only pay the $75 if the tool was really awesome.

Now, Django specific features:


Seamless integration with Google Apps
(get me the urchin, the license for
Google Maps, and put it in my
templates)
Full support for the templating engine (details in the other answers you have received)
Lorem ipsum generation (Django has it, just make it simpler)
Prepackaged modules for common tasks (e.g. give me a full login page with template an all)
Link within the code for Django documentation and examples (e.g. Django snippets)
One-click for multi-browser comparison
Full CSS support
An object explorer (along the lines of the Django-admin, but off-line)
A color palette with cool combinations (say, blue-based, orange-based)
Wizard for uploading the local project to Webfaction or similar hosting solution


If I can think of anything else I will edit the answer.

Good luck in designing your product!
",Does Django need an IDE?,"My company is evaluating the possibility of developing a specialized IDE for Django. 

So we would like to ask Django users: 


Do you feel the need for a specialized IDE for Django?
Would you be willing to pay for it, or would you only consider free a open-source product? 
What Django-specific features are you missing currently in your development tools?

"
"Metaclasses are indispensable if you want to have class objects (as opposed to instances of class objects) equipped with ""special customized behavior"", since an object's behavior depends on special methods on the type of the object, and a class object's type is, exactly a synonym for, the metaclass.

For example, if you want a class object X such that ""print X"" emits ""Time is now 8:46am"" (at 8:46 am, or, more generally, the current time) this must mean that type(x) (AKA X's metaclass) has a special custom __str__ method -- and similarly (with the various applicable special-methods) if you want to give meaning to expressions such as X + Y where X and Y are both class objects, or X[23] (where X, again, is a class object), and so forth.

Most other customization tasks are now (in Python 2.6 or better) easier to implement with a class decorator, which can alter a class object right after the end of the class statement. There are a few more cases where this is not feasible because the alterations must be made very early on if they are to have any effect (e.g., setting or altering __slots__).

In Python 3, metaclasses gain one extra little bit of usefulness: a metaclass can now optionally specify the mapping object to be populated during the execution of the class statement's body (by default, it's a normal dict). This allows the order of name bindings in the class body to be preserved and used (while the normal dict loses order), which is sometimes nice when the class must have ""fields"" in a certain specific order (e.g. to map 1:1 onto a C struct, a row in a CSV file or DB table, and the like) -- in Python 2.* this had to be redundantly specified (typically with an extra class attribute that's a sequence and thus does preserve order), and this feature of Python 3 metaclasses allows the redundancy to be removed.
",What are Python metaclasses useful for?,"What can be done with metaclasses that can't be in any other way?

Alex Martelli told that there are tasks that can't be achieved without metaclasses here http://stackoverflow.com/questions/1779372/python-metaclasses-vs-class-decorators
I'd like to know which are?
"
"PEP 336 - Make None Callable proposed a similar feature:


  None should be a callable object that when called with any arguments
  has no side effect and returns None.


The reason for why it was rejected was simply ""It is considered a feature that None raises an error when called.""
",Null pattern in Python underused?,"Every now and then I come across code like this:

foo = Foo()
...
if foo.bar is not None and foo.bar.baz == 42:
   shiny_happy(...)


Which seems, well, unpythonic, to me.

In Objective-C, you can send messages to nil and get nil as the answer. I've always thought that's quite handy. Of course it is possible to implement a Null pattern in Python, however judging from the results Google's given me, it seems this is not very widely used. Why's that?

Or even better—would it be a bad idea to let None.whatever return None instead of raising an exception?
"
"With a little bit of LINQ:

var q = from el in li
        orderby foo(el)
        select el;
li = q.ToList();

",How do I sort this list?,"I have a list of lists.

List> li = {
   {a1,a2,a3 ... aN},
   {b1,b2,b3 ... bN},
   ...
};

double foo(List list)
{
    // do something 
    // e.g {1,2,3} 
    // it = 1 + 2 + 3

    return it;
}


Now I want to sort li in such a way that higher the foo(x) for a x higher it should appear in a sorted list.

What is the best way in C#/Python/any other lang to this?
"
"Largely distribution won't matter, as Python is present and largely self sufficient on virtually all Linux distributions.

If you're wanting to focus on development, I'd recommend Ubuntu.  Ubuntu is arguably one of the most fully featured ""ready for the user"" distributions that makes system administration a snap, so you can focus on the development tasks you want to tackle.

If you have a Linux environment that's a target for your code (like say, RedHat or something), then go with the desktop distribution that matches your target environment (like, say, Fedora for RedHat, Gentoo for Gentoo, Ubuntu for Ubuntu Server, etc.)

Otherwise, all of them are suitable. 
",What linux distro is better suited for Python web development?,"Which linux distro is better suited for Python web development?

Background:

I currently develop on Windows and it's fine, but I am looking to move my core Python development to Linux. I'm sure most any distro will work fine, but does anyone have any reasons to believe one distro is better than another?
"
"I highly recommend


  http://www.diveintopython3.net


It assumes you already understand programming, and walks you through examples that demonstrate the unique abilities of Python.
",What are some good projects to make for a newbie Python (but not new to programming) developer?,"I'm downloading Python 3.1.1 and that comes with the IDLE correct?

I'm also downloading QT for Windows which I'm told is a good GUI framework to work with Python. 

What projects should I try to make in order to grasp some of the goodies Python brings to the table?

Thanks a bunch SO.
"
"i starts at 0, so the while condition stays always true; see the range docs for details.
",why is this an infinite loop in python?,"I can't seem to figure out why this is an infinite loop in python??

for i in range(n):
    j=1
    while((i*j)<n):
       j+=1


shouldn't the outer loop go n times. incrementing j until its equal to n div i each time?
"
"lots of possible ways

>>> mylist = [[3,4],[5],[6,7,8]]
>>> mylist[0] = [4]
>>> mylist
[[4], [5], [6, 7, 8]]
>>> mylist = [[3,4],[5],[6,7,8]]
>>> del mylist[0][0]
>>> mylist
[[4], [5], [6, 7, 8]]
>>> mylist = [[3,4],[5],[6,7,8]]
>>> mylist[0].remove(3)
>>> mylist
[[4], [5], [6, 7, 8]]


Take your pick :)
",How to delete element from list in Python?,"I am new to python. I have created a list

a = [[3,4],[5],[6,7,8]]


I want to delete 3 from this list. What is the command for this?
"
"Interrogate version string of already-installed distribution

To retrieve the version from inside your package at runtime (what your question appears to actually be asking), you can use:

import pkg_resources  # part of setuptools
version = pkg_resources.require(""MyProject"")[0].version


Store version string for use during install

If you want to go the other way 'round (which appears to be what other answer authors here appear to have thought you were asking), put the version string in a separate file and read that file's contents in setup.py.

You could make a version.py in your package with a __version__ line, then read it from setup.py using execfile('mypackage/version.py'), so that it sets __version__ in the setup.py namespace.

If you want a much simpler way that will work with all Python versions and even non-Python languages that may need access to the version string:

Store the version string as the sole contents of a plain text file, named e.g. VERSION, and read that file during setup.py.

version_file = open(os.path.join(mypackage_root_dir, 'VERSION'))
version = version_file.read().strip()


The same VERSION file will then work exactly as well in any other program, even non-Python ones, and you only need to change the version string in one place for all programs.

Warning about race condition during install

By the way, DO NOT import your package from your setup.py as suggested in another answer here: it will seem to work for you (because you already have your package's dependencies installed), but it will wreak havoc upon new users of your package, as they will not be able to install your package without manually installing the dependencies first.
",How can I get the version defined in setup.py (setuptools) in my package?,"How could I get the version defined in setup.py from my package (for --version, or other purposes)?
"
"Right this is what you want.
http://www.sno.phy.queensu.ca/~phil/exiftool/
Gets what flickr does!
",How to get the EXIF or meta-data from images?,"I need a really good library or a command-line software that can be used to extract Exif data from images. No specific programming language, except the library or the software has to work really well. 

I found various libraries for PHP and Python, but most of it hasn't been updated or being maintained and don't work for various manufactures. I wasted a lot of time just to find something that works.

Anyone knows what Flickr uses to get Exif data? Maybe that might answer the questions.  

Thanks for any help
"
"Do a while True inside your for loop, put your try code inside, and break from that while loop only when your code succeeds.

for i in range(0,100):
    while True:
        try:
            # do stuff
        except SomeSpecificException:
            continue
        break

",How to retry after exception in python?,"I have a loop starting with for i in range(0, 100). Normally it runs correctly, but sometimes it fails due to network conditions. Currently I have it set so that on failure, it will continue in the except clause (continue on to the next number for i).

Is it possible for me to reassign the same number to i and run through the failed iteration of the loop again?
"
"for i in {0001..1000}
do
  echo ""some text"" > ""file_${i}.txt""
done


or  if you want to use Python 

for x in range(1000):
    open(""file%03d.txt"" % x,""w"").write(""some text"")

",How can I create 1000 files that I can use to test a script?,"I would like to create 1000+ text files with some text to test a script, how to create this much if text files at a go using shell script or Perl. Please could anyone help me.
"
"For code in your project, the only way is adding a comment saying that you expected that (the static code-analysis only sees what you see, not runtime info -- if you opened that module yourself, you'd have no indication that main was expected).

You can use ctrl+1 (Cmd+1 for Mac) in a line with an error and pydev will present you an option to add a comment to ignore that error.

If it was some external module, you could add it to the forced builtins so that it was forced to be analyzed by a running shell with runtime information (see http://pydev.org/manual_101_interpreter.html for details).

Another option could be creating a 'stub' yourself and adding it to the 'predefined' completions (http://pydev.org/manual_101_interpreter.html also has details on that).
","How do I fix PyDev ""Undefined variable from import"" errors?","I've got a Python project using PyDev in Eclipse, and PyDev keeps generating false errors for my code.  I have a module settings that defines a settings object.  I import that in module b and assign an attribute with:

from settings import settings
settings.main = object()


In some of my code--but not all of it, statements like:

from settings import settings
print settings.main 


... generate ""Undefined variable from import: main"" messages in the Eclipse code error pane, even though the code runs without a problem.  How can I correct these?
"
"There is nothing ""dirty"" about using try-except clause. This is the pythonic way. ValueError will be raised by the .index method only, because it's the only code you have there!

To answer the comment:
In Python, easier to ask forgiveness than to get permission philosophy is well established, and no index will not raise this type of error for any other issues. Not that I can think of any. 
",Best way to handle list.index(might-not-exist) in python?,"I have code which looks something like this:

thing_index = thing_list.index(thing)
otherfunction(thing_list, thing_index)


ok so that's simplified but you get the idea. Now thing might not actually be in the list, in which case I want to pass -1 as thing_index. In other languages this is what you'd expect index() to return if it couldn't find the element. In fact it throws a ValueError.

I could do this:

try:
    thing_index = thing_list.index(thing)
except ValueError:
    thing_index = -1
otherfunction(thing_list, thing_index)


But this feels dirty, plus I don't know if ValueError could be raised for some other reason. I came up with the following solution based on generator functions, but it seems a little complex:

thing_index = ( [(i for i in xrange(len(thing_list)) if thing_list[i]==thing)] or [-1] )[0]


Is there a cleaner way to achieve the same thing? Let's assume the list isn't sorted.
"
"The Birthday Paradox, or why PRNGs produce duplicates more often than you might think.

There are a couple of issues at play in the OP's problem.  One is the birthday paradox as mentioned above and the second is the nature of what you are generating, which does not inherently guarantee that a given number will not be repeated.  

The Birthday Paradox applies where given value can occur more than once during the period of the generator - and therefore duplicates can happen within a sample of values.  The effect of the Birthday Paradox is that the real likelihood of getting such duplicates is quite significant and the average period between them is smaller than one might otherwise have thought.  This dissonance between the percived and actual probabilities makes the Birthday Paradox a good example example of a cognitive bias, where a naive intuitive estimate is likely to be wildly wrong.

A quick primer on Pseudo Random Number Generators (PRNGs)

The first part of your problem is that you are taking the exposed value of a random number generator and converting it to a much smaller number, so the space of possible values is reduced.  Although some pseudo-random number generators do not repeat values during their period this transformation changes the domain to a much smaller one.  The smaller domain invalidates the 'no repeats' condition so you can expect a significant likelihood of repeats.   

Some algorithms, such as the linear congruential PRNG (A'=AX|M) do guarantee uniqueness for the entire period.  In a LCG the generated value contains the entire state of the accumulator and no additional state is held.  The generator is deterministic and cannot repeat a number within the period - any given accumulator value can imply only one possible successive value.  Therefore, each value can only occur once within the period of the generator.  However, the period of such a PRNG is relatively small - about 2^30 for typical implementations of the LCG algorithm - and cannot possibly be larger than the number of distinct values.

Not all PRNG algorithms share this characteristic; some can repeat a given value within the period.  In the OP's problem the Mersenne Twister algorithm (used in Python's random module) has a very long period - much greater than 2^32.   Unlike a Linear Congruential PRNG, the result is not purely a function of the previous output value as the accumulator contains additional state.  With 32 bit integer output and a period of ~2^19937 it cannot possibly provide a such a guarantee.  

The Mersenne Twister is a popular algorithm for PRNGs because it has good statistical and geometric properties and a very long period - desirable characteristics for a PRNG used on simulation models.   


Good statistical properties mean that the numbers generated by the algorithm are evenly distributed with no numbers having a significantly higher probability of appearing than others.  Poor statistical properties could produce unwanted skew in the results.
Good geometric properies mean that sets of N numbers do not lie on a hyperplane in N dimensional space.  Poor geometric properties can generate spurious correlations in a simulation model and distort the results.
A long period means that you can generate a lot of numbers before the sequence wraps around to the start.  If a model needs a large number of iterations or has to be run from several seeds then the 2^30 or so discrete numbers available from a typical LCG implementation may not be sufficient.  The MT19337 algorithm has a very long period - 2^19337-1, or about 10^5821.  By comparison the total number of atoms in the universe is estimated at about 10^80.


The 32 bit integer produced by a MT19337 PRNG cannot possibly represent enough discrete values to avoid repeating during such a large period.  In this case duplicate values are likely to occur and inevitable with a large enough sample.  

The Birthday Paradox in a nutshell

This problem is originally defined as the probability of any two people in the room sharing the same birthday.  The key point is that any two people in the room could share a birthday.  People tend to naively misinterpret the problem as the probability of someone in the room sharing a birthday with a specific individual, which is the source of the cognitive bias that often causes people to underestimate the probability.  This is the incorrect assumption - there is no requirement for the match to be to a specific individual and any two individuals could match.  



The probability of a match occurring between any two individuals is much higher than the probability of a match to a specific individual as the match does not have to be to a specific date.  Rather, you only have to find two individuals that share the same birthday.  From this graph (which can be found on the wikipedia page on the subject), we can see that we only need 23 people in the room for there to be a 50% chance of finding two that match in this way.

From the Wikipedia entry on the subject we can get a nice summary.  In the OP's problem we have 4,500 possible 'birthdays', rather than 365.  For a given number of random values generated (equating to 'people') we want to know the probability of any two identical values appearing within the sequence.  

Computing the likely effect of the Birthday Paradox on the OP's problem

For a sequence of 100 numbers, we have  pairs (see Understanding the Problem) that could potentially match (i.e. the first could match with the second, third etc., the second could match the third, fourth etc. and so on), so the number of combinations that could potentially match is rather more than just 100.  

From Calculating the Probability we get an expression of .  The following snippet of Python code below does a naive evaluation of the probability of a matching pair occurring.  

# === birthday.py ===========================================
#
from math import log10, factorial

PV=4500          # Number of possible values
SS=100           # Sample size

# These intermediate results are exceedingly large numbers;
# Python automatically starts using bignums behind the scenes.
#
numerator = factorial (PV)          
denominator = (PV ** SS) * factorial (PV - SS)

# Now we need to get from bignums to floats without intermediate
# values too large to cast into a double.  Taking the logs and 
# subtracting them is equivalent to division.
#  
log_prob_no_pair = log10 (numerator) - log10 (denominator)

# We've just calculated the log of the probability that *NO*
# two matching pairs occur in the sample.  The probability
# of at least one collision is 1.0 - the probability that no 
# matching pairs exist.
#
print 1.0 - (10 ** log_prob_no_pair)


This produces a sensible looking result of p=0.669 for a match occuring within 100 numbers sampled from a population of 4500 possible values. (Maybe someone could verify this and post a comment if it's wrong).  From this we can see that the lengths of runs between matching numbers observed by the OP seem to be quite reasonable.

Footnote: using shuffling to get a unique sequence of pseudo-random numbers 

See this answer below from S. Mark for a means of getting a guaranteed unique set of random numbers.  The technique the poster refers to takes an array of numbers (which you supply, so you can make them unique) and shuffles them into random order.  Drawing the numbers in sequence from the shuffled array will give you a sequence of pseudo-random numbers that are guaranteed not to repeat.

Footnote: Cryptographically Secure PRNGs 

The MT algorithm is not cryptographically secure as it is relatively easy to infer the internal state of the generator by observing a sequence of numbers.  Other algorithms such as Blum Blum Shub are used for cryptographic applications, but may be unsuitable for simulation or general random number applications.  Cryptographically secure PRNGs may be expensive (perhaps requiring bignum calculations) or may not have good geometric properties.  In the case of this type of algorithm the primary requirement is that it should be computationally infeasible to infer the internal state of the generator by observing a sequence of values.
",Random is barely random at all?,"I did this to test the randomness of randint:

>>> from random import randint
>>>
>>> uniques = []
>>> for i in range(4500):  # You can see I was optimistic.
...     x = randint(500, 5000)
...     if x in uniques:
...         raise Exception('We duped %d at iteration number %d' % (x, i))
...     uniques.append(x)
...
Traceback (most recent call last):
  File """", line 4, in 
Exception: We duped 887 at iteration number 7


I tried about 10 times more and the best result I got was 121 iterations before a repeater. Is this the best sort of result you can get from the standard library?
"
"xmltodict (full disclosure: I wrote it) does exactly that:

xmltodict.parse(""""""


  john
  20
"""""")
# {u'person': {u'age': u'20', u'name': u'john'}}

",How to convert an xml string to a dictionary in Python?,"I have a program that reads an xml document from a socket. I have the xml document stored in a string which I would like to convert directly to a Python dictionary, the same way it is done in Django's simplejson library.

Take as an example:

str =""john20</person""
dic_xml = convert_to_dic(str)


Then dic_xml would look like {'person' : { 'name' : 'john', 'age' : 20 } }

Thanks in advance,
Ze Maria
"
"Scikit-Learn provide a confusion_matrix function

from sklearn.metrics import confusion_matrix
y_actu = [2, 0, 2, 2, 0, 1, 1, 2, 2, 0, 1, 2]
y_pred = [0, 0, 2, 1, 0, 2, 1, 0, 2, 0, 2, 2]
confusion_matrix(y_actu, y_pred)


which output a Numpy array

array([[3, 0, 2],
       [0, 1, 1],
       [0, 2, 3]])


But you can also create a confusion matrix using Pandas:

import pandas as pd
y_actu = pd.Series([2, 0, 2, 2, 0, 1, 1, 2, 2, 0, 1, 2], name='Actual')
y_pred = pd.Series([0, 0, 2, 1, 0, 2, 1, 0, 2, 0, 2, 2], name='Predicted')
df_confusion = pd.crosstab(y_actu, y_pred)


You will get a (nicely labeled) Pandas DataFrame:

Predicted  0  1  2
Actual
0          3  0  0
1          0  1  2
2          2  1  3


If you add margins=True like

df_confusion = pd.crosstab(y_actu, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)


you will get also sum for each row and column:

Predicted  0  1  2  All
Actual
0          3  0  0    3
1          0  1  2    3
2          2  1  3    6
All        5  2  5   12


You can also get a normalized confusion matrix using:

df_conf_norm = df_confusion / df_confusion.sum(axis=1)

Predicted         0         1         2
Actual
0          1.000000  0.000000  0.000000
1          0.000000  0.333333  0.333333
2          0.666667  0.333333  0.500000


You can plot this confusion_matrix using

def plot_confusion_matrix(df_confusion, title='Confusion matrix', cmap=plt.cm.gray_r):
    plt.matshow(df_confusion, cmap=cmap) # imshow
    #plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(df_confusion.columns))
    plt.xticks(tick_marks, df_confusion.columns, rotation=45)
    plt.yticks(tick_marks, df_confusion.index)
    #plt.tight_layout()
    plt.ylabel(df_confusion.index.name)
    plt.xlabel(df_confusion.columns.name)

plot_confusion_matrix(df_confusion)




Or plot normalized confusion matrix using:

plot_confusion_matrix(df_conf_norm)  




You might also be interested by this project https://github.com/pandas-ml/pandas-ml and its Pip package https://pypi.python.org/pypi/pandas_ml

With this package confusion matrix can be pretty-printed, plot.
You can binarize a confusion matrix, get class statistics such as TP, TN, FP, FN, ACC, TPR, FPR, FNR, TNR (SPC), LR+, LR-, DOR, PPV, FDR, FOR, NPV and some overall statistics

In [1]: from pandas_ml import ConfusionMatrix
In [2]: y_actu = [2, 0, 2, 2, 0, 1, 1, 2, 2, 0, 1, 2]
In [3]: y_pred = [0, 0, 2, 1, 0, 2, 1, 0, 2, 0, 2, 2]
In [4]: cm = ConfusionMatrix(y_actu, y_pred)
In [5]: cm.print_stats()
Confusion Matrix:

Predicted  0  1  2  __all__
Actual
0          3  0  0        3
1          0  1  2        3
2          2  1  3        6
__all__    5  2  5       12


Overall Statistics:

Accuracy: 0.583333333333
95% CI: (0.27666968568210581, 0.84834777019156982)
No Information Rate: ToDo
P-Value [Acc > NIR]: 0.189264302376
Kappa: 0.354838709677
Mcnemar's Test P-Value: ToDo


Class Statistics:

Classes                                        0          1          2
Population                                    12         12         12
P: Condition positive                          3          3          6
N: Condition negative                          9          9          6
Test outcome positive                          5          2          5
Test outcome negative                          7         10          7
TP: True Positive                              3          1          3
TN: True Negative                              7          8          4
FP: False Positive                             2          1          2
FN: False Negative                             0          2          3
TPR: (Sensitivity, hit rate, recall)           1  0.3333333        0.5
TNR=SPC: (Specificity)                 0.7777778  0.8888889  0.6666667
PPV: Pos Pred Value (Precision)              0.6        0.5        0.6
NPV: Neg Pred Value                            1        0.8  0.5714286
FPR: False-out                         0.2222222  0.1111111  0.3333333
FDR: False Discovery Rate                    0.4        0.5        0.4
FNR: Miss Rate                                 0  0.6666667        0.5
ACC: Accuracy                          0.8333333       0.75  0.5833333
F1 score                                    0.75        0.4  0.5454545
MCC: Matthews correlation coefficient  0.6831301  0.2581989  0.1690309
Informedness                           0.7777778  0.2222222  0.1666667
Markedness                                   0.6        0.3  0.1714286
Prevalence                                  0.25       0.25        0.5
LR+: Positive likelihood ratio               4.5          3        1.5
LR-: Negative likelihood ratio                 0       0.75       0.75
DOR: Diagnostic odds ratio                   inf          4          2
FOR: False omission rate                       0        0.2  0.4285714

",How to write a confusion matrix in Python?,"I wrote a confusion matrix calculation code in Python:

def conf_mat(prob_arr, input_arr):
        # confusion matrix
        conf_arr = [[0, 0], [0, 0]]

        for i in range(len(prob_arr)):
                if int(input_arr[i]) == 1:
                        if float(prob_arr[i]) < 0.5:
                                conf_arr[0][1] = conf_arr[0][1] + 1
                        else:
                                conf_arr[0][0] = conf_arr[0][0] + 1
                elif int(input_arr[i]) == 2:
                        if float(prob_arr[i]) >= 0.5:
                                conf_arr[1][0] = conf_arr[1][0] +1
                        else:
                                conf_arr[1][1] = conf_arr[1][1] +1

        accuracy = float(conf_arr[0][0] + conf_arr[1][1])/(len(input_arr))


prob_arr is an array that my classification code returned and a sample array is like this: 

 [1.0, 1.0, 1.0, 0.41592955657342651, 1.0, 0.0053405015805891975, 4.5321494433440449e-299, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.70943426182688163, 1.0, 1.0, 1.0, 1.0]


input_arr is the original class labels for a dataset and it is like this: 

[2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1]


What my code is trying to do is: i get prob_arr and input_arr and for each class (1 and 2) I check if they are misclassified or not.

But my code only works for two classes. If I run this code for a multiple classed data, it doesn't work. How can I make this for multiple classes? 

For example for a three classed data, it should return me: [[21,7,3],[3,38,6],[5,4,19]]
"
"Contrary to most other answers here, this can be done in a single regex using a positive lookahead assertion with a capturing group:

>>> my_pattern = '(?=(a.*?b.*?c))'
>>> my_regex = re.compile(my_pattern, re.DOTALL|re.IGNORECASE)
>>> matches = my_regex.findall(string)
>>> print min(matches, key=len)
A|B|C


findall() will return all possible matches, so you need min() to get the shortest one.

How this works:


We're not matching any text in this regex, just positions in the string (which the regex engine steps through during a match attempt). 
At each position, the regex engine looks ahead to see whether your regex would match at this position. 
If so, it will be captured by the capturing group. 
If not, it won't. 
In either case, the regex engine then steps ahead one character and repeats the process until the end of the string. 
Since the lookahead assertion doesn't consume any characters, all overlapping matches will be found.

",How do I find the shortest overlapping match using regular expressions?,"I'm still relatively new to regex. I'm trying to find the shortest string of text that matches a particular pattern, but am having trouble if the shortest pattern is a substring of a larger match. For example:

import re
string = ""A|B|A|B|C|D|E|F|G""
my_pattern = 'a.*?b.*?c'

my_regex = re.compile(my_pattern, re.DOTALL|re.IGNORECASE)
matches = my_regex.findall(string)

for match in matches:
    print match


prints: 

A|B|A|B|C


but I'd want it to return:

A|B|C


Is there a way to do this without having to loop over each match to see if it contains a substring that matches? 
"
"Local to ISO-8601:

import datetime
datetime.datetime.now().isoformat()


UTC to ISO-8601:

import datetime
datetime.datetime.utcnow().isoformat()

",ISO Time (ISO 8601) in Python?,"I have a file. In Python, I would like to take its creation time, and convert it to an ISO time (ISO 8601) string while preserving the fact that it was created in the Eastern Time Zone.

How do I take the file's ctime and convert it to an ISO time string, that indicates the Eastern Time Zone (and takes into account daylight savings time, if necessary)?
"
"In Python 2.7, you can use collections.Counter:

import collections
a = [1,1,1,1,2,2,2,2,3,3,4,5,5]
counter=collections.Counter(a)
print(counter)
# Counter({1: 4, 2: 4, 3: 2, 5: 2, 4: 1})
print(counter.values())
# [4, 4, 2, 1, 2]
print(counter.keys())
# [1, 2, 3, 4, 5]
print(counter.most_common(3))
# [(1, 4), (2, 4), (3, 2)]


If you are using Python 2.6 or older, you can download it here. 
",How to count the frequency of the elements in a list?,"I'm a python newbie, so please bear with me.

I need to find the frequency of elements in a list

a = [1,1,1,1,2,2,2,2,3,3,4,5,5]


output->

b = [4,4,2,1,2]


Also I want to remove the duplicates from a

a = [1,2,3,4,5]

"
"It depends!

If the files and directories are distributed more or less evenly you could show rough process by assuming every toplevel directory is going to take the same amount of time. But if they are not distributed evenly you cannot find out about it cheaply. You either have to know roughly how populated every directory is in advance, or you have to os.walk the entire thing twice (but that is only useful if your actual processing takes much longer than the os.walk itself does).

That is: say you have 4 toplevel directories, and each one contains 4 files. If you assume every toplevel dir takes 25% of progress, and each file takes another 25% of the progress for that dir, you can show a nice progress indicator. But if the last subdir turns out to contain many more files than the first few your progress indicator will have hit 75% before you find out about it. You cannot really fix that if the os.walk itself is the bottleneck (not your processing) and it's an arbitrary directory tree (not one where you know in advance roughly how long every subtree is going to take).

And of course that's assuming the cost here is about the same for every file...
",How to get progress of os.walk in python?,"I have a piece of code which I'm using to search for the executables of game files and returning the directories.  I would really like to get some sort of progress indicator as to how far along os.walk is.  How would I accomplish such a thing?

I tried doing startpt = root.count(os.sep) and gauging off of that but that just gives how deep os.walk is in a directory tree.

def locate(filelist, root=os.curdir): #Find a list of files, return directories.
    for path, dirs, files in os.walk(os.path.abspath(root)):
        for filename in returnMatches(filelist, [k.lower() for k in files]):
            yield path + ""\\""

"
"
immutable objects can allow substantial optimization; this is presumably why strings are also immutable in Java, developed quite separately but about the same time as Python, and just about everything is immutable in truly-functional languages.
in Python in particular, only immutables can be hashable (and, therefore, members of sets, or keys in dictionaries). Again, this afford optimization, but far more than just ""substantial"" (designing decent hash tables storing completely mutable objects is a nightmare -- either you take copies of everything as soon as you hash it, or the nightmare of checking whether the object's hash has changed since you last took a reference to it rears its ugly head).


Example of optimization issue, which a commenter says ""he's never seen"":

$ python -mtimeit '[""fee"", ""fie"", ""fo"", ""fum""]'
1000000 loops, best of 3: 0.432 usec per loop
$ python -mtimeit '(""fee"", ""fie"", ""fo"", ""fum"")'
10000000 loops, best of 3: 0.0563 usec per loop


Speeding an operation up by seven-eight times not ""substantial enough"" for you?!  Wow, you're definitely a very demanding person when it comes to deeming an optimization ""substantial""...!-)
",Why do we need tuples in Python (or any immutable data type)?,"I've read several python tutorials (Dive Into Python, for one), and the language reference on Python.org - I don't see why the language needs tuples.

Tuples have no methods compared to a list or set, and if I must convert a tuple to a set or list to be able to sort them, what's the point of using a tuple in the first place?

Immutability?

Why does anyone care if a variable lives at a different place in memory than when it was originally allocated? This whole business of immutability in Python seems to be over emphasized.

In C/C++ if I allocate a pointer and point to some valid memory, I don't care where the address is located as long as it's not null before I use it.

Whenever I reference that variable, I don't need to know if the pointer is still pointing to the original address or not. I just check for null and use it (or not).

In Python, when I allocate a string (or tuple) assign it to x, then modify the string, why do I care if it's the original object? As long as the variable points to my data, that's all that matters.

>>> x='hello'
>>> id(x)
1234567
>>> x='good bye'
>>> id(x)
5432167


x still references the data I want, why does anyone need to care if its id is the same or different?
"
"You could try this. Same semantics as range:

import operator
def lrange(num1, num2 = None, step = 1):
    op = operator.__lt__

    if num2 is None:
        num1, num2 = 0, num1
    if num2 < num1:
        if step > 0:
            num1 = num2
        op = operator.__gt__
    elif step < 0:
        num1 = num2

    while op(num1, num2):
        yield num1
        num1 += step

>>> list(lrange(138264128374162347812634134, 138264128374162347812634140))
[138264128374162347812634134L, 138264128374162347812634135L, 138264128374162347812634136L, 138264128374162347812634137L, 138264128374162347812634138L, 138264128374162347812634139L]


Another solution would be using itertools.islice, as suggested inxrange's documentation
",range and xrange for 13-digit numbers in Python?,"range() and xrange() work for 10-digit-numbers. But how about 13-digit-numbers? I didn't find anything in the forum.
"
"if not name.startswith('doc'):
     print name


If you have more prefixes to exclude you can even do this:

if not name.startswith(('prefix', 'another', 'yetanother')):
     print name


startswith can accept a tuple of prefixes.
","In python, how do I exclude files from a loop if they begin with a specific set of letters?","I'm writing a Python script that goes through a directory and gathers certain files, but there are a number of files I want excluded that all start the same.

Example code:

for name in files:
   if name != ""doc1.html"" and name != ""doc2.html"" and name != ""doc3.html"":
      print name


Let's say there are 100 hundred HTML files in the directory all beginning with 'doc'. What would be the easiest way to exclude them?

Sorry I'm new to Python, I know this is probably basic.

Thanks in advance.
"
"âIf I have seen furtherâ¦â

The erat2 function from the cookbook can be further sped up (by about 20-25%):

erat2a

import itertools as it
def erat2a( ):
    D = {  }
    yield 2
    for q in it.islice(it.count(3), 0, None, 2):
        p = D.pop(q, None)
        if p is None:
            D[q*q] = q
            yield q
        else:
            # old code here:
            # x = p + q
            # while x in D or not (x&1):
            #     x += p
            # changed into:
            x = q + 2*p
            while x in D:
                x += 2*p
            D[x] = p


The not (x&1) check verifies that x is odd. However, since both q and p are odd, by adding 2*p half of the steps are avoided along with the test for oddity.

erat3

If one doesn't mind a little extra fanciness, erat2 can be sped up by 35-40% with the following changes (NB: needs Python 2.7+ or Python 3+ because of the itertools.compress function):

import itertools as it
def erat3( ):
    D = { 9: 3, 25: 5 }
    yield 2
    yield 3
    yield 5
    MASK= 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0,
    MODULOS= frozenset( (1, 7, 11, 13, 17, 19, 23, 29) )

    for q in it.compress(
            it.islice(it.count(7), 0, None, 2),
            it.cycle(MASK)):
        p = D.pop(q, None)
        if p is None:
            D[q*q] = q
            yield q
        else:
            x = q + 2*p
            while x in D or (x%30) not in MODULOS:
                x += 2*p
            D[x] = p


The erat3 function takes advantage of the fact that all primes (except for  2, 3, 5) modulo 30 result to only eight numbers: the ones included in the MODULOS frozenset. Thus, after yielding the initial three primes, we start from 7 and work only with the candidates.
The candidate filtering uses the itertools.compress function; the âmagicâ is in the MASK sequence; MASK has 15 elements (there are 15 odd numbers in every 30 numbers, as chosen by the itertools.islice function) with a 1 for every possible candidate, starting from 7. The cycle repeats as specified by the itertools.cycle function.
The introduction of the candidate filtering needs another modification: the or (x%30) not in MODULOS check. The erat2 algorithm processed all odd numbers; now that the erat3 algorithm processes only r30 candidates, we need to make sure that all D.keys() can only be such âfalseâ candidates.

Benchmarks

Results

On an Atom 330 Ubuntu 9.10 server, versions 2.6.4 and 3.1.1+:

$ testit
up to 8192
==== python2 erat2 ====
100 loops, best of 3: 18.6 msec per loop
==== python2 erat2a ====
100 loops, best of 3: 14.5 msec per loop
==== python2 erat3 ====
Traceback (most recent call last):
â¦
AttributeError: 'module' object has no attribute 'compress'
==== python3 erat2 ====
100 loops, best of 3: 19.2 msec per loop
==== python3 erat2a ====
100 loops, best of 3: 14.1 msec per loop
==== python3 erat3 ====
100 loops, best of 3: 11.7 msec per loop


On an AMD Geode LX Gentoo home server, Python 2.6.5 and 3.1.2:

$ testit
up to 8192
==== python2 erat2 ====
10 loops, best of 3: 104 msec per loop
==== python2 erat2a ====
10 loops, best of 3: 81 msec per loop
==== python2 erat3 ====
Traceback (most recent call last):
â¦
AttributeError: 'module' object has no attribute 'compress'
==== python3 erat2 ====
10 loops, best of 3: 116 msec per loop
==== python3 erat2a ====
10 loops, best of 3: 82 msec per loop
==== python3 erat3 ====
10 loops, best of 3: 66 msec per loop


Benchmark code

A primegen.py module contains the erat2, erat2a and erat3 functions. Here follows the testing script:

#!/bin/sh
max_num=${1:-8192}
echo up to $max_num
for python_version in python2 python3
do
    for function in erat2 erat2a erat3
    do
        echo ""==== $python_version $function ====""
        $python_version -O -m timeit -c \
        -s  ""import itertools as it, functools as ft, operator as op, primegen; cmp= ft.partial(op.ge, $max_num)"" \
            ""next(it.dropwhile(cmp, primegen.$function()))""
    done
done

",How to implement an efficient infinite generator of prime numbers in Python?,"This is not a homework, I am just curious.

INFINITE is the key word here.

I wish to use it as for p in primes(). I believe that this is a built-in function in Haskell.

So, the answer cannot be as naive as ""Just do a Sieve"".

First of all, you do not know how many consecutive primes will be consumed. Well, suppose you could concoct 100 of them at a time. Would you use the same Sieve approach as well as the frequency of prime numbers formula?

I prefer non-concurrent approach.

Thank you for reading (and writing ;) )!
"
"Keys cannot be changed. You will need to add a new key with the modified value then remove the old one, or create a new dict with a dict comprehension or the like.
","In Python, I have a dictionary. How do I change the keys of this dictionary?","Let's say I have a pretty complex dictionary.

{'fruit':'orange','colors':{'dark':4,'light':5}}


Anyway, my objective is to scan every key in this complex multi-level dictionary. Then, append ""abc"" to the end of each key. 

So that it will be:

{'fruitabc':'orange','colorsabc':{'darkabc':4,'lightabc':5}}


How would you do that?
"
"I have done some profiling, and the results are completely counterintuitive.
For simple array access operations, numpy and array.array are 10x slower than native Python arrays.

Note that for array access, I am doing operations of the form:

a[i] += 1


Profiles:


[0] * 20000000


Access: 2.3M / sec
Initialization: 0.8s

numpy.zeros(shape=(20000000,), dtype=numpy.int32)


Access: 160K/sec
Initialization: 0.2s

array.array('L', [0] * 20000000)


Access: 175K/sec
Initialization: 2.0s

array.array('L', (0 for i in range(20000000)))


Access: 175K/sec, presumably, based upon the profile for the other array.array
Initialization: 6.7s


",Efficient Python array with 100 million zeros?,"What is an efficient way to initialize and access elements of a large array in Python?

I want to create an array in Python with 100 million entries, unsigned 4-byte integers, initialized to zero. I want fast array access, preferably with contiguous memory.

Strangely, NumPy arrays seem to be performing very slow. Are there alternatives I can try?

There is the array.array module, but I don't see a method to efficiently allocate a block of 100 million entries.

Responses to comments:


I cannot use a sparse array. It will be too slow for this algorithm because the array becomes dense very quickly.
I know Python is interpreted, but surely there is a way to do fast array operations?
I did some profiling, and I get about 160K array accesses (looking up or updating an element by index) per second with NumPy. This seems very slow.

"
"Fundamentally it doesn't matter, such minutiae doesn't really affect whether something is 'pythonic' or not.

If you're interested in trivia however, there are some differences.


The builtin boolean type didn't exist till Python 2.3 so code that was intended to run on ancient versions tends to use the while 1: form. You'll see it in the standard library, for instance.
The True and False builtins are not reserved words prior to Python 3 so could be assigned to, changing their value. This helps with the case above because code could do True = 1 for backwards compatibility, but means that the name True needs to be looked up in the globals dictionary every time it is used.
Because of the above restriction, the bytecode the two versions compile to is different in Python 2 as there's an optimisation for constant integers that it can't use for True. Because Python can tell when compiling the 1 that it's always non-zero, it removes the conditional jump and doesn't load the constant at all:

>>> import dis
>>> def while_1():
...     while 1:
...         pass
...
>>> def while_true():
...     while True:
...         pass
...
>>> dis.dis(while_1)
  2           0 SETUP_LOOP               5 (to 8)


  3     >>    3 JUMP_ABSOLUTE            3
              6 POP_TOP
              7 POP_BLOCK
        >>    8 LOAD_CONST               0 (None)
             11 RETURN_VALUE
>>> dis.dis(while_true)
  2           0 SETUP_LOOP              12 (to 15)
        >>    3 LOAD_GLOBAL              0 (True)
              6 JUMP_IF_FALSE            4 (to 13)
              9 POP_TOP


  3          10 JUMP_ABSOLUTE            3
        >>   13 POP_TOP
             14 POP_BLOCK
        >>   15 LOAD_CONST               0 (None)
             18 RETURN_VALUE



So, while True: is a little easier to read, and while 1: is a bit kinder to old versions of Python. As you're unlikely to need to run on Python 2.2 these days or need to worry about the bytecode count of your loops, the former is marginally preferable.
","What's the difference between ""while 1"" and ""while True""?","I've seen two ways to create an infinite loop in Python:


while 1:
    do_something()

while True:
    do_something()



Is there any difference between these? Is one more pythonic than the other?
"
"Boo is a statically typed language for the Common Language Infrastructure (aka. the Microsoft .NET platform). The syntax is highly inspired by Python, and hashes/lists/array are part of the syntax:

i = 5
if i > 5:
    print ""i is greater than 5.""
else:
    print ""i is less than or equal to 5.""

hash = {'a': 1, 'b': 2, 'monkey': 3, 42: 'the answer'}
print hash['a']
print hash[42]

for item in hash:
    print item.Key, '=>', item.Value

",What statically typed languages are similar to Python?,"Python is the nicest language I currently know of, but static typing is a big advantage due to auto-completion (although there is limited support for dynamic languages, it is nothing compared to that supported in static). I'm curious if there are any languages which try to add the benefits of Python to a statically typed language. In particular I'm interesting in languages with features like:


Syntax support: such as that for dictionaries, array comprehensions
Functions: Keyword arguments, closures, tuple/multiple return values
Runtime modification/creation of classes
Avoidance of specifying classes everywhere (in Python this is due to duck typing, although type inference would work better in a statically typed language)
Metaprogramming support: This is achieved in Python through reflection, annotations and metaclasses


Are there any statically typed languages with a significant number of these features?
"
"I found a solution for this:

logger = logging.getLogger('my-logger')
logger.propagate = False
# now if you use logger it will not log to console.


This will prevent logging from being send to the upper logger that includes the console logging.
",How to I disable and re-enable console logging in Python?,"I am using python logging module and I want to disable the console logging for some time but it doesn't work.


  #!/usr/bin/python
  import logging

  logger = logging.getLogger() # this gets the root logger
  # ... here I add my own handlers 
  #logger.removeHandler(sys.stdout)
  #logger.removeHandler(sys.stderr)

  print logging.handlers 
  # this will print []
  # but I may have other handlers there that I want to keep

  logger.debug(""bla bla"")


The above code displays the ""bla bla"" on stdout and I don't know how can I safely disable the console handler. How can I bu sure that I temporary remove the console streamhandler and not another one?
"
"Here's a solution I wrote to do just what you're talking about on some of my own projects:

def expire_view_cache(view_name, args=[], namespace=None, key_prefix=None):
    """"""
    This function allows you to invalidate any view-level cache. 
        view_name: view function you wish to invalidate or it's named url pattern
        args: any arguments passed to the view function
        namepace: optioal, if an application namespace is needed
        key prefix: for the @cache_page decorator for the function (if any)
    """"""
    from django.core.urlresolvers import reverse
    from django.http import HttpRequest
    from django.utils.cache import get_cache_key
    from django.core.cache import cache
    # create a fake request object
    request = HttpRequest()
    # Loookup the request path:
    if namespace:
        view_name = namespace + "":"" + view_name
    request.path = reverse(view_name, args=args)
    # get cache key, expire if the cached item exists:
    key = get_cache_key(request, key_prefix=key_prefix)
    if key:
        if cache.get(key):
            # Delete the cache entry.  
            #
            # Note that there is a possible race condition here, as another 
            # process / thread may have refreshed the cache between
            # the call to cache.get() above, and the cache.set(key, None) 
            # below.  This may lead to unexpected performance problems under 
            # severe load.
            cache.set(key, None, 0)
        return True
    return False


Django keys these caches of the view request, so what this does is creates a fake request object for the cached view, uses that to fetch the cache key, then expires it. 

To use it in the way you're talking about, try something like:

from django.db.models.signals import post_save
from blog.models import Entry

def invalidate_blog_index(sender, **kwargs):
    expire_view_cache(""blog"")

post_save.connect(invalidate_portfolio_index, sender=Entry)


So basically, when ever a blog Entry object is saved, invalidate_blog_index is called and the cached view is expired. NB: haven't tested this extensively, but it's worked fine for me so far. 
",Expire a view-cache in Django?,"The @cache_page decorator is awesome. But for my blog I would like to keep a page in cache until someone comments on a post. This sounds like a great idea as people rarely comment so keeping the pages in memcached while nobody comments would be great. I'm thinking that someone must have had this problem before? And this is different than caching per url.

So a solution I'm thinking of is:

@cache_page( 60 * 15, ""blog"" );
def blog( request ) ...


And then I'd keep a list of all cache keys used for the blog view and then have way of expire the ""blog"" cache space. But I'm not super experienced with Django so I'm wondering if someone knows a better way of doing this?
"
"The original code can be streamlined a little by using __dict__:

In [1]: class data:
   ...:     def __init__(self, **kwargs):
   ...:         self.__dict__.update(kwargs)
   ...: 

In [2]: d = data(foo=1, bar=2)

In [3]: d.foo
Out[3]: 1

In [4]: d.bar
Out[4]: 2

",Shortest way of creating an object with arbitrary attributes in Python?,"Hey, I just started wondering about this as I came upon a code that expected an object with a certain set of attributes (but with no specification of what type this object should be).

One solution would be to create a new class that has the attributes the code expects, but as I call other code that also needs objects with (other) attributes, I'd have to create more and more classes.

A shorter solution is to create a generic class, and then set the attributes on instances of it (for those who thought of using an instance of object instead of creating a new class, that won't work since object instances don't allow new attributes).

The last, shortest solution I came up with was to create a class with a constructor that takes keyword arguments, just like the dict constructor, and then sets them as attributes:

class data:
    def __init__(self, **kw):
        for name in kw:
            setattr(self, name, kw[name])

options = data(do_good_stuff=True, do_bad_stuff=False)


But I can't help feeling like I've missed something obvious... Isn't there a built-in way to do this (preferably supported in Python 2.5)?
"
"I think it depends on the area of the project. While GUI is not hard in Python, any kind of GUI-framework will have a somewhat steep learning curve.
If it is a webapp, I'd say go for Python. The added time for learning is quickly gained back by easy of use of the many Python webframeworks.

The big risk is that you will code Python just like you code Java. Many of the things true in Java are not true in Python and vice versa. It will probably make your Python code slow and verbose.

If you decide to try Python, read up on common pitfalls coming from Java, for example:
http://dirtsimple.org/2004/12/python-is-not-java.html
",How much leeway do I have to leave myself to learn a new language?,"I'm a relatively new hire, and I'm starting on a small, fairly simple project. The language that this project will be implemented in is still to be determined. The question basically boils down to - Java or Python? 

Here's the dilemma: My manager would prefer it to be done in Python. I don't object to that, but I have no experience in Python. I'd really love to learn Python and think I could manage it fairly quickly (especially as it's a small project). BUT the project is due at the end of March and must be ready by then. So they'd rather have it in Java and on time than in Python and late, and they don't want to pressure me to do it in Python if I think I can't make it on time.

Sorry about the background - but my question basically is, how long does it take, on average, to adapt to a new language? I know this is subjective and personalized, and depends on how fast the particular programmer is... but talking about an average programmer, or even a somewhat fast one that picks up things quickly, what percentage of an increase does programming in a non-native language (but with similar concepts) cause? As in, if this project would take me about 2 weeks in Java or a .NET language, how much longer can it take me in Python? Can I assume that having double the amount of time (i.e. a new, unfamiliar language causes a 50% increase in programming time) is adequate?

And included in this question - from what I've heard, it seems to be pretty easy/intuitive to switch over from Java to Python. Is this true...?

Thanks everyone for all the answers! I didn't realize there are so many sides to this question... I will try to choose an answer soon - each response made me look at it a different way and it's hard to choose one answer.
"
"have a look at the getopt and optparse modules from the standard lib, many good things could be also said about more advanced argparse module.

Generally you just need to access sys.argv.
",How do I make a command line program that takes arguments?,"How can I make a command line, so I can execute my program on Windows with some parameters...

For example:

C:/Program/App.exe -safemode

"
"No, it is not:


  Field name âhidingâ is not permitted
  
  In normal Python class inheritance, it is permissible for a child
  class to override any attribute from the parent class. In Django, this
  is not permitted for attributes that are Field instances (at least,
  not at the moment). If a base class has a field called author, you
  cannot create another model field called author in any class that
  inherits from that base class.

",In Django - Model Inheritance - Does it allow you to override a parent model's attribute?,"I'm looking to do this:

class Place(models.Model):
 name = models.CharField(max_length=20)
 rating = models.DecimalField()

class LongNamedRestaurant(Place):  # Subclassing `Place`.
 name = models.CharField(max_length=255)  # Notice, I'm overriding `Place.name` to give it a longer length.
 food_type = models.CharField(max_length=25)


This is the version I would like to use (although I'm open to any suggestion):
http://docs.djangoproject.com/en/dev/topics/db/models/#id7

Is this supported in Django? If not, is there a way to achieve similar results?
"
"Derive from dict and and implement __getattr__ and __setattr__.

Or you can use Bunch which is very similar.

I don't think it's possible to monkeypatch built-in dict class.
","How to use a dot ""."" to access members of dictionary?","How do I make Python dictionary members accessible via a dot "".""?

For example, instead of writing mydict['val'], I'd like to write mydict.val.

Also I'd like to access nested dicts this way. For example, mydict.mydict2.val would refer to mydict = { 'mydict2': { 'val': ... } }.

Thanks, Boda Cydo.
"
"The ceil (ceiling) function:

import math
print math.ceil(4.2)

",How do you round UP a number in Python?,"This problem is killing me. How does one roundup a number UP in Python?

I tried round(number) but it round the number down. Example:

round(2.3) = 2.0 and not 3, what I would like


The I tried int(number + .5) but it round the number down again! Example:

int(2.3 + .5) = 2


Then I tried round(number + .5) but it won't work in edge cases. Example:

WAIT! THIS WORKED!


Please advise.
"
"Python doesn't have the quite the extensive range of ""built-in"" data structures as Java does. However, because Python is dynamic, a general tree is easy to create. For example, a binary tree might be:

class Tree(object):
    def __init__(self):
        self.left = None
        self.right = None
        self.data = None


You can use it like this:

root = Tree()
root.data = ""root""
root.left = Tree()
root.left.data = ""left""
root.right = Tree()
root.right.data = ""right""

",How can I implement a tree in Python? Are there any built in data structures in Python like in Java?,"I am trying to construct a general tree.  Are there any built in data structures in Python to implement a tree?
"
"
  That makes me think dulwich is not
  installed correctly, or not in the
  path.


You're absolutely right. Mercurial binary distributions for Windows are 'frozen' - they use the Python code and interpreter bundled with them and therefore independent of packages installed in system PYTHONPATH. When you specify path to hggit extension in Mercurial.ini, hg tries to import it using direct path, but dulwich library is not imported explicitly by hg and doesn't bundled with its library, so the import fails.

It is possible to add both Dulwich and HgGit into library.zip that is installed along with hg.exe, but for me the best way is to install everything from source including Mercurial and execute commands using .bat files installed into \Python\Scripts. In this case you will need to:


Install Mercurial from source. This builds ""pure"" version, because Windows users usually don't have Visual Studio or alternative compiler for compiling C speedups.
Install Dulwich - I'd use latest trunk snapshot for both Git and Dulwich.

python setup.py --pure install
Install latest HgGit snapshot

python setup.py install
Edit Mercurial.ini to enable hggit =
Launch Mercurial using your \Python\Scripts\hg.bat

",How do I correctly install dulwich to get hg-git working on Windows?,"I'm trying to use the hg-git Mercurial extension on Windows (Windows 7 64-bit, to be specific). I have Mercurial and Git installed. I have Python 2.5 (32-bit) installed.

I followed the instructions on http://hg-git.github.com/ to install the extension. The initial easy_install failed because it was unable to compile dulwich without Visual Studio 2003.

I installed dulwich manually by:


git clone git://git.samba.org/jelmer/dulwich.git
cd dulwich
c:\Python25\python setup.py --pure install


Now when I run easy_install hg-git, it succeeds (since the dulwich dependency is satisfied).

In my C:\Users\username\Mercurial.ini, I have:

[extensions]
hgext.bookmarks =
hggit =


When I type 'hg' at a command prompt, I see:
""* failed to import extension hggit: No module named hggit""

Looking under my c:\Python25 folder, the only reference to hggit I see is Lib\site-packages\hg_git-0.2.1-py2.5.egg. Is this supposed to be extracted somewhere, or should it work as-is?

Since that failed, I attempted the ""more involved"" instructions from the hg-git page that suggested cloning git://github.com/schacon/hg-git.git and referencing the path in my Mercurial configuration. I cloned the repo, and changed my extensions file to look like:

[extensions]
hgext.bookmarks =
hggit = c:\code\hg-git\hggit


Now when I run hg, I see: * failed to import extension hggit from c:\code\hg-git\hggit: No module named dulwich.errors.

Ok, so that tells me that it is finding hggit now, because I can see in hg-git\hggit\git_handler.py that it calls

from dulwich.errors import HangupException


That makes me think dulwich is not installed correctly, or not in the path.

Update:

From Python command line:

import dulwich


yields Import Error: No module named dulwich

However, under C:\Python25\Lib\site-packages, I do have a dulwich-0.5.0-py2.5.egg folder which appears to be populated. This was created by the steps mentioned above. Is there an additional step I need to take to make it part of the Python ""path""?

From Python command line (as suggested in one of the answers):

import pkg_resources
pkg_resources.require('dulwich')


yields [dulwich 0.5.0 (c:\python25\lib\site-packages\dulwich-0.5.0-py2.5.egg)]

So what does that tell me? Importing dulwich fails, but apparently pkg_resources can find it. What can I do with that information?
"
"In Python 2.6 or better:


next(x for x in the_iterable if x > 3)

if you want StopIteration to be raised if no matching element is found,
next( (x for x in the_iterable if x>3), default_value)

if you want default_value (e.g. None) to be returned instead.
Note that you need an extra pair of parentheses around the generator expression in this case - they are needed always when the generator expression isn't the only argument.


I see most answers resolutely ignore the next built-in and so I assume that for some mysterious reason they're 100% focused on versions 2.5 and older -- without mentioning the Python-version issue (but then I don't see that mention in the answers that do mention the next built-in, which is why I thought it necessary to provide an answer myself -- at least the ""correct version"" issue gets on record this way;-).

In 2.5, the .next() method of iterators immediately raises StopIteration if the iterator immediately finishes -- i.e., for your use case, if no item in the iterable satisfies the condition.  If you don't care (i.e., you know there must be at least one satisfactory item) then just use .next() (best on a genexp, line for the next built-in in Python 2.6 and better).

If you do care, wrapping things in a function as you had first indicated in your Q seems best, and while the function implementation you proposed is just fine, you could alternatively use itertools, a for...: break loop, or a genexp, or a try/except StopIteration as the function's body, as various answers suggested.  There's not much added value in any of these alternatives so I'd go for the starkly-simple version you first proposed.
",What is the best way to get the first item from an iterable matching a condition?,"In Python, I would like to get the first item from a list matching a condition. For example, the following function is adequate:

def first(the_iterable, condition = lambda x: True):
    for i in the_iterable:
        if condition(i):
            return i


This function could be used something like this:

>>> first(range(10))
0
>>> first(range(10), lambda i: i > 3)
4


However, I can't think of a good built-in / one-liner to let me do this (and I don't particularly want to copy this function around if I don't have to). Any ideas?

(It's important that the resulting method not process the entire list, which could be quite large.)
"
"A pattern that often came up in Python was

bar = []
for item in some_iterable:
    bar.append(SOME EXPRESSION)


which helped motivate the introduction of list comprehensions, which convert that snippet to

bar = [SOME EXPRESSION for item in some_iterable]


which is shorter and sometimes clearer. Usually you get in the habit of recognizing these and often replacing loops with comprehensions.

Your code follows this pattern twice

twod_list = []                                       \                      
for i in range (0, 10):                               \
    new = []                  \ can be replaced        } this too
    for j in range (0, 10):    } with a list          /
        new.append(foo)       / comprehension        /
    twod_list.append(new)                           /

",How to initialize a two-dimensional array in Python?,"I'm beginning python and I'm trying to use a two-dimensional list, that I initially fill up with the same variable in every place. I came up with this:

def initialize_twodlist(foo):
    twod_list = []
    new = []
    for i in range (0, 10):
        for j in range (0, 10):
            new.append(foo)
        twod_list.append(new)
        new = []


It gives the desired result, but feels like a workaround. Is there an easier/shorter/more elegant way to do this?
"
"Another way to use .ui in your code is:

from PyQt4 import QtCore, QtGui, uic
class MyWidget(QtGui.QWidget)
    ...
    #somewhere in constructor:
    uic.loadUi('MyWidget.ui', self)


both approaches are good. Do not forget, that if you use Qt resource files (extremely useful) for icons and so on, you must compile it too:

pyrcc4.exe -o ui/images_rc.py ui/images/images.qrc


Note, when uic compiles interface, it adds 'import images_rc' at the end of .py file, so you must compile resources into the file with this name, or rename it in generated code.
",Linking a qtDesigner .ui file to python/pyqt?,"So if I go into QtDesigner and build a UI, it'll be saved as a .ui file.  How can I make this as a python file or use this in python?
"
"In an environment like that, you can't go wrong with VB/C#. Try the various VS Express editions.

If you want something that will translate to Linux a little more, Python and just about any cross-platform GUI framework(QT, or wxpython) would work.

EDIT:
Then there's the database. I would probably suggest sqlite if you want to learn something cross platform. Sticking in the Microsoft world, there's SQL server compact. 

In a business environment like that, a .NET app is probably more maintainable(after you're gone, etc) then anything that's not completely Microsoft.
","wanting to move up from ms access, thinking .net? visual studio?","So I wrote a project-management program for a small business using Microsoft Access 2007.

Now they've requested lots of additional features (timekeeping, privileged data tiers ...)

I personally use Linux, but the whole office uses Windows.

I'm relatively new to programming but like to teach myself using projects like this. 

I'm right on the edge on this -- I can't really tell what the path of least resistance here is: do I stay in access + VBA and teach myself a dying, annoying language -- while struggling against all the limitations of Access? Or do I move to something else?

Python seems simple enough ... Whatever I use, i need to be able to offer a GUI.

screenshot so you can get the jist:
http://img707.imageshack.us/img707/9360/screenshot1fi.jpg

http://img707.imageshack.us/img707/7338/screenshotmh.jpg

--
notes:
current access project uses seperate frontend-backend for multiuser sharing over a LAN

cross compatibility with linux is not that important to me, i've been using virtualbox for a while now.

--UPDATE--
my wanderings have convinced me that i should proceed in IronPython -- however -- as I try to install the suite in both XP and 7, and fail ... I wonder if this also is something outdated ... most importantly, iv'e been reading up on it and I LOVE PYTHON 3 -- but i need to offer a GUI for Windows not sure where to start with that (including which IDE to use, etc)
"
"The better is the one you like better. I would use first version with if but this is very personal.
",Python: avoiding if condition?,"Which is better?
if not var:
    var = get_var()
(or)


  var = var or get_var()


Also, How do I know the better of the two?
edit:One more option from steve,

var = var if var else get_var()
"
"Generally, bash works better than python only in those environments where python is not available. :)

Seriously, I have to deal with both languages daily, and will take python instantly over bash if given the choice. Alas, I am forced to use bash on certain ""small"" platforms because someone has (mistakenly, IMHO) decided that python is ""too large"" to fit.

While it is true that bash might be faster than python for some select tasks, it can never be as quick to develop with, or as easy to maintain (at least after you get past 10 lines of code or so). Bash's sole strong point wrt python or ruby or lua, etc., is its ubiquity.
",Python vs Bash - In which kind of tasks each one outruns the other performance-wise?,"Obviously Python is more user friendly, a quick search on google shows many results that say that, as Python is byte-compiled is usually faster. I even found this that claims that you can see an improvement of over 2000% on dictionary-based operations.

What is your experience on this matter? In which kind of task each one is a clear winner?
"
"The Python generator API is one way: You can't push back elements you've read. But you can create a new iterator using the itertools module and prepend the element:

import itertools

gen = iter([1,2,3])
peek = gen.next()
print list(itertools.chain([peek], gen))

",How to look ahead one element in a Python generator?,"I can't figure out how to look ahead one element in a Python generator. As soon as I look it's gone.

Here is what I mean:

gen = iter([1,2,3])
next_value = gen.next()  # okay, I looked forward and see that next_value = 1
# but now:
list(gen)  # is [2, 3]  -- the first value is gone!


Here is a more real example:

gen = element_generator()
if gen.next_value() == 'STOP':
  quit_application()
else:
  process(gen.next())


Can anyone help me write a generator that you can look one element forward?

Thanks, Boda Cydo.
"
"Recent progress

March 2014: Good news! Python 3.4 ships with Pip. Pip has long been Python's de-facto standard package manager. You can install a package like this:

pip install httpie


Wahey! This is the best feature of any Python release. It makes the community's wealth of libraries accessible to everyone. Newbies are no longer excluded from using community libraries by the prohibitive difficulty of setup.

However, there remains a number of outstanding frustrations with the Python packaging experience. Cumulatively, they make Python very unwelcoming for newbies. Also, the long history of neglect (ie. not shipping with a package manager for 14 years from Python 2.0 to Python 3.3) did damage to the community. I describe both below.

Outstanding frustrations

It's important to understand that while experienced users are able to work around these frustrations, they are significant barriers to people new to Python. In fact, the difficulty and general user-unfriendliness is likely to deter many of them. 

PyPI website is counter-helpful

Every language with a package manager has an official (or quasi-official) repository for the community to download and publish packages. Python has the Python Package Index, PyPI.  https://pypi.python.org/pypi 

Let's compare its pages with those of RubyGems and Npm (the Node package manager).


https://rubygems.org/gems/rails RubyGems page for the package rails 
https://www.npmjs.org/package/express Npm page for the package express
https://pypi.python.org/pypi/simplejson/ PyPI page for the package simplejson


You'll see the RubyGems and Npm pages both begin with a one-line description of the package, then large friendly instructions how to install it.

Meanwhile, woe to any hapless Python user who naively browses to PyPI. On https://pypi.python.org/pypi/simplejson/ , they'll find no such helpful instructions. There is however, a large green 'Download' link. It's not unreasonable to follow it. Aha, they click! Their browser downloads a .tar.gz file. Many Windows users can't even open it, but if they persevere they may eventually extract it, then run setup.py and eventually with the help of Google setup.py install. Some will give up and reinvent the wheel..  

Of course, all of this is wrong. The easiest way to install a package is with a Pip command. But PyPI didn't even mention Pip. Instead, it led them down an archaic and tedious path.

Error: Unable to find vcvarsall.bat

Numpy is one of Python's most popular libraries. Try to install it with Pip, you get this cryptic error message:


  Error: Unable to find vcvarsall.bat


Trying to fix that is one of the most popular questions on Stack Overflow: ""error: Unable to find vcvarsall.bat""

Few people succeed.

For comparison, in the same situation, Ruby prints this message, which explains what's going on and how to fix it:


  Please update your PATH to include build tools or download the DevKit from http://rubyinstaller.org/downloads and follow the instructions at http://github.com/oneclick/rubyinstaller/wiki/Development-Kit


Publishing packages is hard

Ruby and Nodejs ship with full-featured package managers, Gem (since 2007) and Npm (since 2011), and have nurtured sharing communities centred around GitHub. Npm makes publishing packages as easy as installing them, it already has 64k packages. RubyGems lists 72k packages. The venerable Python package index lists only 41k.

History

Flying in the face of its ""batteries included"" motto, Python shipped without a package manager until 2014. 

Until Pip, the de facto standard was a command  easy_install. It was woefully inadequate. The was no command to uninstall packages.

Pip was a massive improvement. It had most the features of Ruby's Gem. Unfortunately, Pip was--until recently--ironically difficult to install. In fact, the problem remains a top Python question on Stack Overflow: ""How do I install pip on Windows?""
",Does Python have a package/module management system?,"Does Python have a package/module management system, similar to how Ruby has rubygems where you can do gem install packagename?

On Installing Python Modules, I only see references to python setup.py install, but that requires you to find the package first.
"
"I don't actually think that DI/IoC are that uncommon in Python. What is uncommon, however, are DI/IoC frameworks/containers.

Think about it: what does a DI container do? It allows you to 


wire together independent components into a complete application ...
... at runtime.


We have names for ""wiring together"" and ""at runtime"":


scripting
dynamic


So, a DI container is nothing but an interpreter for a dynamic scripting language. Actually, let me rephrase that: a typical Java/.NET DI container is nothing but a crappy interpreter for a really bad dynamic scripting language with butt-ugly, often XML-based, syntax.

When you program in Python, why would you want to use an ugly, bad scripting language when you have a beautiful, brilliant scripting language at your disposal? Actually, that's a more general question: when you program in pretty much any language, why would you want to use an ugly, bad scripting language when you have Jython and IronPython at your disposal?

So, to recap: the practice of DI/IoC is just as important in Python as it is in Java, for exactly the same reasons. The implementation of DI/IoC however, is built into the language and often so lightweight that it completely vanishes. 

(Here's a brief aside for an analogy: in assembly, a subroutine call is a pretty major deal - you have to save your local variables and registers to memory, save your return address somewhere, change the instruction pointer to the subroutine you are calling, arrange for it to somehow jump back into your subroutine when it is finished, put the arguments somewhere where the callee can find them, and so on. IOW: in assembly, ""subroutine call"" is a Design Pattern, and before there were languages like Fortran which had subroutine calls built in, people were building their own ""subroutine frameworks"". Would you say that subroutine calls are ""uncommon"" in Python, just because you don't use subroutine frameworks?)

BTW: for an example of what it looks like to take DI to its logical conclusion, take a look at Gilad Bracha's Newspeak Programming Language and his writings on the subject:


Constructors Considered Harmful
Lethal Injection
A Ban on Imports (continued)

",Why is IoC / DI not common in Python?,"In Java IoC / DI is a very common practice which is extensively used in web applications, nearly all available frameworks and Java EE. On the other hand, there are also lots of big Python web applications, but beside of Zope (which I've heard should be really horrible to code) IoC doesn't seem to be very common in the Python world. (Please name some examples if you think that I'm wrong).

There are of course several clones of popular Java IoC frameworks available for Python, springpython for example. But none of them seems to get used practically. At least, I've never stumpled upon a Django or sqlalchemy+ based web application which uses something like that.

In my opinion IoC has reasonable advantages and would make it easy to replace the django-default-user-model for example, but extensive usage of interface classes and IoC in Python looks a bit odd and not Â»pythonicÂ«. But maybe someone has a better explanation, why IoC isn't widely used in Python.
"
"Do you have an application that is running too slow and you profiled it to find that a line like this snippet is causing it to be slow? Bottlenecks occur at unexpected places.

The current snippet traverses the string 5 times, doing one thing each time. You are suggesting traversing it once, probably doing doing five things each time (or at least doing something each time). It isn't clear that this will automatically do a better job to me. Currently the algorithm used is O(nm) (assuming the length of the string is longer than the stuff in the rules), where n is the length of the string and m is the number of substitution rules. You could, I think, reduce the algorithmic complexity to something like O(nlog(m)) and in the specific case we're inâwhere the original things are all only one character (but not in the case of multiple calls to replace in general)âO(n), but this doesn't matter since m is 5 but n is unbounded. 

If m is held constant, then, the complexity of both solutions really goes to O(n). It is not clear to me that it is going to be a worthy task to try to turn five simple passes into one complex one, the actual time of which I cannot guess at the current moment. If there was something about it that could make it scale better, I would have thought it was much more worthwhile task.

Doing everything on one pass rather than consecutive passes also demands questions be answered about what to do about conflicting rules and how they are applied. The resolution to these questions is clear with a chain of replace.
",Is str.replace(..).replace(..) ad nauseam a standard idiom in Python?,"For instance, say I wanted a function to escape a string for use in HTML (as in Django's escape filter):

    def escape(string):
        """"""
        Returns the given string with ampersands, quotes and angle 
        brackets encoded.
        """"""
        return string.replace('&', '&amp;').replace('', '&gt;').replace(""'"", '&#39;').replace('""', '&quot;')


This works, but it gets ugly quickly and appears to have poor algorithmic performance (in this example, the string is repeatedly traversed 5 times). What would be better is something like this:

    def escape(string):
        """"""
        Returns the given string with ampersands, quotes and angle 
        brackets encoded.
        """"""
        # Note that ampersands must be escaped first; the rest can be escaped in 
        # any order.
        return replace_multi(string.replace('&', '&amp;'),
                             {'': '&gt;', 
                              ""'"": '&#39;', '""': '&quot;'})


Does such a function exist, or is the standard Python idiom to use what I wrote before?
"
"As you explicitly state that you want obscurity not security, we'll avoid reprimanding you for the weakness of what you suggest :)

So, using PyCrypto:

from Crypto.Cipher import AES
import base64

msg_text = 'test some plain text here'.rjust(32)
secret_key = '1234567890123456' # create new & store somewhere safe

cipher = AES.new(secret_key,AES.MODE_ECB) # never use ECB in strong systems obviously
encoded = base64.b64encode(cipher.encrypt(msg_text))
# ...
decoded = cipher.decrypt(base64.b64decode(encoded))
print decoded.strip()


If someone gets a hold of your database and your code base, they will be able to decode the encrypted data. Keep your secret_key safe!
",Simple way to encode a string according to a password?,"Does Python have a built-in, simple way of encoding/decoding strings using a password?

Something like this:

>>> encode('John Doe', password = 'mypass')
'sjkl28cn2sx0'
>>> decode('sjkl28cn2sx0', password = 'mypass')
'John Doe'


So the string ""John Doe"" gets encrypted as 'sjkl28cn2sx0'. To get the original string, I would ""unlock"" that string with the key 'mypass', which is a password in my source code. I'd like this to be the way I can encrypt/decrypt a Word document with a password.

I would like to use these encrypted strings as URL parameters. My goal is obfuscation, not strong security; nothing mission critical is being encoded. I realize I could use a database table to store keys and values, but am trying to be minimalist.
"
"
  forgetting to check a type


This doesn't make much sense.  You so rarely need to ""check"" a type.  You simply run unit tests and if you've provided the wrong type object, things fail.  You never need to ""check"" much, in my experience.


  trying to call an attribute and
  getting the NoneType (or any other)
  has no attribute x error.


Unexpected None is a plain-old bug.  80% of the time, I omitted the return.  Unit tests always reveal these.

Of those that remain, 80% of the time, they're plain old bugs due to an ""early exit"" which returns None because someone wrote an incomplete return statement.  These if foo: return structures are easy to detect with unit tests.  In some cases, they should have been if foo: return somethingMeaningful, and in still other cases, they should have been if foo: raise Exception(""Foo"").  

The rest are dumb mistakes misreading the API's.  Generally, mutator functions don't return anything.  Sometimes I forget.  Unit tests find these quickly, since basically, nothing works right.

That covers the ""unexpected None"" cases pretty solidly.  Easy to unit test for.  Most of the mistakes involve fairly trivial-to-write tests for some pretty obvious species of mistakes: wrong return; failure to raise an exception.

Other ""has no attribute X"" errors are really wild mistakes where a totally wrong type was used.  That's either really wrong assignment statements or really wrong function (or method) calls.  They always fail elaborately during unit testing, requiring very little effort to fix.


  A lot of them are pretty harmless but if not handled correctly they can bring down your entire app/process/etc.


Um... Harmless?  If it's a bug, I pray that it brings down my entire app as quickly as possible so I can find it.  A  bug that doesn't crash my app is the most horrible situation imaginable.  ""Harmless"" isn't a word I'd use for a bug that fails to crash my app.
",What is your strategy to avoid dynamic typing errors in Python (NoneType has no attribute x)?,"I'm not sure if I like Python's dynamic-ness.  It often results in me forgetting to check a type, trying to call an attribute and getting the NoneType (or any other) has no attribute x error. A lot of them are pretty harmless but if not handled correctly they can bring down your entire app/process/etc. 

Over time I got better predicting where these could pop up and adding explicit type checking, but because I'm only human I miss one occasionally and then some end-user finds it.

So I'm interested in your strategy to avoid these. Do you use type-checking decorators? Maybe special object wrappers? 

Please share...
"
"Sure, it's the easy way to make your code look good:

char *someGlobalString = ""very long ""
                         ""so broken ""
                         ""onto multiple ""
                         ""lines"";


The best reason, though, is for weird printf formats, like type forcing:

uint64_t num = 5;
printf(""Here is a number:  %""PRIX64"", what do you think of that?"", num);


There are a bunch of those defined, and they can come in handy if you have type size requirements.  Check them all out at this link.  A few examples:

PRIo8 PRIoLEAST16 PRIoFAST32 PRIoMAX PRIoPTR

",Why allow concatenation of string literals?,"I was recently bitten by a subtle bug.

char ** int2str = {
   ""zero"", // 0
   ""one"",  // 1
   ""two""   // 2
   ""three"",// 3
   nullptr };

assert( int2str[1] == std::string(""one"") ); // passes
assert( int2str[2] == std::string(""two"") ); // fails


If you have godlike code review powers you'll notice I forgot the , after ""two"".

After the considerable effort to find that bug I've got to ask why would anyone ever want this behavior?

I can see how this might be useful for macro magic, but then why is this a ""feature"" in a modern language like python?

Have you ever used string literal concatenation in production code?
"
"Your system already has Python on it. Use the text editor or IDE of your choice; I like vim. 

I can't tell you what third-party modules you need without knowing what kind of development you will be doing. Use apt as much as you can to get the libraries.



To speak to your edit:

This isn't minimalistic, like handing a .NET newbie notepad and a compiler: a decent text editor and the stdlib are all you really need to start out. You will likely need third-party libraries to develop whatever kind of applications you are writing, but I cannot think of any third-party modules all Python programmers will really need or want.

Unlke the .NET/Windows programming world, there is no one set of dev tools that stands above all others. Different people use different editors a whole lot. In Python, a module namespace is fully within a single file and project organization is based on the filesystem, so people do not lean on their IDEs as hard. Different projects use different version control software, which has been booming with new faces recently. Most of these are better than TFS and all are 1000 times better than SourceSafe.

When I want an interactive session, I use the vanilla Python interpreter. Various more fancy interpreters exist: bpython, ipython, IDLE. bpython is the least fancy of these and is supposed to be good about not doing weird stuff. ipython and IDLE can lead to strange bugs where code that works in them doens't work in normal Python and vice-versa; I've seen this first hand with IDLE.

For some of the tools you asked about and some others


In .NET you would use NUnit. In Python, use the stdlib unittest module. There are various third-party extensions and test runners, but unittest should suit you okay. 

If you really want to look into something beyond this, get unittest2, a backport of the 2.7 version of unittest. It has incorporated all the best things from the third-party tools and is really neat.

In .NET you would use SQL Server. In Python, you may use PostgreSQL, MySQL, sqlite, or some other database. Python specifies a unified API for databases and porting from one to another typically goes pretty smoothly. sqlite is in the stdlib.

There are various Object Relational Models to make using databases more abstracted. SQLAlchemy is the most notable of these.

If you are doing network programming, get Twisted.
If you are doing numerical math, get numpy and scipy.
If you are doing web development, choose a framework. There are about 200000: Pylons, zope, Django, CherryPy, werkzeug...I won't bother starting an argument by recommending one. Most of these will happily work with various servers with a quick setting.
If you want to do GUI development, there are quite a few Python bindings. The stdlib ships with Tk bindings I would not bother with. There are wx bindings (wxpython), GTK+ bindings (pygtk), and two sets of Qt bindings. If you want to do native Windows GUI development, get IronPython and do it in .NET. There are win32 bindings, but they'll make you want to pull your hair out trying to use them directly.

",How do I set up a Python development environment on Linux?,"I'm a .NET developer who knows very little about Python, but want to give it a test drive for a small project I'm working on.

What tools and packages should I install on my machine? I'm looking for a common, somewhat comprehensive, development environment.

I'll likely run Ubuntu 9.10, but I'm flexible.  If Windows is a better option, that's fine too.

Edit: To clarify, I'm not looking for the bare minimum to get a Python program to run.  I wouldn't expect a newbie .NET dev to use notepad and a compiler. I'd recommend Visual Studio, NUnit, SQL Server, etc.
"
"Performance comparison

Note: time in the table doesn't include the time it takes to load files.

| approach       | american-english, |      big.txt, | time w.r.t. defaultdict |
|                |     time, seconds | time, seconds |                         |
|----------------+-------------------+---------------+-------------------------|
| Counter        |             0.451 |         3.367 |                     3.6 |
| setdefault     |             0.348 |         2.320 |                     2.5 |
| list           |             0.277 |         1.822 |                       2 |
| try/except     |             0.158 |         1.068 |                     1.2 |
| defaultdict    |             0.141 |         0.925 |                       1 |
| numpy          |             0.012 |         0.076 |                   0.082 |
| S.Mark's ext.  |             0.003 |         0.019 |                   0.021 |
| ext. in Cython |             0.001 |         0.008 |                  0.0086 |
#+TBLFM: $4=$3/@7$3;%.2g


The files used: '/usr/share/dict/american-english' and 'big.txt'.

The script that compares 'Counter', 'setdefault', 'list', 'try/except', 'defaultdict', 'numpy', 'cython' -based, and @S.Mark's solutions is at http://gist.github.com/347000

The fastest solution is Python extension written in Cython:

import cython

@cython.locals(
    chars=unicode,
    i=cython.Py_ssize_t,
    L=cython.Py_ssize_t[0x10000])
def countchars_cython(chars):
    for i in range(0x10000): # unicode code points > 0xffff are not supported
        L[i] = 0

    for c in chars:
        L[c] += 1

    return {unichr(i): L[i] for i in range(0x10000) if L[i]}




Previous comparison:

* python (dict) : 0.5  seconds
* python (list) : 0.5  (ascii) (0.2 if read whole file in memory)
* perl          : 0.5
* python (numpy): 0.07 
* c++           : 0.05
* c             : 0.008 (ascii)


Input data:

$ tail /usr/share/dict/american-english
Ã©clat's
Ã©lan
Ã©lan's
Ã©migrÃ©
Ã©migrÃ©s
Ã©pÃ©e
Ã©pÃ©es
Ã©tude
Ã©tude's
Ã©tudes

$ du -h /usr/share/dict/american-english
912K    /usr/share/dict/american-english


python (Counter): 0.5 seconds

#!/usr/bin/env python3.1
import collections, fileinput, textwrap

chars = (ch for word in fileinput.input() for ch in word.rstrip())
# faster (0.4s) but less flexible: chars = open(filename).read()
print(textwrap.fill(str(collections.Counter(chars)), width=79))


Run it:

$ time -p python3.1 count_char.py /usr/share/dict/american-english


Counter({'e': 87823, 's': 86620, 'i': 66548, 'a': 62778, 'n': 56696, 'r':
56286, 't': 51588, 'o': 48425, 'l': 39914, 'c': 30020, 'd': 28068, 'u': 25810,
""'"": 24511, 'g': 22262, 'p': 20917, 'm': 20747, 'h': 18453, 'b': 14137, 'y':
12367, 'f': 10049, 'k': 7800, 'v': 7573, 'w': 6924, 'z': 3088, 'x': 2082, 'M':
1686, 'C': 1549, 'S': 1515, 'q': 1447, 'B': 1387, 'j': 1376, 'A': 1345, 'P':
974, 'L': 912, 'H': 860, 'T': 858, 'G': 811, 'D': 809, 'R': 749, 'K': 656, 'E':
618, 'J': 539, 'N': 531, 'W': 507, 'F': 502, 'O': 354, 'I': 344, 'V': 330, 'Z':
150, 'Y': 140, 'Ã©': 128, 'U': 117, 'Q': 63, 'X': 42, 'Ã¨': 29, 'Ã¶': 12, 'Ã¼': 12,
'Ã³': 10, 'Ã¡': 10, 'Ã¤': 7, 'Ãª': 6, 'Ã¢': 6, 'Ã±': 6, 'Ã§': 4, 'Ã¥': 3, 'Ã»': 3, 'Ã­':
2, 'Ã´': 2, 'Ã': 1})
real 0.44
user 0.43
sys 0.01

perl: 0.5 seconds

time -p perl -MData::Dumper -F'' -lanwe'$c{$_}++ for (@F);
END{ $Data::Dumper::Terse = 1; $Data::Dumper::Indent = 0; print Dumper(\%c) }
' /usr/share/dict/american-english


Output:

{'S' => 1515,'K' => 656,'' => 29,'d' => 28068,'Y' => 140,'E' => 618,'y' => 12367,'g' => 22262,'e' => 87823,'' => 2,'J' => 539,'' => 241,'' => 3,'' => 6,'' => 4,'' => 128,'D' => 809,'q' => 1447,'b' => 14137,'z' => 3088,'w' => 6924,'Q' => 63,'' => 10,'M' => 1686,'C' => 1549,'' => 10,'L' => 912,'X' => 42,'P' => 974,'' => 12,'\'' => 24511,'' => 6,'a' => 62778,'T' => 858,'N' => 531,'j' => 1376,'Z' => 150,'u' => 25810,'k' => 7800,'t' => 51588,'' => 6,'W' => 507,'v' => 7573,'s' => 86620,'B' => 1387,'H' => 860,'c' => 30020,'' => 12,'I' => 344,'' => 3,'G' => 811,'U' => 117,'F' => 502,'' => 2,'r' => 56286,'x' => 2082,'V' => 330,'h' => 18453,'f' => 10049,'' => 1,'i' => 66548,'A' => 1345,'O' => 354,'n' => 56696,'m' => 20747,'l' => 39914,'' => 7,'p' => 20917,'R' => 749,'o' => 48425}
real 0.51
user 0.49
sys 0.02

python (numpy): 0.07 seconds

Based on Ants Aasma's answer (modified to support unicode):

#!/usr/bin/env python
import codecs, itertools, operator, sys
import numpy

filename = sys.argv[1] if len(sys.argv)>1 else '/usr/share/dict/american-english'

# ucs2 or ucs4 python?
dtype = {2: numpy.uint16, 4: numpy.uint32}[len(buffer(u""u""))]

# count ordinals
text = codecs.open(filename, encoding='utf-8').read()
a = numpy.frombuffer(text, dtype=dtype)
counts = numpy.bincount(a)

# pretty print
counts = [(unichr(i), v) for i, v in enumerate(counts) if v]
counts.sort(key=operator.itemgetter(1))
print ' '.join('(""%s"" %d)' % c for c in counts  if c[0] not in ' \t\n')


Output:

(""Ã"" 1) (""Ã­"" 2) (""Ã´"" 2) (""Ã¥"" 3) (""Ã»"" 3) (""Ã§"" 4) (""Ã¢"" 6) (""Ãª"" 6) (""Ã±"" 6) (""Ã¤"" 7) (""Ã¡"" 10) (""Ã³"" 10) (""Ã¶"" 12) (""Ã¼"" 12) (""Ã¨"" 29) (""X"" 42) (""Q"" 63) (""U"" 117) (""Ã©"" 128) (""Y"" 140) (""Z"" 150) (""V"" 330) (""I"" 344) (""O"" 354) (""F"" 502) (""W"" 507) (""N"" 531) (""J"" 539) (""E"" 618) (""K"" 656) (""R"" 749) (""D"" 809) (""G"" 811) (""T"" 858) (""H"" 860) (""L"" 912) (""P"" 974) (""A"" 1345) (""j"" 1376) (""B"" 1387) (""q"" 1447) (""S"" 1515) (""C"" 1549) (""M"" 1686) (""x"" 2082) (""z"" 3088) (""w"" 6924) (""v"" 7573) (""k"" 7800) (""f"" 10049) (""y"" 12367) (""b"" 14137) (""h"" 18453) (""m"" 20747) (""p"" 20917) (""g"" 22262) (""'"" 24511) (""u"" 25810) (""d"" 28068) (""c"" 30020) (""l"" 39914) (""o"" 48425) (""t"" 51588) (""r"" 56286) (""n"" 56696) (""a"" 62778) (""i"" 66548) (""s"" 86620) (""e"" 87823)
real 0.07
user 0.06
sys 0.01


c++: 0.05 seconds

// $ g++ *.cc -lboost_program_options 
// $ ./a.out /usr/share/dict/american-english    
#include 
#include 
#include  // exit

#include 
#include 
#include 

int main(int argc, char* argv[]) {
  using namespace std;

  // open input file
  if (argc != 2) {
    cerr \n"";
    exit(2);
  }
  wifstream f(argv[argc-1]); 

  // assume the file has utf-8 encoding
  locale utf8_locale(locale(""""), 
      new boost::program_options::detail::utf8_codecvt_facet);
  f.imbue(utf8_locale); 

  // count characters frequencies
  typedef std::tr1::unordered_map hashtable_t;  
  hashtable_t counts;
  for (wchar_t ch; f >> ch; )
    counts[ch]++;

  // print result
  wofstream of(""output.utf8"");
  of.imbue(utf8_locale);
  BOOST_FOREACH(hashtable_t::value_type i, counts) 
    of << ""("" << i.first << "" "" << i.second << "") "";
  of << endl;
}


Result:

$ cat output.utf8 


(Ã­ 2) (O 354) (P 974) (Q 63) (R 749) (S 1,515) (Ã± 6) (T 858) (U 117) (Ã³ 10) (Ã´ 2) (V 330) (W 507) (X 42) (Ã¶ 12) (Y 140) (Z 150) (Ã» 3) (Ã¼ 12) (a 62,778) (b 14,137) (c 30,020) (d 28,068) (e 87,823) (f 10,049) (g 22,262) (h 18,453) (i 66,548) (j 1,376) (k 7,800) (l 39,914) (m 20,747) (n 56,696) (o 48,425) (p 20,917) (q 1,447) (r 56,286) (s 86,620) (t 51,588) (u 25,810) (Ã 1) (' 24,511) (v 7,573) (w 6,924) (x 2,082) (y 12,367) (z 3,088) (A 1,345) (B 1,387) (C 1,549) (Ã¡ 10) (Ã¢ 6) (D 809) (E 618) (F 502) (Ã¤ 7) (Ã¥ 3) (G 811) (H 860) (Ã§ 4) (I 344) (J 539) (Ã¨ 29) (K 656) (Ã© 128) (Ãª 6) (L 912) (M 1,686) (N 531)

c (ascii): 0.0079 seconds

// $ gcc -O3 cc_ascii.c -o cc_ascii && time -p ./cc_ascii < input.txt
#include 

enum { N = 256 };
size_t counts[N];

int main(void) {
  // count characters
  int ch = -1;
  while((ch = getchar()) != EOF)
    ++counts[ch];

  // print result
  size_t i = 0;
  for (; i < N; ++i) 
    if (counts[i])
      printf(""('%c' %zu) "", (int)i, counts[i]);
  return 0;
}

",Python - Is a dictionary slow to find frequency of each character?,"I am trying to find a frequency of each symbol in any given text using an algorithm of O(n) complexity. My algorithm looks like:

s = len(text) 
P = 1.0/s 
freqs = {} 
for char in text: 
    try: 
       freqs[char]+=P 
    except: 
       freqs[char]=P 


but I doubt that this dictionary-method is fast enough, because it depends on the underlying implementation of the dictionary methods. Is this the fastest method?

UPDATE: there is no increase in speed if collections and integers are used. It is because the algorithm is already of O(n) complexity, so no essential speedup is possible.

For example, results for 1MB text:

without collections:
real    0m0.695s

with collections:
real    0m0.625s

"
"Hostip.info is an open-source project with the goal to build/maintain a database mapping IP addresses to cities. Their about page explains the data sources relied on to populate this database.

Using HostIP, there are two ways to get location data from an IP address:

They also have a well-designed and easy-to-use RESTFUL API: just pass in your ip address after the i*p=* in the GET request string):

import urllib

response = urllib.urlopen('http://api.hostip.info/get_html.php?ip=12.215.42.19&position=true').read()

print(response)


Second, the Project Website also makes its complete database available for download.
",What python libraries can tell me approximate location and time zone given an IP address?,"Looking to implement better geo-location with Python.
"
"Most functional languages which evaluate lazily can simulate the processing of infinite series.  Of course, on a finite computer it is not possible to process infinite series, as I am sure you are aware.  Off the top of my head, I guess Mathematica can do most of what you might want, I suspect that Maple can too, maybe Sage and other computer-algebra systems and I'd be surprised if you can't find a Haskell implementation that suits you.

EDIT to clarify for OP: I do not propose generating infinite loops.  Lazy evaluation allows you to write programs (or functions) which simulate infinite series, programs which themselves are finite in time and space.  With such languages you can determine many of the properties, such as convergence, of the simulated infinite series with considerable accuracy and some degree of certainty.  Try Mathematica or, if you don't have access to it, try Wolfram Alpha to see what one system can do for you.
",Which programming language or a library can process Infinite Series?,"Which programming language or a library is able to process infinite series (like geometric or harmonic)? It perhaps must have a database of some well-known series and automatically give proper values in case of convergence, and maybe generate an exception in case of divergence.

For example, in Python it could look like:

sum  = 0
sign = -1.0
for i in range(1,Infinity,2):
     sign = -sign
     sum += sign / i


then, sum must be math.pi/4 without doing any computations in the loop (because it's a well-known sum).
"
"IMO the best way todo this is to use the http://furius.ca/snakefood/ package.  The author has done all of the required work to get not only directly imported modules but it uses the AST to parse the code for runtime dependencies that a more static analysis would miss.

Worked up a command example to demonstrate:

sfood ./example.py | sfood-cluster > example.deps

That will generate a basic dependency file of each unique module.  For even more detail use:

sfood -r -i ./example.py | sfood-cluster > example.deps

To walk a tree and find all imports, you can also do this in code:
Please NOTE - The AST chunks of this routine were lifted from the snakefood source which has this copyright:  Copyright (C) 2001-2007 Martin Blais. All Rights Reserved.

 import os
 import compiler
 from compiler.ast import Discard, Const
 from compiler.visitor import ASTVisitor

 def pyfiles(startPath):
     r = []
     d = os.path.abspath(startPath)
     if os.path.exists(d) and os.path.isdir(d):
         for root, dirs, files in os.walk(d):
             for f in files:
                 n, ext = os.path.splitext(f)
                 if ext == '.py':
                     r.append([d, f])
     return r

 class ImportVisitor(object):
     def __init__(self):
         self.modules = []
         self.recent = []
     def visitImport(self, node):
         self.accept_imports()
         self.recent.extend((x[0], None, x[1] or x[0], node.lineno, 0)
                            for x in node.names)
     def visitFrom(self, node):
         self.accept_imports()
         modname = node.modname
         if modname == '__future__':
             return # Ignore these.
         for name, as_ in node.names:
             if name == '*':
                 # We really don't know...
                 mod = (modname, None, None, node.lineno, node.level)
             else:
                 mod = (modname, name, as_ or name, node.lineno, node.level)
             self.recent.append(mod)
     def default(self, node):
         pragma = None
         if self.recent:
             if isinstance(node, Discard):
                 children = node.getChildren()
                 if len(children) == 1 and isinstance(children[0], Const):
                     const_node = children[0]
                     pragma = const_node.value
         self.accept_imports(pragma)
     def accept_imports(self, pragma=None):
         self.modules.extend((m, r, l, n, lvl, pragma)
                             for (m, r, l, n, lvl) in self.recent)
         self.recent = []
     def finalize(self):
         self.accept_imports()
         return self.modules

 class ImportWalker(ASTVisitor):
     def __init__(self, visitor):
         ASTVisitor.__init__(self)
         self._visitor = visitor
     def default(self, node, *args):
         self._visitor.default(node)
         ASTVisitor.default(self, node, *args) 

 def parse_python_source(fn):
     contents = open(fn, 'rU').read()
     ast = compiler.parse(contents)
     vis = ImportVisitor() 

     compiler.walk(ast, vis, ImportWalker(vis))
     return vis.finalize()

 for d, f in pyfiles('/Users/bear/temp/foobar'):
     print d, f
     print parse_python_source(os.path.join(d, f)) 

",Return a list of imported Python modules used in a script?,"I am writing a program that categorizes a list of Python files by which modules they import. As such I need to scan the collection of .py files ad return a list of which modules they import. As an example, if one of the files I import has the following lines:

import os
import sys, gtk


I would like it to return:

[""os"", ""sys"", ""gtk""]


I played with modulefinder and wrote:

from modulefinder import ModuleFinder

finder = ModuleFinder()
finder.run_script('testscript.py')

print 'Loaded modules:'
for name, mod in finder.modules.iteritems():
    print '%s ' % name,


but this returns more than just the modules used in the script. As an example in a script which merely has:

import os
print os.getenv('USERNAME')


The modules returned from the ModuleFinder script return:

tokenize  heapq  __future__  copy_reg  sre_compile  _collections  cStringIO  _sre  functools  random  cPickle  __builtin__  subprocess  cmd  gc  __main__  operator  array  select  _heapq  _threading_local  abc  _bisect  posixpath  _random  os2emxpath  tempfile  errno  pprint  binascii  token  sre_constants  re  _abcoll  collections  ntpath  threading  opcode  _struct  _warnings  math  shlex  fcntl  genericpath  stat  string  warnings  UserDict  inspect  repr  struct  sys  pwd  imp  getopt  readline  copy  bdb  types  strop  _functools  keyword  thread  StringIO  bisect  pickle  signal  traceback  difflib  marshal  linecache  itertools  dummy_thread  posix  doctest  unittest  time  sre_parse  os  pdb  dis


...whereas I just want it to return 'os', as that was the module used in the script.

Can anyone help me achieve this?

UPDATE: I just want to clarify that I would like to do this without running the Python file being analyzed, and just scanning the code.
"
"If you are using Python 2.7 or 3 and you want number of occurrences for each element:

>>> from collections import Counter
>>> z = ['blue', 'red', 'blue', 'yellow', 'blue', 'red']
>>> Counter(z)
Counter({'blue': 3, 'red': 2, 'yellow': 1})

",How can I count the occurrences of a list item in Python?,"Given an item, how can I count its occurrences in a list in Python?
"
"datetime.date has a isocalendar() method, which returns a tuple containing the calendar week:

>>> datetime.date(2010, 6, 16).isocalendar()[1]
24


datetime.date.isocalendar() is an instance-method returning a tuple containing year, weeknumber and weekday in respective order for the given date instance.
",How to get week number in Python?,"How to find out what week number is this year on June 16th (wk24) with Python?  
"
"I'll tell you how I've improved my productivity with Python on Windows. I just try to write everything in Python - every application I need, unless I know it won't scale and I'll need more efficient tools (in which case I personally use C++, but you could also use C#/Delphi). 

It turns out that for most (> 95%) of the tools and utilities are need, Python (coupled with PyQt for the GUI) is good enough, and it's a much more productive language for me than C++. The key is stop thinking of Python as a ""scripting language"". It is no less a programming language than C++/Java/C#/Delphi/what say you. It has it strengths, and it has its limitations. As long as you're aware of them and know how to pick the appropriate tool for the job, you'll do just fine.

You don't need any special IDE. I use Scite for all my Python coding (on Windows and Linux, by the way), and it works great.
","How do you use scripting language (PHP, Python, etc) to improve your productivity?","I'm a Delphi developer on the Windows platform, recently read the PHP tutorial at W3CSchools, it looks interesting. 

We all know scripting languages are very good at web site development, but I also want to utilize it to improve my productivity or get some tedious tasks done quickly, maybe some quick-and-dirty string/file processing? 

What do you usually do with scripting languages apart from software development? 
And we need a responsive, decent IDE/editor in order to gain productivity when writing scripts for this purpose? 
"
"You can convert the characters to integers and xor those instead:

l = [ord(a) ^ ord(b) for a,b in zip(s1,s2)]


Here's an updated function in case you need a string as a result of the XOR:

def sxor(s1,s2):    
    # convert strings to a list of character pair tuples
    # go through each tuple, converting them to ASCII code (ord)
    # perform exclusive or on the ASCII code
    # then convert the result back to ASCII (chr)
    # merge the resulting array of characters as a string
    return ''.join(chr(ord(a) ^ ord(b)) for a,b in zip(s1,s2))


See it working online: ideone
",how to do bitwise exclusive or of two strings in python?,"I would like to perform a bitwise exclusive or of two strings in python, but xor of strings are not allowed in python. How can I do it ?
"
"You have various possibilities:


You can slice it: 

new_list = old_list[:]


Alex Martelli's opinion (at least back in 2007) about this is, that it is a weird syntax and it does not make sense to use it ever. ;) (In his opinion, the next one is more readable).
You can use the built in list() function:

new_list = list(old_list)

You can use generic copy.copy():

import copy
new_list = copy.copy(old_list)


This is a little slower than list() because it has to find out the datatype of old_list first.
If the list contains objects and you want to copy them as well, use generic copy.deepcopy():

import copy
new_list = copy.deepcopy(old_list)


Obviously the slowest and most memory-needing method, but sometimes unavoidable.


Example:

import copy

class Foo(object):
    def __init__(self, val):
         self.val = val

    def __repr__(self):
        return str(self.val)

foo = Foo(1)

a = ['foo', foo]
b = a[:]
c = list(a)
d = copy.copy(a)
e = copy.deepcopy(a)

# edit orignal list and instance 
a.append('baz')
foo.val = 5

print('original: %r\n slice: %r\n list(): %r\n copy: %r\n deepcopy: %r'
      % (a, b, c, d, e))


Result:

original: ['foo', 5, 'baz']
slice: ['foo', 5]
list(): ['foo', 5]
copy: ['foo', 5]
deepcopy: ['foo', 1]

",How to clone or copy a list?,"What are the options to clone or copy a list in Python?

Using new_list = my_list then modifies new_list every time my_list changes.
Why is this?
"
"As an intern you'll want to use the tools your mentor is most comfortable with. If you get stuck you'll be able to ask for advice quickly. 

Learning your way around either vi, vim, or emacs to start with will help. The basic concepts used in one will transfer to the other. You'll need to be able to open and read files, search through files, edit and save files, and learn how to apply any python formatting helpers correctly.

You should also familiarize yourself with version control if you haven't already. Again any one will do, you need to focus on concepts and etiquette rather than the specific tool.

The goal of the internship (and really your entire time at university) should be used to learn concepts rather than specific tools. If you learn the concepts you'll be well placed to apply those concepts using any tool. You will also ""learn how to learn"" a new tool, which is really valuable.
",How do I prepare myself for a summer of working on Python using Linux environment?,"I have used just Windows for programming so far. Now, I have an internship starting in two weeks and I will be using just Linux environment with Python programming language. I've installed Ubuntu on my system but have no exposure to shell scripting.

I need some advice on how I can quickly learn to use the Linux terminal quickly. Any books or web resources that you can suggest?

Also, is there a particular IDE that is generally preferred for Python programming on Linux, or is Vim preferred? How can I best prepare myself for the internship ahead?

Thanks for taking the time.
"
"Twistedless solution:

from urlparse import urlparse
from threading import Thread
import httplib, sys
from Queue import Queue

concurrent = 200

def doWork():
    while True:
        url = q.get()
        status, url = getStatus(url)
        doSomethingWithResult(status, url)
        q.task_done()

def getStatus(ourl):
    try:
        url = urlparse(ourl)
        conn = httplib.HTTPConnection(url.netloc)   
        conn.request(""HEAD"", url.path)
        res = conn.getresponse()
        return res.status, ourl
    except:
        return ""error"", ourl

def doSomethingWithResult(status, url):
    print status, url

q = Queue(concurrent * 2)
for i in range(concurrent):
    t = Thread(target=doWork)
    t.daemon = True
    t.start()
try:
    for url in open('urllist.txt'):
        q.put(url.strip())
    q.join()
except KeyboardInterrupt:
    sys.exit(1)


This one is slighty faster than the twisted solution and uses less CPU.
","What is the fastest way to send 100,000 HTTP requests in Python?","I am opening a file which has 100,000 url's.  I need to send an http request to each url and print the status code. I am using Python 2.6, and so far looked at the many confusing ways Python implements threading/concurrency.  I have even looked at the python concurrence library, but cannot figure out how to write this program correctly.  Has anyone come across a similar problem?  I guess generally I need to know how to perform thousands of tasks in Python as fast as possible - I suppose that means 'concurrently'.

Thank you,
Igor
"
"Let's see:


If you want to know how something works, you can just try it.  There is no need to write up  a file.  I almost always scratch write my programs in the interpreter before coding them.  It's not just for things that you don't know how they work in the programming language.  I never remember what the correct arguments to range are to create, for example, [-2, -1, 0, 1].  I don't need to.  I just have to fire up the interpreter and try stuff until I figure out it is range(-2, 2) (did that just now, actually).
You can use it as a calculator. 
Python is a very introspective programming language.  If you want to know anything about an object, you can just do dir(object).  If you use IPython, you can even do object. and it will tab-complete the methods and attributes of that object.  That's way faster than looking stuff up in documentation or even in code.
help(anything) for documentation.  It's way faster than any web interface.  
Again, you have to use IPython (highly recommended), but you can time stuff.  %timeit func1() and %timeit func2() is a common idiom to determine what is faster.  
How often have you wanted to write a program to use once, and then never again.  The fastest way to do this is to just do it in the Python interpreter.  Sure, you have to be careful writing loops or functions (they must have the correct syntax the first time), but most stuff is just line by line, and you can play around with it.
Debugging.  You don't need to put selective print statements in code to see what variables are when you write it in the interpreter.  You just have to type >>> a, and it will show what a is.  Nice again to see if you constructed something correctly.  The building Python debugger pdb also uses the intrepeter functionality, so you can not only see what a variable is when debugging, but you can also manipulate or even change it without halting debugging.  


When people say that Python is faster to develop in, I guarantee that this is a big part of what they are talking about.

Commenters: anything I am forgetting?
",Why use Python interactive mode?,"When I first started reading about Python, all of the tutorials have you use Python's Interactive Mode. It is difficult to save, write long programs, or edit your existing lines (for me at least). It seems like a far more difficult way of writing Python code than opening up a code.py file and running the interpreter on that file.

python code.py


I am coming from a Java background, so I have ingrained expectations of writing and compiling files for programs. I also know that a feature would not be so prominent in Python documentation if it were not somehow useful. So what am I missing?
"
"This might be the correct snippet you were looking for:

import threading

def set_interval(func, sec):
    def func_wrapper():
        set_interval(func, sec)
        func()
    t = threading.Timer(sec, func_wrapper)
    t.start()
    return t

",Python Equivalent of setInterval()?,"Does Python have a function similar to JavaScript's setInterval()?

Thanks
"
"Python doesn't have a builtin frozendict type. It turns out this wouldn't be useful too often (though it would still probably be useful more often than frozenset is).

The most common reason to want such a type is when memoizing function calls for functions with unknown arguments. The most common solution to store a hashable equivalent of a dict (where the values are hashable) is something like tuple(sorted(kwargs.iteritems())). 

This depends on the sorting not being a bit insane. Python cannot positively promise sorting will result in something reasonable here. (But it can't promise much else, so don't sweat it too much.)



You could easily enough make some sort of wrapper that works much like a dict. It might look something like

import collections

class FrozenDict(collections.Mapping):
    """"""Don't forget the docstrings!!""""""

    def __init__(self, *args, **kwargs):
        self._d = dict(*args, **kwargs)
        self._hash = None

    def __iter__(self):
        return iter(self._d)

    def __len__(self):
        return len(self._d)

    def __getitem__(self, key):
        return self._d[key]

    def __hash__(self):
        # It would have been simpler and maybe more obvious to 
        # use hash(tuple(sorted(self._d.iteritems()))) from this discussion
        # so far, but this solution is O(n). I don't know what kind of 
        # n we are going to run into, but sometimes it's hard to resist the 
        # urge to optimize when it will gain improved algorithmic performance.
        if self._hash is None:
            self._hash = 0
            for pair in self.iteritems():
                self._hash ^= hash(pair)
        return self._hash


It should work great:

>>> x = FrozenDict(a=1, b=2)
>>> y = FrozenDict(a=1, b=2)
>>> x is y
False
>>> x == y
True
>>> x == {'a': 1, 'b': 2}
True
>>> d = {x: 'foo'}
>>> d[y]
'foo'

","What would a ""frozen dict"" be?","
A frozen set is a frozenset.  
A frozen list could be a tuple.  
What would a frozen dict be? An immutable, hashable dict.  


I guess it could be something like collections.namedtuple, but that is more like a frozen-keys dict (a half-frozen dict). Isn't it?

A ""frozendict"" should be a frozen dictionary, it should have keys, values, get, etc., and support in, for, etc.
"
"There's no performance difference, as they compile to the same bytecode:

Python 2.6.2 (r262:71600, Apr 15 2009, 07:20:39)
>>> import dis
>>> def f(x):
...    return x is not None
...
>>> dis.dis(f)
  2           0 LOAD_FAST                0 (x)
              3 LOAD_CONST               0 (None)
              6 COMPARE_OP               9 (is not)
              9 RETURN_VALUE
>>> def g(x):
...   return not x is None
...
>>> dis.dis(g)
  2           0 LOAD_FAST                0 (x)
              3 LOAD_CONST               0 (None)
              6 COMPARE_OP               9 (is not)
              9 RETURN_VALUE


Stylistically, I try to avoid not x is y.  Although the compiler will always treat it as not (x is y), a human reader might misunderstand the construct as (not x) is y.  If I write x is not y then there is no ambiguity.
",Python `if x is not None` or `if not x is None`?,"I've always thought of the if not x is None version to be more clear, but Google's style guide implies (based on this excerpt) that they use if x is not None. Is there any minor performance difference (I'm assuming not), and is there any case where one really doesn't fit (making the other a clear winner for my convention)?*

*I'm referring to any singleton, rather than just None.


  ...to compare singletons like
  None. Use is  or is not.

"
"For the case of Python, source files are compiled before being executed (the .pyc files), and the comments are stripped in the process. So comments could slow down the compilation time if you have gazillions of them, but they won't impact the execution time.
",Do comments slow down an interpreted language?,"I am asking this because I use Python, but it could apply to other interpreted languages as well (Ruby, PHP, JavaScript).

Am I slowing down the interpreter whenever I leave a comment in my code? According to my limited understanding of an interpreter, it reads program expressions in as strings and then converts those strings into code. It seems that every time it parses a comment, that is wasted time.

Is this the case? Is there some convention for comments in interpreted languages, or is the effect negligible?
"
"You can take a look at InterpolatedUnivariateSpline

Here an example using it: 

import matplotlib.pyplot as plt
import numpy as np
from scipy.interpolate import InterpolatedUnivariateSpline

# given values
xi = np.array([0.2, 0.5, 0.7, 0.9])
yi = np.array([0.3, -0.1, 0.2, 0.1])
# positions to inter/extrapolate
x = np.linspace(0, 1, 50)
# spline order: 1 linear, 2 quadratic, 3 cubic ... 
order = 1
# do inter/extrapolation
s = InterpolatedUnivariateSpline(xi, yi, k=order)
y = s(x)

# example showing the interpolation for linear, quadratic and cubic interpolation
plt.figure()
plt.plot(xi, yi)
for order in range(1, 4):
    s = InterpolatedUnivariateSpline(xi, yi, k=order)
    y = s(x)
    plt.plot(x, y)
plt.show()

",How to make scipy.interpolate give an extrapolated result beyond the input range?,"I'm trying to port a program which uses a hand-rolled interpolator (developed by a mathematician colleage) over to use the interpolators provided by scipy. I'd like to use or wrap the scipy interpolator so that it has as close as possible behavior to the old interpolator.

A key difference between the two functions is that in our original interpolator - if the input value is above or below the input range, our original interpolator will extrapolate the result. If you try this with the scipy interpolator it raises a ValueError. Consider this program as an example:

import numpy as np
from scipy import interpolate

x = np.arange(0,10)
y = np.exp(-x/3.0)
f = interpolate.interp1d(x, y)

print f(9)
print f(11) # Causes ValueError, because it's greater than max(x)


Is there a sensible way to make it so that instead of crashing, the final line will simply do a linear extrapolate, continuing the gradients defined by the first and last two points to infinity. 

Note, that in the real software I'm not actually using the exp function - that's here for illustration only!
"
"What about

functionList = [is_func1, is_func2, ..., is_func20]
for index, func in enumerate(functionList):
    if(func(param1, param2)):
        abc(index+1)
        some_list.append(index+1)
        break

",if else-if making code look ugly any cleaner solution?,"I have around 20 functions (is_func1, is_fucn2, is_func3...) returning boolean

I assume there is only one function which returns true and I want that!

I am doing:

if is_func1(param1, param2):
    # I pass 1 to following
    abc(1) # I pass 1
    some_list.append(1)
elif is_func2(param1, param2):
    # I pass 2 to following
    abc(2) # I pass 1
    some_list.append(2)
...
.
.
elif is_func20(param1, param2):
...


Please note: param1 and param2 are different for each, abc and some_list take parameters depending on the function.

The code looks big and there is repetition in calling abc and some_list, I can pull this login in a function! but is there any other cleaner solution?

I can think of putting functions in a data structure and loop to call them.
"
"Most of the answers seem massively over complicated. You don't need back references. You don't need to depend on whether or not re.findall gives overlapping matches.  Given that the input cannot be parsed with the csv module so a regular expression is pretty well the only way to go, all you need is to call re.split with a pattern that matches a field.

Note that it is much easier here to match a field than it is to match a separator:

import re
data = """"""part 1;""this is ; part 2;"";'this is ; part 3';part 4;this ""is ; part"" 5""""""
PATTERN = re.compile(r'''((?:[^;""']|""[^""]*""|'[^']*')+)''')
print PATTERN.split(data)[1::2]


and the output is:

['part 1', '""this is ; part 2;""', ""'this is ; part 3'"", 'part 4', 'this ""is ; part"" 5']


As Jean-Luc Nacif Coelho correctly points out this won't handle empty groups correctly. Depending on the situation that may or may not matter. If it does matter it may be possible to handle it by, for example, replacing ';;' with ';;' where  would have to be some string (without semicolons) that you know does not appear in the data before the split. Also you need to restore the data after:

>>> marker = "";!$%^&;""
>>> [r.replace(marker[1:-1],'') for r in PATTERN.split(""aaa;;aaa;'b;;b'"".replace(';;', marker))[1::2]]
['aaa', '', 'aaa', ""'b;;b'""]


However this is a kludge. Any better suggestions?
","How to split but ignore separators in quoted strings, in python?","I need to split a string like this, on semicolons. But I don't want to split on semicolons that are inside of a string (' or ""). I'm not parsing a file; just a simple string with no line breaks.

part 1;""this is ; part 2;"";'this is ; part 3';part 4;this ""is ; part"" 5

Result should be:


part 1
""this is ; part 2;""
'this is ; part 3'
part 4
this ""is ; part"" 5


I suppose this can be done with a regex but if not; I'm open to another approach.
"
"To remove an element's first occurrence in a list, simply use list.remove:

>>> a = ['a', 'b', 'c', 'd']
>>> a.remove('b')
>>> print a
['a', 'c', 'd']


Mind that it does not remove all occurrences of your element. Use a list comprehension for that.

>>> a = [1, 2, 3, 4, 2, 3, 4, 2, 7, 2]
>>> a = [x for x in a if x != 2]
>>> print a
[1, 3, 4, 3, 4, 7]

",Is there a simple way to delete a list element by value in python?,"a=[1,2,3,4]
b=a.index(6)
del a[b]
print a


The above shows the following error:

Traceback (most recent call last):
  File ""D:\zjm_code\a.py"", line 6, in 
    b=a.index(6)
ValueError: list.index(x): x not in list




So I have to do this:

a=[1,2,3,4]
try:
    b=a.index(6)
    del a[b]
except:
    pass
print a


But is there not a simpler way to do this?
"
"I was thinking something more along the lines of:

File f = File.open(""C:/Users/File.txt"");

for(String s : f){
   System.out.println(s);
}


Here is my source code for it:

import java.io.BufferedReader;
import java.io.BufferedWriter;
import java.io.FileReader;
import java.io.FileWriter;
import java.io.IOException;
import java.io.Writer;
import java.util.Iterator;

public abstract class File implements Iterable{
    public final static String READ = ""r"";
    public final static String WRITE = ""w"";

    public static File open(String filepath) throws IOException{
        return open(filepath, READ);
    }   

    public static File open(String filepath, String mode) throws IOException{
    if(mode == READ){
        return new ReadableFile(filepath);
    }else if(mode == WRITE){
        return new WritableFile(filepath);
    }
    throw new IllegalArgumentException(""Invalid File Write mode '"" + mode + ""'"");
    }

    //common methods
    public abstract void close() throws IOException;

    // writer specific
    public abstract void write(String s) throws IOException;

}

class WritableFile extends File{
    String filepath;
    Writer writer;

    public WritableFile(String filepath){
        this.filepath = filepath;
    }

    private Writer writer() throws IOException{
        if(this.writer == null){
            writer = new BufferedWriter(new FileWriter(this.filepath));
        }
        return writer;
    }

    public void write(String chars) throws IOException{
        writer().write(chars);
    }

    public void close() throws IOException{
        writer().close();
    }

    @Override
    public Iterator iterator() {        
        return null;
    }
}

class ReadableFile extends File implements Iterator{
    private BufferedReader reader;
    private String line;    
    private String read_ahead;

    public ReadableFile(String filepath) throws IOException{        
        this.reader = new BufferedReader(new FileReader(filepath)); 
        this.read_ahead = this.reader.readLine();
    }

    private Reader reader() throws IOException{
         if(reader == null){
               reader = new BufferedReader(new FileReader(filepath));   
         }
         return reader;
    }

    @Override
    public Iterator iterator() {
        return this;
    }

    @Override
    public void close() throws IOException {
        reader().close();
    }

    @Override
    public void write(String s) throws IOException {
        throw new IOException(""Cannot write to a read-only file."");
    }

    @Override
    public boolean hasNext() {      
        return this.read_ahead != null;
    }

    @Override
    public String next() {
        if(read_ahead == null)
            line = null;
        else
            line = new String(this.read_ahead);

        try {
            read_ahead = this.reader.readLine();
        } catch (IOException e) {
            read_ahead = null;
            reader.close()
        }
        return line;
    }

    @Override
    public void remove() {
        // do nothing       
    }
}


and here is the unit-test for it:

import java.io.IOException;
import org.junit.Test;

public class FileTest {
    @Test
    public void testFile(){
        File f;
        try {
            f = File.open(""File.java"");
            for(String s : f){
                System.out.println(s);
            }
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    @Test
    public void testReadAndWriteFile(){
        File from;
        File to;
        try {
            from = File.open(""File.java"");
            to = File.open(""Out.txt"", ""w"");
            for(String s : from){           
                to.write(s + System.getProperty(""line.separator""));
            }
            to.close();
        } catch (IOException e1) {
            e1.printStackTrace();
        }   
    }
}

",python-like Java IO library?,"Java is not my main programming language so I might be asking the obvious.

But is there a simple file-handling library in Java, like in python?

For example I just want to say:

File f = Open('file.txt', 'w')
for(String line:f){
      //do something with the line from file
}


Thanks!

UPDATE: Well, the stackoverflow auto-accepted a weird answer. It has to do with bounty that I placed - so if you want to see other answers, just scroll down!
"
"import re

astr='My---sun--is------very-big---.'

print(re.sub('-+','-',astr))
# My-sun-is-very-big-.

",How do I coalesce a sequence of identical characters into just one?,"Suppose I have this:

My---sun--is------very-big---.

I want to replace all multiple hyphens with just one hyphen.
"
"As long as all the arrays are the same length, you can use array_map with null as the first argument.

array_map(null, $a, $b, $c, ...);


If some of the arrays are shorter, they will be padded with nulls to the length of the longest, unlike python where the returned result is the length of the shortest array.
",Is there a php function like python's zip?,"Python has a nice zip() function. Is there a PHP equivalent?
"
"Here's my take on the code cleanup:

Edit: I've taken David's code into my answer to make it even more compact (and faster execution time).

>>> from itertools import product
>>>
>>> def fringe8((px, py), (x1, y1, x2, y2)):
...     f = [(px+dx, py+dy) for (dx, dy) in product((-1,0,1),(-1,0,1)) if (dx, dy) != (0, 0)]
...     f_inrange = [(fx, fy) for (fx, fy) in f if x1 <= fx < x2 and y1 <= fy < y2]
...     return f_inrange
...   
>>> fringe8((2, 2), (1, 1, 3, 3))
[(1, 1), (1, 2), (2, 1)]


Edit: If you're not too comfortable with list comprehensions, feel free to break it down to a for loop. The conditions proposed here, and others' answers, are all much more concise for you to use.

After all, one the goals of list comprehesion is to make it easier to read, and not verbose.

Edit again: Please also look at Ryan Ginstrom's answer.
","How can this verbose, unpythonic routine be improved?","Is there a more pythonic way of doing this?  I am trying to find the eight neighbours of an integer coordinate lying within an extent.  I am interested in reducing its verbosity without sacrificing execution speed.

def fringe8((px, py), (x1, y1, x2, y2)):
    f = [(px - 1, py - 1),
         (px - 1, py),
         (px - 1, py + 1),
         (px, py - 1),
         (px, py + 1),
         (px + 1, py - 1),
         (px + 1, py),
         (px + 1, py + 1)]
    f_inrange = []
    for fx, fy in f:
        if fx < x1:  continue
        if fx >= x2: continue
        if fy < y1:  continue
        if fy >= y2: continue
        f_inrange.append((fx, fy))
    return f_inrange

"
"Here's a simple example: you need to try a few alternative URLs and return the contents of the first one to respond.

import Queue
import threading
import urllib2

# called by each thread
def get_url(q, url):
    q.put(urllib2.urlopen(url).read())

theurls = [""http://google.com"", ""http://yahoo.com""]

q = Queue.Queue()

for u in theurls:
    t = threading.Thread(target=get_url, args = (q,u))
    t.daemon = True
    t.start()

s = q.get()
print s


This is a case where threading is used as a simple optimization: each subthread is waiting for a URL to resolve and respond, in order to put its contents on the queue; each thread is a daemon (won't keep the process up if main thread ends -- that's more common than not); the main thread starts all subthreads, does a get on the queue to wait until one of them has done a put, then emits the results and terminates (which takes down any subthreads that might still be running, since they're daemon threads).

Proper use of threads in Python is invariably connected to I/O operations (since CPython doesn't use multiple cores to run CPU-bound tasks anyway, the only reason for threading is not blocking the process while there's a wait for some I/O).  Queues are almost invariably the best way to farm out work to threads and/or collect the work's results, by the way, and they're intrinsically threadsafe so they save you from worrying about locks, conditions, events, semaphores, and other inter-thread coordination/communication concepts.
",How to use threading in Python?,"I am trying to understand threading in Python. I've looked at the documentation and examples, but quite frankly, many examples are overly sophisticated and I'm having trouble understanding them.

How do you clearly show tasks being divided for multi-threading?
"
"psutil can find process by name and kill it:

import psutil

PROCNAME = ""python.exe""

for proc in psutil.process_iter():
    # check whether the process name matches
    if proc.name() == PROCNAME:
        proc.kill()

",Kill process by name?,"I'm trying to kill a process (specifically iChat). On the command line, I use these commands:

ps -A | grep iChat 


Then:

kill -9 PID


However, I'm not exactly sure how to translate these commands over to Python.
"
"You could use an import and single line code like this:

import ctypes  # An included library with Python install.
ctypes.windll.user32.MessageBoxW(0, ""Your text"", ""Your title"", 1)


Or define a function (Mbox) like so:

import ctypes  # An included library with Python install.
def Mbox(title, text, style):
    ctypes.windll.user32.MessageBoxW(0, text, title, style)
Mbox('Your title', 'Your text', 1)


Note the styles are as follows:

##  Styles:
##  0 : OK
##  1 : OK | Cancel
##  2 : Abort | Retry | Ignore
##  3 : Yes | No | Cancel
##  4 : Yes | No
##  5 : Retry | No 
##  6 : Cancel | Try Again | Continue


Have fun!

Note: edited to use MessageBoxW instead of MessageBoxA
",How can I create a simple message box in Python?,"I'm looking for the same effect as alert() in JavaScript.

I wrote a simple web-based interpreter this afternoon using Twisted.web. You basically submit a block of Python code through a form, and the client comes and grabs it and executes it. I want to be able to make a simple popup message, without having to re-write a whole bunch of boilerplate wxPython or TkInter code every time (since the code gets submitted through a form and then disappears).

I've tried tkMessageBox:

import tkMessageBox
tkMessageBox.showinfo(title=""Greetings"", message=""Hello World!"")


but this opens another window in the background with a tk icon. I don't want this. I was looking for some simple wxPython code but it always required setting up a class and entering an app loop etc. Is there no simple, catch-free way of making a message box in Python?
"
"There are no technical reasons.  It would not be too hard to modify the Python interpreter to require exactly four spaces per indentation level.

Here is one use case for other indentation levels: when typing into the interactive interpreter, it's very handy to use one-space indentations.  It saves on typing, it's easier to count the number of spaces correctly, and readability is not a major concern (since the code isn't even saved in a file).
",Why doesn't Python require exactly four spaces per indentation level?,"Whitespace is signification in Python in that code blocks are defined by their indentation.

Furthermore, Guido van Rossum recommends using four spaces per indentation level (see PEP 8: Style Guide for Python Code).

What was the reasoning behind not requiring exactly four spaces per indentation level as well? Are there any technical reasons?

It seems like all the arguments that can be made for making whitespace define code blocks can also be used to argument for setting an exact whitespace length for one indentation level (say four spaces).
"
"Python can call functions in dynamically loaded C libraries (.so in unix, .dll in Windows) using the ctypes module.

There is also cython - a variation of python that compiles to C and can call C libraries directly.  You can mix modules written in pure Python and cython.

You may also want to look at the numerous 3D game engines either written specifically for Python or with a python interface.  The ones I have heard the most about (but not used) are Blender and Python-Ogre.
",Any high-level languages that can use c libraries?,"I know this question could be in vain, but it's just out of curiosity, and I'm still much a newb^^ Anyways I've been loving python for some time while learning it. My problem is obviously speed issues. I'd like to get into indie game creation, and for the short future, 2d and pygame will work. 
But I'd eventually like to branch into the 3d area, and python is really too slow to make anything 3d and professional. So I'm wondering if there has ever been work to create a high-level language able to import and use c libraries? I've looked at Genie and it seems to be able to use certain libraries, but I'm not sure to what extent. Will I be able to use it for openGL programing, or in a c game engine?
I do know some lisp and enjoy it a lot, but there aren't a great many libraries out there for it. Which leads to the problem: I can't stand C syntax, but C has libraries galore that I could need! And game engines like irrlicht. Is there any language that can be used in place of C around C?

Thanks so much guys
"
"with open(filename) as f:
  while True:
    c = f.read(1)
    if not c:
      print ""End of file""
      break
    print ""Read a character:"", c

",How to read a single character at a time from a file in Python?,"Can anyone tell me how can I do this?
"
"As you mentioned, the easiest way is to use raw_input(). There is no built-in way to do this. From Recipe 577058:

import sys

def query_yes_no(question, default=""yes""):
    """"""Ask a yes/no question via raw_input() and return their answer.

    ""question"" is a string that is presented to the user.
    ""default"" is the presumed answer if the user just hits .
        It must be ""yes"" (the default), ""no"" or None (meaning
        an answer is required of the user).

    The ""answer"" return value is True for ""yes"" or False for ""no"".
    """"""
    valid = {""yes"": True, ""y"": True, ""ye"": True,
             ""no"": False, ""n"": False}
    if default is None:
        prompt = "" [y/n] ""
    elif default == ""yes"":
        prompt = "" [Y/n] ""
    elif default == ""no"":
        prompt = "" [y/N] ""
    else:
        raise ValueError(""invalid default answer: '%s'"" % default)

    while True:
        sys.stdout.write(question + prompt)
        choice = raw_input().lower()
        if default is not None and choice == '':
            return valid[default]
        elif choice in valid:
            return valid[choice]
        else:
            sys.stdout.write(""Please respond with 'yes' or 'no' ""
                             ""(or 'y' or 'n').\n"")


Usage example:

>>> query_yes_no(""Is cabbage yummier than cauliflower?"")
Is cabbage yummier than cauliflower? [Y/n] oops
Please respond with 'yes' or 'no' (or 'y' or 'n').
Is cabbage yummier than cauliflower? [Y/n] [ENTER]
>>> True

>>> query_yes_no(""Is cabbage yummier than cauliflower?"", None)
Is cabbage yummier than cauliflower? [y/n] [ENTER]
Please respond with 'yes' or 'no' (or 'y' or 'n').
Is cabbage yummier than cauliflower? [y/n] y
>>> True

",APT command line interface-like yes/no input?,"Is there any short way to achieve what the APT (Advanced Package Tool) command line interface does in Python?

I mean, when the package manager prompts a yes/no question followed by [Yes/no], the script accepts YES/Y/yes/y or Enter (defaults to Yes as hinted by the capital letter).

The only thing I find in the official docs is input and raw_input...

I know it's not that hard to emulate, but it's annoying to rewrite :|
"
"The interface  as a keyword and artifact was introduced by Java1 ( and C# took it from there ) to describe what the contract an object must adhere was. 

But, interface has always been a key part of Object Oriented Paradigm and basically it represents the methods an object has to respond.  Java just enforces this mechanism to provide statically type checking.

So, dynamic ( OO ) programming languages do use interfaces, even thought they don't statically check them. Just like other data types, for instance in Ruby:

 @i = 1;


You don't have to declare i of type FixNum you just use it. Same goes for interfaces, they just flow.  The trade-off is, you can't have a static check on that and failures are only show at runtime. 

In the other hand Structural type ( or static duck type as I call it :P )  used by languages as Go or Scala, gives the best of both worlds. 


1. See Daniel Earwicker  comment about CORBA interface keyword


",Why don't we require interfaces in dynamic languages?,"Is it just because of dynamic typing we don't require a concept of interfaces(like in Java and C#) in python?
"
"There is no 'built in' way to do this. Django will raise the DoesNotExist exception every time.
The idiomatic way to handle this in python is to wrap it in a try catch:

try:
   x = SomeModel.objects.get(foo='bar')
except SomeModel.DoesNotExist:
   x = None


What I did do, is to sublcass models.Manager, create a safe_get like the code above and use that manager for my models. That way you can write: SomeModel.objects.safe_get(foo='bar')
","In Django, how do I objects.get, but return None when nothing is found?","go  = Content.objects.get(name=""baby"")
# go should be None, since nothing is in the database.

"
"lxml has been mentioned. You might also check out lxml.objectify for some really simple manipulation.

>>> from lxml import objectify
>>> tree = objectify.fromstring(your_xml)
>>> tree.weather.attrib[""module_id""]
'0'
>>> tree.weather.forecast_information.city.attrib[""data""]
'Mountain View, CA'
>>> tree.weather.forecast_information.postal_code.attrib[""data""]
'94043'

",Really simple way to deal with XML in Python?,"Musing over a recently asked question, I started to wonder if there is a really simple way to deal with XML documents in Python. A pythonic way, if you will.

Perhaps I can explain best if i give example: let's say the following - which i think is a good example of how XML is (mis)used in web services - is the response i get from http request to http://www.google.com/ig/api?weather=94043


  
    
      
      
      
      
      
      
      
    
    
      
      
      
      
      
      
    
    ...
    
      
      
      
      
      
    
  



After loading/parsing such document, i would like to be able to access the information as simple as say 

>>> xml['xml_api_reply']['weather']['forecast_information']['city'].data
'Mountain View, CA'


or

>>> xml.xml_api_reply.weather.current_conditions.temp_f['data']
'68'


From what I saw so far, seems that ElementTree is the closest to what I dream of. But it's not there, there is still some fumbling to do when consuming XML. OTOH, what I am thinking is not that complicated - probably just thin veneer on top of a parser - and yet it can decrease annoyance of dealing with XML. Is there such a magic? (And if not - why?)

PS. Note I have tried BeautifulSoup already and while I like its approach, it has real issues with empty s - see below in comments for examples.
"
"Solution

Make one of the function's default arguments be a reference to the function itself.

def f(self):
    return self.x
f.func_defaults = (f,)


Example usage:

>>> f.x = 17
>>> b = f
>>> del f
>>> b()
17


Explanation

The original poster wanted a solution that does not require a global name lookup.  The simple solution

def f():
    return f.x


performs a lookup of the global variable f on each call, which does not meet the requirements.  If f is deleted, then the function fails.  The more complicated inspect proposal fails in the same way.

What we want is to perform early binding and store the bound reference within the object itself.  The following is conceptually what we are doing:

def f(self=f):
    return self.x


In the above, self is a local variable, so no global lookup is performed.  However, we can't write the code as-is, because f is not yet defined when we try to bind the default value of self to it.  Instead, we set the default value after f is defined.

Decorator

Here's a simple decorator to do this for you.  Note that the self argument must come last, unlike methods, where self comes first.  This also means that you must give a default value if any of your other arguments take a default value.

def self_reference(f):
    f.func_defaults = f.func_defaults[:-1] + (f,)
    return f

@self_reference
def foo(verb, adverb='swiftly', self=None):
    return '%s %s %s' % (self.subject, verb, adverb)


Example:

>>> foo.subject = 'Fred'
>>> bar = foo
>>> del foo
>>> bar('runs')
'Fred runs swiftly'

",how can python function access its own attributes?,"is it possible to access the python function object attributes from within the function scope?

e.g. let's have

def f():
    return SOMETHING

f._x = ""foo""
f()           # -> ""foo""


now, what SOMETHING has to be, if we want to have the _x attribute content ""foo"" returned? if it's even possible (simply)

thanks

UPDATE:

i'd like the following work also:

g = f
del f
g()          # -> ""foo""


UPDATE 2:

Statement that it is not possible (if it is the case), and why, is more satisfying than providing a way how to fake it e.g. with a different object than a function
"
"I see you got a lot of examples, all so far from @Noctis, but I'm not sure how they're going to help you.  Addressing your question more directly: the only way multithreading can speed your application up, in today's CPython, is if your slow-down is due in good part to ""blocking I/O"" operations, e.g. due to interactions with (for example) DB servers, mail servers, websites, and so on.  (A powerful alternative to speed up I/O is asynchronous, AKA event-driven, programming, for which the richest Python framework is twisted -- but it can be harder to learn, if you've never done event-driven coding).

Even if you have many cores in your machine, one multi-threaded Python process will use only one of them at a time, except when it's executing specially coded extensions (typically in C, C++, Cython, and the like) which ""release the GIL"" (the global interpreter lock) when feasible.

If you do have many cores, multiprocessing (a module whose interface is designed to look a lot like threading) can indeed speed up your program.  There are many other packages supporting ""symmetric multi-processor"" distributed programming, see the list here, but, out of all of them, multiprocessing is the one that comes as part of the standard library (a very convenient thing).  If you have multiple computers with a fast LAN between them, you should also consider the more general approach of distributed processing, which could let you use all of your available computers for the same task (some of these packages are also listed at the previous URL I gave, under the ""cluster computing"" header).

What speed-up you can get for any number of available cores or computers ultimately depends on the nature of your problems -- and, if the problems per se are suitable for it, then also of the algorithms and data structures you're using... not all will speed-up well (it varies between ""embarassingly parallel"" problems such as ray-tracing, which speed up linearly all the way, to ""intrinsically serial"" ones where 100 machines won't be any faster than one). So, it's hard to advise you further without understanding the nature of your problems; care to explain that?
","I have a serial Python application that takes hours to process, how can I decrease the time it takes to run?","Could someone please post a few examples of multi-threaded python? I am searching all over the internet but cannot find a simple, easy-to-replicate tutorial. Simple examples are fine.

I have written a program which takes a few hours to run serially--I am hoping I can bring it's run time down to minutes after multi-threading it.
"
"First, and foremost, try not to compare and contrast between Python and Java.  They are different languages, with different semantics.  Compare and contrast will only lead to confusing questions like this where you're trying to compare something Python doesn't use with something Java requires.  

It's a lot like comparing the number 7 and the color green.  They're both nouns.  Beyond that, you're going to have trouble comparing the two.

Here's the bottom line.

Python does not need interfaces.

Java requires them.


  Multiple objects can implement the same interface, but multiple inheritance doesn't provide this as well?


The two concepts have almost nothing to do with each other.

I can define a large number of classes which share a common interface.  In Python, because of ""duck typing"", I don't have to carefully be sure they all have a common superclass.

An interface is a declaration of ""intent"" for disjoint class hierarchies.  It provides a common specification (that can be checked by the compiler) that is not part of the simple class hierarchy.  It allows multiple class hierarchies to implement some common features and be polymorphic with respect to those features.

In Python you can use multiple inheritance with our without interfaces.  Multiple inheritance can include interface classes or not include interface classes.  

Java doesn't even have multiple inheritance.  Instead it uses a completely different technique called ""mixins"".


  Why do I need to create an Interface ""with no implementation"" - mainly a ""contract"" - if I can just check if a method exists in an object in Python, that inherits from multiple classes?


If you create an interface in Python, it can be a kind of formal contract.  A claim that all subclasses will absolutely do what the interface claims.

Of course, a numbskull is perfectly free to lie.  They can inherit from an interface and mis-implement everything.  Nothing prevents bad behavior from sociopaths.

You create an interface in Java to allow multiple classes of objects to have a common behavior.  Since you don't tell the compiler much in Python, the concept doesn't even apply.


  Do Interfaces were created in another languages because they don't provide multiple inheritance? 


Since the concepts aren't related, it's hard to answer this.

In Java, they do use ""mixin"" instead of multiple inheritance.  The ""interface"" allows some mixing-in of additional functionality.  That's one use for an interface.

Another use of an Interface to separate ""is"" from ""does"".  The class hierarchy defines what an objects IS.  The interface hierarchy defines what a class DOES.

In most cases, IS and DOES are isomorphic, so there's no distinction.

In some cases, what an  object IS and what an object DOES are different.
","Are Interfaces just ""Syntactic Sugar""?","I've been playing mostly with PHP and Python.

I've been reading about Interfaces in OO programming and can't see an advantage in using it.

Multiple objects can implement the same interface, but multiple inheritance doesn't provide this as well?

Why do I need to create an Interface ""with no implementation"" - mainly a ""contract"" - if I can just check if a method exists in an object in Python, that inherits from multiple classes?

Do Interfaces were created in another languages because they don't provide multiple inheritance? Or am I missing something more important here?
"
">>> import string
>>> string.lowercase[:14]
'abcdefghijklmn'
>>> string.lowercase[:14:2]
'acegikm'


To do the urls, you could use something like this

[i + j for i, j in zip(list_of_urls, string.lowercase[:14])]

",Python: how to print range a-z?,"1. Print a-n: a b c d e f g h i j k l m n

2. Every second in a-n: a c e g i k m

3. Append a-n to index of urls{hello.com/, hej.com/, ..., hallo.com/}: hello.com/a hej.com/b ... hallo.com/n
"
"self isn't a keyword in python, its just a normal variable name. When creating instance methods, you can name the first parameter whatever you want, self is just a convention.

You should almost always prefer passing arguments to functions over setting properties for input, but if you must, you can do so using the actual functions name to access variables within it:

def a:
    if a.foo:
        #blah

a.foo = false
a()


see python function attributes - uses and abuses for when this comes in handy. :D
","""self"" inside plain function?","I've got a bunch of functions (outside of any class) where I've set attributes on them, like funcname.fields = 'xxx'. I was hoping I could then access these variables from inside the function with self.fields, but of course it tells me:


  global name 'self' is not defined


So... what can I do? Is there some magic variable I can access? Like __this__.fields?



A few people have asked ""why?"". You will probably disagree with my reasoning, but I have a set of functions that all must share the same signature (accept only one argument). For the most part, this one argument is enough to do the required computation. However, in a few limited cases, some additional information is needed. Rather than forcing every function to accept a long list of mostly unused variables, I've decided to just set them on the function so that they can easily be ignored. 

Although, it occurs to me now that you could just use **kwargs as the last argument if you don't care about the additional args. Oh well...

Edit: Actually, some of the functions I didn't write, and would rather not modify to accept the extra args. By ""passing in"" the additional args as attributes, my code can work both with my custom functions that take advantage of the extra args, and with third party code that don't require the extra args.

Thanks for the speedy answers :)
"
"You can use the ECDF function from the scikits.statsmodels library:

import numpy as np
import scikits.statsmodels as sm
import matplotlib.pyplot as plt

sample = np.random.uniform(0, 1, 50)
ecdf = sm.tools.ECDF(sample)

x = np.linspace(min(sample), max(sample))
y = ecdf(x)
plt.step(x, y)


With version 0.4 scicits.statsmodels was renamed to statsmodels. ECDF is now located in the distributions module (while statsmodels.tools.tools.ECDF is depreciated).

import numpy as np
import statsmodels.api as sm # recommended import according to the docs
import matplotlib.pyplot as plt

sample = np.random.uniform(0, 1, 50)
ecdf = sm.distributions.ECDF(sample)

x = np.linspace(min(sample), max(sample))
y = ecdf(x)
plt.step(x, y)
plt.show()

",How to plot empirical cdf in matplotlib in Python?,"How can I plot the empirical CDF of an array of numbers in matplotlib in Python?  I'm looking for the cdf analog of pylab's ""hist"" function.

One thing I can think of is:

from scipy.stats import cumfreq
a = array([...]) # my array of numbers
num_bins =  20
b = cumfreq(a, num_bins)
plt.plot(b)


Is that correct though?  Is there an easier/better way?

thanks. 
"
"My first thought was that the JSON serializer is probably pretty good at nested dictionaries, so I'd cheat and use that:

>>> import json
>>> print json.dumps({'a':2, 'b':{'x':3, 'y':{'t1': 4, 't2':5}}},
...                  sort_keys=True, indent=4)
{
    ""a"": 2,
    ""b"": {
        ""x"": 3,
        ""y"": {
            ""t1"": 4,
            ""t2"": 5
        }
    }
}

",pretty printing nested dictionaries in Python?,"How can I pretty print a dictionary with depth of ~4 in Python? I tried pretty printing with pprint but it did not work:

import pprint 
pp = pprint.PrettyPrinter(indent=4)
pp.pprint(mydict)


I simply want an identation (""\t"") for each nesting, so that I get something like this:

key1
    value1
    value2
    key2
       value1
       value2


etc. 

how can I do this?
"
"I just found this wonderful theme :

http://github.com/nek4life/pycharm-twilight
","Does anyone have a ""dark"" pycharm schema file?","I'm trying out pycharm for django development and I can't stand the white background.  Can someone provide a place to download a schema file?  Switching all the colors manually is tedious and time consuming.  

Is it possible to use komodo schemas?
"
"Aha! So your real problem is how to test many conditions per line and if one of them is satisfied, to output that line. Easiest will be using regular expression, me thinks:

import re
keywords = ['S0414', 'GT213', 'AT3423', 'PR342'] # etc - you probably get those from some source
pattern = re.compile('|'.join(keywords))

for line in inf:
    if pattern.search(ln):
        outf.write(line)

",Extract specific text lines?,"I have a large several hudred thousand lines text file. I have to extract 30,000 specific lines that are all in the text file in random spots. This is the program I have to extract one line at a time:

big_file = open('C:\\gbigfile.txt', 'r')
small_file3 = open('C:\\small_file3.txt', 'w')
for line in big_file:
   if 'S0414' in line:
      small_file3.write(line)
gbigfile.close()
small_file3.close()


How can I speed this up for 30,000 lines that I need to look up>?
"
"Here's a good example:

def key(x):
    return x[1]

a = [(1, 2), (3, 1), (5, 10), (11, -3)]
a.sort(key=key)


versus

a = [(1, 2), (3, 1), (5, 10), (11, -3)]
a.sort(key=lambda x: x[1])


From another angle: Lambda expressions are also known as ""anonymous functions"", and are very useful in certain programming paradigms, particularly functional programming, which lambda calculus provided the inspiration for.

http://en.wikipedia.org/wiki/Lambda_calculus
",Why use lambda functions?,"I can find lots of stuff showing me what a lambda function is, and how the syntax works and what not.  But other than the ""coolness factor"" (I can make a function in middle a call to another function, neat!) I haven't seen something that's overwelmingly compelling to say why I really need/want to use them.

It seems to be more of a stylistic or structual choice in most examples I've seen.  And kinda breaks the ""Only one correct way to do something"" in python rule.  How does it make my programs, more correct, more reliable, faster, or easier to understand?  (Most coding standards I've seen tend to tell you to avoid overly complex statements on a single line.  If it makes it easier to read break it up.)
"
"I see many answers suggesting itertools.tee, but that's ignoring one crucial warning in the docs for it:


  This itertool may require significant
  auxiliary storage (depending on how
  much temporary data needs to be
  stored). In general, if one iterator
  uses most or all of the data before
  another iterator starts, it is faster
  to use list() instead of tee().


Basically, tee is designed for those situation where two (or more) clones of one iterator, while ""getting out of sync"" with each other, don't do so by much -- rather, they say in the same ""vicinity"" (a few items behind or ahead of each other).  Not suitable for the OP's problem of ""redo from the start"".

L = list(DictReader(...)) on the other hand is perfectly suitable, as long as the list of dicts can fit comfortably in memory.  A new ""iterator from the start"" (very lightweight and low-overhead) can be made at any time with iter(L), and used in part or in whole without affecting new or existing ones; other access patterns are also easily available.

As several answers rightly remarked, in the specific case of csv you can also .seek(0) the underlying file object (a rather special case).  I'm not sure that's documented and guaranteed, though it does currently work;  it would probably be worth considering only for truly huge csv files, in which the list I recommmend as the general approach would have too large a memory footprint.
",Can iterators be reset in Python?,"Can I reset an iterator / generator in Python?  I am using DictReader and would like to reset it (from the csv module) to the beginning of the file.
"
"This is detailed with a reasonable amount of detail by Guido himself at http://python-history.blogspot.com/2010/06/method-resolution-order.html (including two earlier attempts).

But, briefly: in your example, Third() will call First.__init__. For such simple situations, Python will look for the attribute (in this case, __init__) on the class's parents, left to right. So, if you define

class Third(First, Second):
    ...


Python will look at First, and, if First doesn't have the attribute, at Second.

This situation becomes more complex when inheritance starts crossing paths (say, if First inherited from Second, for instance). Read the link above for more details, but, in a nutshell, Python will try to maintain the order in which each class appears on the inheritance list, child classes first.

So, for instance, if you had:

class First(object):
    def __init__(self):
        print ""first""

class Second(First):
    def __init__(self):
        print ""second""

class Third(First):
    def __init__(self):
        print ""third""

class Fourth(Second, Third):
    def __init__(self):
        super(Fourth, self).__init__()
        print ""that's it""


the MRO would be [Fourth, Second, Third, First].

By the way: if Python cannot find a coherent method resolution order, it'll raise an exception, instead of falling back to a behaviour which might surprise the user.

Edited to add example of an ambiguous MRO:

class First(object):
    def __init__(self):
        print ""first""

class Second(First):
    def __init__(self):
        print ""second""

class Third(First, Second):
    def __init__(self):
        print ""third""


Should Third's MRO be [First, Second] or [Second, First]? There's no obvious expectation, and Python will raise an error:


  TypeError: Error when calling the
  metaclass bases
      Cannot create a consistent method resolution order (MRO) for bases
  Second, First


[Edit] I see several people arguing that the examples above lack super() calls, so let me explain: the point of the examples is to show how the MRO is constructed. They are not intended print ""first\nsecond\third"" or whatever. You can - and should, of course, play around with the example, add super() calls, see what happens, and gain a deeper understanding of Python's inheritance model. But my goal here is to keep it simple and show how the MRO is build. And it is built as I explained:

>>> Fourth.__mro__
(, , , , )

",How does Python's super() work with multiple inheritance?,"I'm pretty much new in Python object oriented programming and I have trouble
understanding the super() function (new style classes) especially when it comes to multiple inheritance.

For example if you have something like:

class First(object):
    def __init__(self):
        print ""first""

class Second(object):
    def __init__(self):
        print ""second""

class Third(First, Second):
    def __init__(self):
        super(Third, self).__init__()
        print ""that's it""


What I don't get is: will the Third() class inherit both constructor methods? If yes, then which one will be run with super() and why?

And what if you want to run the other one? I know it has something to do with Python method resolution order (MRO). 
"
"I eventually found the solution (and it is really simple!).
In my fabfile, I added:

from fabric.main import main

if __name__ == '__main__':
    import sys
    sys.argv = ['fab', '-f', __file__, 'update_server']
    main()


I hope this helps people...
",Stand-alone fabfile for fabric?,"Is it possible to make the fabfile stand-alone?
I'm not very fond of running the external tool 'fab'. If I manage to get the fabfile standalone I can run the file from within the (Eclipse / Pydev) IDE, easily debug it, use project configurations and paths etc.
Why doesn't this work:

from fabric.api import run

def host_type():
    run('uname -s')

if __name__ == '__main__':
    host_type()    

"
"I could not use the codes posted so far for three reasons.


The codes using ""multiprocessing.Pool"" do not work with lambda expressions.
The codes not using ""multiprocessing.Pool"" spawn as many processes as there are work items.
All codes iterate through the whole input list before doing the actual work.


2.) is a performance concern, 3.) prohibits the use of a progress bar like http://code.google.com/p/python-progressbar/

I adapted the code s.t. it spawns a predefined amount of workers and only iterates through the input list if there exists an idle worker. I also enabled the ""daemon"" mode for the workers s.t. strg-c works as expected.

import multiprocessing


def fun(f, q_in, q_out):
    while True:
        i, x = q_in.get()
        if i is None:
            break
        q_out.put((i, f(x)))


def parmap(f, X, nprocs=multiprocessing.cpu_count()):
    q_in = multiprocessing.Queue(1)
    q_out = multiprocessing.Queue()

    proc = [multiprocessing.Process(target=fun, args=(f, q_in, q_out))
            for _ in range(nprocs)]
    for p in proc:
        p.daemon = True
        p.start()

    sent = [q_in.put((i, x)) for i, x in enumerate(X)]
    [q_in.put((None, None)) for _ in range(nprocs)]
    res = [q_out.get() for _ in range(len(sent))]

    [p.join() for p in proc]

    return [x for i, x in sorted(res)]


if __name__ == '__main__':
    print(parmap(lambda i: i * 2, [1, 2, 3, 4, 6, 7, 8]))

",Multiprocessing: How to use Pool.map on a function defined in a class?,"When I run something like:

from multiprocessing import Pool

p = Pool(5)
def f(x):
     return x*x

p.map(f, [1,2,3])


it works fine. However, putting this as a function of a class:

class calculate(object):
    def run(self):
        def f(x):
            return x*x

        p = Pool()
        return p.map(f, [1,2,3])

cl = calculate()
print cl.run()


Gives me the following error:

Exception in thread Thread-1:
Traceback (most recent call last):
  File ""/sw/lib/python2.6/threading.py"", line 532, in __bootstrap_inner
    self.run()
  File ""/sw/lib/python2.6/threading.py"", line 484, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/sw/lib/python2.6/multiprocessing/pool.py"", line 225, in _handle_tasks
    put(task)
PicklingError: Can't pickle : attribute lookup __builtin__.function failed


I've seen a post from Alex Martelli dealing with the same kind of problem, but it wasn't explicit enough.
"
"just for fun :o)

class Less(object):
    def __init__(self, num_lines):
        self.num_lines = num_lines
    def __ror__(self, other):
        s = str(other).split(""\n"")
        for i in range(0, len(s), self.num_lines):
            print ""\n"".join(s[i:i+self.num_lines])
            raw_input(""Press  for more"")

less=Less(num_lines=30)  
""\n"".join(map(str,range(100))) | less

",Python -- How do you view output that doesn't fit the screen?,"I should say I'm looking for a solution to the problem of viewing output that does not fit on your screen. For example, range(100) will show the last 30ish lines in your terminal of 30 height. 

I am only looking to be nudged in the right direction and am curious how you guys have approached this problem. 

What have you done when you run into a situation where you wish you could conveniently scroll through some large output? 

Best Answer

Use the scrollback buffer on your terminal. 

If you're using GNU Screen, it can be set with defscrollback 1000 or any other number in HOME/.screenrc. 

Use Ctrl-a, [ to enter copy mode

j -    Move the cursor down by one line
k -    Move the cursor up by one line
C-u -  Scrolls a half page up.
C-b -  Scrolls a full page up.
C-d -  Scrolls a half page down.
C-f -  Scrolls the full page down.
G -    Moves to the specified line 


The best part is ? for reverse search, / for forward search while in copy mode. 

Super convenient.

Thank you!



Original question:

What is the python equivalent of the bash less command? 

LongString | less 


Is there something like that for python? I find myself thinking I could use it fairly often but just move on and find some other solution. 

By ""long things"" I mean anything that generates more output lines than my screen. 1000 print messages, a dictionary, a large string, range(1000), etc. 

My googlefu has failed.
"
"It is a guard against a stack overflow, yes. Python (or rather, the CPython implementation) doesn't optimize tail recursion, and unbridled recursion causes stack overflows. You can change the recursion limit with sys.setrecursionlimit, but doing so is dangerous -- the standard limit is a little conservative, but Python stackframes can be quite big.

Python isn't a functional language and tail recursion is not a particularly efficient technique. Rewriting the algorithm iteratively, if possible, is generally a better idea.
",Maximum recursion depth?,"I have this tail recursive function here:

def fib(n, sum):
    if n < 1:
        return sum
    else:
        return fib(n-1, sum+n)

c = 998
print(fib(c, 0))


It works up to n=997, then it just breaks and spits a ""maximum recursion depth exceeded in comparison"" RuntimeError. Is this just a stack overflow? Is there a way to get around it?
"
"cloud-ide.com offer Exo IDE. This is a richly featured, cloud-based IDE that you use in the browser.  Importantly for you, it supports the full cycle of deployment to various Platform as a Service (PaaS) providers, including Google App Engine!

I've used this before, and it's as simple as saying you want a new GAE project.  You'll be redirected to Google pages when necessary to register details such as the app's name and domain. It even supports accessing GAE's log records for your app, although I've found this to be quite a bit slower than just using the Google-provided dashboard.

You can sign in with a Google account, and while I don't think that's necessary, I'd recommend it since this allows it to automatically associate the app you make with that account.

HTH
",Is there an online IDE for Google App Engine?,"I am learning Google App Engine / Python and I love it. Unfortunately I am not allowed to use my own computer in the office and not allowed to install anything on the corporate machine.

It would be so great to have an online IDE for Google App Engine where I could play with my Python code using any browser, including the one on my iPad.

Maybe http://www.devunity.com/ will be an online IDE for GAE some day. Do you know any existing way to program GAE in a browser?
"
"Python has a built-in compiler (to byte-code):

python -OO -m py_compile 


produces a .pyo file that contains byte-code, and where docstrings are removed, etc.  You can rename the .pyo file with a .py extension, and python  runs like your program but does not contain your source code.

PS: If your program imports modules obfuscated like this, then you need to rename them with a .pyc suffix instead (I'm not sure this won't break one day), or you can work with the .pyo and run them with python -O â¦.pyo (the imports should work).  This will allow Python to find your modules (otherwise, Python looks for .py modules).
",Obfuscating Python code?,"I am looking for how to hide my Python source code.

print ""hello World !"" 


How can I encode this example so that it isn't human-readable?  I've been told to use base64 but I'm not sure how.
"
"docs for io module

with open(fname, 'rb') as fh:
    first = next(fh).decode()

    fh.seek(-1024, 2)
    last = fh.readlines()[-1].decode()


The variable value here is 1024: it represents the average string length. I choose 1024 only for example. If you have an estimate of average line length you could just use that value times 2.

Since you have no idea whatsoever about the possible upper bound for the line length, the obvious solution would be to loop over the file:

for line in fh:
    pass
last = line


You don't need to bother with the binary flag you could just use open(fname).

ETA: Since you have many files to work on, you could create a sample of couple of dozens of files using random.sample and run this code on them to determine length of last line. With an a priori large value of the position shift (let say 1 MB). This will help you to estimate the value for the full run.
",What is the most efficient way to get first and last line of a text file?,"I have a text file which contains a time stamp on each line. My goal is to find the time range. All the times are in order so the first line will be the earliest time and the last line will be the latest time. I only need the very first and very last line. What would be the most efficient way to get these lines in python?

Note: These files are relatively large in length, about 1-2 million lines each and I have to do this for several hundred files. 
"
"Yes, this is how I would do it

>>> for i in xrange(0, 10):
...     if i == 4:
...         continue
...     print i,
...
0 1 2 3 5 6 7 8 9


EDIT
Based on the update to your original question... I would suggest you take a look at optparse
",Python: is there a C-like for loop available?,"Can I do something like this in Python?

for (i = 0; i < 10; i++):
  if someCondition:
     i+=1
  print i


I need to be able to skip some values based on a condition

EDIT: All the solutions so far suggest pruning the initial range in one way or another, based on an already known condition. This is not useful for me, so let me explain what I want to do.

I want to manually (i.e. no getopt) parse some cmd line args, where each 'keyword' has a certain number of parameters, something like this:

for i in range(0,len(argv)):
    arg = argv[i]
    if arg == '--flag1':
       opt1 = argv[i+1]
       i+=1
       continue
    if arg == '--anotherFlag':
       optX = argv[i+1]
       optY = argv[i+2]
       optZ = argv[i+3]
       i+=3
       continue

    ...

"
"Wiktionary runs on MediaWiki, which has an API.

One of the subpages for the API documentation is Client code, which lists some Python libraries.
",Has anyone parsed Wiktionary?,"Wiktionary is a wiki dictionary that covers many languages. It even has translations. I would be interested in parsing it and playing with the data, has anyone does anything like this before? Is there any library I can use? (Preferably Python.)
"
"Edit: Here's one way to recursively import everything at runtime... 

It uses exec, so there's almost certainly a better way, but it does work (even for arbitrarily nested sub-packages, I think).

(Contents of __init__.py in top package directory)

import pkgutil

__all__ = []
for loader, module_name, is_pkg in  pkgutil.walk_packages(__path__):
    __all__.append(module_name)
    module = loader.find_module(module_name).load_module(module_name)
    exec('%s = module' % module_name)


I'm not using __import__(__path__+'.'+module_name) here, as it's difficult to properly recursively import packages using it.  If you don't have nested sub-packages, and wanted to avoid the exec/eval, though, it's one way to do it.

There's probably a better way, but this is the best I can do, anyway.

Original Answer (For context, ignore othwerwise. I misunderstood the question initially):

What does your scripts/__init__.py look like?  It should be something like:

import script1
import script2
import script3
__all__ = ['script1', 'script2', 'script3']


You could even do without defining __all__, but things (pydoc, if nothing else) will work more cleanly if you define it, even if it's just a list of what you imported.
",How to import all submodules?,"I have a directory structure as follows:

| main.py
| scripts
|--| __init__.py
   | script1.py
   | script2.py
   | script3.py


From main.py, the module scripts is imported. I tried using pkgutils.walk_packages in combination with __all__, but using that, I can only import all the submodules directly under main using from scripts import *. I would like to get them all under scripts. What would be the cleanest way to import all the submodules of scripts so that I could access scripts.script1 from main?

EDIT: I am sorry that I was a bit vague. I would like to import the submodules on run-time without specifying them explicitly in __init__.py. I can use pkgutils.walk_packages to get the submodule names (unless someone knows of a better way), but I am not sure of the cleanest way to use these names (or maybe the ImpImporters that walk_packages returns?) to import them.
"
"A friend and I have written a Python profile viewer called SnakeViz that runs in a web browser. If you are already successfully using RunSnakeRun SnakeViz may not add that much value, but SnakeViz is much easier to install.

Edit: SnakeViz supports Python 2 and 3 and works on all major systems.
",Is there a visual profiler for Python?,"I use cProfile now but I find it tedious to write pstats code just to query the statistics data.

I'm looking for a visual tool that shows me what my Python code is doing in terms of CPU time and memory allocation.

Some examples from the Java world are visualvm and JProfiler.


Does something like this exist?
Is there an IDE that does this?
Would dtrace help?


I know about KCachegrind for Linux, but I would prefer something that I can run on Windows/Mac without installing KDE.
"
"""Figure out whether a given year is a leap year"" springs to mind almost immediately. Just give 'em the rules and turn 'em loose.

Other possibilities (albeit with stuff other than if statements):


Hunt the Wumpus (you may have to google for this one, I'm showing my age).
The perennial ""detect a win in a Tic Tac Toe (Noughts and Crosses) game"" (you could do this with eight if statements if you don't want a loop).
Guessing a number between 1 and 100 as quickly as possible (higher, lower).


For nothing but if/else statements, the leap year one is good. You could also consider:


Test if a number is a multiple of 3, 5 or 7.
Given an age, figure out whether someone's a baby, toddler, child, teenager, adult or old codger.
Calculate grades A-F based on final percentage score.
Given a number on the roulette table, figure out whether it's red/black, high/low and odd/even.
Given a blackjack hand, check if it's okay or bust (this is good since J/Q/K morph into 10). You could also figure out whether to draw another card (if total under 17 for example).


That's just a smattering of possibilities that you could get away with.
","What are good programming questions to exercise the use of ""if ... else"" in Python?","What would be a good set of programming exercises that would help Python newbies to learn the use of the ""if ... else"" construct? I could cook up the following, do you know of any more?


Find the largest/smallest of three numbers.
Given a date (year, month, day), find the next date.


Most of the intended audience have not had much of an exposure to programming before, and I am keen on getting them used to thinking correctly about ""if ... else"" (and all the rest of it, in due course).
"
"Your best Perl to Python converter is probably 23 years old, just graduated university and is looking for a job.
",Why is it not possible to create a practical Perl to Python source code converter?,"It would be nice if there existed a program that automatically transforms Perl code to Python code, making the resultant Python program as readable and maintainable as the original one, let alone working the same way.

The most obvious solution would just invoke perl via Python utils:

#!/usr/bin/python
os.exec(""tail -n -2 ""+__file__+"" | perl -"")
...the rest of file is the original perl program...


However, the resultant code is hardly a Python code, it's essentially a Perl code.  The potential converter should convert Perl constructs and idioms to easy-to-read Python code, it should retain variable and subroutine names (i.e. the result should not look obfuscated) and should not shatter the wrokflow too much.

Such a conversion is obviously very hard.  The hardness of the conversion depends on the number of Perl features and syntactical constructs, which do not have easy-to-read, unobfuscated Python equivalents.  I believe that the large amount of such features renders such automatic conversion impossible practically  (while theoretical possibility exists).

So, could you please name Perl idioms and syntax features that can't be expressed in Python as concise as in the original Perl code?

Edit: some people linked Python-to-Perl conventers and deduced, on this basis, that it should be easy to write Perl-to-Python as well.  However, I'm sure that converting to Python is in greater demand; still this converter is not yet written--while the reverse has already been!  Which only makes my confidence in impossibility of writing a good converter to Python more solid.
"
"You can use the third party dateutil module (PyPI entry here).

import datetime
import dateutil.relativedelta

d = datetime.datetime.strptime(""2013-03-31"", ""%Y-%m-%d"")
d2 = d - dateutil.relativedelta.relativedelta(months=1)
print d2


output:

2013-02-28 00:00:00

",What's the simplest way to subtract a month from a date in Python?,"If only timedelta had a month argument in it's constructor.  So what's the simplest way to do this?

EDIT: I wasn't thinking too hard about this as was pointed out below.  Really what I wanted was any day in the last month because eventually I'm going to grab the year and month only.  So given a datetime object, what's the simplest way to return any datetime object that falls in the previous month?
"
"i will recommend to check this book 
http://www.amazon.com/Code-Complete-Practical-Handbook-Construction/dp/0735619670/ref=sr_1_1?s=books&ie=UTF8&qid=1281129036&sr=1-1
",are there tutorials on how to name variables?,"as you can probably tell from my previous posts i have horrific naming conventions. do you know of any tutorials dealing with how to name stuff?
"
"Since you mentioned python, I would suggest looking into Django. You may need to look harder for hosting options, however...
",What language (Java or Python) + framework for mid sized web project?,"I plan to start a mid sized web project, what language + framework would you recommend?
I know Java and Python. I am looking for something simple.

Is App Engine a good option? I like the overall simplicity and free hosting, but I am worried about the datastore (how difficult is it to make it similarly fast as a standard SQL solution? + I need fulltext search + I need to filter objects by several parameters).

What about Java with Stripes? Should I use another framework in addition to Stripes (e.g. for database).

UPDATE:
Thanks for the advice, I finally decided to use Django with Eclipse/PyDev as an IDE.
Python/Django is simple and elegant, it's widely used and there is a great documentation. A small disadvantage is that perhaps I'll have to buy a VPS, but it shouldn't be very hard to port the project to App Engine, which is free to some extent.
"
"You can use the in operator:

if ""blah"" not in somestring: 
    continue

",Does Python have a string contains substring method?,"I'm looking for a string.contains or string.indexof method in Python.

I want to do:

if not somestring.contains(""blah""):
   continue

"
"Let's assume that you are running your program as:

python YOURSCRIPT.py


Try running your program as:

python -m trace --trace YOURSCRIPT.py


And have some patience while lots of stuff is printed on the screen. If you have an infinite loop, it will go on for-ever (halting problem). If it gets stuck somewhere, then mostly you are stuck on I/O or it is a deadlock.
",How can I tell where my python script is hanging?,"So I'm debugging my python program and have encountered a bug that makes the program hang, as if in an infinite loop. Now, I had a problem with an infinite loop before, but when it hung up I could kill the program and python spat out a helpful exception that told me where the program terminated when I sent it the kill command. Now, however, when the program hangs up and I ctrl-c it, it does not abort but continues running. Is there any tool I can use to locate the hang up? I'm new to profiling but from what I know a profiler can only provide you with information about a program that has successfully completed. Or can you use a profiler to debug such hang ups?
"
"It looks like you are trying to validate IP addresses. A regular expression is probably not the best tool for this.

If you want to accept all valid IP addresses (including some addresses that you probably didn't even know were valid) then you can use IPy (Source):

from IPy import IP
IP('127.0.0.1')


If the IP address is invalid it will throw an exception.

Or you could use socket (Source):

import socket
try:
    socket.inet_aton(addr)
    # legal
except socket.error:
    # Not legal


If you really want to only match IPv4 with 4 decimal parts then you can split on dot and test that each part is an integer between 0 and 255.

def validate_ip(s):
    a = s.split('.')
    if len(a) != 4:
        return False
    for x in a:
        if not x.isdigit():
            return False
        i = int(x)
        if i  255:
            return False
    return True


Note that your regular expression doesn't do this extra check. It would accept 999.999.999.999 as a valid address.
",check if a string matches an IP address pattern in python?,"What is the fastest way to check if a string matches a certain pattern? Is regex the best way?

For example, I have a bunch of strings and want to check each one to see if they are a valid IP address (valid in this case meaning correct format), is the fastest way to do this using regex? Or is there something faster with like string formatting or something. 

Something like this is what I have been doing so far:

for st in strs:
    if re.match('\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}', st) != None:
       print 'IP!'

"
"EDIT: I'm expanding the answer to include a more polished example. I have found a lot hostility and misinformation in this post regarding threading v.s. async I/O. Therefore I also adding more argument to refute certain invalid claim. I hope this will help people to choose the right tool for the right job.

This is a dup to a question 3 days ago.

Python urllib2.open is slow, need a better way to read several urls - Stack Overflow
  http://stackoverflow.com/questions/3472515/python-urllib2-open-is-slow-need-a-better-way-to-read-several-urls/3472905#3472905

I'm polishing the code to show how to fetch multiple webpage in parallel using threads.

import time
import threading
import Queue

# utility - spawn a thread to execute target for each args
def run_parallel_in_threads(target, args_list):
    result = Queue.Queue()
    # wrapper to collect return value in a Queue
    def task_wrapper(*args):
        result.put(target(*args))
    threads = [threading.Thread(target=task_wrapper, args=args) for args in args_list]
    for t in threads:
        t.start()
    for t in threads:
        t.join()
    return result

def dummy_task(n):
    for i in xrange(n):
        time.sleep(0.1)
    return n

# below is the application code
urls = [
    ('http://www.google.com/',),
    ('http://www.lycos.com/',),
    ('http://www.bing.com/',),
    ('http://www.altavista.com/',),
    ('http://achewood.com/',),
]

def fetch(url):
    return urllib2.urlopen(url).read()

run_parallel_in_threads(fetch, urls)


As you can see, the application specific code has only 3 lines, which can be collapsed into 1 line if you are aggressive. I don't think anyone can justify their claim that this is complex and unmaintainable. 

Unfortunately most other threading code posted here has some flaws. Many of them do active polling to wait for the code to finish. join() is a better way to synchronize the code. I think this code has improved upon all the threading examples so far.

keep-alive connection

WoLpH's suggestion about using keep-alive connection could be very useful if all you URLs are pointing to the same server.

twisted

Aaron Gallagher is a fans of twisted framework and he is hostile any people who suggest thread. Unfortunately a lot of his claims are misinformation. For example he said ""-1 for suggesting threads. This is IO-bound; threads are useless here."" This contrary to evidence as both Nick T and I have demonstrated speed gain from the using thread. In fact I/O bound application has the most to gain from using Python's thread (v.s. no gain in CPU bound application). Aaron's misguided criticism on thread shows he is rather confused about parallel programming in general.

Right tool for the right job

I'm well aware of the issues pertain to parallel programming using threads, python, async I/O and so on. Each tool has their pros and cons. For each situation there is an appropriate tool. I'm not against twisted (though I have not deployed one myself). But I don't believe we can flat out say that thread is BAD and twisted is GOOD in all situations.

For example, if the OP's requirement is to fetch 10,000 website in parallel, async I/O will be prefereable. Threading won't be appropriable (unless maybe with stackless Python).

Aaron's opposition to threads are mostly generalizations. He fail to recognize that this is a trivial parallelization task. Each task is independent and do not share resources. So most of his attack do not apply.

Given my code has no external dependency, I'll call it right tool for the right job.

Performance

I think most people would agree that performance of this task is largely depend on the networking code and the external server, where the performance of platform code should have negligible effect. However Aaron's benchmark show an 50% speed gain over the threaded code. I think it is necessary to response to this apparent speed gain.

In Nick's code, there is an obvious flaw that caused the inefficiency. But how do you explain the 233ms speed gain over my code? I think even twisted fans will refrain from jumping into conclusion to attribute this to the efficiency of twisted. There are, after all, a huge amount of variable outside of the system code, like the remote server's performance, network, caching, and difference implementation between urllib2 and twisted web client and so on.

Just to make sure Python's threading will not incur a huge amount of inefficiency, I do a quick benchmark to spawn 5 threads and then 500 threads. I am quite comfortable to say the overhead of spawning 5 thread is negligible and cannot explain the 233ms speed difference.

In [274]: %time run_parallel_in_threads(dummy_task, [(0,)]*5)
CPU times: user 0.00 s, sys: 0.00 s, total: 0.00 s
Wall time: 0.00 s
Out[275]: 

In [276]: %time run_parallel_in_threads(dummy_task, [(0,)]*500)
CPU times: user 0.16 s, sys: 0.00 s, total: 0.16 s
Wall time: 0.16 s

In [278]: %time run_parallel_in_threads(dummy_task, [(10,)]*500)
CPU times: user 1.13 s, sys: 0.00 s, total: 1.13 s
Wall time: 1.13 s       <<<<<<<< This means 0.13s of overhead


Further testing on my parallel fetching shows a huge variability in the response time in 17 runs. (Unfortunately I don't have twisted to verify Aaron's code).

0.75 s
0.38 s
0.59 s
0.38 s
0.62 s
1.50 s
0.49 s
0.36 s
0.95 s
0.43 s
0.61 s
0.81 s
0.46 s
1.21 s
2.87 s
1.04 s
1.72 s


My testing does not support Aaron's conclusion that threading is consistently slower than async I/O by a measurable margin. Given the number of variables involved, I have to say this is not a valid test to measure the systematic performance difference between async I/O and threading.
",How can I speed up fetching pages with urllib2 in python?,"I have a script that fetches several web pages and parses the info.

(An example can be seen at http://bluedevilbooks.com/search/?DEPT=MATH&CLASS=103&SEC=01 )

I ran cProfile on it, and as I assumed, urlopen takes up a lot of time. Is there a way to fetch the pages faster? Or a way to fetch several pages at once? I'll do whatever is simplest, as I'm new to python and web developing.

Thanks in advance! :)

UPDATE: I have a function called fetchURLs(), which I use to make an array of the URLs I need
so something like urls = fetchURLS().The URLS are all XML files from Amazon and eBay APIs (which confuses me as to why it takes so long to load, maybe my webhost is slow?)

What I need to do is load each URL, read each page, and send that data to another part of the script which will parse and display the data.

Note that I can't do the latter part until ALL of the pages have been fetched, that's what my issue is.

Also, my host limits me to 25 processes at a time, I believe, so whatever is easiest on the server would be nice :)



Here it is for time:

Sun Aug 15 20:51:22 2010    prof

         211352 function calls (209292 primitive calls) in 22.254 CPU seconds

   Ordered by: internal time
   List reduced from 404 to 10 due to restriction 

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
       10   18.056    1.806   18.056    1.806 {_socket.getaddrinfo}
     4991    2.730    0.001    2.730    0.001 {method 'recv' of '_socket.socket' objects}
       10    0.490    0.049    0.490    0.049 {method 'connect' of '_socket.socket' objects}
     2415    0.079    0.000    0.079    0.000 {method 'translate' of 'unicode' objects}
       12    0.061    0.005    0.745    0.062 /usr/local/lib/python2.6/HTMLParser.py:132(goahead)
     3428    0.060    0.000    0.202    0.000 /usr/local/lib/python2.6/site-packages/BeautifulSoup.py:1306(endData)
     1698    0.055    0.000    0.068    0.000 /usr/local/lib/python2.6/site-packages/BeautifulSoup.py:1351(_smartPop)
     4125    0.053    0.000    0.056    0.000 /usr/local/lib/python2.6/site-packages/BeautifulSoup.py:118(setup)
     1698    0.042    0.000    0.358    0.000 /usr/local/lib/python2.6/HTMLParser.py:224(parse_starttag)
     1698    0.042    0.000    0.275    0.000 /usr/local/lib/python2.6/site-packages/BeautifulSoup.py:1397(unknown_starttag)

"
"Python never does copy unless you specifically ask it to do a copy.  This is a perfectly simple, clear, and totally understandable rule.  Putting exceptions and distinguos on it, such as ""except under the following circumstances within a list comprehension..."", would be utter folly: if Python's design had ever been under the management of somebody with such crazy ideas,  Python would be a sick, contorted, half-broken language not worth learning.  Thanks for making me happy all over again in the realization that is is definitely not the case!

You want a copy?  Make a copy!  That's always the solution in Python when you prefer a copy's overhead because you need to perform some changes that must not be reflected in the original.  That is, in a clean approach, you'd do

dcopy = list(d)
[dcopy.pop() for _ in range(len(d))]


If you're super-keen to have everything within a single expression, you can, though it's possibly not code one would call exactly ""clean"":

[dcopy.pop() for dcopy in [list(d)] for _ in range(len(d))]


i.e., the usual trick one uses when one would really like to fold an assignment into a list comprehension (add a for clause, with the ""control variable"" being the name you want to assign to, and the ""loop"" is over a single-item sequence of the value you want to assign).

Functional languages never mutate data, therefore they don't make copies either (nor do they need to).  Python is not a functional language, but of course there's a lot of things you can do in Python ""the functional way"", and often it's a better way.  For example, a much better replacement for your list comprehension (guaranteed to have identical results and not affect d, and vastly faster, more concise, and cleaner):

d[::-1]


(AKA ""the Martian Smiley"", per my wife Anna;-).  Slicing (not slice assignment, which is a different operation) always perform a copy in core Python (language and standard library), though of course not necessarily in independently developed third party modules like the popular numpy (which prefers to see a slice as a ""view"" on the original numpy.array).
",Why don't Python's list comprehensions make copies of arguments so actual objects can't be mutated?,"Maybe I've been drinking too much of the functional programming Kool Aid, but this behavior of list comprehensions seems like a bad design choice:

>>> d = [1, 2, 3, 4, 5]
>>> [d.pop() for _ in range(len(d))]
[5, 4, 3, 2, 1]
>>> d
[]


Why is d not copied, and then the copied lexically-scoped version not mutated (and then lost)? The point of list comprehensions seems like it should be to return the desired list, not return a list and silently mutate some other object behind the scenes. The destruction of d is somewhat implicit, which seems unPythonic. Is there a good use case for this?  

Why is it advantageous to have list comps behave exactly like for loops, rather than behave more like functions (from a functional language, with local scope)?
"
"In Python, strings are immutable, so you have to create a new string.  You have a few options of how to create the new string.  If you want to remove the 'M' wherever it appears:

newstr = oldstr.replace(""M"", """")


If you want to remove the central character:

midlen = len(oldstr)/2
newstr = oldstr[:midlen] + oldstr[midlen+1:]


You asked if strings end with a special character.  No, you are thinking like a C programmer.  In Python, strings are stored with their length, so any byte value, including \0, can appear in a string.
",How to delete a character from a string using python?,"There is a string, for example EXAMPLE

How can I remove the middle character i.e. M from it. I don't need the code, what I want to know is


Do strings in python end in any special character?
Which is a better way - shifting everything right to left starting from the middle character OR creation of a new string and not copying the middle character?

"
"try changing the inner loop to something like this

results += [each for each in os.listdir(folder) if each.endswith('.c')]

",Python: How can I find all files with a particular extension?,"I am trying to find all the .c files in a directory using Python. 

I wrote this, but it is just returning me all files - not just .c files.

import os
import re

results = []

for folder in gamefolders:
    for f in os.listdir(folder):
        if re.search('.c', f):
            results += [f]

print results


How can I just get the .c files?
"
"Ned's GetLongPathName answer doesn't quite work (at least not for me). You need to call GetLongPathName on the return value of GetShortPathname. Using pywin32 for brevity (a ctypes solution would look similar to Ned's):

>>> win32api.GetLongPathName(win32api.GetShortPathName('stopservices.vbs'))
'StopServices.vbs'

","In Python, how can I get the correctly-cased path for a file?","Windows uses case-insensitive file names, so I can open the same file with any of these:

r""c:\windows\system32\desktop.ini""
r""C:\WINdows\System32\DESKTOP.ini""
r""C:\WiNdOwS\SyStEm32\DeSkToP.iNi""


etc.  Given any of these paths, how can I find the true case?  I want them all to produce:

r""C:\Windows\System32\desktop.ini""


os.path.normcase doesn't do it, it simply lowercases everything. os.path.abspath returns an absolute path, but each of these is already absolute, and so it doesn't change any of them.  os.path.realpath is only used to resolve symbolic links, which Windows doesn't have, so it's the same as abspath on Windows.

Is there a straightforward way to do this? 
"
"base = ord('A') - 1
mystring = 'ABC'
print sum(ord(char) - base for char in mystring)

",How do I assign a numerical value to each uppercase Letter?,"How do i assign a numerical value to each uppercase letter, and then use it later via string and then add up the values.

EG. 

A = 1, B = 2, C = 3 (etc..)

string = 'ABC'


Then return the answer 6 (in this case).
"
"os.path.dirname(os.path.abspath(__file__))


is indeed the best you're going to get.

It's unusual to be executing a script with exec/execfile; normally you should be using the module infrastructure to load scripts. If you must use these methods, I suggest setting __file__ in the globals you pass to the script so it can read that filename.

There's no other way to get the filename in execed code: as you note, the CWD may be in a completely different place.
",How to properly determine current script directory in Python?,"I would like to see what is best way to determine current script directory in python?

I discovered that two to the many ways of calling python code, it is hard to find a good solution.

Here are some problems:


__file__ is not defined if the script is executed with exec, execfile
__module__ is defined only in modules


Use cases: 


./myfile.py
python myfile.py
./somedir/myfile.py
python somedir/myfile.py
execfile('myfile.py') (from another script, that can be located in another directory and that can have another current directory.


I know that there is no perfect solution, because in some cases but I'm looking for the best approach that solved most of the cases.

The most used approach is os.path.dirname(os.path.abspath(__file__)) but this really doesn't work if you execute the script from another one with exec().

Warning

Any solution that uses current directory will fail, this can be different based on the way the script is called or it can be changed inside the running script.
"
"Choosing a framework for a project you already know what will be the purpose will only slow your development down. If your project's main goal is to be an online store, then pick your choice among the many projects already implemented for you with payment gateways, shipping options, product management, etc. A framework may offer all that too, but will not be ready-to-use out of the box and you will have to bind everything together yourself. My personal opinion is that frameworks are good candidate when you need an highly customized web application that you will write from scratch, that will not only do e-Commerce but handle other specific business models too.

General purpose CMS such as Drupal, WordPress, etc. are good if you plan to extend your online store to also offer other options (i.g. forums, blogs, multimedia/interactive contents, etc.) If you choose to pick this avenue, I would suggest you download the source code of each CMS you retain and play with it for a while and pick the one you feel the most comfortable with, and which has a good user community. Because there's nothing worst than being stuck with someone else's broken code with no one to help you out.

For e-Commerce solutions, you can find many good projects here. If I may choose one to suggest, a solution that you may consider as it looks simple, it is written in PHP and has good reviews is OpenCart

A good one I have worked with is the Instinct e-Commerce plugin for WordPress. I don't necessarily like WordPress, but that plugin is fairly good and will have you get your online store up and running in no time. The plugin also enable you to code new custom payment gateways fairly easily (just one file to code...)
",CMS or Framework?,"I'm looking to build a online store. However, the first question, past the idea of the store, is the platform. I've previously worked with Java and PHP and am quite comfortable with PHP. So my first considerations were Drupal or maybe CodeIgniter (which I have heard lots of good  things about)

On discussions with friends, they suggested Django. But I have no experience with Python or Django.

So my question is, is CI better or Drupal? And further, if not either of them, is Django better in terms of ease of development and extensibility?

Request you to not make this a php vs python battle as I'm looking for advice here. Thanks

Edit: More information about the project:

The Project is intended to create a web-store for certain products which aren't currently sold online. The store will have high-resolution images of the products and other associated details. A few other special features related to the products will be added on in time so they aren't that important.

Another clarification: I understand that Drupal is a CMS and not a framework per so. The only reason I compared it to CI was due to the base platform - php. Perhaps the better comparison would have been Joomla vs Django (but I'm not sure as I do not know enough about either, yet)
"
"I would advise taking a look at the Timer class in the threading module.  I used it to implement a timeout for a Popen.

First, create a callback:

    def timeout( p ):
        if p.poll() is None:
            print 'Error: process taking too long to complete--terminating'
            p.kill()


Then open the process:

    proc = Popen( ... )


Then create a timer that will call the callback passing the process to it.

    t = threading.Timer( 10.0, timeout, [proc] )
    t.start()
    t.join()


Somewhere later in the program, you may want to add the line:

    t.cancel()


Otherwise, the python program will keep running until the timer has finished running.

EDIT: I was advised that there is a race condition that the subprocess p may terminate between the p.poll() and p.kill() calls.  I believe the following code can fix that:

    import errno

    def timeout( p ):
        if p.poll() is None:
            try:
                p.kill()
                print 'Error: process taking too long to complete--terminating'
            except OSError as e:
                if e.errno != errno.ESRCH:
                    raise


Though you may want to clean the exception handling to specifically handle just the particular exception that occurs when the subprocess has already terminated normally.
",Python subprocess timeout?,"Is there any argument or options to setup a timeout for Python's subprocess.Popen method?

Something like this:

subprocess.Popen(['..'], ..., timeout=20) ?
"
"All modern languages require this because referencing a function and calling a function are separate actions.

For example,

def func():
    print ""hello""
    return 10
a = func
a()


Clearly, a = func and a = func() have very different meanings.

Ruby--the most likely language you're thinking of in contrast--doesn't require the parentheses; it can do this because it doesn't support taking references to functions.
","Why does java/javascript/python force the use of () after a method name, even if it takes no arguments?","One of my most common bugs is that I can never remember whether something is a method or a property, so I'm constantly adding or removing parentheses.

So I was wondering if there was good logic behind making the difference between calling on an object's properties and methods explicit.

Obviously, it allows you to have properties and methods that share the same name, but I don't think that comes up much.

The only big benefit I can come up with is readability.  Sometimes you might want to know whether something is a method or a property while you're looking at code, but I'm having trouble coming up with specific examples when that would be really helpful.  But I am a n00b, so I probably just haven't encountered such a situation yet. I'd appreciate examples of such a situation.

Also, are there other languages where the difference isn't explicit?  

Anyways, if you could answer, it will help me be less annoyed every time I make this mistake ^-^.

UPDATE:
Thanks everyone for the awesome answers so far! I only have about a week's worth of js, and 1 day of python, so I had no idea you could reference functions without calling them. That's awesome. I have a little more experience with java, so that's where I was mostly coming from... can anyone come up with an equally compelling argument for that to be the case in java, where you can't reference functions? Aside from it being a very explicit language, with all the benefits that entails :). 
"
"The subprocess module will help you out. 

Here is a decent tutorial. 

Blatantly trivial example:

>>> import subprocess
>>> subprocess.call(['./test.sh']) # Thanks @Jim Dennis for suggesting the []
0 
>>> 


Where test.sh is a simple shell script and 0 is its return value for this run.
",How to call a shell script from python code?,"how to call a shell script from python code?
"
"Old question, new answer (for Java 8)

    IntStream.range(0, 10).forEach(
        n -> {
            System.out.println(n);
        }
    );


or with method references:

IntStream.range(0, 10).forEach(System.out::println);

","Java: Equivalent of Python's range(int, int)?","Does Java have an equivalent to Python's range(int, int) method?
"
"What gets returned is the return value of executing this command. What you see in while executing it directly is the output of the command in stdout. That 0 is returned means, there was no error in execution.

Use popen etc for capturing the output .

Some thing along this line:

import subprocess as sub
p = sub.Popen(['your command', 'arg1', 'arg2', ...],stdout=sub.PIPE,stderr=sub.PIPE)
output, errors = p.communicate()
print output


or 

import os
p = os.popen('command',""r"")
while 1:
    line = p.readline()
    if not line: break
    print line


ON SO : Popen and python
","Python, os.system for command-line call (linux) not returning what it should?","I need to make some command line calls to linux and get the return from this, however doing it as below is just returning 0 when it should return a time value, like 00:08:19, I am testing the exact same call in regular command line and it returns the time value 00:08:19 so I am confused as to what I am doing wrong as I thought this was how to do it in python. Any advice is appreciated.

import os
retvalue = os.system(""ps -p 2993 -o time --no-headers"")
print retvalue

"
"Make sure your code is well structured (proper indentation, blank lines to separate sections of code, etc.) and use standard, consistent, and fully named (rather than incomprehensible abbreviated) variable names.

Others would suggest using proper comments. I would tend to disagree. If your code is well structured and variables well named, then comments would just clutter things up. The exception to the rule being when you must do something counter-intuitive to work around a bug somewhere else (I've had to resort to this in WCF and Entity Framework code in the past).
",Are there any basic standards and practices for making human readable code?,"More specifically making HTML, Java, and python more readable? Does anyone have suggestions for this programming student?
"
"User @i_4_got points to this page with a very efficent solution in Python. I reproduce it here for convenience (since it would have made me happy to have it here):

def ccw(A,B,C):
    return (C.y-A.y) * (B.x-A.x) > (B.y-A.y) * (C.x-A.x)

# Return true if line segments AB and CD intersect
def intersect(A,B,C,D):
    return ccw(A,C,D) != ccw(B,C,D) and ccw(A,B,C) != ccw(A,B,D)

",How can I check if two segments intersect?,"How can I check if 2 segments intersect?

I've the following data:

Segment1 [ {x1,y1}, {x2,y2} ]
Segment2 [ {x1,y1}, {x2,y2} ] 


I need to write a small algorithm in python to detect if the 2 lines are intersecting.

Update:
"
"There are a couple of ways you might want to go about this: the most simple would probably be to use something like Adobe AIR, which is basically a Webkit rendering engine with an extended javascript engine, which allows you to program in more complex functionality.

Otherwise you could check out the wxWebConnect project, which is aimed at enabling ""developers to quickly integrate advanced Web browser capabilities into their own applications."" and is provided as a wxWidgets control library, which is something most python developers should be familiar with. It integrates the Mozilla Gecko rendering engine into your application.
",how to write a desktop application which uses HTML and CSS for user interface and python/perl/c++/java for the processing?,"Different languages have different GUI toolkits, but it looks very difficult to achieve attractive user interfaces as good as we can using HTML and CSS with less effort. 
I don't do my application in javascript as I doubt if it has all the required libraries and I want to do it in python.

How do I use rendering engines like gecko, webkit etc in python? Which one will be more suited to work with python?.Is there any 'only html/css' rendering engine without javascript? 

Will it be easy to write event handlers for DOM events and manipulate DOM in python? 
"
"I've managed O(n log n).

Here is a (somewhat intense) C++ implementation:

#include 
#include 

#include 
#include 
#include 


typedef std::map rank_t;
typedef std::map parent_t;

typedef boost::associative_property_map rank_pmap_t;
typedef boost::associative_property_map parent_pmap_t;

typedef boost::disjoint_sets group_sets_t;

typedef std::set key_set;
typedef std::map > output;


With some typedefs out of the way, here's the real meat.  I'm using boost::disjoint_sets, which is just happens to be an exceptionally good representation for the problem.  This first function checks to see if either of the keys given have been seen before, and adds them to the collections if needed.  the important part is really the union_set(a, b) which links the two sets together.  If one or the other of the sets are already in the groups collection, they get linked too.

void add_data(int a, int b, group_sets_t & groups, key_set & keys)
{
  if (keys.count(a) < 1) groups.make_set(a);
  if (keys.count(b) < 1) groups.make_set(b);
  groups.union_set(a, b);
  keys.insert(a);
  keys.insert(b);
}


This isn't too exciting, it just iterates through all of the keys we've seen and gets the representative key for that key, then adds the pair (representative, key) to a map.  Once that's done, print out the map.

void build_output(group_sets_t & groups, key_set & keys)
{
  output out;
  for (key_set::iterator i(keys.begin()); i != keys.end(); i++)
    out[groups.find_set(*i)].insert(*i);

  for (output::iterator i(out.begin()); i != out.end(); i++)
  {
    std::cout first << "": "";
    for (output::mapped_type::iterator j(i->second.begin()); j != i->second.end(); j++)
      std::cout << *j << "" "";
    std::cout << std::endl;
  }
}

int main()
{

  rank_t rank;
  parent_t parent;
  rank_pmap_t rank_index(rank);
  parent_pmap_t parent_index(parent);


  group_sets_t groups( rank_index, parent_index );
  key_set keys;

  int a, b;
  while (std::cin >> a)
  {
    std::cin >> b;
    add_data(a, b, groups, keys);
  }  


  build_output(groups, keys);
  //std::cout << ""number of sets: "" << 
  //  groups.count_sets(keys.begin()), keys.end()) << std::endl;

}


I stayed up many hours learning how to use boost::disjoint_sets on this problem.  There doesn't seem to be much of any documentation on it.  

About the performance.  The disjoint_sets structure is O(α(n) ) for its key operations (make_set, find_set and union_set) which is pretty close to constant, and so if it were just a matter of building the structure, the whole algorithm would be O(n α(n) ) (which is effectively O(n) ) but we have to print it out.  That means we have to build up some associative containers, which cannot perform better than O(n log n).  It might be possible to get a constant factor speedup by choosing a different associative containers (say, hash_set etc), since once you populate the initial list, you can reserve an optimal amount of space.
",Trying to group values?,"I have some data like this:

1 2
3 4
5 9
2 6
3 7


and am looking for an output like this (group-id and the members of that group):

1: 1 2 6
2: 3 4 7
3: 5 9


First row because 1 is ""connected"" to 2 and 2 is connected to 6.
Second row because 3 is connected to 4 and 3 is connected to 7

This looked to me like a graph traversal but the final order does not matter so I was wondering if someone can suggest a simpler solution that I can use on a large dataset (billions of entries).



From the comments:


The problem is to find the set of disjoint sub-graphs given a set of edges.
The edges are not directed; the line '1 2' means that 1 is connected to 2 and 2 is connected to 1.
The '1:' in the sample output could be 'A:' without changing the meaning of the answer.


EDIT 1:

Problem looks solved now. Thanks to everyone for their help. I need some more help picking the best solution that can be used on billions of such entries.

EDIT 2:

Test Input file:

1 27
1 134
1 137
1 161
1 171
1 275
1 309
1 413
1 464
1 627
1 744
2 135
2 398
2 437
2 548
2 594
2 717
2 738
2 783
2 798
2 912
5 74
5 223
7 53
7 65
7 122
7 237
7 314
7 701
7 730
7 755
7 821
7 875
7 884
7 898
7 900
7 930
8 115
9 207
9 305
9 342
9 364
9 493
9 600
9 676
9 830
9 941
10 164
10 283
10 380
10 423
10 468
10 577
11 72
11 132
11 276
11 306
11 401
11 515
11 599
12 95
12 126
12 294
13 64
13 172
13 528
14 396
15 35
15 66
15 210
15 226
15 360
15 588
17 263
17 415
17 474
17 648
17 986
21 543
21 771
22 47
23 70
23 203
23 427
23 590
24 286
24 565
25 175
26 678
27 137
27 161
27 171
27 275
27 309
27 413
27 464
27 627
27 684
27 744
29 787


Benchmarks:

I tried out everything and the version posted by TokenMacGuy is the fastest on the sample dataset that I tried. The dataset has about 1 million entries for which it took me about 6 seconds on a Dual Quad-Core 2.4GHz machine. I haven't gotten a chance to run it on the entire dataset yet but I will post the benchmark as soon as it is available.
"
"If you want to remove \n from the last element only, use this:

t[-1] = t[-1].strip()


If you want to remove \n from all the elements, use this:

t = map(lambda s: s.strip(), t)


You might also consider removing \n before splitting the line:

line = line.strip()
# split line...

",How to remove \n from a list element?,"I'm trying to get Python to a read line from a .txt file and write the elements of the first line into a list. The elements in the file were tab- separated so I used split(""\t"") to separate the elements. Because the .txt file has a lot of elements I saved the data found in each line into a separate list.

The problem I currently have is that it's showing each list like this:

['Name1', '7.3', '6.9', '6.6', '6.6', '6.1', '6.4', '7.3\n']


How can I remove \n from the last element of the list and make it just '7.3'?
"
"It is highly probable that re.finditer(link) uses fairly minimal memory overhead.

def split_iter(string):
    return (x.group(0) for x in re.finditer(r""[A-Za-z']+"", string))


Demo:

>>> list( split_iter(""A programmer's RegEx test."") )
['A', ""programmer's"", 'RegEx', 'test']


edit: I have just confirmed that this takes constant memory in python 3.2.1, assuming my testing methodology was correct. I created a string of very large size (1GB or so), then iterated through the iterable with a for loop (NOT a list comprehension, which would have generated extra memory). This did not result in a noticeable growth of memory (that is, if there was a growth in memory, it was far far less than the 1GB string).
",Is there a generator version of `string.split()` in Python?,"string.split() returns a list instance. Is there a version that returns a generator instead? Are there any reasons against having a generator version? 
"
"Note: The author disavows a deep expertise in this subject. Some assertions may be incorrect.

Python actually is compiled into bytecode, which is what gets run by the python interpreter.  Whenever you use a Python module, Python will generate a .pyc file with a name corresponding to the module.  This is the equivalent of the .o file that's generated when you compile a C file.

So if you want something to disassemble, the .pyc file would be it :)

The process that Python goes through when compiling a module is pretty similar to what gcc or another C compiler does with C source code.  The major difference is that it happens transparently as part of execution of the file.  It's also optional: when running a non-module, i.e. an end-user script, Python will just interpret the code rather than compiling it first.

So really your question is ""Why are python programs distributed as source rather than as compiled modules?""  Or, put another way, ""Why are C applications distributed as compiled binaries rather than as source code?""

It used to be very common for C applications to be distributed as source code.  This was back before operating systems and their various subentities (i.e. linux distributions) became more established.  Some distros, for example gentoo, still distribute apps as source code.  Apps which are a bit more cutting edge or obscure are still distributed as source code for all platforms they target.

The reason for this is compatibility, and dependencies.  The reason you can run the precompiled binary Safari on a Mac, or Firefox on Ubuntu Linux, is because it's been specifically built for that operating system, architecture (e.g. x86_64), and set of libraries.

Unfortunately, compilation of a large app is pretty slow, and needs to be redone at least partially every time the app is updated.  Thus the motivation for binary distributions.

So why not create a binary distribution of Python?  For one thing, as Aaron mentions, modules would need to be recompiled for each new version of the Python bytecode.  But this would be similar to rebuilding a C app to link with a newer version of a dynamic library â Python modules are analogous in this sense to C libraries.

The real reason is that Python compilation is very much quicker than C compilation.  This is in part, I think, because of the dynamic nature of the language, and also because it's not as thorough of a compilation.  This has its tradeoffs: in particular, Python apps run much more slowly than do their C counterparts, because Python has to interpret the compiled bytecode into instructions for the processor, whereas the C app already contains such instructions.

That all being said, there is a program called py2exe that will take a Python module and distribution and build a precompiled windows executable, including in it the logic of the module and its dependencies, including Python itself. I guess the point of this is to avoid having to coerce people into installing Python on their Windows system just to run your app. Under linux, or I think even OS/X, Python is usually already installed, so precompilation is not really necessary. Linux systems also have super-dandy package managers that will transparently install dependencies such as Python if they are not already installed.
",Why do C programs require decompilers but python programs dont?,"If I write a python script, anyone can simply point an editor to it and read it. But for programming written in C, one would have to use decompilers and hex tables and such. Why is that? I mean I simply can't open up the Safari web browser and look at its code.
"
"Here's a few different approaches you could use:

Compare lengths


Find the length of the original string.
Sum the length of the matched strings. 
If the two numbers differ there were unused characters.


Note that you can also combine this method with your existing code rather than doing it as an extra step if you want to avoid parsing the string twice.

Regular expression for entire string

You can check if this regular expression matches the entire string:

^([A-Z][a-z]{0,2}\d*)*$


(Rubular)

Tokenize

You can use the following regular expression to tokenize the original string:

[A-Z][^A-Z]*


Then check each token to see if it matches your original regular expression.
","How to check that a regular expression has matched a string completely, i.e. - the string did not contain any extra character?","I have two questions:

1) I have a regular expression ([A-Z][a-z]{0,2})(\d*) and I am using Python's re.finditer() to match appropriate strings. My problem is, that I want to match only strings that contain no extra characters, otherwise I want to raise an exception. 

I want to catch a following pattern:
- capital letter, followed by 0, 1 or 2 small letters, followed by 0 or more numbers.

The pattern represents a chemical formula, i.e. atom followed by number of it's occurences. I want to put the atom into a dictionary with it's number of occurences, so I need to separate atoms (capital letter followed by 0, 1 or 2 small letters) and numbers, but remember that they belong together. 

Example:

C6H5Fe2I   # this string should be matched successfully. Result: C6 H5 Fe2 I
H2TeO4     # this string should be matched successfully Result: H2 Te O4
H3PoooO5   # exception should be raised
C2tH6      # exception should be raised


2) second question is what kind of Exception should I raise in case the input string is wrong.

Thank you, Tomas
"
"5.55 % 1


Keep in mind this won't help you with floating point rounding problems. I.e., you may get:

0.550000000001


Or otherwise a little off the 0.55 you are expecting.
",python: how to get numbers after decimal point?,"how do i get the numbers after a decimal point?

for example if i have 5.55

how do i get .55?
"
"If you'd prefer just an integer number of cents:

cents_int = int(round(float(dollars.strip('$'))*100))


If you want a Decimal, just use...

from decimal import Decimal
dollars_dec = Decimal(dollars.strip('$'))


If you know that the dollar sign will always be there, you could use dollars[1:] instead of dollars.strip('$'), but using strip() lets you also handle strings that omit the dollar sign (5.99 instead of $5.99).
",python: how to convert currency to decimal?,"i have dollars in a string variable

dollars = '$5.99'


how do i convert this to a decimal instead of a string so that i can do operations with it like adding dollars to it?
"
"Change the line to this:

handler = SysLogHandler(address='/dev/log')


This works for me

import logging
import logging.handlers

my_logger = logging.getLogger('MyLogger')
my_logger.setLevel(logging.DEBUG)

handler = logging.handlers.SysLogHandler(address = '/dev/log')

my_logger.addHandler(handler)

my_logger.debug('this is debug')
my_logger.critical('this is critical')

",How to configure logging to syslog in python?,"I can't get my head around Python's logging module. My needs are very simple: I just want to log everything to syslog. After reading documentation I came up with this simple test script:

import logging
import logging.handlers

my_logger = logging.getLogger('MyLogger')
my_logger.setLevel(logging.DEBUG)

handler = logging.handlers.SysLogHandler()

my_logger.addHandler(handler)

my_logger.debug('this is debug')
my_logger.critical('this is critical')


But this script does not produce any log records in syslog. What's wrong?
"
"a.index(max(a))


will tell you the index of the first instance of the largest valued element of list a.
",How to find all positions of the maximum value in a list?,"I have a list:

a = [32, 37, 28, 30, 37, 25, 27, 24, 35, 55, 23, 31, 55, 21, 40, 18, 50,
             35, 41, 49, 37, 19, 40, 41, 31]


max element is 55 (two elements on position 9 and 12)

I need to find on which position(s) the maximum value is situated. Please, help.
"
"If you like R's layout. I highly recommend trying out Spyder. If you are using windows, try out Python(x,y). It is a package with a few different editors and a lot of common extra modules like scipy and numpy.
",Which Python IDE can run my script line-by-line?,"I wouldn't call myself programmer, but I've started learning Python recently and really enjoy it.

I mainly use it for small tasks so far - scripting, text processing, KML generation and ArcGIS.

From my experience with R (working with excellent Notepad++ and NppToR combo) I usually try to work with my scripts line by line (or region by region) in order to understand what each step of my script is doing.. and to check results on the fly.

My question: is there and IDE (or editor?) for Windows that lets you evaluate single line of Python script?

I have seen quite a lot of discussion regarding IDEs in Python context.. but havent stubled upon this specific question so far.

Thanks for help!
"
"Are you the only one who's going to read the code? 

No matter what language you're programming in, it's recommended practice to keep code line length down.
There are typically 2 types of causes for long lines:


Deeply nested code: this type of code is hard to follow, especially if you have more than 2 levels of nesting. There is a tendency to miss else clauses when reading the code, or forgetting which else is for what if when reading longer functions. Try to break the code in several functions to improve readability.
Complex expressions: like when you access a value from an object from an object from an object ... Or when you need to do a single operation on multiple values from 10 different places and you merge all the function calls and operators in a single line. You'll significantly improve the readability if you use temporary variables to split the logic into smaller segments that are easier to grasp. You should also look into this.


That being said, that PEP is just a guideline. Feel free to break it when you feel you're justified to do so. If you break it most of the time you need to reconsider the way you write code.
",Is it bad that I don't follow PEP 8 and cut my lines at 79 characters?,"I think every Python code has seen PEP 8. The part that sticks out to me is:

Limit all lines to a maximum of 79 characters.


I'm sitting here on a widescreen monitor and coding right across the screen. I'm not coding in a terminal and don't plan on coding in a terminal. I therefor have no problems with character-line limits.

How many people actually follow this limit? Do you still follow it if you're not coding in a 80 character limit terminal? Is it bad that I don't follow it?

I hate how this restriction is apart of 'the style guide' for Python >.
"
"If you're after webkit bindings for Python, look at PyQt, which includes Webkit, as well as wxWebkit (http://wxwebkit.wxcommunity.com/) if you're using wxWidgets. This lets you embed webkit in a Qt or Wxwidgets app so that you won't have to go through a browser.

If you do use this, then you can either use a web server in Python, like others have mentioned, or you can control the Webkit control directly (though I'm not sure how practical this is).

Beyond that, there's also Pyjamas Desktop (http://pyjs.org/), which lets you use Pyjamas to build the application, then run it.
",How can I use HTML + Javascript to build a python GUI?,"I have been experimenting with Appcelerator Titanum yesterday and I think it's cool when it comes to Javascript.  

Python features on Appcelerator Titanum are so limited (can't use some modules for example).  

My question is How can I use html & javascript as a GUI tool for a real python application ?  

I am running windows 7 and i was thinking of using webkit for that purpose but couldn't know how to work with it in python.  

I am planning to make a standalone executable using py2exe as I don't know if the users always have python and the appropriate modules installed.
"
"Serialization is just a fancy way of describing what you do when you want a certain data structure, class, etc to be transmitted.

For example, say I have a structure:

struct Color
{
    int R, G, B;
};


When you transmit this over a network you don't say send Color. You create a line of bits and send it. I could create an unsigned char* and concatenate R, G, and B and then send these. I just did serialization
",Is serialization a must in order to transfer data across the wire?,"Below is something I read and was wondering if the statement is true.


  Serialization is the process of
  converting a data structure or object
  into a sequence of bits so that it can
  be stored in a file or memory buffer,
  or transmitted across a network
  connection link to be ""resurrected""
  later in the same or another computer
  environment.[1] When the resulting
  series of bits is reread according to
  the serialization format, it can be
  used to create a semantically
  identical clone of the original
  object. For many complex objects, such
  as those that make extensive use of
  references, this process is not
  straightforward.

"
"The advice seems poor to me. When you're iterating over some kind of collection, it is usually better to use one of Python's iteration tools, but that doesn't mean that while is always wrong. There are lots of cases where you're not iterating over any kind of collection.

For example:

def gcd(m, n):
    ""Return the greatest common divisor of m and n.""
    while n != 0:
        m, n = n, m % n
    return m


You could change this to:

def gcd(m, n):
    ""Return the greatest common divisor of m and n.""
    while True:
        if n == 0:
            return m
        m, n = n, m % n


but is that really an improvement? I think not.
",Why avoid while loops?,"I'm about 2 weeks deep in my study of Python as an introductory language.  I've hit a point in Zed's ""Learn Python the Hard Way"" where he suggests:


  Use a while-loop only to loop forever, and that means probably never.  This only applies
      to Python, other languages are different.


I've googled all over this, referenced everything I can, but I can't find any reason in the world why this would be a convention in Python.  What makes it different? 

When I gave up programming 10 years ago, I was working in VB and would regularly be told to get rid of my For loops and use While loops instead.  I was a hack (as I am today, though I wrote a LOT of code back then), so I just did what I was told without questioning it.  Well, now I'm questioning it.  Is this a speed issue?  Is it just to avoid escape-less infinites?
"
"Use socket and its gethostname() functionality. This will get the hostname of the computer where the Python interpreter is running:

import socket
print(socket.gethostname())

",How can I use Python to get the system hostname?,"I'm writing a chat program for a local network. I would like be able to identify computers and get the user-set computer name with Python.
"
"As a temporary workaround you can try dumping in JSON format.
You lose some type information, but it looks nice and keeps the order.

import json

pprint(data, indent=4)
# ^ugly

print(json.dumps(data, indent=4))
# ^nice

",Any way to properly pretty-print ordered dictionaries in Python?,"I like the pprint module in Python. I use it a lot for testing and debugging. I frequently use the width option to make sure the output fits nicely within my terminal window.

It has worked fine until they added the new ordered dictionary type in Python 2.7 (another cool feature I really like). If I try to pretty-print an ordered dictionary, it doesn't show nicely. Instead of having each key-value pair on its own line, the whole thing shows up on one long line, which wraps many times and is hard to read.

Does anyone here have a way to make it print nicely, like the old unordered dictionaries? I could probably figure something out, possibly using the PrettyPrinter.format method, if I spend enough time, but I am wondering if anyone here already knows of a solution.

UPDATE: I filed a bug report for this. You can see it at http://bugs.python.org/issue10592.
"
"This one works except for leaving the first word as lowercase.

def convert(word):
    return ''.join(x.capitalize() or '_' for x in word.split('_'))


(I know this isn't exactly what you asked for, and this thread is quite old, but since it's quite prominent when searching for such conversions on Google I thought I'd add my solution in case it helps anyone else).
",How can I simplify this conversion from underscore to camelcase in Python?,"I have written the function below that converts underscore to camelcase with first word in lowercase, i.e. ""get_this_value"" -> ""getThisValue"". Also I have requirement to preserve leading and trailing underscores and also double (triple etc.) underscores, if any, i.e.

""_get__this_value_"" -> ""_get_ThisValue_"".


The code:

def underscore_to_camelcase(value):
    output = """"
    first_word_passed = False
    for word in value.split(""_""):
        if not word:
            output += ""_""
            continue
        if first_word_passed:
            output += word.capitalize()
        else:
            output += word.lower()
        first_word_passed = True
    return output


I am feeling the code above as written in non-Pythonic style, though it works as expected, so looking how to simplify the code and write it using list comprehensions etc.
"
"You can do this without installing anything into python itself.

You don't need sudo or any privileges.

You don't need to edit any files.

Install virtualenv into a bootstrap virtual environment. Use the that virtual environment to create more. Since virtualenv ships with pip and distribute, you get everything from one install.


Download virtualenv:

http://pypi.python.org/pypi/virtualenv
https://pypi.python.org/packages/source/v/virtualenv/virtualenv-12.0.7.tar.gz
(or whatever is the latest version!)

Unpack the source tarball
Use the unpacked tarball to create a clean virtual environment. This virtual environment will be used to ""bootstrap"" others. All of your virtual environments will automatically contain pip and distribute.
Using pip, install virtualenv into that bootstrap environment.
Use that bootstrap environment to create more!


Here is an example in bash:

# Select current version of virtualenv:
VERSION=12.0.7
# Name your first ""bootstrap"" environment:
INITIAL_ENV=bootstrap
# Set to whatever python interpreter you want for your first environment:
PYTHON=$(which python)
URL_BASE=https://pypi.python.org/packages/source/v/virtualenv

# --- Real work starts here ---
curl -O $URL_BASE/virtualenv-$VERSION.tar.gz
tar xzf virtualenv-$VERSION.tar.gz
# Create the first ""bootstrap"" environment.
$PYTHON virtualenv-$VERSION/virtualenv.py $INITIAL_ENV
# Don't need this anymore.
rm -rf virtualenv-$VERSION
# Install virtualenv into the environment.
$INITIAL_ENV/bin/pip install virtualenv-$VERSION.tar.gz


Now you can use your ""bootstrap"" environment to create more:

# Create a second environment from the first:
$INITIAL_ENV/bin/virtualenv py-env1
# Create more:
$INITIAL_ENV/bin/virtualenv py-env2


Go nuts!

Note

This assumes you are not using a really old version of virtualenv.
Old versions required the flags --no-site-packges (and depending on the version of Python, --distribute). Now you can create your bootstrap environment with just python virtualenv.py path-to-bootstrap or python3 virtualenv.py path-to-bootstrap.
","What's the proper way to install pip, virtualenv, and distribute for Python?","Short Question


What is the proper way to install pip, virtualenv, and distribute?


Background

In my answer to SO question 4314376, I recommended using ez_setup so that you could then install pip and virtualenv as follows:

curl -O http://peak.telecommunity.com/dist/ez_setup.py
sudo python ez_setup.py
sudo easy_install pip
sudo pip install virtualenv


I originally pulled these instructions from Jesse Noller's blog post So you want to use Python on the Mac?. I like the idea of keeping a clean global site-packages directory, so the only other packages I install there are  virtualenvwrapper and distribute. (I recently added distribute to my toolbox because of this Python public service announcement. To install these two packages, I used:

sudo pip install virtualenvwrapper
curl -O http://python-distribute.org/distribute_setup.py
sudo python distribute_setup.py


No more setuptools and easy_install

To really follow that Python public service announcement, on a fresh Python install, I would do the following:

curl -O http://python-distribute.org/distribute_setup.py
sudo python distribute_setup.py
sudo easy_install pip
sudo pip install virtualenv
sudo pip install virtualenvwrapper


Glyph's Rebuke

In a comment to my answer to SO question 4314376, SO user Glyph stated:


  NO. NEVER EVER do sudo python setup.py install whatever. Write a ~/.pydistutils.cfg that puts your pip installation into ~/.local or something. Especially files named ez_setup.py tend to suck down newer versions of things like setuptools and easy_install, which can potentially break other things on your operating system.


Back to the short question

So Glyph's response leads me to my original question:


What is the proper way to install pip, virtualenv, and distribute?

"
"You can do that like this:

with open(""/etc/apt/sources.list"", ""r"") as sources:
    lines = sources.readlines()
with open(""/etc/apt/sources.list"", ""w"") as sources:
    for line in lines:
        sources.write(re.sub(r'^# deb', 'deb', line))


The with statement ensures that the file is closed correctly, and re-opening the file in ""w"" mode empties the file before you write to it. re.sub(pattern, replace, string) is the equivalent of s/pattern/replace/ in sed/perl.

Edit: fixed syntax in example
",How to do sed like text replace with python?,"I would like to enable all apt repositories in this file

cat /etc/apt/sources.list
## Note, this file is written by cloud-init on first boot of an instance                                                                                                            
## modifications made here will not survive a re-bundle.                                                                                                                            
## if you wish to make changes you can:                                                                                                                                             
## a.) add 'apt_preserve_sources_list: true' to /etc/cloud/cloud.cfg                                                                                                                
##     or do the same in user-data
## b.) add sources in /etc/apt/sources.list.d                                                                                                                                       
#                                                                                                                                                                                   

# See http://help.ubuntu.com/community/UpgradeNotes for how to upgrade to                                                                                                           
# newer versions of the distribution.                                                                                                                                               
deb http://us-east-1.ec2.archive.ubuntu.com/ubuntu/ maverick main                                                                                                                   
deb-src http://us-east-1.ec2.archive.ubuntu.com/ubuntu/ maverick main                                                                                                               

## Major bug fix updates produced after the final release of the                                                                                                                    
## distribution.                                                                                                                                                                    
deb http://us-east-1.ec2.archive.ubuntu.com/ubuntu/ maverick-updates main                                                                                                           
deb-src http://us-east-1.ec2.archive.ubuntu.com/ubuntu/ maverick-updates main                                                                                                       

## N.B. software from this repository is ENTIRELY UNSUPPORTED by the Ubuntu                                                                                                         
## team. Also, please note that software in universe WILL NOT receive any                                                                                                           
## review or updates from the Ubuntu security team.                                                                                                                                 
deb http://us-east-1.ec2.archive.ubuntu.com/ubuntu/ maverick universe                                                                                                               
deb-src http://us-east-1.ec2.archive.ubuntu.com/ubuntu/ maverick universe                                                                                                           
deb http://us-east-1.ec2.archive.ubuntu.com/ubuntu/ maverick-updates universe
deb-src http://us-east-1.ec2.archive.ubuntu.com/ubuntu/ maverick-updates universe

## N.B. software from this repository is ENTIRELY UNSUPPORTED by the Ubuntu 
## team, and may not be under a free licence. Please satisfy yourself as to
## your rights to use the software. Also, please note that software in 
## multiverse WILL NOT receive any review or updates from the Ubuntu
## security team.
# deb http://us-east-1.ec2.archive.ubuntu.com/ubuntu/ maverick multiverse
# deb-src http://us-east-1.ec2.archive.ubuntu.com/ubuntu/ maverick multiverse
# deb http://us-east-1.ec2.archive.ubuntu.com/ubuntu/ maverick-updates multiverse
# deb-src http://us-east-1.ec2.archive.ubuntu.com/ubuntu/ maverick-updates multiverse

## Uncomment the following two lines to add software from the 'backports'
## repository.
## N.B. software from this repository may not have been tested as
## extensively as that contained in the main release, although it includes
## newer versions of some applications which may provide useful features.
## Also, please note that software in backports WILL NOT receive any review
## or updates from the Ubuntu security team.
# deb http://us-east-1.ec2.archive.ubuntu.com/ubuntu/ maverick-backports main restricted universe multiverse
# deb-src http://us-east-1.ec2.archive.ubuntu.com/ubuntu/ maverick-backports main restricted universe multiverse

## Uncomment the following two lines to add software from Canonical's
## 'partner' repository.
## This software is not part of Ubuntu, but is offered by Canonical and the
## respective vendors as a service to Ubuntu users.
# deb http://archive.canonical.com/ubuntu maverick partner
# deb-src http://archive.canonical.com/ubuntu maverick partner

deb http://security.ubuntu.com/ubuntu maverick-security main
deb-src http://security.ubuntu.com/ubuntu maverick-security main
deb http://security.ubuntu.com/ubuntu maverick-security universe
deb-src http://security.ubuntu.com/ubuntu maverick-security universe
# deb http://security.ubuntu.com/ubuntu maverick-security multiverse
# deb-src http://security.ubuntu.com/ubuntu maverick-security multiverse


With sed this is a simple sed -i 's/^# deb/deb/' /etc/apt/sources.list what's the most elegant (""pythonic"") way to do this?
"
"The simplest is to convert to a set then back to a list:

my_list = list(set(my_list))


One disadvantage with this is that it won't preserve the order. You may also want to consider if a set would be a better data structure to use in the first place, instead of a list.
",How to make lists distinct?,"I have a list in Python, how can I make it's values unique?
"
"The stack frame tells us what code object we're in. If we can find a function object that refers to that code object in its func_code attribute, we have found the function.

Fortunately, we can ask the garbage collector which objects hold a reference to our code object, and sift through those, rather than having to traverse every active object in the Python world. There are typically only a handful of references to a code object.

Now, functions can share code objects, and do in the case where you return a function from a function, i.e. a closure. When there's more than one function using a given code object, we can't tell which function it is, so we return None.

import inspect, gc

def giveupthefunc():
    frame = inspect.currentframe(1)
    code  = frame.f_code
    globs = frame.f_globals
    functype = type(lambda: 0)
    funcs = []
    for func in gc.get_referrers(code):
        if type(func) is functype:
            if getattr(func, ""func_code"", None) is code:
                if getattr(func, ""func_globals"", None) is globs:
                    funcs.append(func)
                    if len(funcs) > 1:
                        return None
    return funcs[0] if funcs else None


Some test cases:

def foo():
    return giveupthefunc()

zed = lambda: giveupthefunc()

bar, foo = foo, None

print bar()
print zed()


I'm not sure about the performance characteristics of this, but i think it should be fine for your use case.
",Python code to get current function into a variable?,"How can I get a variable that contains the currently executing function in Python? I don't want the function's name. I know I can use inspect.stack to get the current function name. I want the actual callable object. Can this be done without using inspect.stack to retrieve the function's name and then evaling the name to get the callable object?

Edit: I have a reason to do this, but it's not even a remotely good one. I'm using plac to parse command-line arguments. You use it by doing plac.call(main), which generates an ArgumentParser object from the function signature of ""main"". Inside ""main"", if there is a problem with the arguments, I want to exit with an error message that includes the help text from the ArgumentParser object, which means that I need to directly access this object by calling plac.parser_from(main).print_help(). It would be nice to be able to say instead: plac.parser_from(get_current_function()).print_help(), so that I am not relying on the function being named ""main"". Right now, my implementation of ""get_current_function"" would be:

import inspect    
def get_current_function():
    return eval(inspect.stack()[1][3])


But this implementation relies on the function having a name, which I suppose is not too onerous. I'm never going to do plac.call(lambda ...).

In the long run, it might be more useful to ask the author of plac to implement a print_help method to print the help text of the function that was most-recently called using plac, or something similar.
"
"From http://docs.python.org/whatsnew/2.6.html#pep-3105-print-as-a-function

>>> from __future__ import print_function
>>> print('a', end='')


Obviously that only works with python 2.6 or higher.
","Printing without newline (print 'a',) prints a space, how to remove?","I have this code:

>>> for i in xrange(20):
...     print 'a',
... 
a a a a a a a a a a a a a a a a a a a a


I want to output 'a', without ' ' like this:

aaaaaaaaaaaaaaaaaaaa


Is it possible?
"
"Use re.search(): 

>>> import re
>>> s1 = ""thishasadigit4here""
>>> m = re.search(""\d"", s1)
>>> if m:
...     print ""Digit found at position %d"" % m.start()
... else:
...     print ""No digit in that string""
... 
Digit found at position 13
>>> 

",Python: find index of first digit in string?,"I suspect this is a regular expression problem - and a very basic one, so apologies. 

In Python, if I have a string like 

xdtwkeltjwlkejt7wthwk89lk


how can I get the index of the first digit in the string?

Thanks!
"
"8.833333333339 (or 8.833333333333334, the result of 106.00/12) properly rounded to two decimal places is 8.83. Mathematically it sounds like what you want is a ceiling function. The one in Python's math module is named ceil:

import math

v = 8.8333333333333339
print(math.ceil(v*100)/100)  # -> 8.84


Respectively, the floor and ceiling functions generally map a real number to the largest previous or smallest following integer which has zero decimal places â so to use them for 2 decimal places the number is first multiplied by 102 (or 100) to shift the decimal point and is then divided by it afterwards to compensate.

If you don't want to use the math module for some reason, you can use this (minimally tested) implementation I just wrote:

def ceiling(x):
    n = int(x)
    return n if n-1 < x <= n else n+1


How this applies to the linked loan and payment calculator problem



From the sample output it appears that they rounded up the monthly payment, which is what some call the effect of the ceiling function. This means that each month a little more than 1⁄12 of the total amount is being paid. That made the final payment a little smaller than usual â leaving a remaining unpaid balance of only 8.76.

It would have been equally valid to use normal rounding producing a monthly payment of 8.83 and a slightly higher final payment of 8.87. However, in the real world people generally don't like to have their payments go up, so rounding up each payment is the common practice â it also returns the money to the lender more quickly.
",How to round off a floating number?,"Suppose I am having 8.8333333333333339 and I want to convert it to 8.84, how can I accomplish this in python ? round(8.8333333333333339 , 2) gives 8.8300000000000001 and not 8.84. I am new to python or programming in general.

I don't want to print it as a string, the result will be further used. For more information on the problem please check this link http://openbookproject.net/pybiblio/practice/wilson/loan.php
"
"In the standard library, there is no cross-platform way to create aware timezones without creating your own timezone class.

On Windows, there's win32timezone.utcnow(), but that's part of pywin32. I would rather suggest to use the pytz library, which has an up-to-date database of most timezones.

Working with local timezones can be very tricky (read the pytz documentation!), so you may rather want to use UTC throughout your application. You can get the current date/time like so:

import pytz
from datetime import datetime
datetime.utcnow().replace(tzinfo=pytz.utc)


Mind that datetime.today() and datetime.now() return the local time, not the UTC time, so applying .replace(tzinfo=pytz.utc) to them would not be correct.

Another nice way to do it is:

datetime.now(pytz.utc)


which is a bit shorter and does the same.
","Python: How to get a value of datetime.today() that is ""timezone aware""?","I am trying to subtract one date value from the value of datetime.today() to calculate how long ago something was. But it complains:

TypeError: can't subtract offset-naive and offset-aware datetimes


The value datetime.today() doesn't seem to be ""timezone aware"", while my other date value is. How do I get a value of datetime.today() that is timezone aware? Right now it's giving me the time in local time, which happens to be PST, i.e. UTC-8hrs. Worst case, is there a way I can manually enter a timezone value into the datetime object returned by datetime.today() and set it to UTC-8? Of course, the ideal solution would be for it to automatically know the timezone.
"
"Bottle is a very lightweight micro-framework. It comes as a single .py-file with no external dependencies, supports routing, a small template-engine and comes with an integrated webserver. It is easy to use and slim.

This sounds like a perfect match to your requirements :) 
",Recommended python library/framework for local web app?,"I want to create a simple LOCAL web app in Python.

The web server and ""back-end"" code will run on the same system (initially, Windows system) as the UI. I doubt it matters, but the UI will be a typical webish combo of Google Chrome, HTML, CSS, JavaScript, and jQuery.

There are a TON of Python-based web programming frameworks, but they all seem designed for building sophisticated, large-scale apps with lots of back-end infrastructure. I want the opposite: Something very simple, lightweight, and easily self-contained--just enough web server and framework to create/support a local web app.

Suggestions?
"
"def get_client_ip(request):
    x_forwarded_for = request.META.get('HTTP_X_FORWARDED_FOR')
    if x_forwarded_for:
        ip = x_forwarded_for.split(',')[0]
    else:
        ip = request.META.get('REMOTE_ADDR')
    return ip


Make sure you have reverse proxy (if any) configured correctly (e.g. mod_rpaf installed for Apache).

Note: the above uses the first item in X-Forwarded-For, but you might want to use the last item (e.g., in the case of Heroku: Get client's real IP address on Heroku)

get_client_ip = lambda req: req.META.get('HTTP_X_FORWARDED_FOR') if req.META.get('HTTP_X_FORWARDED_FOR') else ip = request.META.get('REMOTE_ADDR')


And then just pass the request as argument to it;

get_client_ip(request)

",How do I get user IP address in django?,"How do I get user's IP in django?

I have a view like this:

# Create your views
from django.contrib.gis.utils import GeoIP
from django.template import  RequestContext
from django.shortcuts import render_to_response


def home(request):
  g = GeoIP()
  client_ip = request.META['REMOTE_ADDR']
  lat,long = g.lat_lon(client_ip)
  return render_to_response('home_page_tmp.html',locals())


But I get this error:

KeyError at /mypage/
    'REMOTE_ADDR'
    Request Method: GET
    Request URL:    http://mywebsite.com/mypage/
    Django Version: 1.2.4
    Exception Type: KeyError
    Exception Value:    
    'REMOTE_ADDR'
    Exception Location: /mysite/homepage/views.py in home, line 9
    Python Executable:  /usr/bin/python
    Python Version: 2.6.6
    Python Path:    ['/mysite', '/usr/local/lib/python2.6/dist-packages/flup-1.0.2-py2.6.egg', '/usr/lib/python2.6', '/usr/lib/python2.6/plat-linux2', '/usr/lib/python2.6/lib-tk', '/usr/lib/python2.6/lib-old', '/usr/lib/python2.6/lib-dynload', '/usr/local/lib/python2.6/dist-packages', '/usr/lib/python2.6/dist-packages', '/usr/lib/pymodules/python2.6']
    Server time:    Sun, 2 Jan 2011 20:42:50 -0600

"
"egrep -o '[^ ]{N,}' 


Find all non-space constructs at least N characters long. If you're concerned about ""words"" you might try [a-zA-Z].
","How to filter all words, which contain N or more characters?","I would like to process a textual file to find all words which contain more than N characters. Any solution in Bash (grep,awk) or Python (re) is welcomed! However, the shortest one is prefered.
"
"oneliner:

>>> s = 'badcfe'
>>> ''.join([ s[x:x+2][::-1] for x in range(0, len(s), 2) ])
'abcdef'



s[x:x+2] returns string slice from x to x+2; it is safe for odd len(s).
[::-1] reverses the string in Python
range(0, len(s), 2) returns 0, 2, 4, 6 ... while x 

",What is the simplest way to swap char in a string with Python?,"I want to swap each pair of characters in a string. '2143' becomes '1234', 'badcfe' becomes 'abcdef'.

How can I do this in Python?
"
"This blog provides an updated answer.

Quoting from the blog post, this is suggested and worked for me.

>>> from sqlalchemy.dialects import postgresql
>>> print str(q.statement.compile(dialect=postgresql.dialect()))


Where q is defined as:

>>> q = DBSession.query(model.Name).distinct(model.Name.value) \
             .order_by(model.Name.value)


Or just any kind of session.query().

Thanks to Nicolas Cadou for the answer! I hope it helps others who come searching here.
","How do I get a raw, compiled SQL query from a SQLAlchemy expression?","I have a SQLAlchemy query object and want to get the text of the compiled SQL statement, with all its parameters bound (e.g. no %s or other variables waiting to be bound by the statement compiler or MySQLdb dialect engine, etc).

Calling str() on the query reveals something like this:

SELECT id WHERE date_added = %s ORDER BY count DESC


I've tried looking in query._params but it's an empty dict.  I wrote my own compiler using this example of the sqlalchemy.ext.compiler.compiles decorator but even the statement there still has %s where I want data.

I can't quite figure out when my parameters get mixed in to create the query; when examining the query object they're always an empty dictionary (though the query executes fine and the engine prints it out when you turn echo logging on).

I'm starting to get the message that SQLAlchemy doesn't want me to know the underlying query, as it breaks the general nature of the expression API's interface all the different DB-APIs.  I don't mind if the query gets executed before I found out what it was; I just want to know!
"
"If you want to do the redirection within the Python script, set sys.stdout to an file object does the trick:

import sys
sys.stdout = open('file', 'w')
print 'test'


A far more common method is to use shell redirection when executing (same on Windows and Linux):

$ python foo.py > file

",Redirect stdout to a file in Python?,"How do I redirect stdout to an arbitrary file in Python?

When a long-running Python script (e.g, web application) is started from within the ssh session and backgounded, and the ssh session is closed, the application will raise IOError and fail the moment it tries to write to stdout. I needed to find a way to make the application and modules output to a file rather than stdout to prevent failure due to IOError. Currently, I employ nohup to redirect output to a file, and that gets the job done, but I was wondering if there was a way to do it without using nohup, out of curiosity.

I have already tried sys.stdout = open('somefile', 'w'), but this does not seem to prevent some external modules from still outputting to terminal (or maybe the sys.stdout = ... line did not fire at all). I know it should work from simpler scripts I've tested on, but I also didn't have time yet to test on a web application yet.
"
"Usually, python support is built in the official gvim distribution.

You will need to install python though: Python 2.7.9 Windows installer for X86

to check if vim supports python:

:echo has(""python"")

",How to enable Python support in gVim on Windows?,"I'm trying to get Python support in gVim on Windows. Is there a way to accomplish that?

I'm using:


Windows XP SP3
gVim v. 7.3
Python 2.7.13 (ActivePython through Windows Installer binaries)

"
"reduce(int.__mul__,range(n,0,-2))

",How do you a double factorial in python?,"I've been stucked on this question for a really long time.
I've managed to do a single recursive factorial.

def factorial(n):
     if n == 0:
         return 1
     else:
         return n * factorial(n-1)


Double factorial
For an even integer n, the double factorial is the product of all even positive integers less than or equal to n. For an odd integer p, the double factorial is the product of all odd positive integers less than or equal to p.

If n is even, then n!! = n*(n - 2)*(n - 4)*(n - 6)* ... *4*2

If p is odd, then p!! = p*(p - 2)*(p - 4)*(p - 6)* ... *3*1

But I have no idea to do a double factorial. Any help?
"
"You can use git+ssh URI scheme, but you MUST set username:

pip install git+ssh://git@github.com/echweb/echweb-utils.git


See git@ part into URI?

PS: Also read about deploy keys.

PPS: In my installation the ""git+ssh"" URI scheme works only with ""editable"" requirements:

pip install -e URI#egg=EggName


Remember: Change the : character that git remote -v prints to a / character before using the remote's address in the pip command:

$ git remote -v
origin  git@github.com:echweb/echweb-utils.git (fetch)
                      ^ change this to a '/' character


If you forget, you will get this error:

ssh: Could not resolve hostname github.com:echweb:
         nodename nor servname provided, or not known

",Is it possible to use pip to install a package from a private github repository?,"As the title suggests I am trying to install a python package from a private github repo. For a public repository I can issue the following command which works fine:

pip install git+git://github.com/django/django.git


However if I try this for a private repository:

pip install git+git://github.com/echweb/echweb-utils.git


I get the following output:

Downloading/unpacking git+git://github.com/echweb/echweb-utils.git
Cloning Git repository git://github.com/echweb/echweb-utils.git to /var/folders/cB/cB85g9P7HM4jcPn7nrvWRU+++TI/-Tmp-/pip-VRsIoo-build
Complete output from command /usr/local/bin/git clone git://github.com/echweb/echweb-utils.git /var/folders/cB/cB85g9P7HM4jcPn7nrvWRU+++TI/-Tmp-/pip-VRsIoo-build:
fatal: The remote end hung up unexpectedly

Cloning into /var/folders/cB/cB85g9P7HM4jcPn7nrvWRU+++TI/-Tmp-/pip-VRsIoo-build...

----------------------------------------
Command /usr/local/bin/git clone git://github.com/echweb/echweb-utils.git /var/folders/cB/cB85g9P7HM4jcPn7nrvWRU+++TI/-Tmp-/pip-VRsIoo-build failed with error code 128


I guess this is because I am trying to access a private repository without providing any authentication. I therefore tried to use git+ssh hoping that pip would use my ssh public key to authenticate:

pip install git+ssh://github.com/echweb/echweb-utils.git


This gives the following output:

Downloading/unpacking git+ssh://github.com/echweb/echweb-utils.git
Cloning Git repository ssh://github.com/echweb/echweb-utils.git to /var/folders/cB/cB85g9P7HM4jcPn7nrvWRU+++TI/-Tmp-/pip-DQB8s4-build
Complete output from command /usr/local/bin/git clone ssh://github.com/echweb/echweb-utils.git /var/folders/cB/cB85g9P7HM4jcPn7nrvWRU+++TI/-Tmp-/pip-DQB8s4-build:
Cloning into /var/folders/cB/cB85g9P7HM4jcPn7nrvWRU+++TI/-Tmp-/pip-DQB8s4-build...

Permission denied (publickey).

fatal: The remote end hung up unexpectedly

----------------------------------------
Command /usr/local/bin/git clone ssh://github.com/echweb/echweb-utils.git /var/folders/cB/cB85g9P7HM4jcPn7nrvWRU+++TI/-Tmp-/pip-DQB8s4-build failed with error code 128


Does anyone know if it what I am trying to achieve is even possible? If so can you please tell me how?
"
"Try this:

import re

def natural_sort(l): 
    convert = lambda text: int(text) if text.isdigit() else text.lower() 
    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] 
    return sorted(l, key = alphanum_key)


Output:

['elm0', 'elm1', 'Elm2', 'elm9', 'elm10', 'Elm11', 'Elm12', 'elm13']


See it working online: ideone.

Code adapted from here: Sorting for Humans : Natural Sort Order.
",Does Python have a built in function for string natural sort?,"Using Python 3.x, I have a list of strings for which I would like to perform a natural alphabetical sort. 

Natural sort: The order by which files in Windows are sorted.

For instance, the following list is naturally sorted (what I want):

['elm0', 'elm1', 'Elm2', 'elm9', 'elm10', 'Elm11', 'Elm12', 'elm13']


And here's the ""sorted"" version of the above list (what I have):

['Elm11', 'Elm12', 'Elm2', 'elm0', 'elm1', 'elm10', 'elm13', 'elm9']


I'm looking for a sort function which behaves like the first one.
"
"Try

list2 = [x for x in list1 if x != []]


If you want to get rid of everything that is ""falsy"", e.g. empty strings, empty tuples, zeros, you could also use

list2 = [x for x in list1 if x]

",Python: How to remove empty lists from a list?,"I have a list with empty lists in it:

list1 = [[], [], [], [], [], 'text', 'text2', [], 'moreText']


How can I remove the empty lists so that I get:

list2 = ['text', 'text2', 'moreText']


I tried list.remove('') but that doesn't work.
"
"with open('dwn.txt') as f:
    for i in xrange(6):
        f.next()
    for line in f:
        process(line)

","Using python, how to read a file starting at the seventh line ?","I have a text file structure as:

date
downland

user 

date data1 date2
201102 foo bar 200 50
201101 foo bar 300 35


So first six lines of file are not needed. filename:dnw.txt

f = open('dwn.txt', 'rb')


How do I ""split"" this file starting at line 7 to EOF? 
"
"Not sure if it's ""Pythonic"" enough, but you can define a ""resettable"" decorator 
for the __init__ method that creates a copy the object's __dict__ and adds a reset() method that switches the current __dict__ to the original one.

Edit - Here's an example implementation:

def resettable(f):
    import copy

    def __init_and_copy__(self, *args, **kwargs):
        f(self, *args)
        self.__original_dict__ = copy.deepcopy(self.__dict__)

        def reset(o = self):
            o.__dict__ = o.__original_dict__

        self.reset = reset

    return __init_and_copy__

class Point(object):
    @resettable
    def __init__(self, x, y):
        self.x = x
        self.y = y

    def __str__(self):
        return ""%d %d"" % (self.x, self.y)

class LabeledPoint(Point):
    @resettable
    def __init__(self, x, y, label):
        self.x = x
        self.y = y
        self.label = label

    def __str__(self):
        return ""%d %d (%s)"" % (self.x, self.y, self.label)

p = Point(1, 2)

print p # 1 2

p.x = 15
p.y = 25

print p # 15 25

p.reset()

print p # 1 2

p2 = LabeledPoint(1, 2, ""Test"")

print p2 # 1 2 (Test)

p2.x = 3
p2.label = ""Test2""

print p2 # 3 2 (Test2)

p2.reset()

print p2 # 1 2 (Test)


Edit2: Added a test with inheritance
","""Pythonic"" way to ""reset"" an object's variables?","(""variables"" here refers to ""names"", I think, not completely sure about the definition pythonistas use)

I have an object and some methods. These methods all need and all change the object's variables. How can I, in the most pythonic and in the best, respecting the techniques of OOP, way achieve to have the object variables used by the methods but also keep their original values for the other methods?

Should I copy the object everytime a method is called? Should I save the original values and have a reset() method to reset them everytime a method needs them? Or is there an even better way?

EDIT: I was asked for pseudocode. Since I am more interested in understanding the concept rather than just specifically solving the problem I am encountering I am going to try give an example:

class Player():
    games = 0
    points = 0
    fouls = 0
    rebounds = 0
    assists = 0
    turnovers = 0
    steals = 0

    def playCupGame(self):
        # simulates a game and then assigns values to the variables, accordingly
        self.points = K #just an example

    def playLeagueGame(self):
        # simulates a game and then assigns values to the variables, accordingly
        self.points = Z #just an example
        self.rebounds = W #example again

    def playTrainingGame(self):
        # simulates a game and then assigns values to the variables, accordingly
        self.points = X #just an example
        self.rebounds = Y #example again


The above is my class for a Player object (for the example assume he is a basketball one). This object has three different methods that all assign values to the players' statistics.

So, let's say the team has two league games and then a cup game. I'd have to make these calls:

p.playLeagueGame()
p.playLeagueGame()
p.playCupGame()


It's obvious that when the second and the third calls are made, the previously changed statistics of the player need to be reset. For that, I can either write a reset method that sets all the variables back to 0, or copy the object for every call I make. Or do something completely different.

That's where my question lays, what's the best approach, python and oop wise?

UPDATE: I am suspicious that I have superovercomplicated this and I can easily solve my problem by using local variables in the functions. However, what happens if I have a function inside another function, can I use locals of the outer one inside the inner one?
"
"Without actually having to download or install any additional packages you can use the syntax for specifying a particular version while not actually specifying any version, and the available versions will be printed:

$ pip install pylibmc==
Collecting pylibmc==
  Could not find a version that satisfies the requirement pylibmc== (from v
  ersions: 0.2, 0.3, 0.4, 0.5.1, 0.5.2, 0.5.3, 0.5.4, 0.5.5, 0.5, 0.6.1, 0.6, 
  0.7.1, 0.7.2, 0.7.3, 0.7.4, 0.7, 0.8.1, 0.8.2, 0.8, 0.9.1, 0.9.2, 0.9, 
  1.0-alpha, 1.0-beta, 1.0, 1.1.1, 1.1, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.3.0)
No matching distribution found for pylibmc==


update: I had changed my answer to have nothing after the ==, this however doesn't work for older versions of pip (those of you should probably update pip) add any string after the == that is not likely to be an install candidate:

pip install pylibmc==blork

","Python and pip, list all versions of a package that's available?","Given the name of a Python (2.X) package that can be installed with pip and virtualenv, is there any way to find out a list of all the possible versions of it that pip could install? Right now it's trial and error.

I'm trying to install a version for a third party library, but the newest version is too new, there were backwards incompatible changes made. So I'd like to somehow have a list of all the versions that pip knows about, so that I can test them.
"
"using pip:

pip install mechanize


or download the mechanize distribution archive, open it, and run:

python setup.py install

",How to install mechanize for Python 2.7?,"I saved mechanize in my Python 2.7 directory. But when I type import mechanize into the Python shell, I get an error message that reads:

Traceback (most recent call last):
  File """", line 1, in 
    import mechanize
ImportError: No module named mechanize

"
"Yes! There's a Python debugger called pdb just for doing that!

You can launch a Python program through pdb by using pdb myscript.py or python -m pdb myscript.py.

There are a few commands you can then issue, which are documented on the pdb page.

Some useful ones to remember are:


b: set a breakpoint
c: continue debugging until you hit a breakpoint
s: step through the code
n: to go to next line of code
l: list source code for the current file (default: 11 lines including the line being executed)
u: navigate up a stack frame
d: navigate down a stack frame
p: to print the value of an expression in the current context


If you don't want to use a command line debugger, some IDEs like Pydev have a GUI debugger.
",Can you step through python code to help debug issues?,"In java/c# you can easily step through code to trace what might be going wrong, and IDE's make this process very user friendly.

Can you trace through python code in a similiar fashion?
"
"The main problem seems to be that it is not possible to use Unicode on Windows using only the standard C library and no platform-dependent or third-party extensions. The languages you mentioned originate from Unix platforms, whose method of implementing Unicode blends well with C (they use normal char* strings, the C locale functions, and UTF-8). If you want to do Unicode in C, you more or less have to write everything twice: once using nonstandard Microsoft extensions, and once using the standard C API functions for all other operating systems. While this can be done, it usually doesn't have high priority because it's cumbersome and most scripting language developers either hate or ignore Windows anyway.

At a more technical level, I think the basic assumption that most standard library designers make is that all I/O streams are inherently byte-based on the OS level, which is true for files on all operating systems, and for all streams on Unix-like systems, with the Windows console being the only exception. Thus the architecture many class libraries and programming language standard have to be modified to a great extent if one wants to incorporate Windows console I/O.

Another more subjective point is that Microsoft just did not enough to promote the use of Unicode. The first Windows OS with decent (for its time) Unicode support was Windows NT 3.1, released in 1993, long before Linux and OS X grew Unicode support. Still, the transition to Unicode in those OSes has been much more seamless and unproblematic. Microsoft once again listened to the sales people instead of the engineers, and kept the technically obsolete Windows 9x around until 2001; instead of forcing developers to use a clean Unicode interface, they still ship the broken and now-unnecessary 8-bit API interface, and invite programmers to use it (look at a few of the recent Windows API questions on Stack Overflow, most newbies still use the horrible legacy API!).

When Unicode came out, many people realized it was useful. Unicode started as a pure 16-bit encoding, so it was natural to use 16-bit code units. Microsoft then apparently said ""OK, we have this 16-bit encoding, so we have to create a 16-bit API"", not realizing that nobody would use it. The Unix luminaries, however, thought ""how can we integrate this into the current system in an efficient and backward-compatible way so that people will actually use it?"" and subsequently invented UTF-8, which is a brilliant piece of engineering. Just as when Unix was created, the Unix people thought a bit more, needed a bit longer, has less financially success, but did it eventually right.

I cannot comment on Perl (but I think that there are more Windows haters in the Perl community than in the Python community), but regarding Python I know that the BDFL (who doesn't like Windows as well) has stated that adequate Unicode support on all platforms is a major goal.
",Why don't scripting languages output Unicode to the Windows console?,"The Windows console has been Unicode aware for at least a decade and perhaps as far back as Windows NT. However for some reason the major cross-platform scripting languages including Perl and Python only ever output various 8-bit encodings, requiring much trouble to work around. Perl gives a ""wide character in print"" warning, Python gives a charmap error and quits. Why on earth after all these years do they not just simply call the Win32 -W APIs that output UTF-16 Unicode instead of forcing everything through the ANSI/codepage bottleneck?

Is it just that cross-platform performance is low priority? Is it that the languages use UTF-8 internally and find it too much bother to output UTF-16? Or are the -W APIs inherently broken to such a degree that they can't be used as-is?

UPDATE

It seems that the blame may need to be shared by all parties. I imagined that the scripting languages could just call wprintf on Windows and let the OS/runtime worry about things such as redirection. But it turns out that even wprintf on Windows converts wide characters to ANSI and back before printing to the console!

Please let me know if this has been fixed since the bug report link seems broken but my Visual C test code still fails for wprintf and succeeds for WriteConsoleW.

UPDATE 2

Actually you can print UTF-16 to the console from C using wprintf but only if you first do _setmode(_fileno(stdout), _O_U16TEXT).

From C you can print UTF-8 to a console whose codepage is set to codepage 65001, however Perl, Python, PHP and Ruby all have bugs which prevent this. Perl and PHP corrupt the output by adding additional blank lines following lines which contain at least one wide character. Ruby has slightly different corrupt output. Python crashes.

UPDATE 3

Node.js is the first scripting language that shipped without this problem straight out of the box.

The Python dev team slowly came to realize this was a real problem since it was first reported back at the end of 2007 and has seen a huge flurry of activity to fully understand and fully fix the bug in 2016.
"
"In Python 3, all strings are sequences of Unicode characters. There is a bytes type that holds raw bytes.

In Python 2, a string may be of type str or of type unicode. You can tell which using code something like this:

def whatisthis(s):
    if isinstance(s, str):
        print ""ordinary string""
    elif isinstance(s, unicode):
        print ""unicode string""
    else:
        print ""not a string""

",How do I check if a string is unicode or ascii?,"What do I have to do in Python to figure out which encoding?
"
"Something like this, assuming your terminal handles \b

import sys
import time

def spinning_cursor():
    while True:
        for cursor in '|/-\\':
            yield cursor

spinner = spinning_cursor()
for _ in range(50):
    sys.stdout.write(spinner.next())
    sys.stdout.flush()
    time.sleep(0.1)
    sys.stdout.write('\b')

",How to create a spinning command line cursor using python?,"Is there a way to print a spinning cursor in a terminal using Python?
"
"You could just output your object as a dict:

class User:
   def as_dict(self):
       return {c.name: getattr(self, c.name) for c in self.__table__.columns}


And then you use User.as_dict() to serialize your object.

As explained in Convert sqlalchemy row object to python dict
",How to serialize SqlAlchemy result to JSON?,"Django has some good automatic serialization of ORM models returned from DB to JSON format.

How to serialize SQLAlchemy query result to JSON format? 

I tried jsonpickle.encode but it encodes query object itself.
I tried json.dumps(items) but it returns

TypeError:  is not JSON serializable


Is it really so hard to serialize SQLAlchemy ORM objects to JSON /XML? Isn't there any default serializer for it? It's very common task to serialize ORM query results nowadays.

What I need is just to return JSON or XML data representation of SQLAlchemy query result.

SQLAlchemy objects query result in JSON/XML format is needed to be used in javascript datagird (JQGrid http://www.trirand.com/blog/)
"
"One could use Python's collections.defaultdict instead of creating an AutoVivification class and then instantiating dictionary as an object of that type.

import collections
dictionary = collections.defaultdict(lambda: collections.defaultdict(int))


This will create a dictionary of dictionaries with a default value of 0.  When you wish to increment an entry, use:

dictionary[keyword][filename] += 1

",Python: How to update value of key value pair in nested dictionary?,"i am trying to make an inversed document index, therefore i need to know from all unique words in a collection in which doc they occur and how often.

i have used this answer in order two create a nested dictionary. The provided solution works fine, with one problem though.

First i open the file and make a list of unique words. These unique words i than want to compare with the original file. When there is a match, the frequency counter should be updated and its value be stored in the two dimensional array.

output should eventually look like this:

word1, {doc1 : freq}, {doc2 : freq} 
word2, {doc1 : freq}, {doc2 : freq}, {doc3:freq}
etc....


Problem is that i cannot update the dictionary variable. When trying to do so i get the error: 

  File ""scriptV3.py"", line 45, in main
    freq = dictionary[keyword][filename] + 1
TypeError: unsupported operand type(s) for +: 'AutoVivification' and 'int'


I think i need to cast in some way the instance of AutoVivification to int....

How to go?

thanks in advance

my code:

#!/usr/bin/env python 
# encoding: utf-8

import sys
import os
import re
import glob
import string
import sets

class AutoVivification(dict):
    """"""Implementation of perl's autovivification feature.""""""
    def __getitem__(self, item):
        try:
            return dict.__getitem__(self, item)
        except KeyError:
            value = self[item] = type(self)()
            return value

def main():
    pad = 'temp/'
    dictionary  = AutoVivification()
    docID = 0
    for files in glob.glob( os.path.join(pad, '*.html') ):  #for all files in specified folder:
        docID = docID + 1
        filename = ""doc_""+str(docID)
        text = open(files, 'r').read()                      #returns content of file as string
        text = extract(text, '', '')             #call extract function to extract text from within  tags
        text = text.lower()                                 #all words to lowercase
        exclude = set(string.punctuation)                   #sets list of all punctuation characters
        text = ''.join(char for char in text if char not in exclude) # use created exclude list to remove characters from files
        text = text.split()                                 #creates list (array) from string
        uniques = set(text)                                 #make list unique (is dat handig? we moeten nog tellen)

        for keyword in uniques:                             #For every unique word do   
            for word in text:                               #for every word in doc:
                if (word == keyword and dictionary[keyword][filename] is not None): #if there is an occurence of keyword increment counter 
                    freq = dictionary[keyword][filename]    #here we fail, cannot cast object instance to integer.
                    freq = dictionary[keyword][filename] + 1
                    print(keyword,dictionary[keyword])
                else:
                    dictionary[word][filename] = 1

#extract text between substring 1 and 2 
def extract(text, sub1, sub2): 
    return text.split(sub1, 1)[-1].split(sub2, 1)[0]    

if __name__ == '__main__':
    main()

"
"Ultimately it probably doesn't have a safe .get method because a dict is an associative collection (values are associated with names) where it is inefficient to check if a key is present (and return its value) without throwing an exception, while it is super trivial to avoid exceptions accessing list elements (as the len method is very fast).  The .get method allows you to query the value associated with a name, not directly access the 37th item in the dictionary (which would be more like what you're asking of your list).

Of course, you can easily implement this yourself:

def safe_list_get (l, idx, default):
  try:
    return l[idx]
  except IndexError:
    return default


You could even monkeypatch it onto the __builtins__.list constructor in __main__, but that would be a less pervasive change since most code doesn't use it.  If you just wanted to use this with lists created by your own code you could simply subclass list and add the get method.
","Why list doesn't have safe ""get"" method like dictionary?",">>> d = {'a':'b'}
>>> d['a']
'b'
>>> d['c']
KeyError: 'c'
>>> d.get('c', 'fail')
'fail'

>>> l = [1]
>>> l[10]
IndexError: list index out of range

"
"The assert statement exists in almost every programming language. When you do...

assert condition


... you're telling the program to test that condition, and trigger an error if the condition is false.

In Python, it's roughly equivalent to this:

if not condition:
    raise AssertionError()


Try it in the Python shell:

>>> assert True
>>> assert False
Traceback (most recent call last):
  File """", line 1, in 
AssertionError


Assertions can include an optional message, and you can disable them when you're done debugging. See here for the relevant documentation.
","What is the use of ""assert"" in Python?","I have been reading some source code and in several places I have seen the usage of assert. 

What does it mean exactly? What is its usage?
"
"Lambda is more of a concept or programming technique then anything else. 

Basically it's the idea that you get a function (a first-class object in python) returned as a result of another function instead of an object or primitive type. I know, it's confusing.

See this example from the python documentation: 

def make_incrementor(n):
  return lambda x: x + n
f = make_incrementor(42)
f(0)
>>> 42
f(1)
>>> 43


So make_incrementor creates a function that uses n in it's results. You could have a function that would increment a parameter by 2 like so: 

f2 = make_incrementor(2)
f2(3)
>>> 5


This is a very powerful idea in functional programming and functional programming languages like lisp & scheme. 

Hope this helps.
","What exactly is ""lambda"" in Python?","I want to know what exactly is lambda in python? and where and why it is used.
thanks
"
"Slicing a list

top5 = array[:5]



To slice a list, there's a simple syntax: array[start:stop:step]
You can omit any parameter. These are all valid: array[start:], array[:stop], array[::step]


Slicing a generator

 import itertools
 top5 = itertools.islice(my_list, 5) # grab the first five elements



You can't slice a generator directly in Python. itertools.islice() will wrap an object in a new slicing generator using the syntax itertools.islice(generator, start, stop, step)
Remember, slicing a generator will exhaust it partially. If you want to keep the entire generator intact, perhaps turn it into a tuple or list first, like: result = tuple(generator)

",How to take the first N items from a generator or list in Python?,"With linq I would

var top5 = array.Take(5);


How to do this with Python?
"
"you can even do it without defining your own classes:

from collections import defaultdict

l=lambda:defaultdict(l)
table=l()

table[0][1][2][3][4][5]=6

",Multi-level defaultdict with variable depth?,"I have a large list like:

[A][B1][C1]=1
[A][B1][C2]=2
[A][B2]=3
[D][E][F][G]=4


I want to build a multi-level dict like:

A
--B1
-----C1=1
-----C2=1
--B2=3
D
--E
----F
------G=4


I know that if I use recursive defaultdict I can write table[A][B1][C1]=1, table[A][B2]=2, but this works only if I hardcode those insert statement. While parsing the list, I don't how many []'s I need beforehand to call table[key1][key2][...]. Any advise on how to achieve this?
"
"It's same to my problem, and I solved it!

You need to install psycopg2 Python library.

Installation



Download http://initd.org/psycopg/, then install it under django & python PATH

After downloading, easily extract the tarball and:

python setup.py install


Or if you wish, at [command-line|console] install it by either easy_install or pip.

(I prefer to use pip over easy_install for no reason.)


easy_install psycopg2
pip install psycopg2


Configuration



in settings.py

DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': 'db_name',                      
        'USER': 'db_user',
        'PASSWORD': 'db_user_password',
        'HOST': '',
        'PORT': 'db_port_number',
    }
}




- Other installation instructions can be found at download page and install page.
",How to setup PostgreSQL Database in Django?,"I'm new to Python and Django.

I'm configuring a Django project using PostgreSQL database engine backend, But I'm getting errors on each database operations, for example when i run manage.py syncdb, I'm getting:

C:\xampp\htdocs\djangodir>python manage.py syncdb
Traceback (most recent call last):
  File ""manage.py"", line 11, in 
    execute_manager(settings)
  File ""C:\Python27\lib\site-packages\django\core\management\__init__.py"", line
438, in execute_manager
    utility.execute()
  File ""C:\Python27\lib\site-packages\django\core\management\__init__.py"", line
379, in execute
    self.fetch_command(subcommand).run_from_argv(self.argv)
  File ""C:\Python27\lib\site-packages\django\core\management\__init__.py"", line
261, in fetch_command
    klass = load_command_class(app_name, subcommand)
  File ""C:\Python27\lib\site-packages\django\core\management\__init__.py"", line
67, in load_command_class
    module = import_module('%s.management.commands.%s' % (app_name, name))
  File ""C:\Python27\lib\site-packages\django\utils\importlib.py"", line 35, in im
port_module
    __import__(name)
  File ""C:\Python27\lib\site-packages\django\core\management\commands\syncdb.py""
, line 7, in 
    from django.core.management.sql import custom_sql_for_model, emit_post_sync_
signal
  File ""C:\Python27\lib\site-packages\django\core\management\sql.py"", line 6, in
 
    from django.db import models
  File ""C:\Python27\lib\site-packages\django\db\__init__.py"", line 77, in <modul
e>
    connection = connections[DEFAULT_DB_ALIAS]
  File ""C:\Python27\lib\site-packages\django\db\utils.py"", line 92, in __getitem
__
    backend = load_backend(db['ENGINE'])
  File ""C:\Python27\lib\site-packages\django\db\utils.py"", line 33, in load_back
end
    return import_module('.base', backend_name)
  File ""C:\Python27\lib\site-packages\django\utils\importlib.py"", line 35, in im
port_module
    __import__(name)
  File ""C:\Python27\lib\site-packages\django\db\backends\postgresql\base.py"", li
ne 23, in 
    raise ImproperlyConfigured(""Error loading psycopg module: %s"" % e)
django.core.exceptions.ImproperlyConfigured: Error loading psycopg module: No mo
dule named psycopg


Can someone give me a clue on what is going on?
"
"You can just use:

cat requirements.txt | xargs pip install

",How to specify install order for python pip?,"I'm working with fabric(0.9.4)+pip(0.8.2) and I need to install some python modules for multiple servers. All servers have old version of setuptools (0.6c8) which needs to be upgraded for pymongo module. Pymongo requires setuptools>=0.6c9.

My problem is that pip starts installation with pymongo instead of setuptools which causes pip to stop. Shuffling module order in requirements file doesn't seem to help.

requirements.txt:

setuptools>=0.6c9
pymongo==1.9
simplejson==2.1.3


Is there a way to specify install order for pip as it doesn't seem to do it properly by itself?

This can be resolved with two separate requirements files but it would be nice if I didn't need to maintain multiple requirements files now or in the future. 

Problem persists with pip 0.8.3.
"
"Simply try converting it to an int and then bailing out if it doesn't work.

try:
   val = int(userInput)
except ValueError:
   print(""That's not an int!"")

",Python: how to check if input is a number?,"How do I check if a user's input is a number (e.g. -1, 0, 1, etc.)?

user_input = input(""Enter something:"")

if type(user_input) == int:
    print(""Is a number"")
else:
    print(""Not a number"")


The above won't work since input always returns a string.
"
"Change

data.write(c + n)


to

data.write(""%s%s\n"" % (c, n))

","How to write list of strings to file, adding newlines?"," def generator():
     nums = ['09', '98', '87', '76', '65', '54', '43']
     s_chars = ['*', '&', '^', '%', '$', '#', '@',]

     data = open(""list.txt"", ""w"")
     for c in s_chars:
        for n in nums:
           data.write(c + n)
     data.close()


I would like to add a newline after every ""c + n"". I know this is a newb question, but I am at a loss trying to fix this.
"
"Python does not have a switch statement. The recommended alternative is using a chained if/else chain - which is what you ought to be using in your case anyway.

Another common idiom is using a map. And in your case you could use a tuple of (var1,var2) to match against results.

switch = {
   (1,2): lambda: ..,
   (3,4): lambda: ...,
}
switch[(var1,var2)]


I'm not sure this is commonly used, but at least it's possible.
",Can the switch statement have more than one variable?,"The question is based in all the languages that use the switch block (C++, C# PHP , Java , Python and so on). So is it possible to have something like this?

switch (var1, var2)
case  var1 = a:
    something
    break;
case var2 = b:
    something
    break;
case var1 = 0 ,var2 = 1
     etc...

"
"As others have mentioned, regular expressions are not the way to go for nested constructs. I'll give a basic example using pyparsing:

import pyparsing # make sure you have this installed

thecontent = pyparsing.Word(pyparsing.alphanums) | '+' | '-'
parens     = pyparsing.nestedExpr( '(', ')', content=thecontent)


Here's a usage example:

>>> parens.parseString(""((a + b) + c)"")


Output:

(                          # all of str
 [
  (                        # ((a + b) + c)
   [
    (                      #  (a + b)
     ['a', '+', 'b'], {}   
    ),                     #  (a + b)      [closed]
    '+',
    'c'
   ], {}
  )                        # ((a + b) + c) [closed]
 ], {}  
)                          # all of str    [closed]


(With newlining/indenting/comments done manually)

Edit: Modified to eliminate unnecessary Forward, as per Paul McGuire's suggestions. 

To get the output in nested list format:

res = parens.parseString(""((12 + 2) + 3)"")
res.asList()


Output:

[[['12', '+', '2'], '+', '3']]

",Python: How to match nested parentheses with regex?,"I'm trying to match a mathematical-expression-like string, that have nested parentheses.

import re

p = re.compile('\(.+\)')
str = '(((1+0)+1)+1)'
print p.findall(s)



  ['(((1+0)+1)+1)']


I wanted it to match all the enclosed expressions, such as (1+0), ((1+0)+1)...
I don't even care if it matches unwanted ones like (((1+0), I can take care of those.

Why it's not doing that already, and how can I do it?
"
"You can use py2exe as already answered and use cython to convert your key .py files in .pyc, C compiled files, like .dll in Windows and .so in linux, much harder to revert than common .pyo and .pyc files (and also gain in performance!)
",How to make a Python script standalone executable to run without ANY dependency?,"I'm building a Python application and don't want to force my clients to install Python and modules. I also want to make my application closed-source.

So, is there a way to compile Python scripts to standalone executables?
"
"Here are the options for virtualenv

$ virtualenv
You must provide a DEST_DIR
Usage: virtualenv [OPTIONS] DEST_DIR

Options:
  --version             show program's version number and exit.
  -h, --help            show this help message and exit.
  -v, --verbose         Increase verbosity.
  -q, --quiet           Decrease verbosity.
  -p PYTHON_EXE, --python=PYTHON_EXE
                        The Python interpreter to use, e.g.,
                        --python=python2.5 will use the python2.5 interpreter
                        to create the new environment.  The default is the
                        interpreter that virtualenv was installed with
                        (/usr/bin/python)
  --clear               Clear out the non-root install and start from scratch
  --no-site-packages    Don't give access to the global site-packages dir to
                        the virtual environment
  --unzip-setuptools    Unzip Setuptools or Distribute when installing it
  --relocatable         Make an EXISTING virtualenv environment relocatable.
                        This fixes up scripts and makes all .pth files
                        relative
  --distribute          Use Distribute instead of Setuptools. Set environ
                        variable VIRTUALENV_USE_DISTRIBUTE to make it the
                        default
  --prompt==PROMPT      Provides an alternative prompt prefix for this
                        environment


1) What you want to do is install python to a directory that you are able to write too.

You can follow the instructions here.

For Python 2.7.1
Python source

mkdir ~/src
mkdir ~/.localpython
cd ~/src
wget http://www.python.org/ftp/python/2.7.1/Python-2.7.1.tgz
tar -zxvf Python-2.7.1.tgz
cd Python-2.7.1

make clean
./configure --prefix=/home/${USER}/.localpython
make
make install


2) Install virtualenv
virtualenv source

cd ~/src
wget http://pypi.python.org/packages/source/v/virtualenv/virtualenv-1.5.2.tar.gz#md5=fbcefbd8520bb64bc24a560c6019a73c
tar -zxvf virtualenv-1.5.2.tar.gz
cd virtualenv-1.5.2/
~/.localpython/bin/python setup.py install


3) Create a virtualenv using your local python
virtualenv docs

mkdir /home/${USER}/virtualenvs
cd /home/${USER}/virtualenvs
~/.localpython/bin/virtualenv py2.7 --python=/home/${USER}/.localpython/bin/python2.7


4) Activate the environment

cd ~/virtualenvs/py2.7/bin
source ./activate


5) Check

(py2.7)$ python
Python 2.7.1 (r271:86832, Mar 31 2011, 15:31:37) 
[GCC 4.4.5] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> exit()

(py2.7)$ deactivate
$ python
Python 2.6.6 (r266:84292, Sep 15 2010, 15:52:39) 
[GCC 4.4.5] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> 

",Is it possible to install another version of Python to Virtualenv?,"I have a shared account in a web-hosting that has Python 2.4 installed, but my code is not compatible with 2.4. Is it possible to install Python 2.6 directly to Virtualenv? 

Note: I donÂ´t have permission to install it in the shared server.
"
"I found this to be the only one short + flexible + portable + readable:

from __future__ import print_function
import sys

def eprint(*args, **kwargs):
    print(*args, file=sys.stderr, **kwargs)


The function eprint can be used in the same was as the standard print function:

>>> print(""Test"")
Test
>>> eprint(""Test"")
Test
>>> eprint(""foo"", ""bar"", ""baz"", sep=""---"")
foo---bar---baz

",How to print to stderr in Python?,"I've come across at least three ways to print to stderr:

 import sys

 print >> sys.stderr, 'spam'

 sys.stderr.write('spam\n')

 from __future__ import print_function
 print('spam', file=sys.stderr)


It seems to contradict zen of Python #13 â , so what's the preferred way to do it? Are there any advantages or disadvantages to one way or the other?

â  There should be one â and preferably only one â obvious way to do it.
"
"Python's string library has isdigit() method:

string[0].isdigit()

",How to tell if string starts with a number?,"I have a string that starts with a number (from 0-9)
I know I can ""or"" 10 test cases using startswith() but there is probably a neater solution

so instead of writing

if (string.startswith('0') || string.startswith('2') ||
    string.startswith('3') || string.startswith('4') ||
    string.startswith('5') || string.startswith('6') ||
    string.startswith('7') || string.startswith('8') ||
    string.startswith('9')):
    #do something


Is there a cleverer/more efficient way?
"
"Python 3.5 adds the math.isclose and cmath.isclose functions as described in PEP 485.

If you're using an earlier version of Python, the equivalent function is given in the documentation.

def isclose(a, b, rel_tol=1e-09, abs_tol=0.0):
    return abs(a-b) <= max(rel_tol * max(abs(a), abs(b)), abs_tol)

",What is the best way to compare floats for almost-equality in Python?,"It's well known that comparing floats for equality is a little fiddly due to rounding and precision issues.

For example:
http://www.cygnus-software.com/papers/comparingfloats/comparingfloats.htm

What is the recommended way to deal with this in Python?

Surely there is a standard library function for this somewhere?
"
"If the order is not important, you should use set.difference. However, if you want to retain order, a simple list comprehension is all it takes.

result = [a for a in A if a not in subset_of_A]


EDIT: As delnan says, performance will be substantially improved if subset_of_A is an actual set, since checking for membership in a set is O(1) as compared to O(n) for a list.

A = [6, 7, 8, 9, 10, 11, 12]
subset_of_A = set([6, 9, 12]) # the subset of A

result = [a for a in A if a not in subset_of_A]

",array filter in python?,"For example, I have two lists  

 A           = [6, 7, 8, 9, 10, 11, 12]
subset_of_A  = [6, 9, 12]; # the subset of A


the result should be [7, 8, 10, 11]; the remaining elements 


Is there a built-in function in python to do this?
"
"Regexpal isn't a GUI, but it is handy for testing to see if you've built a regex that matches the correct stuff.

http://regexpal.com/

And at the bottom of regexpal.com is a link to regexbuddy, which seems to be closer to what you are looking for:

http://www.regexbuddy.com/
",Regular Expression GUI?,"I've just started looking at regular expressions, and they are pretty cool.  They are also pretty annoying looking, and I really don't want to 'learn' them if I can avoid it.

Which is why a nice gui would be great.  I'm looking for something intuitive, where you can drag and drop 'condition boxes', select which conditions you want them to select for, get a list of things that your conditions go against, etc.  Something which makes building regular expressions easy... heh

If anyone knows of anything, let me know!

Edit: Thanks for all the responses.   After looking at some, I googled questions based on them and found this link:  Is there anything like RegexBuddy in the open source world?

Quickrex seems to have alot of the stuff I want (although not as good as some), plus its integrated into eclipse, which is the IDE I use at the moment.
"
"You can do this with str.ljust(width[, fillchar]):


  Return the string left justified in a string of length width. Padding is done using the specified fillchar (default is a space). The original string is returned if width is less than len(s).


>>> 'hi'.ljust(10)
'hi        '

",How can I fill out a Python string with spaces?,"I want to fill out a string with spaces. I know that the following works for zero's:

>>> print  ""'%06d'""%4
'000004'


But what should I do when I want this?:

'hi    '


of course I can measure string length and do str+"" ""*leftover, but I'd like the shortest way.
"
"You can do something like

[0] * 10


which will result in 

[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]


But your approach will probably not be very ""pythonic"". If switching to Python, you should also think about thinking in python. ;-)
",How do I handle the following situation in Python?,"I want to say

a[current] = value 


rather than saying 

a.append(value)


because I want to show that the current value is value. The former listing shows this better. I come from C, so I am a bit confused with python lists. In C I preallocate space, so a[current] would exist and contain junk before I assign it value. Can I do something similar in Python? 
"
"To get help on python when in the PowerShell window, type:

python -m pydoc raw_input


substituting your function name for raw_input.
",How to get pydoc command working in Windows 7 cmd?,"I'm learning to program Python from the ""Learning Python the Hard Way"". On one of the chapters it tells me to use pydoc command. The windows 7 cmd failed miserably with that command. 

When I typed in pydoc raw_input() on cmd following error codes were generated:

'pydoc' is not recognized as internal or external command,
operable program or batch file.


I've looked back previous two questions on same issue:


Pydoc is not working (Windows XP)
How to get pydoc command working in Windows?


So far I have created a pydoc.bat with following line

@python c:\Python26\lib\pydoc.py %*


and saved it in C:\python27\Tools\Scripts. 

I've also tried to change the PATH to C:\python27\Lib. I called the two variables python and pydoc because I'm not really sure I set the PATH correctly. 

It's still not working. 

What did I do wrong?
"
"Try this approach:

class Neuron(object):

    def __init__(self, **kwargs):
        prop_defaults = {
            ""num_axon_segments"": 0, 
            ""apical_bifibrications"": ""fancy default"",
            ...
        }

        for (prop, default) in prop_defaults.iteritems():
            setattr(self, prop, kwargs.get(prop, default))


You can then create a Neuron like this:

n = Neuron(apical_bifibrications=""special value"")

",Class with too many parameters: better design strategy?,"I am working with models of neurons. One class I am designing is a cell class which is a topological description of a neuron (several compartments connected together). It has many parameters but they are all relevant, for example:

number of axon segments, apical bifibrications, somatic length, somatic diameter, apical length, branching randomness, branching length and so on and so on... there are about 15 parameters in total!

I can set all these to some default value but my class looks crazy with several lines for parameters. This kind of thing must happen occasionally to other people too, is there some obvious better way to design this or am I doing the right thing?

UPDATE:
As some of you have asked I have attached my code for the class, as you can see this class has a huge number of parameters (>15) but they are all used and are necessary to define the topology of a cell. The problem essentially is that the physical object they create is very complex. I have attached an image representation of objects produced by this class. How would experienced programmers do this differently to avoid so many parameters in the definition?



class LayerV(__Cell):

    def __init__(self,somatic_dendrites=10,oblique_dendrites=10,
                somatic_bifibs=3,apical_bifibs=10,oblique_bifibs=3,
                L_sigma=0.0,apical_branch_prob=1.0,
                somatic_branch_prob=1.0,oblique_branch_prob=1.0,
                soma_L=30,soma_d=25,axon_segs=5,myelin_L=100,
                apical_sec1_L=200,oblique_sec1_L=40,somadend_sec1_L=60,
                ldecf=0.98):

        import random
        import math

        #make main the regions:
        axon=Axon(n_axon_seg=axon_segs)

        soma=Soma(diam=soma_d,length=soma_L)

        main_apical_dendrite=DendriticTree(bifibs=
                apical_bifibs,first_sec_L=apical_sec1_L,
                L_sigma=L_sigma,L_decrease_factor=ldecf,
                first_sec_d=9,branch_prob=apical_branch_prob)

        #make the somatic denrites

        somatic_dends=self.dendrite_list(num_dends=somatic_dendrites,
                       bifibs=somatic_bifibs,first_sec_L=somadend_sec1_L,
                       first_sec_d=1.5,L_sigma=L_sigma,
                       branch_prob=somatic_branch_prob,L_decrease_factor=ldecf)

        #make oblique dendrites:

        oblique_dends=self.dendrite_list(num_dends=oblique_dendrites,
                       bifibs=oblique_bifibs,first_sec_L=oblique_sec1_L,
                       first_sec_d=1.5,L_sigma=L_sigma,
                       branch_prob=oblique_branch_prob,L_decrease_factor=ldecf)

        #connect axon to soma:
        axon_section=axon.get_connecting_section()
        self.soma_body=soma.body
        soma.connect(axon_section,region_end=1)

        #connect apical dendrite to soma:
        apical_dendrite_firstsec=main_apical_dendrite.get_connecting_section()
        soma.connect(apical_dendrite_firstsec,region_end=0)

        #connect oblique dendrites to apical first section:
        for dendrite in oblique_dends:
            apical_location=math.exp(-5*random.random()) #for now connecting randomly but need to do this on some linspace
            apsec=dendrite.get_connecting_section()
            apsec.connect(apical_dendrite_firstsec,apical_location,0)

        #connect dendrites to soma:
        for dend in somatic_dends:
            dendsec=dend.get_connecting_section()
            soma.connect(dendsec,region_end=random.random()) #for now connecting randomly but need to do this on some linspace

        #assign public sections
        self.axon_iseg=axon.iseg
        self.axon_hill=axon.hill
        self.axon_nodes=axon.nodes
        self.axon_myelin=axon.myelin
        self.axon_sections=[axon.hill]+[axon.iseg]+axon.nodes+axon.myelin
        self.soma_sections=[soma.body]
        self.apical_dendrites=main_apical_dendrite.all_sections+self.seclist(oblique_dends)
        self.somatic_dendrites=self.seclist(somatic_dends)
        self.dendrites=self.apical_dendrites+self.somatic_dendrites
        self.all_sections=self.axon_sections+[self.soma_sections]+self.dendrites

"
"A dictionary has, by definition, an arbitrary number of keys. There is no ""the key"". You have the keys() method, which gives you a python list of all the keys, and you have the iteritems() method, which returns key-value pairs, so

for key, value in mydic.iteritems() :
    print key, value


Python 3 version:

for key, value in mydic.items() :
    print (key, value)


So you have a handle on the keys, but they only really mean sense if coupled to a value. I hope I have understood your question.
",Python: how to print a dictionary's key?,"I found a my question in SO already, but it was not answered directly. I would like to print a specific Python dictionary key:

mydic = {}
mydic['key_name'] = 'value_name'


Now I can check if mydic.has_key('key_name'), but what I would like to do is print the name of the key 'key_name'. Of course I could use mydic.items(), but I don't want all the keys listed, merely one specific key. For instance I'd expect something like this (in pseudo-code):

print ""the key name is"", mydic['key_name'].name_the_key(), ""and its value is"", mydic['key_name']


Is there any name_the_key() method to print a key name?



Edit:
OK, thanks a lot guys for your reactions! :) I realise my question is not well formulated and trivial. I just got confused because i realised key_name and mydic['key_name'] are two different things and i thought it would incorrect to print the key_name out of the dictionary context. But indeed i can simply use the 'key_name' to refer to the key! :)
"
"This is the solution to my problem:


Find out the path to the folder ../site-packages/ of your corresponding python version. ( For me it was /opt/local/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/site-packages/ for python 2.6 on my Mac with Snoe Leopard.)
Open eclipse preferences and go to PyDev -> Interpreter - Python.
On the left side of the lower box, click on New Folder.
Add the navigate to ../site-packages/ of your corresponding python version.
Hit open.
Hit Apply.
Hit Ok.


And you should be good to go. =)

Thanks @all particionts, who provided hints into the right direction in the comments.
",Adding python modules to pydev in eclipse results in import error?,"I have a problem getting PyDev on eclipse to recognize already installed modules. Here is my detailed approach. The machine is a Mac (Snow Leopard).

In terminal the command

python --version


shows Python 2.6.6.

import unidecode


and

from unidecode import unidecode


work both fine!

I installed PyDev in Eclipse and went to configured the python interpreter (Auto Config). I selected all the proposed packages and hit Apply and Ok.

But eclipse keeps complaining

Traceback (most recent call last):
  File ""/Users/me/Documents/workspace/myproject/python/pythontest.py"", line 12, in 
    from unidecode import unidecode
ImportError: No module named unidecode


The python file looks like this

#!/usr/bin/env python
# encoding: utf-8


import sys
import os
from unidecode import unidecode


def main():
    print unidecode(u""Ãgot Aakra"")

if __name__ == '__main__':
    main()


When I remove the first line in the script

#!/usr/bin/env python


it results into the same error.

Does someone know where the problem lies?
"
"Python already has a very nice construct for doing just this and it doesn't use continue:

for i in range(10):
    try:
        r = 1.0 / (i % 2)
    except Exception, e:
        print(e)
    else:
        print(r)


I wouldn't nest any more than this, though, or your code will soon get very ugly.

In your case I would probably do something more like this as it is far easier to unit test the individual functions and flat is better than nested:

#!/usr/bin/env python

def something_that_may_raise(i):
    return 1.0 / (i % 2)

def handle(e):
    print(""Exception: "" + str(e))

def do_something_with(result):
    print(""No exception: "" + str(result))

def wrap_process(i):
    try:
        result = something_that_may_raise(i)
    except ZeroDivisionError, e:
        handle(e)
    except OverflowError, e:
        handle(e) # Realistically, this will be a different handler...
    else:
        do_something_with(result)

for i in range(10):
    wrap_process(i)


Remember to always catch specific exceptions. If you were not expecting a specific exception to be thrown, it is probably not safe to continue with your processing loop.

Edit following comments:

If you really don't want to handle the exceptions, which I still think is a bad idea, then catch all exceptions (except:) and instead of handle(e), just pass. At this point wrap_process() will end, skipping the else:-block where the real work is done, and you'll go to the next iteration of your for-loop.

Bear in mind, Errors should never pass silently.
",Python: How to tell the for loop to continue from a function?,"Sometimes I need the following pattern within a for loop. At times more than once in the same loop:

    try:
        var = 'attempt to do something that may fail on a number of levels'
    except Exception, e:
        log(e)
        continue


Now I don't see a nice way to wrap this in a function as it can not return continue:

def attempt(this):
    try:
        return this
    except Exception, e:
        log(e)
        # 1. continue # <-- syntax error: continue not properly in loop or
        # 2. return continue # <-- invalid syntax
        # 3.
        return False # <-- this sort of works, but makes me feel powerless


If I return False than I could:

    var = attempt('to do something that may fail on a number of levels')
    if not var:
        continue


But I don't feel that does it the justice. I want to tell the for loop to continue (or fake it) from within attempt function.
"
"I believe Python has special case handling for sequences of relational operators to make range comparisons easy to express. It's much nicer to be able to say 0  than to say (0 .

These are called chained comparisons. And that's a link to the documentation for them.

With the other cases you talk about, the parenthesis force one relational operator to be applied before the other, and so they are no longer chained comparisons. And since True and False have values as integers you get the answers you do out of the parenthesized versions.
",Why does the expression 0 < 0 == 0 return False in Python?,"Looking into Queue.py in Python 2.6, I found this construct that I found a bit strange:

def full(self):
    """"""Return True if the queue is full, False otherwise
    (not reliable!).""""""
    self.mutex.acquire()
    n = 0 < self.maxsize == self._qsize()
    self.mutex.release()
    return n


If maxsize is 0 the queue is never full.

My question is how does it work for this case? How 0  is considered False?

>>> 0 < 0 == 0
False
>>> (0) < (0 == 0)
True
>>> (0 < 0) == 0
True
>>> 0 < (0 == 0)
True

"
"Try this:

import re

mystr = 'This is a string, with words!'
wordList = re.sub(""[^\w]"", "" "",  mystr).split()


How it works : 

From the docs :

re.sub(pattern, repl, string, count=0, flags=0)


Return the string obtained by replacing the leftmost non-overlapping occurrences of pattern in string by the replacement repl. If the pattern isnât found, string is returned unchanged. repl can be a string or a function.

so in our case : 

pattern is any non alphanumeric character.

[\w] means any alphanumeric character and is equal to the character set 
[a-zA-Z0-9_]

a to z , A to Z , ) to 9 and underscore. 

so we match any non alphanumeric character and replace it with a space . 

and then we split() it which splits string by space  and converts it to a list 

so 'hello-world' 

becomes 'hello world'

with re.sub 

and then ['hello' , 'world']

after split()

let me know if any doubts come up .
",Converting a String to a List of Words?,"I'm trying to convert a string to a list of words using python. I want to take something like the following:

string = 'This is a string, with words!'


Then convert to something like this :

list = ['This', 'is', 'a', 'string', 'with', 'words']


Notice the omission of punctuation and spaces. What would be the fastest way of going about this? 
"
"like @User said before Python has logging.handlers.SMTPHandler to send logged error message. Use logging module! Overriding exception class to send an email is a bad idea.

Quick example:

import logging
import logging.handlers

smtp_handler = logging.handlers.SMTPHandler(mailhost=(""smtp.example.com"", 25),
                                            fromaddr=""from@example.com"", 
                                            toaddrs=""to@example.com"",
                                            subject=u""AppName error!"")


logger = logging.getLogger()
logger.addHandler(smtp_handler)

try:
  break
except Exception as e:
  logger.exception('Unhandled Exception')


Regards.
",Python -- Send Email When Exception Is Raised?,"I have a python class with many methods():

Method1()

Method2()

...........

...........

MethodN()

All methods -- while performing different tasks -- have the same scheme:

do something
do something else
has anything gone wrong?
    raise an exception




I want to be able to get an email whenever an exception is raised anywhere in the class.

Is there some easy way to combine this logic into the class, rather than calling SendEmail() before every raise Exception statement? what is the right, pythonic way to deal with such a case? canh a 'generalized' Exception handler be the solution? I'd be glad for any ideas you may have.
"
"I find this problem in my MacBook, the reason is because as @Stephan said, I use easy_install  to install pip, and the mixture of both py package manage tools led to the pkg_resources.DistributionNotFound problem.
The resolve is:

easy_install --upgrade pip


Remember: just use one of the above tools to manage your Py packages.
",pip broke. how to fix DistributionNotFound error?,"Whenever i try to use pip I get an error. For exampple:

$ sudo pip install gevent-websocket

Traceback (most recent call last):  
File ""/usr/local/bin/pip"", line 5, in 
from pkg_resources import load_entry_point
File ""/usr/lib/python2.7/dist-packages/pkg_resources.py"", line 2675, in 
parse_requirements(__requires__), Environment()
File ""/usr/lib/python2.7/dist-packages/pkg_resources.py"", line 552, in resolve
raise DistributionNotFound(req)
pkg_resources.DistributionNotFound: pip==0.8.1


I feel tempted to change the value of into pip==0.8.2.. but I dont feel dealing with the consequences of 'hacking' up my installation...
I'm running python 2.7 and pip is at version 0.8.2.
"
"I recommend that you use the standard packages email and smtplib together to send Email. Please look at the following example (reproduced from the Python documentation). Notice that if you follow this approach, the ""simple"" task is indeed simple, and the more complex tasks (like attaching binary objects or sending plain/HTML multipart messages) are accomplished very rapidly.

# Import smtplib for the actual sending function
import smtplib

# Import the email modules we'll need
from email.mime.text import MIMEText

# Open a plain text file for reading.  For this example, assume that
# the text file contains only ASCII characters.
fp = open(textfile, 'rb')
# Create a text/plain message
msg = MIMEText(fp.read())
fp.close()

# me == the sender's email address
# you == the recipient's email address
msg['Subject'] = 'The contents of %s' % textfile
msg['From'] = me
msg['To'] = you

# Send the message via our own SMTP server, but don't include the
# envelope header.
s = smtplib.SMTP('localhost')
s.sendmail(me, [you], msg.as_string())
s.quit()


For sending email to multiple destinations, you can also follow the example in the Python documentation:

# Import smtplib for the actual sending function
import smtplib

# Here are the email package modules we'll need
from email.mime.image import MIMEImage
from email.mime.multipart import MIMEMultipart

COMMASPACE = ', '

# Create the container (outer) email message.
msg = MIMEMultipart()
msg['Subject'] = 'Our family reunion'
# me == the sender's email address
# family = the list of all recipients' email addresses
msg['From'] = me
msg['To'] = COMMASPACE.join(family)
msg.preamble = 'Our family reunion'

# Assume we know that the image files are all in PNG format
for file in pngfiles:
    # Open the files in binary mode.  Let the MIMEImage class automatically
    # guess the specific image type.
    fp = open(file, 'rb')
    img = MIMEImage(fp.read())
    fp.close()
    msg.attach(img)

# Send the email via our own SMTP server.
s = smtplib.SMTP('localhost')
s.sendmail(me, family, msg.as_string())
s.quit()


As you can see, the header To in the MIMEText object must be a string consisting of email addresses separated by commas. On the other hand, the second argument to the sendmail function must be a list of strings (each string is an email address).

So, if you have three email addresses: person1@example.com, person2@example.com, and person3@example.com, you can do as follows (obvious sections omitted):

to = [""person1@example.com"", ""person2@example.com"", ""person3@example.com""]
msg['To'] = "","".join(to)
s.sendmail(me, to, msg.as_string())


the """","""".join(to) part makes a single string out of the list, separated by commas.

From your questions I gather that you have not gone through the Python tutorial - it is a MUST if you want to get anywhere in Python - the documentation is mostly excellent for the standard library.
",How to send an email with Python?,"This code works and sends me an email just fine:  

import smtplib
#SERVER = ""localhost""

FROM = 'monty@python.com'

TO = [""jon@mycompany.com""] # must be a list

SUBJECT = ""Hello!""

TEXT = ""This message was sent with Python's smtplib.""

# Prepare actual message

message = """"""\
From: %s
To: %s
Subject: %s

%s
"""""" % (FROM, "", "".join(TO), SUBJECT, TEXT)

# Send the mail

server = smtplib.SMTP('myserver')
server.sendmail(FROM, TO, message)
server.quit()


However if I try to wrap it in a function like this:

def sendMail(FROM,TO,SUBJECT,TEXT,SERVER):
    import smtplib
    """"""this is some test documentation in the function""""""
    message = """"""\
        From: %s
        To: %s
        Subject: %s
        %s
        """""" % (FROM, "", "".join(TO), SUBJECT, TEXT)
    # Send the mail
    server = smtplib.SMTP(SERVER)
    server.sendmail(FROM, TO, message)
    server.quit()


and call it I get the following errors:  

 Traceback (most recent call last):
  File ""C:/Python31/mailtest1.py"", line 8, in 
    sendmail.sendMail(sender,recipients,subject,body,server)
  File ""C:/Python31\sendmail.py"", line 13, in sendMail
    server.sendmail(FROM, TO, message)
  File ""C:\Python31\lib\smtplib.py"", line 720, in sendmail
    self.rset()
  File ""C:\Python31\lib\smtplib.py"", line 444, in rset
    return self.docmd(""rset"")
  File ""C:\Python31\lib\smtplib.py"", line 368, in docmd
    return self.getreply()
  File ""C:\Python31\lib\smtplib.py"", line 345, in getreply
    raise SMTPServerDisconnected(""Connection unexpectedly closed"")
smtplib.SMTPServerDisconnected: Connection unexpectedly closed


Can anyone help me understand why?  
"
"Other examples would be validation/filtering of the set attributes (forcing them to be in bounds or acceptable) and lazy evaluation of complex or rapidly changing terms.

Complex calculation hidden behind an attribute:

class PDB_Calculator(object):
    ...
    @property
    def protein_folding_angle(self):
        # number crunching, remote server calls, etc
        # all results in an angle set in 'some_angle'
        # It could also reference a cache, remote or otherwise,
        # that holds the latest value for this angle
        return some_angle

>>> f = PDB_Calculator()
>>> angle = f.protein_folding_angle
>>> angle
44.33276


Validation:

class Pedometer(object)
    ...
    @property
    def stride_length(self):
        return self._stride_length

    @stride_length.setter
    def stride_length(self, value):
        if value > 10:
            raise ValueError(""This pedometer is based on the human stride - a stride length above 10m is not supported"")
        else:
            self._stride_length = value

",Real world example about how to use property feature in python?,"I am interested in how to use @property in Python. I've read the python docs and the example there, in my opinion, is just a toy code:

class C(object):
    def __init__(self):
        self._x = None

    @property
    def x(self):
        """"""I'm the 'x' property.""""""
        return self._x

    @x.setter
    def x(self, value):
        self._x = value

    @x.deleter
    def x(self):
        del self._x


I do not know what benefit(s) I can get from wrapping the _x filled with the property decorator. Why not just implement as:

class C(object):
    def __init__(self):
        self.x = None


I think, the property feature might be useful in some situations. But when? Could someone please give me some real-world examples?

Thanks.
"
"
  PyDev is a Python IDE for Eclipse,
  which may be used in Python, Jython
  and IronPython development.


Reference: PyDev

Also you can use PySide  - it includes GUI programming

Update:

So, as I searched around, I found some Python IDEs with integrated gui builder,  such as:

Visual Tkinter Python IDE

Monkey Studio

and other ones (please look at the bottom of the page at the section: IDEs with integrated gui builder)

Update 2:

I lately started using PyCharm and I can tell it is very complex IDE and has a lot of features (I was very familiar with the interface of the IDE, since I use for Java development IntelliJ IDEA which is basically from the same company), so I would recommend to anyone to use it.

For more related to Python IDEs, please look at this question. It covers in detail almost each Python IDE for its important features: What IDE to use for Python?
",Python IDE for teaching?,"I am a student in a year 11 Computer Science class. Previously having taught only Visual Basic, my teacher is looking for a language and IDE to teach the class with that is cross-platform and is easy to learn, so I suggested Python to him for the language.

However, he would also like to teach with an IDE with it that includes a form builder in addition to the typical functions of an IDE (editor, project management, code completion, debugging, etc.). Having only ever developed with a text editor (usually nano) and a relevant compiler, I know next to nothing about IDEs and what would be good to use.

I've also realised that Python has bindings for a multitude of graphical toolkits, of which one is probably chosen for use 'behind-the-scenes' in each IDE's form builder, so that is certainly another thing to consider.

Could anyone suggest a free, open source IDE for Python that would fit my class' needs, and would be able to run on Windows, Mac OS X and Linux-based operating systems at least?

For those who recommend that plain console programming is the best start for beginners, I agree! If I were the teacher, I'd direct my students straight over to the Python console that is already installed on the computers and start teaching some programming not tainted by the issues of GUI programming. However, I would still like to find an IDE for him in case he says that he has to follow the curriculum strictly and needs to teach GUI programming with an IDE/form builder.
"
"Because this is just how Python works - keywords such as class and def are not declarations. Instead, they are real live statements which are executed. If they were not executed your module would be .. empty :-)

Anyway, the idiomatic approach is:

# stuff to run always here such as class/def
def main():
    pass

if __name__ == ""__main__"":
   # stuff only to run when not called via 'import' here
   main()


See What is if __name__ == ""__main__"" for?

It does require source control over the module being imported, however.

Happy coding.
","Why is Python running my module when I import it, and how do I stop it?","I have a Python program I'm building that can be run in either of 2 ways: the first is to call ""python main.py"" which prompts the user for input in a friendly manner and then runs the user input through the program.  The other way is to call ""python batch.py -file-"" which will pass over all the friendly input gathering and run an entire file's worth of input through the program in a single go.

The problem is that when I run ""batch.py"" it imports some variables/methods/etc from ""main.py"", and when it runs this code:

import main


at the first line of the program, it immediately errors because it tries to run the code in ""main.py"".

How can I stop Python from running the code contained in the ""main"" module which I'm importing?
"
"I had the same issue about a year and a half ago and I found a nice template loader on djangosnippets.org that makes this easy. It allows you to extend a template in a specific app, giving you the ability to create your own admin/index.html that extends the admin/index.html template from the admin app. Like this:

{% extends ""admin:admin/index.html"" %}

{% block sidebar %}
    {{block.super}}
    
        Extra links
        My extra link
    
{% endblock %}


I've given a full example on how to use this template loader in a blog post on my website.
",How to override and extend basic Django admin templates?,"How do I override an admin template (e.g. admin/index.html) while at the same time extending it (see https://docs.djangoproject.com/en/dev/ref/contrib/admin/#overriding-vs-replacing-an-admin-template)?

First - I know that this question has been asked and answered before (see Django: Overriding AND extending an app template) but as the answer says it isn't directly applicable if you're using the app_directories template loader (which is most of the time).

My current workaround is to make copies and extend from them instead of extending directly from the admin templates. This works great but it's really confusing and adds extra work when the admin templates change.

It could think of some custom extend-tag for the templates but I don't want to reinvent the wheel if there already exists a solution.

On a side note: Does anybody know if this problem will be addressed by Django itself?
"
"I was able to install pip for python 3 on Ubuntu just by running sudo apt-get install python3-pip. 
",How to install pip with Python 3?,"I want to install pip. It should support Python 3, but it requires setuptools, which is available only for Python 2.

How can I install pip with Python 3?
"
"pip freeze will output a list of installed packages and their versions. It also allows you to write those packages to a file that can later be used to set up a new environment.

http://www.pip-installer.org/en/latest/index.html#freezing-requirements
",Find all packages installed with easy_install/pip?,"Is there a way to find all Python PyPI packages that were installed with easy_install or pip?  I mean, excluding everything that was/is installed with the distributions tools (in this case apt-get on Debian).
"
"This is based on Udi's nice answer.

I think that the difficulty of creating anonymous functions is a bit of a red herring. What you really want to do is to keep related code together, and make the code neat. So I think decorators may work for you.

import re

# List of pairs (regexp, handler)
handlers = []

def handler_for(regexp):
    """"""Declare a function as handler for a regular expression.""""""
    def gethandler(f):
        handlers.append((re.compile(regexp), f))
        return f
    return gethandler

@handler_for(r'^ (.*)')
def handle_message(msg):
    print msg

@handler_for(r'^\*{3} (.*)')
def handle_warning(msg):
    global num_warnings, num_fatals
    num_warnings += 1
    if is_fatal(msg):
        num_fatals += 1

",How to make an anonymous function in Python without Christening it?,"Is it possible to put a function in a data structure, without first giving it a name with def?

# This is the behaviour I want. Prints ""hi"".
def myprint(msg):
    print msg
f_list = [ myprint ]
f_list[0]('hi')
# The word ""myprint"" is never used again. Why litter the namespace with it?


The body of a lambda function is severely limited, so I can't use them. 

Edit: For reference, this is more like the real-life code where I encountered the problem.

def handle_message( msg ):
    print msg
def handle_warning( msg ):
    global num_warnings, num_fatals
    num_warnings += 1
    if ( is_fatal( msg ) ):
        num_fatals += 1
handlers = (
    ( re.compile( '^ (.*)' ), handle_message ),
    ( re.compile( '^\*{3} (.*)' ), handle_warning ),
)
# There are really 10 or so handlers, of similar length.
# The regexps are uncomfortably separated from the handler bodies,
# and the code is unnecessarily long.

for line in open( ""log"" ):
    for ( regex, handler ) in handlers:
        m = regex.search( line )
        if ( m ): handler( m.group(1) )

"
"Try this one, works for files opened with open('filename')

for line in iter(data.readline, b''):

",Assignment in While Loop in Python?,"I just came across this piece of code

while 1:
    line = data.readline()
    if not line:
        break
    #...


and thought, there must be a better way to do this, than using an infinite loop with break.

So I tried:

while line = data.readline():
    #...


and, obviously, got an error.

Is there any way to avoid using a break in that situation?

Edit:

Ideally, you'd want to avoid saying readline twice... IMHO, repeating is even worse than just a break, especially if the statement is complex.
"
"consider using a priority queue with one or more worker threads to service the tasks.  The main thread can add work to the queue, with a timestamp of the soonest it should be serviced.  Worker threads pop work off the queue, sleep until the time of priority value is reached, do the work, and then pop another item off the queue.

How about a more fleshed out answer.  mklauber makes a good point.  If there's a chance all of your workers might be sleeping when you have new, more urgent work, then a queue.PriorityQueue isn't really the solution, although a ""priority queue"" is still the technique to use, which is available from the heapq module.  Instead, we'll make use of a different synchronization primitive; a condition variable, which in python is spelled threading.Condition.  

The approach is fairly simple, peek on the heap, and if the work is current, pop it off and do that work.  If there was work, but it's scheduled into the future, just wait on the condition until then, or if there's no work at all, sleep forever.

The producer does it's fair share of the work; every time it adds new work, it notifies the condition, so if there are sleeping workers, they'll wake up and recheck the queue for newer work.

import heapq, time, threading

START_TIME = time.time()
SERIALIZE_STDOUT = threading.Lock()
def consumer(message):
    """"""the actual work function.  nevermind the locks here, this just keeps
       the output nicely formatted.  a real work function probably won't need
       it, or might need quite different synchronization""""""
    SERIALIZE_STDOUT.acquire()
    print time.time() - START_TIME, message
    SERIALIZE_STDOUT.release()

def produce(work_queue, condition, timeout, message):
    """"""called to put a single item onto the work queue.""""""
    prio = time.time() + float(timeout)
    condition.acquire()
    heapq.heappush(work_queue, (prio, message))
    condition.notify()
    condition.release()

def worker(work_queue, condition):
    condition.acquire()
    stopped = False
    while not stopped:
        now = time.time()
        if work_queue:
            prio, data = work_queue[0]
            if data == 'stop':
                stopped = True
                continue
            if prio < now:
                heapq.heappop(work_queue)
                condition.release()
                # do some work!
                consumer(data)
                condition.acquire()
            else:
                condition.wait(prio - now)
        else:
            # the queue is empty, wait until notified
            condition.wait()
    condition.release()

if __name__ == '__main__':
    # first set up the work queue and worker pool
    work_queue = []
    cond = threading.Condition()
    pool = [threading.Thread(target=worker, args=(work_queue, cond))
            for _ignored in range(4)]
    map(threading.Thread.start, pool)

    # now add some work
    produce(work_queue, cond, 10, 'Grumpy')
    produce(work_queue, cond, 10, 'Sneezy')
    produce(work_queue, cond, 5, 'Happy')
    produce(work_queue, cond, 10, 'Dopey')
    produce(work_queue, cond, 15, 'Bashful')
    time.sleep(5)
    produce(work_queue, cond, 5, 'Sleepy')
    produce(work_queue, cond, 10, 'Doc')

    # and just to make the example a bit more friendly, tell the threads to stop after all
    # the work is done
    produce(work_queue, cond, float('inf'), 'stop')
    map(threading.Thread.join, pool)

","How to efficiently do many tasks a ""little later"" in Python?","I have a process, that needs to perform a bunch of actions ""later"" (after 10-60 seconds usually). The problem is that those ""later"" actions can be a lot (1000s), so using a Thread per task is not viable. I know for the existence of tools like gevent and eventlet, but one of the problem is that the process uses zeromq for communication so I would need some integration (eventlet already has it).

What I'm wondering is What are my options? So, suggestions are welcome, in the lines of libraries (if you've used any of the mentioned please share your experiences), techniques (Python's ""coroutine"" support, use one thread that sleeps for a while and checks a queue), how to make use of zeromq's poll or eventloop to do the job, or something else.
"
"s = [""this"", ""this"", ""and"", ""that""]
for i in xrange(1,len(s)):
    if s[i] == s[i-1]:
        print s[i]


EDIT:

Just as a side note, if you are using python 3.X use range instead of xrange
",How does one compare a string to the next string in a list?,"I'm writing a small NLP algorithm and I need to do the following: 

For every string x in the list [""this"", ""this"", ""and"", ""that""], if the string x and the next string are identical, I want to print the string. 
"
"def factors(n):    
    return set(reduce(list.__add__, 
                ([i, n//i] for i in range(1, int(n**0.5) + 1) if n % i == 0)))


This will return all of the factors, very quickly, of a number n.

Why square root as the upper limit?

sqrt(x) * sqrt(x) = x. So if the two factors are the same, they're both the square root. If you make one factor bigger, you have to make the other factor smaller. This means that one of the two will always be less than or equal to sqrt(x), so you only have to search up to that point to find one of the two matching factors. You can then use x / fac1 to get fac2.

The reduce(list.__add__, ...) is taking the little lists of [fac1, fac2] and joining them together in one long list.

The [i, n/i] for i in range(1, int(sqrt(n)) + 1) if n % i == 0 returns a pair of factors if the remainder when you divide n by the smaller one is zero (it doesn't need to check the larger one too; it just gets that by dividing n by the smaller one.)

The set(...) on the outside is getting rid of duplicates. I think this only happens for perfect squares. For n = 4, this will return 2 twice, so set gets rid of one of them.

sqrt is actually faster than **0.5, but I'll leave it out as it's nice as a self-contained snippet.
",What is the most efficient way of finding all the factors of a number in Python?,"Can someone explain to me an efficient way of finding all the factors of a number in Python (2.7)?

I can create algorithms to do this job, but i think it is poorly coded, and takes too long to execute a result for a large numbers.
"
"FWIW, the multiprocessing module has a nice interface for this using the Pool class.  And if you want to stick with threads rather than processes, you can just use the multiprocessing.pool.ThreadPool class as a drop-in replacement.

def foo(bar, baz):
  print 'hello {0}'.format(bar)
  return 'foo' + baz

from multiprocessing.pool import ThreadPool
pool = ThreadPool(processes=1)

async_result = pool.apply_async(foo, ('world', 'foo')) # tuple of args for foo

# do some other stuff in the main process

return_val = async_result.get()  # get the return value from your function.

",how to get the return value from a thread in python?,"How can I access that return value 'foo' from the thread?  

def foo(bar):
    print 'hello {0}'.format(bar)
    return 'foo'

from threading import Thread
t = Thread(target=foo, args=('world!',))
t.start()
x = t.join()
print x


The one obvious way to do it, above, seems to just return None in x.  
"
"Newer NumPy versions (1.8 and up) have a function called argpartition for this. To get the indices of the four largest elements, do

>>> a
array([9, 4, 4, 3, 3, 9, 0, 4, 6, 0])
>>> ind = np.argpartition(a, -4)[-4:]
>>> ind
array([1, 5, 8, 0])
>>> a[ind]
array([4, 9, 6, 9])


Unlike argsort, this function runs in linear time in the worst case, but the returned indices are not sorted, as can be seen from the result of evaluating a[ind]. If you need that too, sort them afterwards:

>>> ind[np.argsort(a[ind])]
array([1, 8, 5, 0])


To get the top-k elements in sorted order in this way takes O(n + k log k) time.
",How to get indices of N maximum values in a numpy array?,"Numpy proposes a way to get the index of the maximum value of an array via np.argmax. 

I would like a similar thing, but returning the indexes of the N maximum values.

For instance, if I have an array [1, 3, 2, 4, 5], it function(array, n=3) would return [4, 3, 1].

Thanks :)
"
"It appears to me that the simplest way to do this is

import datetime

epoch = datetime.datetime.utcfromtimestamp(0)

def unix_time_millis(dt):
    return (dt - epoch).total_seconds() * 1000.0

",How can I convert a datetime object to milliseconds since epoch (unix time) in Python?,"I have a Python datetime object that I want to convert to unix time, or seconds/milliseconds since the 1970 epoch.

How do I do this?
"
"There isn't any reason not to use keyword arguments apart from the clarity and readability of the code. The choice of whether to use keywords should be based on whether the keyword adds additional useful information when reading the code or not.

I follow the following general rule:


If it is hard to infer the function (name) of the argument from the function name â pass it by keyword (e.g. I wouldn't want to have text.splitlines(True) in my code).
If it is hard to infer the order of the arguments, for example if you have too many arguments, or when you have independent optional arguments â pass it by keyword (e.g. funkyplot(x, y, None, None, None, None, None, None, 'red') doesn't look particularly nice).
Never pass the first few arguments by keyword if the purpose of the argument is obvious. You see, sin(2*pi) is better than sin(value=2*pi), the same is true for plot(x, y, z).


In most cases, stable mandatory arguments would be positional, and optional arguments would be keyword.

There's also a possible difference in performance, because in every implementation the keyword arguments would be slightly slower, but considering this would be generally a premature optimisation and the results from it wouldn't be significant, I don't think it's crucial for the decision.

UPDATE: Non-stylistical concerns

Keyword arguments can do everything that positional arguments can, and if you're defining a new API there are no technical disadvantages apart from possible performance issues. However, you might have little issues if you're combining your code with existing elements.

Consider the following:


If you make your function take keyword arguments, that becomes part of your interface. 
You can't replace your function with another that has a similar signature but a different keyword for the same argument.
You might want to use a decorator or another utility on your function that assumes that your function takes a positional argument. Unbound methods are an example of such utility because they always pass the first argument as positional after reading it as positional, so cls.method(self=cls_instance) doesn't work even if there is an argument self in the definition.


None of these would be a real issue if you design your API well and document the use of keyword arguments, especially if you're not designing something that should be interchangeable with something that already exists.
",Any reason NOT to always use keyword arguments?,"Before jumping into python, I had started with some Objective-C / Cocoa books. As I recall, most functions required keyword arguments to be explicitly stated. Until recently I forgot all about this, and just used positional arguments in Python. But lately, I've ran into a few bugs which resulted from improper positions - sneaky little things they were. 

Got me thinking - generally speaking, unless there is a circumstance that specifically requires non-keyword arguments - is there any good reason NOT to use keyword arguments? Is it considered bad style to always use them, even for simple functions? 

I feel like as most of my 50-line programs have been scaling to 500 or more lines regularly, if I just get accustomed to always using keyword arguments, the code will be more easily readable and maintainable as it grows. Any reason this might not be so? 

UPDATE:

The general impression I am getting is that its a style preference, with many good arguments that they should generally not be used for very simple arguments, but are otherwise consistent with good style. Before accepting I just want to clarify though - is there any specific non-style problems that arise from this method - for instance, significant performance hits? 
"
"I would return None. If there is no result, why return something that looks like a result?

It is also easier to test:

result = getCity()
if result:
   # do something


I would only return (None, None) if it were possible that only one of the two values is None (i.e. ('Boston', None)). It would be more consistent in this case.
","Should I Return None or (None, None)?","We have a object method that returns a city/state tuple, i.e. ('Boston', 'MA'). Under some valid circumstances, there is no valid city/state to return. Stylistically, does it make more sense to return None, or a two element tuple containing (None, None) in that case?
"
"The print() function writes, i.e., ""prints"", a string in the console. The return statement causes your function to exit and hand back a value to its caller. The point of functions in general is to take in inputs and return something. The return statement is used when a function is ready to return a value to its caller. 

For example, here's a function utilizing both print() and return:

def foo():
    print(""hello from inside of foo"")
    return 1


Now you can run code that calls foo, like so:

if __name__ == '__main__':
    print(""going to call foo"")
    x = foo()
    print(""called foo"")
    print(""foo returned "" + str(x))


If you run this as a script (e.g. a .py file) as opposed to in the Python interpreter, you will get the following output:

going to call foo
hello from inside foo
called foo   
foo returned 1


I hope this makes it clearer. The interpreter writes return values to the console so I can see why somebody could be confused.

Here's another example from the interpreter that demonstrates that:

>>> def foo():
...     print(""hello from within foo"")
...     return 1
...
>>> foo()
hello from within foo
1
>>> def bar():
...   return 10 * foo()
...
>>> bar()
hello from within foo
10


You can see that when foo() is called from bar(), 1 isn't written to the console. Instead it is used to calculate the value returned from bar().  

print() is a function that causes a side effect (it writes a string in the console), but execution resumes with the next statement. return causes the function to stop executing and hand a value back to whatever called it.
",Why would you use the return statement in Python?,"What is the simple basic explanation of what the return statement is, how to use it in Python?

And what is the difference between it and the print statement?
"
"For collections that implement the List interface, you can call the listIterator() method to get a ListIterator. The iterator has (amongst others) two methods - nextIndex(), to get the index; and next(), to get the value (like other iterators).

So a Java equivalent of the Python above might be:

List numbers = Arrays.asList(""zero"", ""one"", ""two"");
ListIterator it = numbers.listIterator();
while (it.hasNext()) {
    System.out.println(it.nextIndex() + "" "" + it.next());
}


which, like the Python, outputs:

0 zero
1 one
2 two

",Is there a Java equivalent of Python's 'enumerate' function?,"In Python, the enumerate function allows you to iterate over a sequence of (index, value) pairs. For example:

>>> numbers = [""zero"", ""one"", ""two""]
>>> for i, s in enumerate(numbers):
...     print i, s
... 
0 zero
1 one
2 two


Is there any way of doing this in Java? 
"
"You don't need fancy things, just see the string methods in the standard library and you can easily split your url between 'filename' part and the rest:

url.rsplit('/', 1)


So you can get the part you're interested in simply with:

url.rsplit('/', 1)[-1]

",How to get everything after last slash in a URL?,"How can I extract whatever follows the last slash in a URL in Python? For example, these URLs should return the following:

URL: http://www.test.com/TEST1
returns: TEST1

URL: http://www.test.com/page/TEST2
returns: TEST2

URL: http://www.test.com/page/page/12345
returns: 12345


I've tried urlparse, but that gives me the full path filename, such as page/page/12345.
"
"
  How to configure py2app to include the source code in the executable,
  so the final users will not have access to my program?


Unless you very seriously hack the python interpreter (and include the mangled version) there is no really good way to hide the source from a moderately skilled and determined user.  I strongly believe this is true on Windows also. Basically, whether you include true source or bytecode, a pretty clean version of the source can be recovered.  More importantly, in my opinion, unless you include the actual source code (as opposed to bytecode, you will introduce a possible dependency on the interpreter version).  


  How to convert UNIX executable to Mac "".app"" ?


What do you mean by a UNIX executable? A Darwin (OS X) binary [which isn't actually UNIX]?  That can be done using the kinds of tools you already mentioned, but it must be done carefully to avoid library dependencies.

If all you want it a simple wrapper to put a command-line binary into a window, it's pretty easy to accomplish and the free XCode suite has several examples that would serve (depending on what output
you wan to deliver, if any).


  Is there a way to compile Python code with GCC ?


GCC does not compile Python.  It's a different language (although there tools in the gcc family rthat support multiple language front-ends, but not Python).  There are tools that attempt to translate Python into C, and then you can compile that into a true binary, but this only works for programs that avoid certain types of construct, and the process (and restrictions) need to apply your libraries as well.
    One project to allow this is Cython.  It works well for some types
of code, mostly numerical code, but it is not trivial to install and
exploit, very especially if you want to produce something that runs on multiple 
different computers.


  In Windows it's easy, I created an ""exe"" file from Python code and it
  works. Is it possible to create a single file ""app"" for Mac ?


I would have to say I am skeptical -- very skeptical -- about this.  Just like the OS X case, the exe almost certainly has the source code trivially accessible within it.

One fairly easy trick is to encrypt the source code and then decrypt it on the fly, but this
seems to me like more trouble than it's worth.
",How to create a Mac OS X app with Python?,"I want to create a GUI application which should work on Windows and Mac. For this I've chosen Python.

The problem is on Mac OS X.

There are 2 tools to generate an "".app"" for Mac: py2app and pyinstaller.


py2app is pretty good, but it adds the source code in the package. I
don't want to share the code with the final users.
Pyinstaller generates UNIX executable, so how to run it on Mac? I
created a bundles with this executable, but the resulted "".app"" is
not working.


The questions are:


How to configure py2app to include the source code in the
executable, so the final users will not have access to my program?
How to convert UNIX executable to Mac "".app"" ?
Is there a way to compile Python code with GCC ?
In Windows it's easy, I created an ""exe"" file from Python code and
it works. Is it possible to create a single file ""app"" for Mac ?


P.S. I use two computers (Windows and for Mac), Python 2.7, wxPython, py2exe, py2app and pyinstaller.

Also, I have checked out these sites: 


http://svn.pythonmac.org/py2app/py2app/trunk/doc/index.html
http://www.pyinstaller.org/export/develop/project/doc/Manual.html?format=raw
http://www.pyinstaller.org/wiki/Features/MacOsCompatibility
http://www.stackoverflow.com/questions/2933/an-executable-python-app

"
"Use the 'range' built-in function. The signature is range(start, stop, step).  This produces a sequence that yields numbers, starting with start, and ending if stop has been reached, excluding stop.

>>> range(9,-1,-1)   
    [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]
>>> range(-2, 6, 2)
    [-2, 0, 2, 4]


In Python 3, this produces a non-list range object, which functions effectively like a read-only list (but uses way less memory, particularly for large ranges).
",Print a list in reverse order with range()?,"How can you produce the following list with range() in Python?

[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]

"
"Here is a version using a list instead of a generator:

def removeVowels(word):
    letters = []            # make an empty list to hold the non-vowels
    for char in word:       # for each character in the word
        if char.lower() not in 'aeiou':    # if the letter is not a vowel
            letters.append(char)           # add it to the list of non-vowels
    return ''.join(letters) # join the list of non-vowels together into a string


You could also write it just as 

''.join(char for char in word if char.lower() not in 'aeiou')


Which does the same thing, except finding the non-vowels one at a time as join needs them to make the new string, instead of adding them to a list then joining them at the end. 

If you wanted to speed it up, making the string of values a set makes looking up each character in them faster, and having the upper case letters too means you don't have to convert each character to lowercase.

''.join(char for char in word if char not in set('aeiouAEIOU'))

",String replace vowels in Python?,"Expected:

>>> removeVowels('apple')
""ppl""
>>> removeVowels('Apple')
""ppl""
>>> removeVowels('Banana')
'Bnn'


Code (Beginner):

def removeVowels(word):
    vowels = ('a', 'e', 'i', 'o', 'u')
    for c in word:
        if c in vowels:
            res = word.replace(c,"""")
    return res 


How do I both lowercase and uppercase?
"
"If you just want to measure the elapsed wall-clock time between two points, you could use  time.time():

import time

start = time.time()
print(""hello"")
end = time.time()
print(end - start)


This gives the execution time in seconds.

edit A better option might be to use time.clock (thanks @Amber):


  On Unix, return the current processor time as a floating point number
  expressed in seconds. The precision, and in fact the very definition
  of the meaning of âprocessor timeâ, depends on that of the C function
  of the same name, but in any case, this is the function to use for
  benchmarking Python or timing algorithms.
  
  On Windows, this function returns wall-clock seconds elapsed since the
  first call to this function, as a floating point number, based on the
  Win32 function QueryPerformanceCounter(). The resolution is typically
  better than one microsecond.

",Measure time elapsed in Python?,"What I want is to start counting time somewhere in my code and then get the passed time, to measure the time it took to execute few function. I think I'm using the timeit module wrong, but the docs are just confusing for me.

import timeit

start = timeit.timeit()
print ""hello""
end = timeit.timeit()
print end - start

"
"there is not that I know a backend-agnostic way to do this, but definitely it is possible to do it for some common backends, e.g., WX, tkagg etc.

import matplotlib
matplotlib.use(""wx"")
from pylab import *
figure(1)
plot([1,2,3,4,5])
thismanager = get_current_fig_manager()
thismanager.window.SetPosition((500, 0))
show()


per @tim at the comment section below, you might wanna switch to 

thismanager.window.wm_geometry(""+500+0"")


instead. For TkAgg, just change it to

thismanager.window.wm_geometry(""+500+0"")


So I think you can exhaust through all the backends that are capable of doing this, if imposing a certain one is not an option.
",How do you set the absolute position of figure windows with matplotlib?,"I'm writing a simple Python application that uses matplotlib to display a few figures on screen. The number of figures generated is based on user input and changes throughout the application's life. The user has the ability to issue a ""plot"" command to generate a new figure window with the selected data series. In order to improve the user experience, I would like to provide another command that would programmatically arrange all open figure windows in some convenient arrangement (e.g. tile them across the available screen space).

I believe to have found APIs that allow me to adjust the size of the figure window (in pixels), but haven't had any success in finding a way to set their absolute position on screen. Is there a way to do this without delving into the details of whatever backend is in use? I would like to do this in a backend-agnostic way so I can avoid relying upon implementation details that might change in the future.
"
"I think best bet is to go thru all pytz timezones and check which one matches local timezone, each pytz timezone object contains info about utcoffset and tzname like CDT, EST, same info about local time can be obtained from time.timezone/altzone and time.tzname, and I think that is enough to correctly match local timezone in pytz database e.g.

import time
import pytz
import datetime

local_names = []
if time.daylight:
    local_offset = time.altzone
    localtz = time.tzname[1]
else:
    local_offset = time.timezone
    localtz = time.tzname[0]

local_offset = datetime.timedelta(seconds=-local_offset)

for name in pytz.all_timezones:
    timezone = pytz.timezone(name)
    if not hasattr(timezone, '_tzinfos'):
        continue#skip, if some timezone doesn't have info
    # go thru tzinfo and see if short name like EDT and offset matches
    for (utcoffset, daylight, tzname), _ in timezone._tzinfos.iteritems():
        if utcoffset == local_offset and tzname == localtz:
            local_names.append(name)

print local_names


output:


  ['America/Atikokan', 'America/Bahia_Banderas',
  'America/Bahia_Banderas', 'America/Belize', 'America/Cambridge_Bay',
  'America/Cancun', 'America/Chicago', 'America/Chihuahua',
  'America/Coral_Harbour', 'America/Costa_Rica', 'America/El_Salvador',
  'America/Fort_Wayne', 'America/Guatemala',
  'America/Indiana/Indianapolis', 'America/Indiana/Knox',
  'America/Indiana/Marengo', 'America/Indiana/Marengo',
  'America/Indiana/Petersburg', 'America/Indiana/Tell_City',
  'America/Indiana/Vevay', 'America/Indiana/Vincennes',
  'America/Indiana/Winamac', 'America/Indianapolis', 'America/Iqaluit',
  'America/Kentucky/Louisville', 'America/Kentucky/Louisville',
  'America/Kentucky/Monticello', 'America/Knox_IN',
  'America/Louisville', 'America/Louisville', 'America/Managua',
  'America/Matamoros', 'America/Menominee', 'America/Merida',
  'America/Mexico_City', 'America/Monterrey',
  'America/North_Dakota/Beulah', 'America/North_Dakota/Center',
  'America/North_Dakota/New_Salem', 'America/Ojinaga',
  'America/Pangnirtung', 'America/Rainy_River', 'America/Rankin_Inlet',
  'America/Resolute', 'America/Resolute', 'America/Tegucigalpa',
  'America/Winnipeg', 'CST6CDT', 'Canada/Central', 'Mexico/General',
  'US/Central', 'US/East-Indiana', 'US/Indiana-Starke']


In production you can create such a mapping beforehand and save it instead of iterating always.

Testing script after changing timezone:


  $ export TZ='Australia/Sydney'
  $ python get_tz_names.py
  ['Antarctica/Macquarie', 'Australia/ACT', 'Australia/Brisbane',
  'Australia/Canberra', 'Australia/Currie', 'Australia/Hobart',
  'Australia/Lindeman', 'Australia/Melbourne', 'Australia/NSW',
  'Australia/Queensland', 'Australia/Sydney', 'Australia/Tasmania',
  'Australia/Victoria']

",Get the Olson TZ name for the local timezone?,"How do I get the Olson timezone name (such as Australia/Sydney) corresponding to the value given by C's localtime call?

This is the value overridden via TZ, by symlinking /etc/localtime, or setting a TIMEZONE variable in time-related system configuration files.
"
"In Haskell, the idiom for this is just to go ahead and execute the next state:

type StateMachine = IO ()
a, b, c :: StateMachine
a = print ""a()"" >> b
b = print ""b()"" >> c
c = print ""c()"" >> a


You need not worry that this will overflow a stack or anything like that. If you insist on having states, then you should make the data type more explicit:

data PossibleStates = A | B | C
type StateMachine = PossibleStates -> IO PossibleStates
machine A = print ""a()"" >> return B
machine B = print ""b()"" >> return C
machine C = print ""c()"" >> return A


You can then get compiler warnings about any StateMachine that forgot some states.
",Clean and type-safe state machine implementation in a statically typed language?,"I implemented a simple state machine in Python:

import time

def a():
    print ""a()""
    return b

def b():
    print ""b()""
    return c

def c():
    print ""c()""
    return a


if __name__ == ""__main__"":
    state = a
    while True:
        state = state()
        time.sleep(1)


I wanted to port it to C, because it wasn't fast enough. But C doesn't let me make a function that returns a function of the same type. I tried making the function of this type: typedef *fn(fn)(), but it doesn't work, so I had to use a structure instead. Now the code is very ugly!

#include 
#include 
#include 

typedef struct fn {
    struct fn (*f)(void);
} fn_t;

fn_t a(void);
fn_t b(void);
fn_t c(void);

fn_t a(void)
{
    fn_t f = {b};

    (void)printf(""a()\n"");

    return f;
}

fn_t b(void)
{
    fn_t f = {c};

    (void)printf(""b()\n"");

    return f;
}

fn_t c(void)
{
    fn_t f = {a};

    (void)printf(""c()\n"");

    return f;
}

int main(void)
{
    fn_t state = {a};

    for(;; (void)sleep(1)) state = state.f();

    return EXIT_SUCCESS;
}


So I figured it's a problem with C's broken type system. So I used a language with a real type system (Haskell), but the same problem happens. I can't just do something like:

type Fn = IO Fn
a :: Fn
a = print ""a()"" >> return b
b :: Fn
b = print ""b()"" >> return c
c :: Fn
c = print ""c()"" >> return a


I get the error, Cycle in type synonym declarations.

So I have to make some wrapper the same way I did for the C code like this:

import Control.Monad
import System.Posix

data Fn = Fn (IO Fn)

a :: IO Fn
a = print ""a()"" >> return (Fn b)

b :: IO Fn
b = print ""b()"" >> return (Fn c)

c :: IO Fn
c = print ""c()"" >> return (Fn a)

run = foldM (\(Fn f) () -> sleep 1 >> f) (Fn a) (repeat ())


Why is it so hard to make a state machine in a statically typed language? I have to make unnecessary overhead in statically typed languages as well. Dynamically typed languages don't have this problem. Is there an easier way to do it in a statically typed language?
"
"Django 1.5 introduced {% verbatim %} template tag. It stops template from parsing contents of this tag:

{% verbatim %}
    {{ var }}
{% endverbatim %}


will be rendered as:

{{ var }}

",How to escape {{ or }} in django template?,"Django treats {{ var }} as some variable in its template. How can I escape {{ var }} or {{ or }} such that django does not treat it as variable.

""{{ some text }}"" Should prints exactly the same.
"
"If you're thinking of non-blocking, asynchronous processing, you're probably using (or should use) asynchronous framework/server.


if you're using Tornado, there is Tornado-Redis. It's using native Tornado generator calls. Its Websocket demo provides example on how to use it in combination with pub/sub.
if you're using Twisted, there is txRedis. There you also have pub/sub example.
it also seems that you can use Redis-py combined with Gevent with no problems using Gevent's monkey patching (gevent.monkey.patch_all()). 

",Is non-blocking Redis pubsub possible?,"I want to use redis' pubsub to transmit some messages, but don't want be blocked using listen, like the code below:

import redis
rc = redis.Redis()

ps = rc.pubsub()
ps.subscribe(['foo', 'bar'])

rc.publish('foo', 'hello world')

for item in ps.listen():
    if item['type'] == 'message':
        print item['channel']
        print item['data']


The last for section will block. I just want to check if a given channel has data, how can I accomplish this? Is there a check like method?
"
"I recently found myself in the same boat, except I came from a mako background.  

Mustache does not allow for template extension/inheritance but there are a few options available to you that I know of.


You could use partials:

{{>header}}
    Hello {{name}}
{{>footer}}

You could inject template pre-processing functions into the context for each template that needs to inherit from some other page: 

{{#extendBase}}      
    Hello {{name}}
{{/extendBase}} 


Hash:

{
   ""name"": ""Walden"",
   ""extendBase"": function() {
       return function(text) {
           return """" + render(text) + """"
       }
   }
}

Prepend and append the desired HTML to the relevant pages in your controller. 
Have a layout template ala:

{{>header}}
    {{{body}}}
{{>footer}}


And render the body in your controller, passing that to the layout template as a variable named body.
Implement template inheritance, pre-mustache, in your code that loads templates.    


I wouldn't, however, use the triple mustache because I don't want unescaped HTML to be appearing anywhere, it's just too risky in my opinion.

If someone else has a better solution to this problem I'd love to hear it as well, since I haven't yet taken the plunge in any one of these directions.
",Can Mustache Templates do template extension?,"I'm new to Mustache.

Many templating languages (e.g., Django / Jinja) will let you extend a ""parent"" template like so...

base.html


    
    {% block content %}{% endblock %}
    



frontpage.html

{% extends ""base.html"" %}
{% block content %}Foobar!{% endblock %}


rendered frontpage.html


    
    Foobar!
    



I'm aware of Mustache's partials (e.g., {{>content}}), but those seem to be just includes.

Does template extension exist for Mustache? Or, failing that, is there at least some design pattern that effectively turns includes into template extension equivalents.
"
"There is no point. Even if you can verify that the email address is syntactically valid, you'll still need to check that it was not mistyped, and that it actually goes to the person you think it does. The only way to do that is to send them an email and have them click a link to verify.

Therefore, a most basic check (e.g. that they didn't accidentally entered their street address) is usually enough. Something like: it has exactly one @ sign, and at least one . in the part after the @:

[^@]+@[^@]+\.[^@]+


You'd probably also want to disallow whitespace -- there are probably valid email addresses with whitespace in them, but I've never seen one, so the odds of this being a user error are on your side.

If you want the full check, have a look at this question.



Update: Here's how you could use any such regex:

import re

if not re.match(r""... regex here ..."", email):
  # whatever


Note the r in front of the string; this way, you won't need to escape things twice.

If you have a large number of regexes to check, it might be faster to compile the regex first:

import re

EMAIL_REGEX = re.compile(r""... regex here ..."")

if not EMAIL_REGEX.match(email):
  # whatever

",Python check for valid email address?,"Is there a good way to check a form input using regex to make sure it is a proper style email address? Been searching since last night and everybody that has answered peoples questions regarding this topic also seems to have problems with it if it is a subdomained email address.
"
"Here's a python 3 script that returns a tuple containing an image height and width for .png, .gif and .jpeg without using any external libraries (ie what Kurt McKee referenced above). Should be relatively easy to transfer it to Python 2.

import struct
import imghdr

def get_image_size(fname):
    '''Determine the image type of fhandle and return its size.
    from draco'''
    with open(fname, 'rb') as fhandle:
        head = fhandle.read(24)
        if len(head) != 24:
            return
        if imghdr.what(fname) == 'png':
            check = struct.unpack('>i', head[4:8])[0]
            if check != 0x0d0a1a0a:
                return
            width, height = struct.unpack('>ii', head[16:24])
        elif imghdr.what(fname) == 'gif':
            width, height = struct.unpack('<HH', head[6:10])
        elif imghdr.what(fname) == 'jpeg':
            try:
                fhandle.seek(0) # Read 0xff next
                size = 2
                ftype = 0
                while not 0xc0 <= ftype <= 0xcf:
                    fhandle.seek(size, 1)
                    byte = fhandle.read(1)
                    while ord(byte) == 0xff:
                        byte = fhandle.read(1)
                    ftype = ord(byte)
                    size = struct.unpack('>H', fhandle.read(2))[0] - 2
                # We are at a SOFn block
                fhandle.seek(1, 1)  # Skip `precision' byte.
                height, width = struct.unpack('>HH', fhandle.read(4))
            except Exception: #IGNORE:W0703
                return
        else:
            return
        return width, height

",How to obtain image size using standard Python class (without using external library)?,"I am using Python 2.5. And using the standard classes from Python, I want to determine the image size of a file.

I've heard PIL (Python Image Library), but it requires installation to work.

How might I obtain an image's size without using any external library, just using Python 2.5's own modules?

Note I want to support common image formats, particularly JPG and PNG.
"
"Python does not require semi-colons to terminate statements.  Semi colons can be used to delimit statements if you wish to put multiple statements on the same line.

Now, why is this allowed?  It's a simple design decision.  I don't think Python needs this semi-colon thing, but somebody thought it would be nice to have and added it to the language.
",Why is semicolon allowed in this python snippet?,"Python does not warrant the use of semicolons to end statements.
So why is this (below) allowed?

import pdb; pdb.set_trace()

"
"IPython Notebooks are awesome.  Here's another, newer browser-based tool I've recently discovered: Rodeo.  My impression is that it seems to better support an RStudio-like workflow.


",Is there something like RStudio for Python?,"In RStudio, you can run parts of code in the code editing window, and the results appear in the console.

You can also do cool stuff like selecting whether you want everything up to the cursor to run, or everything after the cursor, or just the part that you selected, and so on. And there are hot keys for all that stuff. 

It's like a step above the interactive shell in Python -- there you can use readline to go back to previous individual lines, but it doesn't have any ""concept"" of what a function is, a section of code, etc. 

Is there a tool like that for Python? Or, do you have some sort of similar workaround that you use, say, in vim? 
"
"It's not that std::string performs poorly (as much as I dislike C++), it's that string handling is so heavily optimized for those other languages.

Your comparisons of string performance are misleading, and presumptuous if they are intended to represent more than just that.

I know for a fact that Python string objects are completely implemented in C, and indeed on Python 2.7, numerous optimizations exist due to the lack of separation between unicode strings and bytes. If you ran this test on Python 3.x you will find it considerably slower.

Javascript has numerous heavily optimized implementations. It's to be expected that string handling is excellent here.

Your Java result may be due to proper string handling, or some other poor case. I expect that a Java expert could step in and fix this test with a few changes.

As for your C++ example, I'd expect performance to slightly exceed the Python version. It does the same operations, with less interpreter overhead. This is reflected in your results. Preceding the test with s.reserve(limit); would remove reallocation overhead.

I'll repeat that you're only testing a single facet of the languages implementations. The results for this test do not reflect the overall language speed.

I've provided a C version to show how silly such pissing contests can be:

#define _GNU_SOURCE
#include 
#include 

void test()
{
    int limit = 102 * 1024;
    char s[limit];
    size_t size = 0;
    while (size < limit) {
        s[size++] = 'X';
        if (memmem(s, size, ""ABCDEFGHIJKLMNOPQRSTUVWXYZ"", 26)) {
            fprintf(stderr, ""zomg\n"");
            return;
        }
    }
    printf(""x's length = %zu\n"", size);
}

int main()
{
    test();
    return 0;
}


Timing:

matt@stanley:~/Desktop$ time ./smash 
x's length = 104448

real    0m0.681s
user    0m0.680s
sys     0m0.000s

",Why do std::string operations perform poorly?,"I made a test to compare string operations in several languages for choosing a language for the server-side application. The results seemed normal until I finally tried C++, which surprised me a lot. So I wonder if I had missed any optimization and come here for help.

The test are mainly intensive string operations, including concatenate and searching. The test is performed on Ubuntu 11.10 amd64, with GCC's version 4.6.1. The machine is Dell Optiplex 960, with 4G RAM, and Quad-core CPU.

in Python (2.7.2):

def test():
    x = """"
    limit = 102 * 1024
    while len(x) < limit:
        x += ""X""
        if x.find(""ABCDEFGHIJKLMNOPQRSTUVWXYZ"", 0) > 0:
            print(""Oh my god, this is impossible!"")
    print(""x's length is : %d"" % len(x))

test()


which gives result:

x's length is : 104448

real    0m8.799s
user    0m8.769s
sys     0m0.008s


in Java (OpenJDK-7):

public class test {
    public static void main(String[] args) {
        int x = 0;
        int limit = 102 * 1024;
        String s="""";
        for (; s.length() < limit;) {
            s += ""X"";
            if (s.indexOf(""ABCDEFGHIJKLMNOPQRSTUVWXYZ"") > 0)
            System.out.printf(""Find!\n"");
        }
        System.out.printf(""x's length = %d\n"", s.length());
    }
}


which gives result:

x's length = 104448

real    0m50.436s
user    0m50.431s
sys     0m0.488s


in Javascript (Nodejs 0.6.3)

function test()
{
    var x = """";
    var limit = 102 * 1024;
    while (x.length < limit) {
        x += ""X"";
        if (x.indexOf(""ABCDEFGHIJKLMNOPQRSTUVWXYZ"", 0) > 0)
            console.log(""OK"");
    }
    console.log(""x's length = "" + x.length);
}();


which gives result:

x's length = 104448

real    0m3.115s
user    0m3.084s
sys     0m0.048s


in C++ (g++ -Ofast)

It's not surprising that Nodejs performas better than Python or Java. But I expected libstdc++ would give much better performance than Nodejs, whose result really suprised me.

#include 
#include 
using namespace std;
void test()
{
    int x = 0;
    int limit = 102 * 1024;
    string s("""");
    for (; s.size() < limit;) {
        s += ""X"";
        if (s.find(""ABCDEFGHIJKLMNOPQRSTUVWXYZ"", 0) != string::npos)
            cout << ""Find!"" << endl;
    }
    cout << ""x's length = "" << s.size() << endl;
}

int main()
{
    test();
}


which gives result:

x length = 104448

real    0m5.905s
user    0m5.900s
sys     0m0.000s


Brief Summary

OK, now let's see the summary:


javascript on Nodejs(V8): 3.1s
Python on CPython 2.7.2 : 8.8s
C++ with libstdc++: 5.9s
Java on OpenJDK 7: 50.4s


Surprisingly! I tried ""-O2, -O3"" in C++ but noting helped. C++ seems about only 50% performance of javascript in V8, and even poor than CPython. Could anyone explain to me if I had missed some optimization in GCC or is this just the case? Thank you a lot.
"
"I like to use continue in loops where there are a lot of contitions to be fulfilled before you get ""down to business"". So instead of code like this:

for x, y in zip(a, b):
    if x > y:
        z = calculate_z(x, y)
        if y - z < x:
            y = min(y, z)
            if x ** 2 - y ** 2 > 0:
                lots()
                of()
                code()
                here()


I get code like this:

for x, y in zip(a, b):
    if x <= y:
        continue
    z = calculate_z(x, y)
    if y - z >= x:
        continue
    y = min(y, z)
    if x ** 2 - y ** 2 <= 0:
        continue
    lots()
    of()
    code()
    here()


By doing it this way I avoid very deeply nested code. Also, it is easy to optimize the loop by eliminating the most frequently occurring cases first, so that I only have to deal with the infrequent but important cases (e.g. divisor is 0) when there is no other showstopper.
","Example use of ""continue"" statement in Python?","The definition of the continue statement is: 


  The continue statement continues with the next iteration of the loop.


I can't find any good example of code. 

Could someone suggest some simple cases where continue is necessary? 
"
"I'm not a Python guy, but tried installing JPype on my machine:

% uname -a
Darwin fatty-i7.local.tld 11.2.0 Darwin Kernel Version 11.2.0: Tue Aug  9 20:54:00 PDT 2011; root:xnu-1699.24.8~1/RELEASE_X86_64 x86_64
% java -version
java version ""1.6.0_29""
Java(TM) SE Runtime Environment (build 1.6.0_29-b11-402-11M3527)
Java HotSpot(TM) 64-Bit Server VM (build 20.4-b02-402, mixed mode)


On OSX Lion, the latest JDK appears to be located here:

/Developer/SDKs/MacOSX10.7.sdk/System/Library/Frameworks/JavaVM.framework/


A little googling turned up this post: http://blog.y3xz.com/post/5037243230/installing-jpype-on-mac-os-x

I followed those instructions to modify setup.py, then ran sudo python setup.py install with no problems. 

Does that help?
",How to install JPype on OS X Lion to use with Neo4j?,"I am trying to use Neo4j for a project, and want to interface with it through Python since I'm a newbie to programming and don't know any Java. I'm following the installation instructions, but I'm stuck on
the first step, which is to install JPype.

I'm using OS X 10.7 (lion). I think my configuration is pretty standard
with Python 2.7.2 downloaded from the Python website and Java 1.6.0 downloaded from the Apple website.

When I run

% sudo python setup.py install


On the JPype installer, I get about a 100 lines of error code about various .h files, then it
terminates with the lines:

lipo: can't figure out the architecture type of: /var/tmp//
ccwOzLi9.out

error: command 'gcc-4.2' failed with exit status 1


I found a blog post about a gcc error with JPype, but I followed the instructions there to no avail. I also emailed the author of that post, and he told me had never actually used JPype, had been working in OS X 10.6, and didn't have any insight.

I also emailed the creator of JPype, who told me that he only uses Windows, and has no idea how to make the install work on OS X. But if we can solve this, I can point him to the answer and maybe he can add the solution to the JPype documentation and help lots of other people as well!

So, anyone know what I'm doing wrong? I would like to use Neo4j, but I
don't know Java so I'm at a complete loss for how to fix a compiler
error.

Based on reading every Google result available, my two running
theories are that:


I'm somehow using a 32-bit version of Python or of Java (though I
used standard official installations and can't figure out how to
switch to 64-bit or if that's even possible)
The JPype files can only be compiled using GCC 4.0 instead of 4.2.
But I can't find anything online about how to rollback to GCC 4.0 (or
if it comes shipped with 2011 MacBooks and there is some way to force
JPype to compile with that instead). 


There is another similar question, but the solution there is to use a different adapter that goes through REST instead of hooking directly into Java. I will try that if I have to, but I would really rather use the recommended Neo4j method if it's possible.
"
"Tools -> Build System -> (choose) Python then:

To Run:

      Tools -> Build

      -or-

      Ctrl + B

      CMD + B  (OSX)


This would start your file in the console which should be at the bottom of the editor.

To Stop:

       Ctrl + Break or Tools -> Cancel Build


You can find out where your Break key is here:  http://en.wikipedia.org/wiki/Break_key.    

Note: CTRL + C will NOT work.

What to do when Ctrl + Break does not work:

Go to: 


  Preferences -> Key Bindings - User


and paste the line below:  

{""keys"": [""ctrl+shift+c""], ""command"": ""exec"", ""args"": {""kill"": true} } 


Now, you can use ctrl+shift+c instead of CTRL+BREAK
",How do I run Python code from Sublime Text 2?,"I want to set up a complete Python IDE in Sublime Text 2.

I want to know how to run the Python code from within the editor. Is it done using build system? How do I do it ?
"
"The range of floating point numbers usually exceeds the range of integers. By returning a floating point value, the functions can return a sensible value for input values that lie outside the representable range of integers.

Consider: If floor() returned an integer, what should floor(1.0e30) return?

Now, while Python's integers are now arbitrary precision, it wasn't always this way. The standard library functions are thin wrappers around the equivalent C library functions.
",Why do Python's math.ceil() and math.floor() operations return floats instead of integers?,"Can someone explain this (straight from the docs- emphasis mine):


  math.ceil(x) Return the ceiling of x as a float, the smallest integer value greater than or equal to x.
  
  math.floor(x) Return the floor of x as a float, the largest integer value less than or equal to x.


Why would .ceil and .floor return floats when they are by definition supposed to calculate integers?



EDIT:

Well this got some very good arguments as to why they should return floats, and I was just getting used to the idea, when @jcollado pointed out that they in fact do return ints in Python 3...
"
"v = [1,2,3,4,3,1,2]
any([2,3] == v[i:i+2] for i in xrange(len(v) - 1))


While @PaoloCapriotti's version does the trick, this one is faster, because it stops parsing the v as soon as a match is found.
","Check if two items are in a list, in a particular order?","Say I have a list v = [1, 2, 3, 4, 3, 1, 2]. I want to write a function, find_pair which will check if two numbers are in the list and adjacent to each other. So, find_pair(v, 2, 3) should return True, but find_pair(v, 1, 4) should return False.

Is it possible to implement find_pair without a loop?
"
"Here is a simple one-pass O(n) solution:

s = [1,4,2,3,5,4,5,6,7,8,1,3,4,5,9,10,11,42]
maxrun = -1
rl = {}
for x in s:
    run = rl[x] = rl.get(x-1, 0) + 1
    print x-run+1, 'to', x
    if run > maxrun:
        maxend, maxrun = x, run
print range(maxend-maxrun+1, maxend+1)


The logic may be a little more self-evident if you think in terms of ranges instead of individual variables for the endpoint and run length:

rl = {}
best_range = xrange(0)
for x in s:
    run = rl[x] = rl.get(x-1, 0) + 1
    r = xrange(x-run+1, x+1)
    if len(r) > len(best_range):
        best_range = r
print list(best_range)

","In python, how does one efficiently find the largest consecutive set of numbers in a list that are not necessarily adjacent?","For instance, if I have a list 

[1,4,2,3,5,4,5,6,7,8,1,3,4,5,9,10,11]


This algorithm should return [1,2,3,4,5,6,7,8,9,10,11].

To clarify, the longest list should run forwards. I was wondering what is an algorithmically efficient way to do this (preferably not O(n^2))?

Also, I'm open to a solution not in python since the algorithm is what matters.

Thank you.
"
"z = (set((""a"", ""b"", ""c"")) - set((x, y))).pop()


I am assuming that one of the three cases in your code holds.  If this is the case, the set set((""a"", ""b"", ""c"")) - set((x, y)) will consist of a single element, which is returned by pop().

Edit: As suggested by Raymond Hettinger in the comments, you could also use tuple unpacking to extract the single element from the set:

z, = set((""a"", ""b"", ""c"")) - set((x, y))

",How can I find the missing value more concisely?,"The following code checks if x and y are distinct values (the variables x, y, z can only have values a, b, or c) and if so, sets z to the third character:

if x == 'a' and y == 'b' or x == 'b' and y == 'a':
    z = 'c'
elif x == 'b' and y == 'c' or x == 'c' and y == 'b':
    z = 'a'
elif x == 'a' and y == 'c' or x == 'c' and y == 'a':
    z = 'b'


Is is possible to do this in a more, concise, readable and efficient way?
"
"To avoid creating duplicate URL:s to the same page, you should use a RedirectRoute with strict_slash set to True to automatically redirect /feed/ to /feed, like this:

from webapp2_extras.routes import RedirectRoute

route = RedirectRoute('/feed', handler=feed, strict_slash=True)


Read more at http://webapp2.readthedocs.io/en/latest/api/webapp2_extras/routes.html
",How do I make a trailing slash optional with webapp2?,"I'm using the new webapp2 (now the default webapp in 1.6), and I haven't been able to figure out how to make the trailing slash optional in code like this:

webapp.Route('/feed', handler = feed)


I've tried /feed/?, /feed/*, /feed\/* and /feed\/?, all to no avail. 
"
"A naive algorithm won't give good results when applied to real-world data. Here is a 20-line algorithm that exploits relative word frequency to give accurate results for real-word text.

(If you want an answer to your original question which does not use word frequency, you need to refine what exactly is meant by ""longest word"": is it better to have a 20-letter word and ten 3-letter words, or is it better to have five 10-letter words? Once you settle on a precise definition, you just have to change the line defining wordcost to reflect the intended meaning.)

The idea

The best way to proceed is to model the distribution of the output. A good first approximation is to assume all words are independently distributed. Then you only need to know the relative frequency of all words. It is reasonable to assume that they follow Zipf's law, that is the word with rank n in the list of words has probability roughly 1/(n log N) where N is the number of words in the dictionary.

Once you have fixed the model, you can use dynamic programming to infer the position of the spaces. The most likely sentence is the one that maximizes the product of the probability of each individual word, and it's easy to compute it with dynamic programming. Instead of directly using the probability we use a cost defined as the logarithm of the inverse of the probability to avoid overflows.

The code

from math import log

# Build a cost dictionary, assuming Zipf's law and cost = -math.log(probability).
words = open(""words-by-frequency.txt"").read().split()
wordcost = dict((k, log((i+1)*log(len(words)))) for i,k in enumerate(words))
maxword = max(len(x) for x in words)

def infer_spaces(s):
    """"""Uses dynamic programming to infer the location of spaces in a string
    without spaces.""""""

    # Find the best match for the i first characters, assuming cost has
    # been built for the i-1 first characters.
    # Returns a pair (match_cost, match_length).
    def best_match(i):
        candidates = enumerate(reversed(cost[max(0, i-maxword):i]))
        return min((c + wordcost.get(s[i-k-1:i], 9e999), k+1) for k,c in candidates)

    # Build the cost array.
    cost = [0]
    for i in range(1,len(s)+1):
        c,k = best_match(i)
        cost.append(c)

    # Backtrack to recover the minimal-cost string.
    out = []
    i = len(s)
    while i>0:
        c,k = best_match(i)
        assert c == cost[i]
        out.append(s[i-k:i])
        i -= k

    return "" "".join(reversed(out))


which you can use with

s = 'thumbgreenappleactiveassignmentweeklymetaphor'
print(infer_spaces(s))




The results

I am using this quick-and-dirty 125k-word dictionary I put together from a small subset of Wikipedia.


  Before: thumbgreenappleactiveassignmentweeklymetaphor.
  After: thumb green apple active assignment weekly metaphor.





  Before: thereismassesoftextinformationofpeoplescommentswhichisparsedfromhtmlbuttherearen
  odelimitedcharactersinthemforexamplethumbgreenappleactiveassignmentweeklymetapho
  rapparentlytherearethumbgreenappleetcinthestringialsohavealargedictionarytoquery
  whetherthewordisreasonablesowhatsthefastestwayofextractionthxalot.
  
  After: there is masses of text information of peoples comments which is parsed from html but there are no delimited characters in them for example thumb green apple active assignment weekly metaphor apparently there are thumb green apple etc in the string i also have a large dictionary to query whether the word is reasonable so what s the fastest way of extraction thx a lot.





  Before: itwasadarkandstormynighttherainfellintorrentsexceptatoccasionalintervalswhenitwascheckedbyaviolentgustofwindwhichsweptupthestreetsforitisinlondonthatoursceneliesrattlingalongthehousetopsandfiercelyagitatingthescantyflameofthelampsthatstruggledagainstthedarkness.
  
  After: it was a dark and stormy night the rain fell in torrents except at occasional intervals when it was checked by a violent gust of wind which swept up the streets for it is in london that our scene lies rattling along the housetops and fiercely agitating the scanty flame of the lamps that struggled against the darkness.


As you can see it is essentially flawless. The most important part is to make sure your word list was trained to a corpus similar to what you will actually encounter, otherwise the results will be very bad.



Optimization

The implementation consumes a linear amount of time and memory, so it is reasonably efficient. If you need further speedups, you can build a suffix tree from the word list to reduce the size of the set of candidates.

If you need to process a very large consecutive string it would be reasonable to split the string to avoid excessive memory usage. For example you could process the text in blocks of 10000 characters plus a margin of 1000 characters on either side to avoid boundary effects. This will keep memory usage to a minimum and will have almost certainly no effect on the quality.
",How to split text without spaces into list of words?,"Input: ""tableapplechairtablecupboard..."" many words  

What would be an efficient algorithm to split such text to the list of words and get:  

Output: [""table"", ""apple"", ""chair"", ""table"", [""cupboard"", [""cup"", ""board""]], ...]

First thing that cames to mind is to go through all possible words (starting with first letter) and find the longest word possible, continue from position=word_position+len(word)

P.S.
We have a list of all possible words.
Word ""cupboard"" can be ""cup"" and ""board"", select longest.
Language: python, but main thing is the algorithm itself. 
"
"I present two approaches.

Approach 1: all-out regex

In [1]: import re

In [2]: s = 'adsgasdlkgasYasdgjaUUalsdkjgaZsdalkjgalsdkjTlaksdjfgasdkgj'

In [3]: re.match(r'(?:.*?[A-Z]){3}.*?([A-Z].*)', s).group(1)
Out[3]: 'ZsdalkjgalsdkjTlaksdjfgasdkgj'


The .*?[A-Z] consumes characters up to, and including, the first uppercase letter.

The (?:...){3} repeats the above three times without creating any capture groups. 

The following .*?  matches the remaining characters before the fourth uppercase letter.

Finally, the ([A-Z].*) captures the fourth uppercase letter and everything that follows into a capture group.

Approach 2: simpler regex

In [1]: import re

In [2]: s = 'adsgasdlkgasYasdgjaUUalsdkjgaZsdalkjgalsdkjTlaksdjfgasdkgj'

In [3]: ''.join(re.findall(r'[A-Z][^A-Z]*', s)[3:])
Out[3]: 'ZsdalkjgalsdkjTlaksdjfgasdkgj'


This attacks the problem directly, and I think is easier to read.
",Parse 4th capital letter of line in Python?,"How can I parse lines of text from the 4th occurrence of a capital letter onward? For example given the lines:

adsgasdlkgasYasdgjaUUalsdkjgaZsdalkjgalsdkjTlaksdjfgasdkgj
oiwuewHsajlkjfasNasldjgalskjgasdIasdllksjdgaPlsdakjfsldgjQ


I would like to capture:

`ZsdalkjgalsdkjTlaksdjfgasdkgj`
`PlsdakjfsldgjQ`


I'm sure there is probably a better way than regular expressions, but I was attempted to do a non-greedy match; something like this:

match = re.search(r'[A-Z].*?$', line).group()

"
"python -V


http://docs.python.org/using/cmdline.html#generic-options

--version may also work (introduced in version 2.5)
",Which version of Python do I have installed?,"I have to run a Python script on a Windows server. How can I know which version of Python I have, and does it even really matter? I was thinking of updating to latest version of Python.
"
"class color:
   PURPLE = '\033[95m'
   CYAN = '\033[96m'
   DARKCYAN = '\033[36m'
   BLUE = '\033[94m'
   GREEN = '\033[92m'
   YELLOW = '\033[93m'
   RED = '\033[91m'
   BOLD = '\033[1m'
   UNDERLINE = '\033[4m'
   END = '\033[0m'

print color.BOLD + 'Hello World !' + color.END

",How do I print bold text in Python?,"How do I print bold text in Python?

For example:

print ""hello""


What should I do so that the text âhelloâ is displayed in bold?
"
"Standard Python dictionaries are unordered. Even if you sorted the (key,value) pairs, you wouldn't be able to store them in a dict in a way that would preserve the ordering.

The easiest way is to use OrderedDict, which remembers the order in which the elements have been inserted:

In [1]: import collections

In [2]: d = {2:3, 1:89, 4:5, 3:0}

In [3]: od = collections.OrderedDict(sorted(d.items()))

In [4]: od
Out[4]: OrderedDict([(1, 89), (2, 3), (3, 0), (4, 5)])


Never mind the way od is printed out; it'll work as expected:

In [11]: od[1]
Out[11]: 89

In [12]: od[3]
Out[12]: 0

In [13]: for k, v in od.iteritems(): print k, v
   ....: 
1 89
2 3
3 0
4 5


Python 3

For Python 3 users, one needs to use the .items() instead of .iteritems():

In [13]: for k, v in od.items(): print(k, v)
   ....: 
1 89
2 3
3 0
4 5

",How can I sort a dictionary by key?,"What would be a nice way to go from {2:3, 1:89, 4:5, 3:0} to {1:89, 2:3, 3:0, 4:5}?
I checked some posts but they all use the ""sorted"" operator that returns tuples. 
"
"First a pointed to the string ""Dog"".  Then you changed the variable a to point at a new string ""Dog eats treats"".  You didn't actually mutate the string ""Dog"".  Strings are immutable, variables can point at whatever they want.
",Aren't Python strings immutable?,"My understanding was that Python strings are immutable.

I tried the following code:

a = ""Dog""
b = ""eats""
c = ""treats""

print a, b, c
# Dog eats treats

print a + "" "" + b + "" "" + c
# Dog eats treats

print a
# Dog

a = a + "" "" + b + "" "" + c
print a
# Dog eats treats
# !!!


Shouldn't Python have prevented the assignment? I am probably missing something.

Any idea?
"
"Except that might not work because if nothing is found, 

driver.findElement(By.css("""")) 


will return an NoSuchElementException which is probably the Java equivalent of the exception you are seeing.

Not sure about Python but in Java this would be better

assertTrue(driver.findElements(By.whateverYouWant).size() == 0) 


or in reverse

assertFalse(driver.findElements(By.whateverYouWant).size() > 0)


http://selenium.googlecode.com/svn/trunk/docs/api/java/org/openqa/selenium/WebDriver.html#findElement(org.openqa.selenium.By)
",How do I create a Selenium Webdriver test to verify an element is not present?,"I am creating unit tests for my Django app in Selenium Webdriver.

I have an AJAX method that deletes a Topic from the database.
I'm trying to figure out how to verify that the deleted Topic is no longer present on the page.

I am trying to catch the Exception that the should be generated when Webdriver can't find an element:
selenium.common.exceptions.NoSuchAttributeException  

Instead I see an error:  

*** URLError: 


Here is how I have setup the tests:  

from selenium import webdriver
from django.utils import unittest  

class TestAuthentication(unittest.TestCase):    
    scheme = 'http'    
    host = 'localhost'    
    port = '4444'    


    def setUp(self):    
        self._driver = webdriver.Firefox()    
        self._driver.implicitly_wait(10)    

    def login_as_Kallie(self):    
        # Kallie has manual login    
        self._driver.get('http://localhost:8000/account/signin/')    
        user = self._driver.find_element_by_id('id_username')    
        user.send_keys(""Kallie"")    
        password = self._driver.find_element_by_id('id_password')    
        password.send_keys('*********')    
        submit = self._driver.find_element_by_id('blogin')    
        submit.click()    

    def test_Kallie_can_delete_topic(self):    
        self.login_as_Kallie()    
        self._driver.find_element_by_link_text(""Topic to delete"").click()    
        self._driver.find_element_by_xpath(""/html/body/div/div[4]/div/div/div[2]/div/table/tbody/tr/td[2]/div/div[3]/span[5]/a"").click()    
        self._driver.find_element_by_class_name('dialog-yes').click()    
        self._driver.get(""http://localhost:8000/questions/"")    
        # this is the Python exception to catch: selenium.common.exceptions.NoSuchAttributeException    
        self.assertRaises('selenium.common.exceptions.NoSuchAttributeException', self._driver.find_element_by_link_text(""Topic to delete""))    

    def tearDown(self):    
        self._driver.quit()    


How can I test that a Element of the page is absent?   
"
"max(i for i in my_list if i % 2)




Edit: without max():

def highest_odd(seq):
    """"""
    Return the highest odd number in `seq`.
    If there are no odd numbers, then return `None`.

    """"""
    for i in sorted(seq, reverse=True):
        if i % 2:
            return i

","In Python, what's the method for returning only the max odd integer in a list?","If you have a list of numbers, how do you return only the max odd integer without using the max() function?

I'm assuming it will have something to do with int % 2 != 0, but I'm not sure what else.



I also have to return the overall max integer without using max(), but I got around that by sorting my list and using list[-1].
"
"By default, cin is synchronized with stdio, which causes it to avoid any input buffering.  If you add this to the top of your main, you should see much better performance:

std::ios_base::sync_with_stdio(false);


Normally, when an input stream is buffered, instead of reading one character at a time, the stream will be read in larger chunks.  This reduces the number of system calls, which are typically relatively expensive.  However, since the FILE* based stdio and iostreams often have separate implementations and therefore separate buffers, this could lead to a problem if both were used together.  For example:

int myvalue1;
cin >> myvalue1;
int myvalue2;
scanf(""%d"",&myvalue2);


If more input was read by cin than it actually needed, then the second integer value wouldn't be available for the scanf function, which has its own independent buffer.  This would lead to unexpected results.

To avoid this, by default, streams are synchronized with stdio.  One common way to achieve this is to have cin read each character one at a time as needed using stdio functions.  Unfortunately, this introduces a lot of overhead.  For small amounts of input, this isn't a big problem, but when you are reading millions of lines, the performance penalty is significant.

Fortunately, the library designers decided that you should also be able to disable this feature to get improved performance if you knew what you were doing, so they provided the sync_with_stdio method.
",Why is reading lines from stdin much slower in C++ than Python?,"I wanted to compare reading lines of string input from stdin using Python and C++ and was shocked to see my C++ code run an order of magnitude slower than the equivalent Python code.  Since my C++ is rusty and I'm not yet an expert Pythonista, please tell me if I'm doing something wrong or if I'm misunderstanding something.  



(tl;dr answer: include the statement: cin.sync_with_stdio(false) or just use fgets instead.

tl;dr results: scroll all the way down to the bottom of my question and look at the table.)



C++ code:

#include 
#include 

using namespace std;

int main() {
    string input_line;
    long line_count = 0;
    time_t start = time(NULL);
    int sec;
    int lps;                                                                   

    while (cin) {
        getline(cin, input_line);
        if (!cin.eof())
            line_count++;
    };

    sec = (int) time(NULL) - start;
    cerr << ""Read "" << line_count << "" lines in "" << sec << "" seconds."" ;
    if (sec > 0) {
        lps = line_count / sec;
        cerr << "" LPS: "" << lps << endl;
    } else
        cerr << endl;
    return 0;
}

//Compiled with:
//g++ -O3 -o readline_test_cpp foo.cpp


Python Equivalent:

#!/usr/bin/env python
import time
import sys

count = 0
start = time.time()

for line in  sys.stdin:
    count += 1

delta_sec = int(time.time() - start_time)
if delta_sec >= 0:
    lines_per_sec = int(round(count/delta_sec))
    print(""Read {0} lines in {1} seconds. LPS: {2}"".format(count, delta_sec,
       lines_per_sec))


Here are my results:

$ cat test_lines | ./readline_test_cpp 
Read 5570000 lines in 9 seconds. LPS: 618889

$cat test_lines | ./readline_test.py 
Read 5570000 lines in 1 seconds. LPS: 5570000


Edit: I should note that I tried this both under OS-X (10.6.8) and Linux 2.6.32 (RHEL 6.2).  The former is a macbook pro, the latter is a very beefy server, not that this is too pertinent.

Edit 2: (Removed this edit, as no longer applicable)

$ for i in {1..5}; do echo ""Test run $i at `date`""; echo -n ""CPP:""; cat test_lines | ./readline_test_cpp ; echo -n ""Python:""; cat test_lines | ./readline_test.py ; done
Test run 1 at Mon Feb 20 21:29:28 EST 2012
CPP:   Read 5570001 lines in 9 seconds. LPS: 618889
Python:Read 5570000 lines in 1 seconds. LPS: 5570000
Test run 2 at Mon Feb 20 21:29:39 EST 2012
CPP:   Read 5570001 lines in 9 seconds. LPS: 618889
Python:Read 5570000 lines in 1 seconds. LPS: 5570000
Test run 3 at Mon Feb 20 21:29:50 EST 2012
CPP:   Read 5570001 lines in 9 seconds. LPS: 618889
Python:Read 5570000 lines in 1 seconds. LPS: 5570000
Test run 4 at Mon Feb 20 21:30:01 EST 2012
CPP:   Read 5570001 lines in 9 seconds. LPS: 618889
Python:Read 5570000 lines in 1 seconds. LPS: 5570000
Test run 5 at Mon Feb 20 21:30:11 EST 2012
CPP:   Read 5570001 lines in 10 seconds. LPS: 557000
Python:Read 5570000 lines in  1 seconds. LPS: 5570000


Edit 3: 

Okay, I tried J.N.'s suggestion of trying having python store the line read: but it made no difference to python's speed.  

I also tried J.N.'s suggestion of using scanf into a char array instead of getline into a std::string.  Bingo!  This resulted in equivalent performance for both python and c++. (3,333,333 LPS with my input data, which by the way are just short lines of three fields each, usually about 20 chars wide, though sometimes more).

Code:

char input_a[512];
char input_b[32];
char input_c[512];
while(scanf(""%s %s %s\n"", input_a, input_b, input_c) != EOF) {             
    line_count++;
};


Speed:

$ cat test_lines | ./readline_test_cpp2 
Read 10000000 lines in 3 seconds. LPS: 3333333
$ cat test_lines | ./readline_test2.py 
Read 10000000 lines in 3 seconds. LPS: 3333333


(Yes, I ran it several times.) So, I guess I will now use scanf instead of getline.  But, I'm still curious if people think this performance hit from std::string/getline is typical and reasonable. 

Edit 4 (was: Final Edit / Solution):

Adding:
    cin.sync_with_stdio(false);

Immediately above my original while loop above results in code that runs faster than Python.  

New performance comparison (this is on my 2011 Macbook Pro), using the original code, the original with the sync disabled, and the original python, respectively, on a file with 20M lines of text.  Yes, I ran it several times to eliminate disk caching confound.

$ /usr/bin/time cat test_lines_double | ./readline_test_cpp
       33.30 real         0.04 user         0.74 sys
Read 20000001 lines in 33 seconds. LPS: 606060
$ /usr/bin/time cat test_lines_double | ./readline_test_cpp1b
        3.79 real         0.01 user         0.50 sys
Read 20000000 lines in 4 seconds. LPS: 5000000
$ /usr/bin/time cat test_lines_double | ./readline_test.py 
        6.88 real         0.01 user         0.38 sys
Read 20000000 lines in 6 seconds. LPS: 3333333


Thanks to @Vaughn Cato for his answer!  Any elaboration people can make or good references people can point to as to why this sync happens, what it means, when it's useful, and when it's okay to disable would be greatly appreciated by posterity. :-)

Edit 5 / Better Solution:

As suggested by Gandalf The Gray below, gets is even faster than scanf or the unsynchronized cin approach.  I also learned that scanf and gets are both UNSAFE and should NOT BE USED due to potential of buffer overflow.  So, I wrote this iteration using fgets, the safer alternative to gets.  Here are the pertinent lines for my fellow noobs:

char input_line[MAX_LINE];
char *result;

//

while((result = fgets(input_line, MAX_LINE, stdin )) != NULL)    
    line_count++;
if (ferror(stdin))
    perror(""Error reading stdin."");


Now, here are the results using an even larger file (100M lines; ~3.4GB) on a fast server with very fast disk, comparing the python, the unsynced cin, and the fgets approaches, as well as comparing with the wc utility.  [The scanf version segfaulted and I don't feel like troubleshooting it.]:

$ /usr/bin/time cat temp_big_file | readline_test.py 
0.03user 2.04system 0:28.06elapsed 7%CPU (0avgtext+0avgdata 2464maxresident)k
0inputs+0outputs (0major+182minor)pagefaults 0swaps
Read 100000000 lines in 28 seconds. LPS: 3571428

$ /usr/bin/time cat temp_big_file | readline_test_unsync_cin 
0.03user 1.64system 0:08.10elapsed 20%CPU (0avgtext+0avgdata 2464maxresident)k
0inputs+0outputs (0major+182minor)pagefaults 0swaps
Read 100000000 lines in 8 seconds. LPS: 12500000

$ /usr/bin/time cat temp_big_file | readline_test_fgets 
0.00user 0.93system 0:07.01elapsed 13%CPU (0avgtext+0avgdata 2448maxresident)k
0inputs+0outputs (0major+181minor)pagefaults 0swaps
Read 100000000 lines in 7 seconds. LPS: 14285714

$ /usr/bin/time cat temp_big_file | wc -l
0.01user 1.34system 0:01.83elapsed 74%CPU (0avgtext+0avgdata 2464maxresident)k
0inputs+0outputs (0major+182minor)pagefaults 0swaps
100000000


Recap (lines per second):
python:         3,571,428 
cin (no sync): 12,500,000
fgets:         14,285,714
wc:            54,644,808


As you can see, fgets is better but still pretty far from wc performance; I'm pretty sure this is due to the fact that wc examines each character without any memory copying.  I suspect that, at this point, other parts of the code will become the bottleneck, so I don't think optimizing to that level would even be worthwhile, even if possible (since, after all, I actually need to store the read lines in memory).  

Also note that a small tradeoff with using a char * buffer and fgets vs unsynced cin to string is that the latter can read lines of any length, while the former requires limiting input to some finite number.  In practice, this is probably a non-issue for reading most line-based input files, as the buffer can be set to a very large value that would not be exceeded by valid input. 

This has been educational.  Thanks to all for your comments and suggestions.

Edit 6:

As suggested by J.F. Sebastian in the comments below, the GNU wc utility uses plain C read() (within the safe-read.c wrapper) to read chunks (of 16k bytes) at a time and count new lines.  Here's a python equivalent based on J.F.'s code (just showing the relevant snippet that replaces the python for loop:

BUFFER_SIZE = 16384 
count = sum(chunk.count('\n') for chunk in iter(partial(sys.stdin.read, BUFFER_SIZE), ''))


The performance of this version is quite fast (though still a bit slower than the raw c wc utility, of course:

$ /usr/bin/time cat temp_big_file | readline_test3.py 
0.01user 1.16system 0:04.74elapsed 24%CPU (0avgtext+0avgdata 2448maxresident)k
0inputs+0outputs (0major+181minor)pagefaults 0swaps
Read 100000000 lines in 4.7275 seconds. LPS: 21152829


Again, it's a bit silly for me to compare C++ fgets/cin and the first python code on the one hand to wc -l and this last python snippet on the other, as the latter two don't actually store the read lines but merely count newlines.  Still, it's interesting to explore all the different implementations and think about the performance implications.  Thanks again!

Edit 7: Tiny benchmark addendum and recap

For completeness, I thought I'd update the read speed for the same file on the same box with the original (synced) C++ code.  Again, this is for a 100M line file on a fast disk. Here's the complete table now:

Implementation      Lines per second
python (default)           3,571,428
cin (default/naive)          819,672
cin (no sync)             12,500,000
fgets                     14,285,714
wc (not fair comparison)  54,644,808

"
">>> line = '1234567890'
>>> n = 2
>>> [line[i:i+n] for i in range(0, len(line), n)]
['12', '34', '56', '78', '90']

",Split python string every nth character?,"
  Possible Duplicate:
  What is the most “pythonic” way to iterate over a list in chunks?  




Is it possible to split a python string every nth character?

For example, suppose I have a string containing the following:

'1234567890'


How can I get it to look like this:

['12','34','56','78','90']

"
"If using pip older than pip 6.0, try deleting the entry in ~/.pip/cache/ and or the directory $PWD/build/ if it exists. You can also try the --ignore-installed option.

In windows this is located under %USERPROFILE%\AppData\Local\pip\cache.

If using pip 6.0 or newer, try using the --no-cache-dir option.
",Removing pip's cache?,"I need to install psycopg2 v2.4.1 specifically. I accidentally did:

 pip install psycopg2


Instead of:

 pip install psycopg2==2.4.1


That installs 2.4.4 instead of the earlier version. 

Now even after I pip uninstall psycopg2 and attempt to reinstall with the correct version, it appears that pip is re-using the cache it downloaded the first time.

How can I force pip to clear out its download cache and use the specific version I'm including in the command?
"
"This will return a list of 10 numbers selected from the range 0 to 99, without duplicates.

random.sample(range(100), 10)


With reference to your specific code example, you probably want to read all the lines from the file once and then select random lines from the saved list in memory. For example:

all_lines = f1.readlines()
for i in range(50):
    lines = random.sample(all_lines, 40)


This way, you only need to actually read from the file once, before your loop. It's much more efficient to do this than to seek back to the start of the file and call f1.readlines() again for each loop iteration.
",How do I create a LIST of unique random numbers?,"I tried using random.randint(0, 100), but some numbers were the same. Is there a method/module to create a list unique random numbers?

def getScores():
    # open files to read and write
    f1 = open(""page.txt"", ""r"");
    p1 = open(""pgRes.txt"", ""a"");

    gScores = [];
    bScores = [];
    yScores = [];

    # run 50 tests of 40 random queries to implement ""bootstrapping"" method 
    for i in range(50):
        # get 40 random queries from the 50
        lines = random.sample(f1.readlines(), 40);

"
"I intepret what you're asking as


  How can I iterate over all pairs of distinct elements of a container?


Answer:

>>> x = {1,2,3}
>>> import itertools
>>> for a, b in itertools.permutations(x, 2):
...     print a, b
... 
1 2
1 3
2 1
2 3
3 1
3 2


EDIT: If you don't want both (a,b) and (b,a), just use itertools.combinations instead.
",How to do C++ style(indexed) nested loops in python?,"What is the equivalent of the following in python?

for (i=0; i<n; i++)
    for (j=i+1; j<n; j++)
        //do stuff with A[i], A[j]


Or in some sense, the following. It should also remove the element from A at the completion of each round of the loop.

for a in A:
    for a' in A/{a}: #i.e. rest of the elements of A
        #do something with a,a'
    #remove a from A


Is there a pythonic way of doing this without using enumerate()?

Edits:

Sorry for the bad description. 


In the first example, I mean to use i & j only as indices. Their values do not matter. Its just a rough c++ equivalent of the latter. 
The outer loop is executed n times. The inner loop is executed (n-1), (n-2)...0 times for each iteration of the outer loop. 


Maybe this might help (pseudocode):

function next_iteration(list):
    head = first element
    tail = remaining elements #list
    each element in tail interacts with head one by one
    next_iteration(tail)


PS: All code samples above are pseudocodes. I'm trying to express something that is still a bit vague in my mind.
"
"Finally, in Django 1.8, we have a specific method to do this. It's called refresh_from_db and it's a  new method of the class django.db.models.Model.

An example of usage:

def update_result(self):
    obj = MyModel.objects.create(val=1)
    MyModel.objects.filter(pk=obj.pk).update(val=F('val') + 1)
    # At this point obj.val is still 1, but the value in the database
    # was updated to 2. The object's updated value needs to be reloaded
    # from the database.
    obj.refresh_from_db()


If your version of Django is less than 1.8 but you want to have this functionality, modify your model to inherit from RefreshableModel:

from django.db import models
from django.db.models.constants import LOOKUP_SEP
from django.db.models.query_utils import DeferredAttribute

class RefreshableModel(models.Model):

    class Meta:
        abstract = True

    def get_deferred_fields(self):
        """"""
        Returns a set containing names of deferred fields for this instance.
        """"""
        return {
            f.attname for f in self._meta.concrete_fields
            if isinstance(self.__class__.__dict__.get(f.attname), DeferredAttribute)
        }

    def refresh_from_db(self, using=None, fields=None, **kwargs):
        """"""
        Reloads field values from the database.
        By default, the reloading happens from the database this instance was
        loaded from, or by the read router if this instance wasn't loaded from
        any database. The using parameter will override the default.
        Fields can be used to specify which fields to reload. The fields
        should be an iterable of field attnames. If fields is None, then
        all non-deferred fields are reloaded.
        When accessing deferred fields of an instance, the deferred loading
        of the field will call this method.
        """"""
        if fields is not None:
            if len(fields) == 0:
                return
            if any(LOOKUP_SEP in f for f in fields):
                raise ValueError(
                    'Found ""%s"" in fields argument. Relations and transforms '
                    'are not allowed in fields.' % LOOKUP_SEP)

        db = using if using is not None else self._state.db
        if self._deferred:
            non_deferred_model = self._meta.proxy_for_model
        else:
            non_deferred_model = self.__class__
        db_instance_qs = non_deferred_model._default_manager.using(db).filter(pk=self.pk)

        # Use provided fields, if not set then reload all non-deferred fields.
        if fields is not None:
            fields = list(fields)
            db_instance_qs = db_instance_qs.only(*fields)
        elif self._deferred:
            deferred_fields = self.get_deferred_fields()
            fields = [f.attname for f in self._meta.concrete_fields
                      if f.attname not in deferred_fields]
            db_instance_qs = db_instance_qs.only(*fields)

        db_instance = db_instance_qs.get()
        non_loaded_fields = db_instance.get_deferred_fields()
        for field in self._meta.concrete_fields:
            if field.attname in non_loaded_fields:
                # This field wasn't refreshed - skip ahead.
                continue
            setattr(self, field.attname, getattr(db_instance, field.attname))
            # Throw away stale foreign key references.
            if field.rel and field.get_cache_name() in self.__dict__:
                rel_instance = getattr(self, field.get_cache_name())
                local_val = getattr(db_instance, field.attname)
                related_val = None if rel_instance is None else getattr(rel_instance, field.related_field.attname)
                if local_val != related_val:
                    del self.__dict__[field.get_cache_name()]
        self._state.db = db_instance._state.db

class MyModel(RefreshableModel):
    # Your Model implementation
    pass

obj = MyModel.objects.create(val=1)
obj.refresh_from_db()

",How do I refresh the values on an object in Django?,"I have a model object in Django.  One of the methods on the object uses row-level locking to ensure values are accurate, like so:

class Foo(model.Model):
    counter = models.IntegerField()

    @transaction.commit_on_success
    def increment(self):
        x = Foo.objects.raw(""SELECT * from fooapp_foo WHERE id = %s FOR UPDATE"", [self.id])[0]
        x.counter += 1
        x.save()


The problem is if you call increment on a foo object, the object's values no longer reflect the values in the database.  I need a way to refresh the values in the object, or at least mark them as stale so they're refetched if necessary.  Apparently, this is functionality the developers of Django refuse to add.

I tried using the following code:

for field in self.__class__._meta.get_all_field_names():
    setattr(self, field, getattr(offer, field)) 


Unfortunately, I have a second model with the following definition:

class Bar(model.Model):
    foo = models.ForeignKey(Foo)


This causes an error, because it shows up in the field listing but you cannot getattr or setattr it.

I have two questions:


How can I refresh the values on my object?
Do I need to worry about refreshing any objects with references to my object, like foreign keys?

"
"The other answers all point out that you should not catch generic exceptions, but no one seems to want to tell you why, which is essential to understanding when you can break the ""rule"". Here is an explanation. Basically, it's so that you don't hide 


the fact that an error occured 
the specifics of the error that occured (error hiding antipattern)


So as long as you take care to do none of those things, it's OK to catch the generic exception. For instance, you could provide information about the exception to the user another way, like:


Present exceptions as dialogs in a GUI
Transfer exceptions from a worker thread or process to the controlling thread or process in a multithreading or multiprocessing application


So how to catch the generic exception? There are several ways. If you just want the exception object, do it like this:

try:
    someFunction()
except Exception as ex:
    template = ""An exception of type {0} occured. Arguments:\n{1!r}""
    message = template.format(type(ex).__name__, ex.args)
    print message


Make sure message is brought to the attention of the user in a hard-to-miss way! Printing it, as shown above, may not be enough if the message is buried in lots of other messages. Failing to get the users attention is tantamount to swallowing all exceptions, and if there's one impression you should have come away with after reading the answers on this page, it's that this is not a good thing. Ending the except block with a raise statement will remedy the problem by transparently reraising the exception that was caught.

The difference between the above and using just except: without any argument is twofold:


A bare except: doesn't give you the exception object to inspect
The exceptions SystemExit, KeyboardInterrupt and GeneratorExit aren't caught by the above code, which is generally what you want. See the exception hierarchy.


If you also want the same stacktrace you get if you do not catch the exception, you can get that like this (still inside the except clause):

    import traceback
    print traceback.format_exc()


If you use the logging module, you can print the exception to the log (along with a message) like this:

    import logging
    log = logging.getLogger()
    log.exception(""Message for you, sir!"")


If you want to dig deeper and examine the stack, look at variables etc., use the post_mortem function of the pdb module inside the except block:

    import pdb
    pdb.post_mortem()


I've found this last method to be invaluable when hunting down bugs.
",python: How do I know what type of exception occured?,"I have a function called by the main program:

try:
    someFunction()
except:
    print ""exception happened!""


but in the middle of the execution of the function it raises exception, so it jumps to the except part.

How can I see exactly what happened in the someFunction() that caused the exception to happen?
"
"Hereâs a bash solution. :)

bash$ perl -CSD -ne 'BEGIN { $s{$_}++ for split //, q(!@#.) }
                     $s{$_}++ || $c++ for split //;
                     END { print ""$c\n"" }' *.utf8

",How to count the number of unique characters in a file?,"Given a file in UTF-8, containing characters in various languages, how can I obtain a count of the number of unique characters it contains, while excluding a select number of symbols (e.g.: ""!"", ""@"", ""#"", ""."") from this count?
"
"A common construct is to run a loop until something is found and then to break out of the loop. The problem is that if I break out of the loop or the loop ends I need to determine which case happened. One method is to create a flag or store variable that will let me do a second test to see how the loop was exited.

For example assume that I need to search through a list and process each item until a flag item is found and then stop processing. If the flag item is missing then an exception needs to be raised.

Using the Python for...else construct you have

...

for i in mylist:
    if i == theflag:
        break
    process(i)
else:
    raise ValueError(""List argument missing terminal flag.)

...


Compare this to a method that does not use this syntactic sugar:

...

flagfound = False
for i in mylist:
    if i == theflag:
        flagfound = True
        break
    process(i)

if not flagfound:
    raise ValueError(""List argument missing terminal flag."")

...


In the first case the raise is bound tightly to the for loop it works with. In the second the binding is not as strong and errors may be introduced during maintenance.
",Why does python use 'else' after for and while loops?,"I understand how this construct works:

for i in range(10):
    print(i)

    if i == 9:
        print(""Too big - I'm giving up!"")
        break;
else:
    print(""Completed successfully"")


But I don't understand why else is used as the keyword here, since it suggests the code in question only runs if the for block does not complete, which is the opposite of what it does! No matter how I think about it, my brain can't progress seamlessly from the for statement to the else block. To me, continue or continuewith would make more sense (and I'm trying to train myself to read it as such).

I'm wondering how Python coders read this construct in their head (or aloud, if you like). Perhaps I'm missing something that would make such code blocks more easily decipherable?
"
"To skip the first element in Python you can simply write

for car in cars[1:]:
    # Do What Ever you want


or to skip the last elem

for car in cars[:-1]:
    # Do What Ever you want


You can use this concept for any sequence.
",Skip first entry in for loop in python?,"In python, How do I do something like:

for car in cars:
   # Skip first and last, do work for rest

"
"fp.read() reads up to the end of the file, so after it's successfully finished you know the file is at EOF; there's no need to check. If it cannot reach EOF it will raise an exception.

When reading a file in chunks rather than with read(), you know you've hit EOF when read returns less than the number of bytes you requested. In that case, the following read call will return the empty string (not None). The following loop reads a file in chunks; it will call read at most once too many.

assert n > 0
while True:
    chunk = fp.read(n)
    if chunk == '':
        break
    process(chunk)


Or, shorter:

for chunk in iter(lambda: fp.read(n), ''):
    process(chunk)

",How to find out whether a file is at its `eof`?,"fp = open(""a.txt"")
#do many things with fp

c = fp.read()
if c is None:
    print 'fp is at the eof'


Besides the above method, any other way to find out whether is fp is already at the eof?
"
"def send_email(user, pwd, recipient, subject, body):
    import smtplib

    gmail_user = user
    gmail_pwd = pwd
    FROM = user
    TO = recipient if type(recipient) is list else [recipient]
    SUBJECT = subject
    TEXT = body

    # Prepare actual message
    message = """"""From: %s\nTo: %s\nSubject: %s\n\n%s
    """""" % (FROM, "", "".join(TO), SUBJECT, TEXT)
    try:
        server = smtplib.SMTP(""smtp.gmail.com"", 587)
        server.ehlo()
        server.starttls()
        server.login(gmail_user, gmail_pwd)
        server.sendmail(FROM, TO, message)
        server.close()
        print 'successfully sent the mail'
    except:
        print ""failed to send mail""


if you want to use Port 465 you have to create an SMTP_SSL object:

# SMTP_SSL Example
server_ssl = smtplib.SMTP_SSL(""smtp.gmail.com"", 465)
server_ssl.ehlo() # optional, called by login()
server_ssl.login(gmail_user, gmail_pwd)  
# ssl server doesn't support or need tls, so don't call server_ssl.starttls() 
server_ssl.sendmail(FROM, TO, message)
#server_ssl.quit()
server_ssl.close()
print 'successfully sent the mail'

",How to send an email with Gmail as provider using Python?,"I am trying to send email (Gmail) using python, but I am getting following error.

Traceback (most recent call last):  
File ""emailSend.py"", line 14, in   
server.login(username,password)  
File ""/usr/lib/python2.5/smtplib.py"", line 554, in login  
raise SMTPException(""SMTP AUTH extension not supported by server."")  
smtplib.SMTPException: SMTP AUTH extension not supported by server.


The Python script is the following.

import smtplib
fromaddr = 'user_me@gmail.com'
toaddrs  = 'user_you@gmail.com'
msg = 'Why,Oh why!'
username = 'user_me@gmail.com'
password = 'pwd'
server = smtplib.SMTP('smtp.gmail.com:587')
server.starttls()
server.login(username,password)
server.sendmail(fromaddr, toaddrs, msg)
server.quit()

"
"It's method overloading not method overriding. And in Python, you do it all in one function:

class A:

    def stackoverflow(self, i='some_default_value'):    
        print 'only method'

ob=A()
ob.stackoverflow(2)
ob.stackoverflow()


You can't have two methods with the same name in Python -- and you don't need to.

See the Default Argument Values section of the Python tutorial. See ""Least Astonishment"" in Python: The Mutable Default Argument for a common mistake to avoid.

Edit: See PEP 443 for information about the new single dispatch generic functions in Python 3.4.
",How do I use method overloading in Python?,"I am trying to implement method overloading in Python: 

class A:
    def stackoverflow(self):    
        print 'first method'
    def stackoverflow(self, i):
        print 'second method', i

ob=A()
ob.stackoverflow(2)


but the output is second method 2; similarly:

class A:
    def stackoverflow(self):    
        print 'first method'
    def stackoverflow(self, i):
        print 'second method', i

ob=A()
ob.stackoverflow()


gives

Traceback (most recent call last):
  File ""my.py"", line 9, in 
    ob.stackoverflow()
TypeError: stackoverflow() takes exactly 2 arguments (1 given)


How do I make this work?
"
"Here is a relatively simple recursive version which will flatten any depth of list

l = [35,53,[525,6743],64,63,[743,754,757]]

def flatten(xs):
    result = []
    if isinstance(xs, (list, tuple)):
        for x in xs:
            result.extend(flatten(x))
    else:
        result.append(xs)
    return result

print flatten(l)

",How to flatten a hetrogenous list of list into a single list in python?,"I have a list of objects where objects can be lists or scalars. I want an flattened list with only scalars.
Eg:

L = [35,53,[525,6743],64,63,[743,754,757]]
outputList = [35,53,525,6743,64,63,743,754,757]


P.S. The answers in this question does not work for heterogeneous lists. Flattening a shallow list in Python
"
"As said by Niklas, you need recursion, i.e. you want to define a function to print your dict, and if the value is a dict, you want to call your print function using this new dict.

Something like :

def myprint(d):
  for k, v in d.iteritems():
    if isinstance(v, dict):
      myprint(v)
    else:
      print ""{0} : {1}"".format(k, v)


Or for Python 3 onwards :

def myprint(d):
  for k, v in d.items():
    if isinstance(v, dict):
      myprint(v)
    else:
      print(""{0} : {1}"".format(k, v))

",Loop through all nested dictionary values?,"for k, v in dict.iteritems():
    if type(v) is dict:
        for t, c in v.iteritems():
            print ""{0} : {1}"".format(t, c)


I'm trying to loop through a dictionary and print out all key value pairs where the value is not a nested dictionary. If the value is a dictionary I want to go into it and print out its key value pairs...etc. Any help?

EDIT

How about this? It still only prints one thing.

def printDict(dict):
    for k, v in dict.iteritems():
        if type(v) is dict:
            printDict(v)
        else:
            print ""{0} : {1}"".format(k, v)


Full Test Case

Dictionary:

{u'xml': {u'config': {u'portstatus': {u'status': u'good'}, u'target': u'1'},
      u'port': u'11'}}


Result:

xml : {u'config': {u'portstatus': {u'status': u'good'}, u'target': u'1'}, u'port': u'11'}

"
"One option is a list comprehension:

[add(x, 2) for x in [1, 2, 3]]


More options:

a = [1, 2, 3]

import functools
map(functools.partial(add, y=2), a)

import itertools
map(add, a, itertools.repeat(2, len(a)))

",How to do multiple arguments to map function where one remains the same in python?,"Lets say we have a function add as follows

def add(x, y):
    return x + y


we want to apply map function for an array 

map(add, [1, 2, 3], 2)


The semantics are I want to add 2 to the every element of the array. But the map function requires a list in the third argument as well.

Note: I am putting the add example for simplicity. My original function is much more complicated. And of course option of setting the default value of y in add function is out of question as it will be changed for every call.
"
"Use collections.Counter:

>>> from collections import Counter
>>> A = Counter({'a':1, 'b':2, 'c':3})
>>> B = Counter({'b':3, 'c':4, 'd':5})
>>> A + B
Counter({'c': 7, 'b': 5, 'd': 5, 'a': 1})


Counters are basically a subclass of dict, so you can still do everything else with them you'd normally do with that type, such as iterate over their keys and values.
",Is there any pythonic way to combine two dicts (adding values for keys that appear in both)?,"For example I have two dicts:

Dict A: {'a':1, 'b':2, 'c':3}
Dict B: {'b':3, 'c':4, 'd':5}


I need a pythonic way of 'combining' two dicts such that the result is :

{'a':1, 'b':5, 'c':7, 'd':5}


That is to say: if a key appears in both dicts, add their values, if it appears in only one dict, keep its value.
"
">>> lst = [0,0,1,0,1,1,0]
>>> l, s = len(lst), sum(lst)
>>> result = [0] * (l - s) + [1] * s
>>> result
[0, 0, 0, 0, 1, 1, 1]

",Sort a list efficiently which contains only 0 and 1 without using any builtin python sort function?,"What is the most efficient way to sort a list, [0,0,1,0,1,1,0] whose elements are only 0 & 1, without using any builtin sort() or sorted() or count() function. O(n) or less than that
"
"I've found this snippet as an alternative solution. It's a more graceful removal of libraries than remaking the virtualenv:

pip freeze | xargs pip uninstall -y




In case you have packages installed via VCS, you need to exclude those lines and remove the packages manually (elevated from the comments below):

pip freeze | grep -v ""^-e"" | xargs pip uninstall -y

",What is the easiest way to remove all packages installed by pip?,"I'm trying to fix up one of my virtualenvs - I'd like to reset all of the installed libraries back to the ones that match production.

Is there a quick and easy way to do this with pip?
"
"Python is strongly, dynamically typed.


Strong typing means that the type of a value doesn't suddenly change. A string containing only digits doesn't magically become a number, as may happen in Perl. Every change of type requires an explicit conversion.
Dynamic typing means that runtime objects (values) have a type, as opposed to static typing where variables have a type.


As for your example

bob = 1
bob = ""bob""


This works because the variable does not have a type; it can name any object. After bob=1, you'll find that type(bob) returns int, but after bob=""bob"", it returns str. (Note that type is a regular function, so it evaluates its argument, then returns the type of the value.)

Contrast this with older dialects of C, which were weakly, statically typed, so that pointers and integers were pretty much interchangeable. (Modern ISO C requires conversions in many cases, but my compiler is still lenient about this by default.)

I must add that the strong vs. weak typing is more of a continuum than a boolean choice. C++ has stronger typing than C (more conversions required), but the type system can be subverted by using pointer casts.

The strength of the type system in a dynamic language such as Python is really determined by how its primitives and library functions respond to different types. E.g., + is overloaded so that it works on two numbers or two strings, but not a string and an number. This is a design choice made when + was implemented, but not really a necessity following from the language's semantics. In fact, when you overload + on a custom type, you can make it implicitly convert anything to a number:

def to_number(x):
    """"""Try to convert x to a number.""""""
    if x is None:
        return 0
    # more special cases here
    else:
        return float(x)  # works for numbers and strings

class Foo(object):
    def __add__(self, other):
        other = to_number(other)
        # now do the addition


(The only language that I know that is completely strongly typed, aka strictly typed, is Haskell, where types are entirely disjoint and only a controlled form of overloading is possible via type classes.)
",Is Python strongly typed?,"I've come across links that say Python is a strongly typed language.

However, I thought in strongly typed languages you couldn't do this :

bob = 1
bob = ""bob""


I thought a strongly typed language didn't accept type-changing at run-time. Maybe I've got a wrong (or too simplist) definition of strong/weak types.

So, is Python a strongly or weakly typed language?
"
"You could use thecsvmodule's Sniffer class to detect whether a header row is present and the built-innext()function to skip over it if necessary:

import csv

with open('all16.csv', 'rb') as inf:
    has_header = csv.Sniffer().has_header(inf.read(1024))
    inf.seek(0)  # rewind
    incsv = csv.reader(inf)
    if has_header:
        next(incsv)  # skip header row
    column = 1
    datatype = float
    data = (datatype(row[column]) for row in incsv)
    least_value = min(data)

print least_value


You can also skip rows with a incsv.next() call if you're using Python 2.x.

Since datatype and column are hardcoded in your example, it would be slightly faster to read data this way:

    data = (float(row[1]) for row in incsv)

","When processing CSV data, how do I ignore the first line of data?","I am asking Python to print the minimum number from a column of CSV data, but the top row is the column number, and I don't want Python to take the top row into account. How can I make sure Python ignores the first line?

This is the code so far:

import csv

with open('all16.csv', 'rb') as inf:
    incsv = csv.reader(inf)
    column = 1                
    datatype = float          
    data = (datatype(column) for row in incsv)   
    least_value = min(data)

print least_value


Could you also explain what you are doing, not just give the code? I am very very new to Python and would like to make sure I understand everything.
"
"You can of course use INOTIFY feature of Linux, but it is safer to avoid the situation: let the writing process create the files (say data.tmp) which the reading process will definitely ignore. When the writer finishes, it should just rename the file for the reader (into say .dat). The rename operation guarantees that there may be no misunderstandings.
",Quick way to know if a file is open on Linux?,"Is there a quick way (i.e. that minimizes time-to-answer) to find out if a file is open on Linux?   

Let's say I have a process that writes a ton a files in a directory and another process which reads those files once they are finished writing, can the latter process know if a file is still being written to by the former process?

A Python based solution would be ideal, if possible.

Note: I understand I could be using a FIFO / Queue based solution but I am looking for something else.
"
"import calendar
print calendar.isleap(1900)


Python provides this functionality already in the library module 'calendar'.
",How to determine whether a year is a leap year in Python?,"I am trying to make a simple calculator to determine whether or not a certain year is a leap year. 

By definition, a leap year is divisible by four, but not by one hundred, unless it is divisible by four hundred.

Here is my code:

def leapyr(n):
    if n%4==0 and n%100!=0:
        if n%400==0:
            print n, "" is a leap year.""
    elif n%4!=0:
        print n, "" is not a leap year.""
print leapyr(1900)


When I try this inside the Python IDLE, the module returns None. I am pretty sure that I should get 1900 is a leap year.
"
"Array access is done with [], not (). Also if you are looking for hundreds and units, remember that arrays are 0 indexed, here is a shortened version of the code.

def is_pal(num):
    return num[0] == num[2]

>>> is_pal('123')
False
>>> is_pal('323')
True


You might want to take in the number as a parameter and then convert it to a string:

def is_pal(num):
    x = str(num)
    return x[0] == x[2]


Note that you can simply just check if string is equal to it's reverse which works for any number of digits:

>>> x = '12321'
>>> x == x[::-1]
True

",How to do check for a palindrome in Python?,"Hi I'm working on a python function isPalindrome(x) for integers of three digits that returns True if the hundreds digit equals the ones digit and false otherwise.  I know that I have to use strings here and this is what I have:

def isPal(x):
    if str(1) == str(3):
        return ""True""

    else:
        return ""False""


the str(0) is the units place and str(2) is the hundreds place.  All I'm getting is False?  Thanks!
"
"Python does not have a trailing if statement.

There are two kinds of if in Python:


if statement:

if condition: statement
if condition:
    block

if expression (introduced in Python 2.5)

expression_if_true if condition else expression_if_false



And note, that both print a and b = a are statements. Only the a part is an expression. So if you write

print a if b else 0


it means

print (a if b else 0)


and similarly when you write

x = a if b else 0


it means

x = (a if b else 0)


Now what would it print/assign if there was no else clause? The print/assignment is still there.

And note, that if you don't want it to be there, you can always write the regular if statement on a single line, though it's less readable and there is really no reason to avoid the two-line variant.
",How to write inline if statement for print?,"I need to print some stuff only when a boolean variable is set to True. So, after looking at this, I tried with a simple example:

>>> a = 100
>>> b = True
>>> print a if b
  File """", line 1
    print a if b
             ^
SyntaxError: invalid syntax  


Same thing if I write print a if b==True.

What am I missing here?
"
"Edit: Mar. 2015

As noted below, pandas now uses SQLAlchemy to both read from (read_sql) and insert into (to_sql) a database. The following should work

import pandas as pd

df = pd.read_sql(sql, cnxn)


Previous answer:
Via mikebmassey from a similar question

import pyodbc
import pandas.io.sql as psql

cnxn = pyodbc.connect(connection_info) 
cursor = cnxn.cursor()
sql = ""SELECT * FROM TABLE""

df = psql.frame_query(sql, cnxn)
cnxn.close()

",How to convert SQL Query result to PANDAS Data Structure?,"Any help on this problem will be greatly appreciated. So basically I want to run a query to my SQL database and store the returned data as Pandas data structure. I have attached code for query. I am reading the documentation on Pandas, but I have problem to identify the return type of my query. I tried to print the query result, but it doesn't give any useful information. 
    Thanks!!!! 

from sqlalchemy import create_engine


engine2 = create_engine('mysql://THE DATABASE I AM ACCESSING')
connection2 = engine2.connect()
dataid = 1022
resoverall = connection2.execute(""SELECT sum(BLABLA) AS BLA, sum(BLABLABLA2) AS BLABLABLA2, sum(SOME_INT) AS SOME_INT, sum(SOME_INT2) AS SOME_INT2, 100*sum(SOME_INT2)/sum(SOME_INT) AS ctr, sum(SOME_INT2)/sum(SOME_INT) AS cpc FROM daily_report_cooked WHERE campaign_id = '%s'""%dataid)


So I sort of want to understand what's the format/datatype of my variable ""resoverall"" and how to put it with PANDAS data structure.
"
"There is also TideSDK formally known as Titanium. This provides a WebKit HTML/JavaScript widget that does pretty much everything you could want, including running the Chrome developer tools. 



EDIT below. Consolidating my update with feedback from the TideSDK developers:

TideSDK, formerly Titanium Desktop, is an open source software development kit for creating multi-platform desktop apps using HTML5, CSS3, JavaScript and other common scripting languages. The project is hosted on Github. The main web site has  comprehensive documentation and hosts an active developer community. Thousands of developers have used the former Titanium Desktop to develop deskop applications. Perhaps the most recognized applications is Wunderlist

TideSDK allows you to use your web development skills to create desktop apps and provides wide range of privileged APIs. You can easily extend the functionality of your app using mature libraries in python, php or ruby. 

The heart of TideSDK is an object bridge compiled into the WebKit component. The bridge allows other scripting languages -  python, php or ruby - to run on the HTML page using script tags in the DOM, just like JavaScript. You can also directly call .py, .rb or .php files from within your application.

TideSDK can be used with no more than a basic text editor - it does not need any special tools or an IDE although many developers prefer richer tools. TideSDK includes command-line tools for running your application locally (for development and debugging) and also to package it into an installer for the OS that you are developing on (Windows, Mac OSX and Linux are supported). To get all the needed installers, a typical TideSDK development environment will include a physical or virtual machine for each OS. The TideSDK team is looking to implement a different and better way soon. 

The TideSDK team is currently developing a TideSDK Builder app. It will provide a GUI for creating, running and packaging TideSDK apps. To get developers started faster, TideSDK Builder introduces a new feature - Scaffolds. Scaffolds generate all the boiler plate to instantiate a projects with specific patterns of development such as Backbone MVC. Developers can use TideSDK Builder to create, import and share scaffolds.

The roadmap for TideSDK includes the implementation of CommonJS for 1.4 which aims to provide developers with a more modular development experience using JavaScript.

Hello World

A TideSDK project consists of some boilerplate code with a Resources folder that contains the core project files. The following illustrates the stucture of a simple hello world app that will run on all supported plaforms:

âââ CHANGELOG.txt
âââ LICENSE.txt
âââ README.md
âââ Resources
â   âââ app.js
â   âââ default_app_logo.png
â   âââ index.html
âââ manifest
âââ tiapp.xml


The manifest contains information about the runtime modules used by the project. tiapp.xml provides configuration and default_app_logo.png is the image that will appear by default in the dock, system tray or in the windows of your app.

The following is the contents of the app.js file for the hello world example (as it will appear in TideSDK 1.3.0). Previous versions will have used the Titanium namespace which has been discontinued.

// create and set menu
var menu = Ti.UI.createMenu(),
fileItem = Ti.UI.createMenuItem('File'),
exitItem = fileItem.addItem('Exit', function() {
  if (confirm('Are you sure you want to quit?')) {
    Ti.App.exit();
  }
});

menu.appendItem(fileItem);
Ti.UI.setMenu(menu);


Here is the HTML for the same app. It calls the script above.




  Hello World
  
    body {background: #fff;}
  


  Hello World
   




In less than 10 lines of JavaScript code, we create a menu, adding 'File' and 'Exit' menu items, and set it to the main window. A simple callback method is used to pop open a exit confirmation dialog. If the user confirms, the app will exit.  

Background

Titanium was developed by Appcelerator and made available under the Apache 2 Licence. Originally Appcelerator provided the open source Titanium Developer to create projects. Later Appcelerator introduced the closed source Titanium Studio, an IDE on top of Aptana. While it currently remains possible to develop TideSDK in Titanium Studio, a plugin may be required in the future. [Andrew: sorry, this is not clear to me. A plugin to Titanium Studio? Or Aptana? Or the TideSDK?]

Appcelerator has supplied an TiStudio SDK to use to use that might assist us in creating a plugin to TiStudio to allow TideSDK to be used through TiStudio
",Is there a cross-OS GUI framework that supports embedding HTML pages?,"I want to develop a desktop app to be used cross-system (win, mac, linux), is there a GUI framework that would allow me to write code once for all 3 platforms and have a fully-scriptable embedded web component?

I need it to have an API to communicate between app and webpage javascript.

I know C#, JavaScript and a little bit of python.
"
"Don't know if you solved the problem but if anyone has this problem in future.

$python
>>import numpy
>>print(numpy)


Go to the location printed and delete the numpy installation found there. You can then use pip or easy_install
",How to fix Python Numpy/Pandas installation?,"I would like to install Python Pandas library (0.8.1) on Mac OS X 10.6.8. This library needs Numpy>=1.6.

I tried this

$ sudo easy_install pandas
Searching for pandas
Reading http://pypi.python.org/simple/pandas/
Reading http://pandas.pydata.org
Reading http://pandas.sourceforge.net
Best match: pandas 0.8.1
Downloading http://pypi.python.org/packages/source/p/pandas/pandas-0.8.1.zip#md5=d2c5c5bea971cd760b0ae6f6850fcb74
Processing pandas-0.8.1.zip
Running pandas-0.8.1/setup.py -q bdist_egg --dist-dir /tmp/easy_install-ckAMym/pandas-0.8.1/egg-dist-tmp-0mlL7t
error: Setup script exited with pandas requires NumPy >= 1.6 due to datetime64 dependency


So I tried to install Numpy

$ sudo easy_install numpy
Searching for numpy
Best match: numpy 1.6.2
Adding numpy 1.6.2 to easy-install.pth file

Using /Library/Python/2.6/site-packages
Processing dependencies for numpy
Finished processing dependencies for numpy


So I tried again

$ sudo easy_install pandas


But the problem is still the same !

error: Setup script exited with pandas requires NumPy >= 1.6 due to datetime64 dependency


I run Python 

$ python
Python 2.6.1 (r261:67515, Jun 24 2010, 21:47:49) 
[GCC 4.2.1 (Apple Inc. build 5646)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import numpy as np
>>> np.__version__
'1.2.1'


So Numpy 1.6 doesn't seems to be installed correctly !

I tried to install Numpy 1.6 with pip (instead of easy_install)...

$ sudo pip install numpy
Requirement already satisfied (use --upgrade to upgrade): numpy in /Library/Python/2.6/site-packages
Cleaning up...


I added --upgrade flag

$ sudo pip install numpy --upgrade
Requirement already up-to-date: numpy in /Library/Python/2.6/site-packages
Cleaning up...

$ sudo pip install pandas
Downloading/unpacking pandas
  Downloading pandas-0.8.1.zip (1.9MB): 1.9MB downloaded
  Running setup.py egg_info for package pandas
    pandas requires NumPy >= 1.6 due to datetime64 dependency
    Complete output from command python setup.py egg_info:
    pandas requires NumPy >= 1.6 due to datetime64 dependency

----------------------------------------
Command python setup.py egg_info failed with error code 1 in /tmp/pip-build/pandas
Storing complete log in /Users/MyUsername/Library/Logs/pip.log


I also tried to install binary version of Numpy http://sourceforge.net/projects/numpy/files/
numpy-1.6.2-py2.6-python.org-macosx10.3.dmg but it fails !!! (installer said me that numpy 1.6.2 can't be install on this disk. Numpy requires python.org Python 2.6 to install.
"
"Non Blocking

If you are on linux (as windows does not support calling select on files) you can use the subprocess module along with the select module.

import time
import subprocess
import select

f = subprocess.Popen(['tail','-F',filename],\
        stdout=subprocess.PIPE,stderr=subprocess.PIPE)
p = select.poll()
p.register(f.stdout)

while True:
    if p.poll(1):
        print f.stdout.readline()
    time.sleep(1)


This polls the output pipe for new data and prints it when it is available. Normally the time.sleep(1) and print f.stdout.readline() would be replaced with useful code.

Blocking

You can use the subprocess module without the extra select module calls.

import subprocess
f = subprocess.Popen(['tail','-F',filename],\
        stdout=subprocess.PIPE,stderr=subprocess.PIPE)
while True:
    line = f.stdout.readline()
    print line


This will also print new lines as they are added, but it will block until the tail program is closed, probably with f.kill().
",How can I tail a log file in Python?,"I'd like to make the output of tail -F or something similar available to me in Python without blocking or locking. I've found some really old code to do that here, but I'm thinking there must be a better way or a library to do the same thing by now. Anyone know of one?

Ideally, I'd have something like tail.getNewData() that I could call every time I wanted more data.
"
"Use a dictionary to look up the one letter codes:

d = {'CYS': 'C', 'ASP': 'D', 'SER': 'S', 'GLN': 'Q', 'LYS': 'K',
     'ILE': 'I', 'PRO': 'P', 'THR': 'T', 'PHE': 'F', 'ASN': 'N', 
     'GLY': 'G', 'HIS': 'H', 'LEU': 'L', 'ARG': 'R', 'TRP': 'W', 
     'ALA': 'A', 'VAL':'V', 'GLU': 'E', 'TYR': 'Y', 'MET': 'M'}


And a simple function to match the three letter codes with one letter codes for the entire string:

def shorten(x):
    if len(x) % 3 != 0: 
        raise ValueError('Input length should be a multiple of three')

    y = ''
    for i in range(len(x)/3):
            y += d[x[3*i:3*i+3]]
    return y


Testing your example:

>>> shorten('ARGHISLEULEULYS')
'RHLLK'

",How do I convert the three letter amino acid codes to one letter code with python or R?,"I have a fasta file as shown below. I would like to convert the three letter codes to one letter code. How can I do this with python or R?

>2ppo
ARGHISLEULEULYS
>3oot
METHISARGARGMET


desired  output

>2ppo
RHLLK
>3oot
MHRRM


your suggestions would be appreciated!!
"
"It works best if you provide a mask. That way you specify how far to sign extend.

>>> bin(-27 & 0b1111111111111111)
'0b1111111111100101'


Or perhaps more generally:

def bindigits(n, bits):
    s = bin(n & int(""1""*bits, 2))[2:]
    return (""{0:0>%s}"" % (bits)).format(s)

>>> print bindigits(-31337, 24)
111111111000010110010111


In basic theory, the actual width of the number is a function of the size of the storage. If it's a 32-bit number, then a negative number has a 1 in the MSB of a set of 32. If it's a 64-bit value, then there are 64 bits to display. 

But in Python, integer precision is limited only to the constraints of your hardware. On my computer, this actually works, but it consumes 9GB of RAM just to store the value of x. Anything higher and I get a MemoryError. If I had more RAM, I could store larger numbers.

>>> x = 1 << (1 << 36)


So with that in mind, what binary number represents -1? Python is well-capable of interpreting literally millions (and even billions) of bits of precision, as the previous example shows. In 2's complement, the sign bit extends all the way to the left, but in Python there is no pre-defined number of bits; there are as many as you need.

But then you run into ambiguity: does binary 1 represent 1, or -1? Well, it could be either. Does 111 represent 7 or -1? Again, it could be either. So does 111111111 represent 511, or -1... well, both, depending on your precision. 

Python needs a way to represent these numbers in binary so that there's no ambiguity of their meaning. The 0b prefix just says ""this number is in binary"". Just like 0x means ""this number is in hex"". So if I say 0b1111, how do I know if the user wants -1 or 15? There are two options:

Option A: The sign bit
You could declare that all numbers are signed, and the left-most bit is the  sign bit. That means 0b1 is -1, while 0b01 is 1. That also means that 0b111 is also -1, while 0b0111 is 7. In the end, this is probably more confusing than helpful particularly because most binary arithmetic is going to be unsigned anyway, and people are more likely to run into mistakes by accidentally marking a number as negative because they didn't include an explicit sign bit.

Option B: The sign indication
With this option, binary numbers are represented unsigned, and negative numbers have a ""-"" prefix, just like they do in decimal. This is (a) more consistent with decimal, (b) more compatible with the way binary values are most likely going to be used. You lose the ability to specify a negative number using its two's complement representation, but remember that two's complement is a storage implementation detail, not a proper indication of the underlying value itself. It shouldn't have to be something that the user has to understand. 

In the end, Option B makes the most sense. There's less confusion and the user isn't required to understand the storage details.
",Two's Complement Binary in Python?,"Integers in Python are stored in two's complement, correct?

Although:

>>> x = 5
>>> bin(x)
0b101


And:

>>> x = -5
>>> bin(x)
-0b101


That's pretty lame. How do I get python to give me the numbers in REAL binary bits, and without the 0b infront of it? So:

>>> x = 5
>>> bin(x)
0101
>>> y = -5
>>> bin(y)
1011

"
"One easy way would be to reassign the dataframe with a list of the columns, rearranged as needed. 

This is what you have now: 

In [6]: df
Out[6]:
          0         1         2         3         4      mean
0  0.445598  0.173835  0.343415  0.682252  0.582616  0.445543
1  0.881592  0.696942  0.702232  0.696724  0.373551  0.670208
2  0.662527  0.955193  0.131016  0.609548  0.804694  0.632596
3  0.260919  0.783467  0.593433  0.033426  0.512019  0.436653
4  0.131842  0.799367  0.182828  0.683330  0.019485  0.363371
5  0.498784  0.873495  0.383811  0.699289  0.480447  0.587165
6  0.388771  0.395757  0.745237  0.628406  0.784473  0.588529
7  0.147986  0.459451  0.310961  0.706435  0.100914  0.345149
8  0.394947  0.863494  0.585030  0.565944  0.356561  0.553195
9  0.689260  0.865243  0.136481  0.386582  0.730399  0.561593

In [7]: cols = df.columns.tolist()

In [8]: cols
Out[8]: [0L, 1L, 2L, 3L, 4L, 'mean']


Rearrange cols in any way you want. This is how I moved the last element to the first position: 

In [12]: cols = cols[-1:] + cols[:-1]

In [13]: cols
Out[13]: ['mean', 0L, 1L, 2L, 3L, 4L]


Then reorder the dataframe like this: 

In [16]: df = df[cols]  #    OR    df = df.ix[:, cols]

In [17]: df
Out[17]:
       mean         0         1         2         3         4
0  0.445543  0.445598  0.173835  0.343415  0.682252  0.582616
1  0.670208  0.881592  0.696942  0.702232  0.696724  0.373551
2  0.632596  0.662527  0.955193  0.131016  0.609548  0.804694
3  0.436653  0.260919  0.783467  0.593433  0.033426  0.512019
4  0.363371  0.131842  0.799367  0.182828  0.683330  0.019485
5  0.587165  0.498784  0.873495  0.383811  0.699289  0.480447
6  0.588529  0.388771  0.395757  0.745237  0.628406  0.784473
7  0.345149  0.147986  0.459451  0.310961  0.706435  0.100914
8  0.553195  0.394947  0.863494  0.585030  0.565944  0.356561
9  0.561593  0.689260  0.865243  0.136481  0.386582  0.730399

",How to change the order of DataFrame columns?,"I have the following DataFrame (df):

import numpy as np
import pandas as pd

df = pd.DataFrame(np.random.rand(10, 5))


I add more column(s) by assignment:

df['mean'] = df.mean(1)


How can I move the column mean to the front, i.e. set it as first column leaving the order of the other columns untouched?
"
"In English:

For each pair of values in the following list of pairs of values, do the stuff in the loop. In this case, (i, o) just means ""Assign the values from the pair to variables named i & o.""

During the first iteration, i is ""&"" and o is ""&amp;""

Each time through the loop, it replaces occurrences of i with the replacement in o so any ""&"" in the source text becomes ""&amp;"", "">"" becomes ""&gt"", etc.
",How does the following for loop work?,"def escape_html(s):
    for (i, o) in ((""&"",""&amp;""),("">"", ""&gt;""),(""<"", ""&lt""),('""', ""&quot;"")):
        s = s.replace(i , o)
    return s


I haven't seen something like this before.

What does the first line of the for loop mean?

In general, what does the loop do and how does it do it?

Note: s is a string

Please try to explain the full iterative process.
"
"A different non-regex approach from the others:

>>> import string
>>> from itertools import groupby
>>> 
>>> special = set(string.punctuation + string.whitespace)
>>> s = ""One two  three    tab\ttabandspace\t end""
>>> 
>>> split_combined = [''.join(g) for k, g in groupby(s, lambda c: c in special)]
>>> split_combined
['One', ' ', 'two', '  ', 'three', '    ', 'tab', '\t', 'tabandspace', '\t ', 'end']
>>> split_separated = [''.join(g) for k, g in groupby(s, lambda c: c if c in special else False)]
>>> split_separated
['One', ' ', 'two', '  ', 'three', '    ', 'tab', '\t', 'tabandspace', '\t', ' ', 'end']


Could use dict.fromkeys and .get instead of the lambda, I guess.

[edit]

Some explanation:

groupby accepts two arguments, an iterable and an (optional) keyfunction.  It loops through the iterable and groups them with the value of the keyfunction:

>>> groupby(""sentence"", lambda c: c in 'nt')

>>> [(k, list(g)) for k,g in groupby(""sentence"", lambda c: c in 'nt')]
[(False, ['s', 'e']), (True, ['n', 't']), (False, ['e']), (True, ['n']), (False, ['c', 'e'])]


where terms with contiguous values of the keyfunction are grouped together.  (This is a common source of bugs, actually -- people forget that they have to sort by the keyfunc first if they want to group terms which might not be sequential.)

As @JonClements guessed, what I had in mind was 

>>> special = dict.fromkeys(string.punctuation + string.whitespace, True)
>>> s = ""One two  three    tab\ttabandspace\t end""
>>> [''.join(g) for k,g in groupby(s, special.get)]
['One', ' ', 'two', '  ', 'three', '    ', 'tab', '\t', 'tabandspace', '\t ', 'end']


for the case where we were combining the separators.  .get returns None if the value isn't in the dict.
",Efficiently split a string using multiple separators and retaining each separator?,"I need to split strings of data using each character from string.punctuation and string.whitespace as a separator.

Furthermore, I need for the separators to remain in the output list, in between the items they separated in the string.

For example,

""Now is the winter of our discontent""


should output:

['Now', ' ', 'is', ' ', 'the', ' ', 'winter', ' ', 'of', ' ', 'our', ' ', 'discontent']


I'm not sure how to do this without resorting to an orgy of nested loops, which is unacceptably slow. How can I do it?
"
"New Project 

Dont use default Location

Browse to existing project location ...

if its an existing eclipse project with project files that have correct paths for your system you can just open the .proj file ...
",How do I import a pre-existing python project into Eclipse?,"I am using eclipse for python. 
  How do I import an existing project into eclipse in the current workspace.

Thanks
"
"I would suggest taking a slight detour and looking at using Java Instrumentation APIs - use (write) a simple Java Agent to do this. From your benchmarking perspective, this will give you far more power as well. You could use your Java Agent to log everything (and hence there would be no contention between different logger threads).

You can read more at http://www.javabeat.net/2012/06/introduction-to-java-agents/ or http://today.java.net/pub/a/today/2008/04/24/add-logging-at-class-load-time-with-instrumentation.html
",How to redirect JVM output without tear up output from the application?,"Recently I am writing some micro-benchmark code, so I have to print out the JVM behaviors along with my benchmark information. I use

-XX:+PrintCompilation
-XX:+PrintGCDetails


and other options to get the JVM status. For benchmark information, I simply use System.out.print() method. Because I need to know the order of the message I printed and the JVM output.

I can get good result when I just print them out in the console, although the JVM output sometimes tear my messages up, but since they are in different threads, it is understandable and acceptable.

When I need to do some batch benchmarks, I'd like to redirect the output into a file with pipe (> in Linux system), and use python to get the result from the file and analyse it.

Here is the problem:

The JVM output always overlapped with the messages I printed in the Java application. It ruined the completion of the messages.

Any idea how to deal with this situation? I need both the JVM output and application output in the same place in order to preserve the sequence because it is important. And they do not overlap on each other so I don't lose anything.
"
"It finally worked!!!

I needed to do things to get it to work


Add C:\Python27\ to the end of the PATH system variable
Add C:\Python27\ to the end of the PYTHONPATH system variable


I had to add these to both for it to work.

If I added any subdirectories, it did not work for some reason.

Thank you all for your responses.
",Python not working in command prompt?,"I type python into the command line, but the command prompt says that python is not recognized as an internal or external command, operable program, or batch file. What should I do

Note: I have installed Python 2.7 and Python 3.2 onto my computer.
"
"A requirement file can contain comments (#) and can include some other files (--requirement or -r).
Thus, if you really want to parse a requirement.txt you should use the pip parser:

from pip.req import parse_requirements

# parse_requirements() returns generator of pip.req.InstallRequirement objects
install_reqs = parse_requirements()

# reqs is a list of requirement
# e.g. ['django==1.5.1', 'mezzanine==1.4.6']
reqs = [str(ir.req) for ir in install_reqs]

setup(
    ...
    install_requires=reqs
)


NOTE: my answer is old now. Pip does not have a public API so this no longer works (e.g. parse_requirements now requires an instance of pip.download.PipSession). You can do the opposite: list the dependances in setup.py and have a single character -- a dot . -- in requirements.txt.
",How can I reference requirements.txt for the install_requires kwarg in setuptools' setup.py file?,"I have a requirements.txt file that I'm using with Travis-CI.  It seems silly to duplicate the requirements in both requirements.txt and setup.py, so I was hoping to pass a file handle to the install_requires kwarg in setuptools.setup.

Is this possible?

If so, how should I go about doing it?

For good measure, here is my requirements.txt file:

guessit>=0.5.2
tvdb_api>=1.8.2
hachoir-metadata>=1.3.3
hachoir-core>=1.3.3
hachoir-parser>=1.3.4

"
"Here is my work flow after creating a folder and cd'ing into it:

$ virtualenv venv --distribute
New python executable in venv/bin/python
Installing distribute.........done.
Installing pip................done.
$ source venv/bin/activate
(venv)$ python

",How to activate virtualenv?,"Newbie here so please be gentle.
I have been through search and tried various alternatives without success and spent several days on it now - driving me mad.

Running on Red Hat Linux with Python 2.5.2
Began using most recent Virtualenv but could not activate it, I found somewhere suggesting needed earlier version so I have used Virtualenv 1.6.4 as should work with Python2.6.

It seems to install the virtual environment ok

[necrailk@server6 ~]$ python virtualenv-1.6.4/virtualenv.py virtual
New python executable in virtual/bin/python
Installing setuptools............done.
Installing pip...............done.


Environment looks ok

[necrailk@server6 ~]$ cd virtual
[necrailk@server6 ~/virtual]$ dir
bin  include  lib


Trying to activate

[necrailk@server6 ~/virtual]$ . bin/activate
/bin/.: Permission denied.


Checked chmod

[necrailk@server6 ~/virtual]$ cd bin
[necrailk@server6 bin]$ ls -l
total 3160
-rw-r--r--    1 necrailk biz12        2130 Jan 30 11:38 activate
-rw-r--r--    1 necrailk biz12        1050 Jan 30 11:38 activate.csh
-rw-r--r--    1 necrailk biz12        2869 Jan 30 11:38 activate.fish
-rw-r--r-


Problem, so I changed it

[necrailk@server6 bin]$ ls -l
total 3160
-rwxr--r--    1 necrailk biz12        2130 Jan 30 11:38 activate
-rw-r--r--    1 necrailk biz12        1050 Jan 30 11:38 activate.csh
-rw-r--r--    1 necrailk biz12        2869 Jan 30 11:38 activate.fish
-rw-r--r--    1 necrailk biz12        1005 Jan 30 11:38 activate_this.py
-rwxr-xr-x    1 necrailk biz


Try activate again

[necrailk@server6 ~/virtual]$ . bin/activate
/bin/.: Permission denied.


Still no joy...
"
"First of all, if you are attempting any kind of scraping (yes this counts as scraping even though you are not necessarily parsing HTML), you have a certain amount of preliminary investigation to perform.

If you don't already have Firefox and Firebug, get them.  Then if you don't already have Chrome, get it.  

Start up Firefox/Firebug, and Chrome, clear out all of your cookies/etc.  Then open up Firebug, and in Chrome open up View->Developer->Developer Tools.  

Then load up the main page of the video you are trying to grab.  Take notice of any cookies/headers/POST variables/query string variables that are being set when the page loads.  You may want to save this info somewhere.

Then try to download the video, once again, take notice of any cookies/headers/post variables/query string variables that are being set when the video is loaded.  It is very likely that there was a cookie or POST variable set when you initially loaded the page, that is required to actually pull the video file.

When you write your python, you are going to need to emulate this interaction as closely as possible.  Use python-requests.  This is probably the simplest URL library available, and unless you run into a wall somehow with it (something it can't do), I would never use anything else.  The second I started using python-requests, all of my URL fetching code shrunk by a factor of 5x.

Now, things are probably not going to work the first time you try them.  Soooo, you will need to load the main page using python.  Print out all of your cookies/headers/POST variables/query string variables, and compare them to what Chrome/Firebug had.  Then try loading your video, once again, compare all of these values (that means what YOU sent the server, and what the SERVER sent you back as well).  You will need to figure out what is different between them (don't worry, we ALL learned this one in Kindergarten... ""one of these things is not like the other"") and dissect how that difference is breaking stuff.

If at the end of all of this, you still can't figure it out, then you probably need to look at the HTML for the page that contains the link to the movie.  Look for any javascript in the page.  Then use Firebug/Chrome Developer Tools to inspect the javascript and see if it is doing some kind of management of your user session.  If it is somehow generating tokens (cookies or POST/GET variables) related to video access, you will need to emulate its tokenizing method in python.

Hopefully all of this helps, and doesn't look too scary.  The key is you are going to need to be a scientist.  Figure out what you know, what you don't, what you want, and start experimenting and recording your results.  Eventually a pattern will emerge.

Edit: Clarify steps


Investigate how state is being maintained
Pull initial page with python, grab any state info you need from it
Perform any tokenizing that may be required with that state info
Pull the video using the tokens from steps 2 and 3
If stuff blows up, output your request/response headers,cookies,query vars, post vars, and compare them to Chrome/Firebug
Return to step 1. until you find a solution


Edit:
You may also be getting redirected at either one of these requests (the html page or the file download).  You will most likely miss the request/response in Firebug/Chrome if that is happening.  The solution would be to use a sniffer like LiveHTTPHeaders, or like has been suggested by other responders, WireShark or Fiddler.  Note that Fiddler will do you no good if you are on a Linux or OSX box.  It is Windows only and is definitely focused on .NET development... (ugh).  Wireshark is very useful but overkill for most problems, and depending on what machine you are running, you may have problems getting it working.  So I would suggest LiveHTTPHeaders first.

I love this kind of problem
",Emulating a Browser to download a file?,"There is a flv file in the web, you can downloaded it directly in Chrome,
the file is a CCTV television programï¼it is free for people to download (no copyrightï¼ CCTV is a non-profit TV, State-owned Companyï¼ chinese people--the tax payer have the right to download it freely, no copyright problem), I can get it in other address with wget, but I want to konw why i can't get it via this address?

When i use the command  

url='http://114.80.235.200/f4v/94/163005294.h264_1.f4v?10000&key=7b9b1155dc632cbab92027511adcb300401443020d&amp;playtype=1&amp;tk=163659644989925531390490125&amp;brt=2&amp;bc=0&amp;nt=0&amp;du=1496650&amp;ispid=23&amp;rc=200&amp;inf=1&amp;si=11000&amp;npc=1606&amp;pp=0&amp;ul=2&amp;mt=-1&amp;sid=10000&amp;au=0&amp;pc=0&amp;cip=222.73.44.31&amp;hf=0&amp;id=tudou&amp;itemid=135558267&amp;fi=163005294&amp;sz=59138302'  
wget -c  $url --user-agent="""" -O  xfgs.f4v  #wget -c  $url   -O  xfgs.f4v  can not run neither


the output is:

Connecting to 118.26.57.12:80... connected.  
HTTP request sent, awaiting response... 403 Forbidden  
2013-02-13 09:50:42 ERROR 403: Forbidden.  



How can I download it with wget?  


I want to download it with Python mechanize, here is the code:

import mechanize  
br = mechanize.Browser()  
br = mechanize.Browser()  
br.set_handle_robots(False)  
br.set_handle_equiv(False)   
br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]  
url='http://114.80.235.200/f4v/94/163005294.h264_1.f4v?10000&key=7b9b1155dc632cbab92027511adcb300401443020d&amp;playtype=1&amp;tk=163659644989925531390490125&amp;brt=2&amp;bc=0&amp;nt=0&amp;du=1496650&amp;ispid=23&amp;rc=200&amp;inf=1&amp;si=11000&amp;npc=1606&amp;pp=0&amp;ul=2&amp;mt=-1&amp;sid=10000&amp;au=0&amp;pc=0&amp;cip=222.73.44.31&amp;hf=0&amp;id=tudou&amp;itemid=135558267&amp;fi=163005294&amp;sz=59138302' 
r = br.open(url).read()  
tofile=open(""/tmp/xfgs.f4v"",""w"")  
tofile.write(r)  
tofile.close()  


I got the wrong output:  

Traceback (most recent call last):  
  File """", line 1, in   
  File ""/usr/lib/python2.7/dist-packages/mechanize/_mechanize.py"", line 203, in open  
   return self._mech_open(url, data, timeout=timeout)  
  File ""/usr/lib/python2.7/dist-packages/mechanize/_mechanize.py"", line 255, in _mech_open  
raise response  
mechanize._response.httperror_seek_wrapper: HTTP Error 403: Forbidden  


2. How can I download it with Python mechanize?  
"
"There's actually a very elegant, very efficient solution using dynamic programming. It takes O(1) space, and O(n) time -- this can't be beat!

Define A to be the input array (zero-indexed) and B[i] to be the maximum sum over all sublists ending at, but not including position i (i.e. all sublists A[j:i]). Therefore, B[0] = 0, and B[1] = max(B[0]+A[0], 0), B[2] = max(B[1]+A[1], 0), B[3] = max(B[2]+A[2], 0), and so on. Then, clearly, the solution is given simply by max(B[0], ..., B[n]).

Since every B value depends only on the previous B, we can avoid storing the whole B array, thus giving us our O(1) space guarantee.

With this approach, mssl reduces to a very simple loop:

def mssl(l):
    best = cur = 0
    for i in l:
        cur = max(cur + i, 0)
        best = max(best, cur)
    return best


Demonstration:

>>> mssl([3,4,5])
12
>>> mssl([4, -2, -8, 5, -2, 7, 7, 2, -6, 5])
19
>>> mssl([-2,-3,-5])
0




If you want the start and end slice indices, too, you need to track a few more bits of information (note this is still O(1) space and O(n) time, it's just a bit hairier):

def mssl(l):
    best = cur = 0
    curi = starti = besti = 0
    for ind, i in enumerate(l):
        if cur+i > 0:
            cur += i
        else: # reset start position
            cur, curi = 0, ind+1

        if cur > best:
            starti, besti, best = curi, ind+1, cur
    return starti, besti, best


This returns a tuple (a, b, c) such that sum(l[a:b]) == c and c is maximal:

>>> mssl([4, -2, -8, 5, -2, 7, 7, 2, -6, 5])
(3, 8, 19)
>>> sum([4, -2, -8, 5, -2, 7, 7, 2, -6, 5][3:8])
19

",Maximum sum sublist?,"I'm getting confused with this question at what it's trying to ask. 


  Write function mssl() (minimum sum sublist) that takes as input a list
  of integers. It then computes and returns the sum of the maximum sum
  sublist of the input list. The maximum sum sublist is a sublist
  (slice) of the input list whose sum of entries is largest. The empty
  sublist is defined to have sum 0. For example, the maximum sum sublist
  of the list [4, -2, -8, 5, -2, 7, 7, 2, -6, 5] is [5, -2, 7, 7, 2]
  and the sum of its entries is 19.


If I were to use this function it should return something similar to

>>> l = [4, -2, -8, 5, -2, 7, 7, 2, -6, 5]
>>> mssl(l)
19
>>> mssl([3,4,5])
12
>>> mssl([-2,-3,-5])
0


How can I do it?

Here is my current try, but it doesn't produce the expected result:

def mssl(x):
    ' list ==> int '
    res = 0
    for a in x:
        if a >= 0:
            res = sum(x)
        return res
    else:
        return 0

"
"# Concatenates a and b with ' - ' or Coalesces them if one is None
'-'.join([x for x in (a,b) if x])


Edit
Here are the results of this algorithm (Note that None will work the same as ''):

>>> '-'.join([x for x in ('foo','bar') if x])
'foo-bar'
>>> '-'.join([x for x in ('foo','') if x])
'foo'
>>> '-'.join([x for x in ('','bar') if x])
'bar'
>>> '-'.join([x for x in ('','') if x])
''


*Also note that Rafael's assessment, in his post below, only showed a difference of .0002 secs over a 1000 iterations of the filter method, it can be reasoned that such a small difference can be due to inconsistencies in available system resources at the time of running the script. I ran his timeit implementation over several iteration and found that either algorithm will be faster about 50% of the time, neither by a wide margin. Thus showing they are basically equivalent.
",What better way to concatenate string in python?,"Understand ""better"" as a quicker, elegant and readable.

I have two strings (a and b) that could be null or not. And I want concatenate them separated by a hyphen only if both are not null:

a - b

a (if b is null)

b (where a is null)
"
"Let's see.

count = 1
i = 3
while count != 1000:
    if i%2 != 0:
       for k in range(2,i):
          if i%k == 0:        # 'i' is _not_ a prime!
            print(i)       # ??
            count += 1     # ??
            break
     i += 1          # should be one space to the left,
                     # for proper indentation


If i%k==0, then i is not a prime. If we detect that it's not a prime, we should (a) not print it out, (b) not increment the counter of found primes and (c) we indeed should break out from the for loop - no need to test any more numbers.

Also, instead of testing i%2, we can just increment by 2, starting from 3 - they will all be odd then, by construction.

So, we now have

count = 1
i = 3
while count != 1000:
    for k in range(2,i):
        if i%k == 0:       
            break
    else:
        print(i)
        count += 1
    i += 2        


The else after for gets executed if the for loop was not broken out of prematurely. 

It works, but it works too hard, so is much slower than necessary. It tests a number by all the numbers below it, but it's enough to test it just up to its square root. Why? Because if a number n == p*q, with p and q between 1 and n, then at least one of p or q will be not greater than the square root of n: if they both were greater, their product would be greater than n.

So the improved code is:

from math import sqrt

count = 1
i = 1
while count < 1000:
    i += 2
    for k in range(2, 1+int(sqrt(i+1))):
        if i%k == 0:       
            break
    else:
        # print(i) ,
        count += 1
        # if count%20==0: print """"
print i


Just try running it with range(2,i) (as in the previous code), and see how slow it gets. For 1000 primes it takes 1.16 secs, and for 2000 – 4.89 secs (3000 – 12.15 ses). But with the sqrt it takes just 0.21 secs to produce 3000 primes, 0.84 secs for 10,000 and 2.44 secs for 20,000 (orders of growth of ~ n2.1...2.2 vs. ~ n1.5).

The algorithm used above is known as trial division. There's one more improvement needed to make it an optimal trial division, i.e. testing by primes only. An example can be seen here, which runs about 3x faster, and at better empirical complexity of  ~ n1.3. 



Then there's the sieve of Eratosthenes, which is quite faster (for 20,000 primes, 12x faster than ""improved code"" above, and much faster yet after that: its empirical order of growth is ~ n1.1, for producing n primes, measured up to n = 1,000,000 primes):

from math import log

count = 1 ; i = 1 ; D = {}
n = 100000                        # 20k:0.20s 
m = int(n*(log(n)+log(log(n))))   # 100k:1.15s 200k:2.36s-7.8M 
while count < n:                  #            400k:5.26s-8.7M 
        i += 2                    #            800k:11.21-7.8M 
        if i not in D:            #            1mln:13.20-7.8M (n^1.1)
            count += 1
            k = i*i
            if k > m:  break      # break, when all is already marked
            while k <= m:
                D[k] = 0 
                k += 2*i
while count < n:
        i += 2
        if i not in D: count += 1
if i >= m: print ""invalid: top value estimate too small"",i,m ; error
print i,m  


The truly unbounded, incremental, ""sliding"" sieve of Eratosthenes is about 1.5x faster yet, in this range as tested here.
",How to generate the 1000th prime in python?,"count = 0
i = 11

while count <= 1000 and i <= 10000:
    if i%2 != 0:
       if (i%3 == 0 or i%4 == 0 or i%5 == 0 or i%6 == 0 or i%7 == 0 or i%9 == 0):
           continue
       else:
           print i,'is prime.'
           count += 1
    i+=1


I'm trying to generate the 1000th prime number only through the use of loops. I generate the primes correctly but the last prime i get is not the 1000th prime. How can i modify my code to do so. Thank in advance for the help.

EDIT: I understand how to do this problem now. But can someone please explain why the following code does not work ? This is the code I wrote before I posted the second one on here.

count = 1
i = 3
while count != 1000:
    if i%2 != 0:
       for k in range(2,i):
          if i%k == 0:
            print(i)
            count += 1
            break
     i += 1

"
"Your post asks several questions:


  What is the number returned from the function ? 


It is ""an integer (or long integer) which is guaranteed to be unique and constant for this object during its lifetime."" (Python Standard Library - Built-in Functions) A unique number. Nothing more, and nothing less. Think of it as a social-security number or employee id number for Python objects.


  Is it the same with memory addresses in C ? 


Conceptually, yes, in that they are both guaranteed to be unique in their universe during their lifetime. And in one particular implementation of Python, it actually is the memory address of the corresponding C object.


  If yes, why doesn't the number increase instantly by the size of the data type ( I assume that it would be int) ?


Because a list is not an array, and an list element is a reference, not an object.


  When do we really use id( ) function ?


Hardly ever. id() (or its equivalent) is used in the is operator. 
",What does id( ) function used for?,"I read the doc and saw this id( ) function.

What the doc said: 


  Return the âidentityâ of an object. This is an integer (or long integer) which is guaranteed to be unique and constant for this object during its lifetime. Two objects with non-overlapping lifetimes may have the same id() value.
  
  CPython implementation detail: This is the address of the object in memory.


So, I tried to use id( ) with list. Here is the result

list = [1,2,3]
id(list[0])
id(list[1])
id(list[2])


output:

31186196
31907092 // increased by 896
31907080 // decreased by 12


What is the number returned from the function ? Is it the same with memory addresses in C ? If yes, why doesn't the number increase instantly by the size of the data type ( I assume that it would be int) ?

When do we really use id( ) function ?
"
"for x in cars:
    print (x)
    for y in cars[x]:
        print (y,':',cars[x][y])


output:

A
color : 2
speed : 70
B
color : 3
speed : 60

",How to print a dictionary line by line in Python?,"This is the dictionary

cars = {'A':{'speed':70,
        'color':2},
        'B':{'speed':60,
        'color':3}}


Using this for loop

for keys,values in cars.items():
    print(keys)
    print(values)


It prints the following:

B
{'color': 3, 'speed': 60}
A
{'color': 2, 'speed': 70}


But I want the program to print it like this:

B
color : 3
speed : 60
A
color : 2
speed : 70


I just started learning dictionaries so I'm not sure how to do this.
"
"If you're doing much numerical work with arrays like this, I'd suggest numpy, which comes with a cumulative sum function cumsum:

import numpy as np

a = [4,6,12]

np.cumsum(a)
#array([4, 10, 22])


Numpy is often faster than pure python for this kind of thing, see in comparison to @Ashwini's accumu:

In [136]: timeit list(accumu(range(1000)))
10000 loops, best of 3: 161 us per loop

In [137]: timeit list(accumu(xrange(1000)))
10000 loops, best of 3: 147 us per loop

In [138]: timeit np.cumsum(np.arange(1000))
100000 loops, best of 3: 10.1 us per loop


But of course if it's the only place you'll use numpy, it might not be worth having a dependence on it.
",How to find the cumulative sum of numbers in a list?,"time_interval=[4,6,12]


I want to sum up the numbers like [4+0, 4+6, 4+6+12] in order to get the list t=[4,10,22]. I tried:

x=0
for i in (time_interval):
    t1=time_interval[0]
    t2=time_interval[1]+t1
    t3=time_interval[2]+t2
    print(t1,t2,t3)

4 10 22
4 10 22
4 10 22

"
"A robust solution that can handle any number of extra fields - sorted by the 'time' field (as a method):

def aggregate(old_d, sort_key='time'):
    new_d = dict((k, []) for k in old_d)
    prev = None
    curr = None
    for i in range(len(old_d[sort_key])):
        curr = old_d[sort_key][i]
        for key, lst in new_d.iteritems(): # .items() in Python 3+
            if prev == curr:
                if key != sort_key:           
                    lst[-1] += old_d[key][i]
            else:
                lst.append(old_d[key][i])
        prev = curr
    return new_d


Using your dictionary:

d = {'time': [1, 2, 2, 3, 4, 4, 5],
     'power': [2, 2, 3, 6, 3, 3, 2],
     'usage': [0, 1, 1, 2, 1, 4, 7]}

print aggregate(d)
>>>
{'usage': [0, 2, 2, 5, 7], 'power': [2, 5, 6, 6, 2], 'time': [1, 2, 3, 4, 5]}

",How to sum 3 same sized sorted lists based on the identical elements of the first one in Python?,"I have a python dictionary containing 3 lists in the keys 'time', 'power' and 'usage'.
All the lists have the same number of elements and all the lists are sorted. What
I want to do is to sum up all the elements for lists 'power' and 'usage' that their indexes
correspond to the same value in list 'time', so as to have only one sample of power and usage per time unit.

For example transform this dictionary:

{'time': [1, 2, 2, 3, 4, 4, 5],
 'power': [2, 2, 3, 6, 3, 3, 2],
 'usage': [0, 1, 1, 2, 1, 4, 7]}


to this one:

{'time': [1, 2, 3, 4, 5],
 'power': [2, 5, 6, 6, 2],
 'usage': [0, 2, 2, 5, 7]}


Already I have written this piece of code that works but I don't like
it so much:

d = {'time':[1,2,2,3,4,4,5], 'power':[0,1,1,2,1,4,7], 'usage':[2,2,3,6,3,3,2]}
prev = -1
new_d = {'time':[], 'power': [], 'usage':[]}
indexes =  range( len(d['time']) )

for i in indexes:
  if d['time'][i]!=prev:
    new_d['time'].append(d['time'][i])
    new_d['power'].append(d['power'][i])
    new_d['usage'].append(d['usage'][i])
  else:
    last_power = len( new_d['power'] ) - 1
    last_usage = len( new_d['usage'] ) - 1
    new_d['power'][last_power]+=d['power'][i]
    new_d['usage'][last_usage]+=d['usage'][i]
  prev=d['time'][i]

print d
print new_d


Is there a pythonian way to do this more simply and comprehensive? 
"
"How about:

def nth_root(val, n):
    ret = int(val**(1./n))
    return ret + 1 if (ret + 1) ** n == val else ret

print nth_root(124, 3)
print nth_root(125, 3)
print nth_root(126, 3)
print nth_root(1, 100)


Here, both val and n are expected to be integer and positive. This makes the return expression rely exclusively on integer arithmetic, eliminating any possibility of rounding errors.

Note that accuracy is only guaranteed when val**(1./n) is fairly small. Once the result of that expression deviates from the true answer by more than 1, the method will no longer give the correct answer (it'll give the same approximate answer as your original version).


  Still I am wondering why int(125**(1/3)) is 4


In [1]: '%.20f' % 125**(1./3)
Out[1]: '4.99999999999999911182'


int() truncates that to 4.
",How to find integer nth roots?,"I want to find the greatest integer less than or equal to the kth root of n. I tried

int(n**(1/k))


But for n=125, k=3 this gives the wrong answer! I happen to know that 5 cubed is 125.

>>> int(125**(1/3))
4


What's a better algorithm?



Background: In 2011, this slip-up cost me beating Google Code Jam. https://code.google.com/codejam/contest/dashboard?c=1150486#s=p2
"
"For a tab length of 5:

>>> s = ""123\t123""
>>> print ''.join('%-5s' % item for item in s.split('\t'))
123  123  
>>> 

","How to replace custom tabs with spaces in a string, depend on the size of the tab?","I'm trying to write a python function not using any modules that will take a string that has tabs and replace the tabs with spaces appropriate for an inputted tabstop size. It can't just replace all size-n tabs by n spaces though, since a tab could be 1 to n spaces. I'm really confused, so if anyone could just point me in the right direction I'd greatly appreciate it. 

For instance,
if tabstop is size 4 originally:

123\t123 = 123 123 #one space in between


but changed to tabstop 5:

123\t123 = 123  123 #two spaces in between


I think I need to pad the end of the string with spaces until string%n==0 and then chunk it, but I'm pretty lost at the moment..
"
"You need to count the number of rows:

row_count = sum(1 for row in fileObject)  # fileObject is your csv.reader


Using sum() with a generator expression makes for an efficient counter, avoiding storing the whole file in memory.

If you already read 2 rows to start with, then you need to add those 2 rows to your total; rows that have already been read are not being counted.
",Count how many lines are in a CSV Python?,"I'm using python (Django Framework) to read a CSV file. I pull just 2 lines out of this CSV as you can see. What I have been trying to do is store in a variable the total number of rows the CSV also.

How can I get the total number of rows?

file = object.myfilePath
fileObject = csv.reader(file)
for i in range(2):
    data.append(fileObject.next()) 


I have tried:

len(fileObject)
fileObject.length

"
"It seems that to achieve the behavior you want, with the given restrictions, you'll have to delve into the JSONEncoder class a little. Below I've written out a custom JSONEncoder that overrides the iterencode method to pass a custom isinstance method to _make_iterencode. It isn't the cleanest thing in the world, but seems to be the best given the options and it keeps customization to a minimum.

# customencoder.py
from json.encoder import (_make_iterencode, JSONEncoder,
                          encode_basestring_ascii, FLOAT_REPR, INFINITY,
                          c_make_encoder, encode_basestring)


class CustomObjectEncoder(JSONEncoder):

    def iterencode(self, o, _one_shot=False):
        """"""
        Most of the original method has been left untouched.

        _one_shot is forced to False to prevent c_make_encoder from
        being used. c_make_encoder is a funcion defined in C, so it's easier
        to avoid using it than overriding/redefining it.

        The keyword argument isinstance for _make_iterencode has been set
        to self.isinstance. This allows for a custom isinstance function
        to be defined, which can be used to defer the serialization of custom
        objects to the default method.
        """"""
        # Force the use of _make_iterencode instead of c_make_encoder
        _one_shot = False

        if self.check_circular:
            markers = {}
        else:
            markers = None
        if self.ensure_ascii:
            _encoder = encode_basestring_ascii
        else:
            _encoder = encode_basestring
        if self.encoding != 'utf-8':
            def _encoder(o, _orig_encoder=_encoder, _encoding=self.encoding):
                if isinstance(o, str):
                    o = o.decode(_encoding)
                return _orig_encoder(o)

        def floatstr(o, allow_nan=self.allow_nan,
                     _repr=FLOAT_REPR, _inf=INFINITY, _neginf=-INFINITY):
            if o != o:
                text = 'NaN'
            elif o == _inf:
                text = 'Infinity'
            elif o == _neginf:
                text = '-Infinity'
            else:
                return _repr(o)

            if not allow_nan:
                raise ValueError(
                    ""Out of range float values are not JSON compliant: "" +
                    repr(o))

            return text

        # Instead of forcing _one_shot to False, you can also just
        # remove the first part of this conditional statement and only
        # call _make_iterencode
        if (_one_shot and c_make_encoder is not None
                and self.indent is None and not self.sort_keys):
            _iterencode = c_make_encoder(
                markers, self.default, _encoder, self.indent,
                self.key_separator, self.item_separator, self.sort_keys,
                self.skipkeys, self.allow_nan)
        else:
            _iterencode = _make_iterencode(
                markers, self.default, _encoder, self.indent, floatstr,
                self.key_separator, self.item_separator, self.sort_keys,
                self.skipkeys, _one_shot, isinstance=self.isinstance)
        return _iterencode(o, 0)


You can now subclass the CustomObjectEncoder so it correctly serializes your custom objects. The CustomObjectEncoder can also do cool stuff like handle nested objects.

# test.py
import json
import datetime
from customencoder import CustomObjectEncoder


class MyEncoder(CustomObjectEncoder):

    def isinstance(self, obj, cls):
        if isinstance(obj, (mList, mDict)):
            return False
        return isinstance(obj, cls)

    def default(self, obj):
        """"""
        Defines custom serialization.

        To avoid circular references, any object that will always fail
        self.isinstance must be converted to something that is
        deserializable here.
        """"""
        if isinstance(obj, datetime.datetime):
            return obj.isoformat()
        elif isinstance(obj, mDict):
            return {""orig"": dict(obj), ""attrs"": vars(obj)}
        elif isinstance(obj, mList):
            return {""orig"": list(obj), ""attrs"": vars(obj)}
        else:
            return None


class mList(list):
    pass


class mDict(dict):
    pass


def main():
    zelda = mList(['zelda'])
    zelda.src = ""oldschool""
    games = mList(['mario', 'contra', 'tetris', zelda])
    games.src = 'console'
    scores = mDict({'dp': 10, 'pk': 45})
    scores.processed = ""unprocessed""
    test_json = {'games': games, 'scores': scores,
                 'date': datetime.datetime.now()}
    print(json.dumps(test_json, cls=MyEncoder))

if __name__ == '__main__':
    main()

",How to change json encoding behaviour for serializable python object?,"It is easy to change the format of an object which is not JSON serializable eg datetime.datetime.

My requirement, for debugging purposes, is to alter the way some custom objects extended from base ones like dict and list , get serialized in json format .  Code :

import datetime
import json

def json_debug_handler(obj):
    print(""object received:"")
    print type(obj)
    print(""\n\n"")
    if  isinstance(obj, datetime.datetime):
        return obj.isoformat()
    elif isinstance(obj,mDict):
        return {'orig':obj , 'attrs': vars(obj)}
    elif isinstance(obj,mList):
        return {'orig':obj, 'attrs': vars(obj)}
    else:
        return None


class mDict(dict):
    pass


class mList(list):
    pass


def test_debug_json():
    games = mList(['mario','contra','tetris'])
    games.src = 'console'
    scores = mDict({'dp':10,'pk':45})
    scores.processed = ""unprocessed""
    test_json = { 'games' : games , 'scores' : scores , 'date': datetime.datetime.now() }
    print(json.dumps(test_json,default=json_debug_handler))

if __name__ == '__main__':
    test_debug_json()


DEMO : http://ideone.com/hQJnLy

Output:

{""date"": ""2013-05-07T01:03:13.098727"", ""games"": [""mario"", ""contra"", ""tetris""], ""scores"": {""pk"": 45, ""dp"": 10}}


Desired output:

{""date"": ""2013-05-07T01:03:13.098727"", ""games"": { ""orig"": [""mario"", ""contra"", ""tetris""] ,""attrs"" : { ""src"":""console""}}  , ""scores"": { ""orig"": {""pk"": 45, ""dp"": 10},""attrs"":
""processed"":""unprocessed }}

Does the default handler not work for serializable objects ?
If not, how can I override this, without adding toJSON methods to the extended classes ?

Also, there is this version of JSON encoder which does not work :

class JsonDebugEncoder(json.JSONEncoder):
    def default(self,obj):
        if  isinstance(obj, datetime.datetime):
            return obj.isoformat()
        elif isinstance(obj,mDict):
            return {'orig':obj , 'attrs': vars(obj)}
        elif isinstance(obj,mList):
            return {'orig':obj, 'attrs': vars(obj)}
        else:
            return json.JSONEncoder.default(self, obj)


If there is a hack with pickle,__getstate__,__setstate__,and then using json.dumps over pickle.loads object , I am open to that as well, I tried , but that did not work.
"
"f is a file object. The documentation lists its structure, so I'll only explain a the indexing/iterating behavior.

An object is indexable only if it implements __getitem__, which you can check by calling hasattr(f, '__getitem__') or just calling f[0] and seeing if it throws an error. In fact, that's exactly what your error message tells you:

TypeError: 'file' object has no attribute '__getitem__'


File objects are not indexable. You can call f.readlines() and return a list of lines, which itself is indexable.

Objects that implement __iter__ are iterable with the for ... in ... syntax. Now there are actually two types of iterable objects: container objects and iterator objects. Iterator objects implement two methods: __iter__ and __next__. Container objects implement only __iter__ and return an iterator object, which is actually what you're iterating over. File objects are their own iterators, as they implement both methods.

If you want to get the next item in an iterable, you can use the next() function:

first_line = next(f)
second_line = next(f)
next_line_that_starts_with_0 = next(line for line in f if line.startswith('0'))


One word of caution: iterables generally aren't ""rewindable"", so once you progress through the iterable, you can't really go back. To ""rewind"" a file object, you can use f.seek(0), which will set the current position back to the beginning of the file.
",Python file variable - what is it?,"I just started with Python, and since my background is in more low-level languages (java, C++), i just cant really get some things. 

So, in python one can create a file variable, by opening a text file, for example, and then iterate through its lines like this:

f = open(sys.argv[1])
for line in f:
    #do something


However, if i try f[0] the interpreter gives an error. So what structure does f object have and how do i know in general, if i can apply for ... in ... : loop to an object?   
"
"Like this:

>>> Cards = [[[""QS"",""5H"",""AS""],[""2H"",""8H""],[""7C""]],[[""9H"",""5C""],[""JH""]],[""7D""]]
>>> from compiler.ast import flatten
>>> flatten(Cards) 
['QS', '5H', 'AS', '2H', '8H', '7C', '9H', '5C', 'JH', '7D']


As, nacholibre pointed out, the compiler package is deprecated. This is the source of flatten:

def flatten(seq):
    l = []
    for elt in seq:
        t = type(elt)
        if t is tuple or t is list:
            for elt2 in flatten(elt):
                l.append(elt2)
        else:
            l.append(elt)
    return l

",How to get every element in a list of list of lists?,"I'm making a heart game for my assignment but I don't know how to get every element in a list of list:

>>>Cards = [[[""QS"",""5H"",""AS""],[""2H"",""8H""],[""7C""]],[[""9H"",""5C],[""JH""]],[[""7D""]]]


and what comes to my mind is :

for values in cards:
    for value in values:


But I think I just got element that has 2 list. How to calculate the one that has 3 and 1 list in the cards?
"
"You could do that with a regex:

import re
a = ""Hello World.""
b = re.sub(""(?i)([aeiou])"", ""up\\1"", a)


The (?i) makes it case-insensitive. \\1 refers to the character that was matched inside ([aeiou]).
","In python, how do I find the vowels in a word?","I am trying to make an up language translator. Simple task for me in python. Or so i thought. If you are unaware, up language is when you take a word and say it while adding up before every vowel. for example, Andrew would be Upandrupew. I am trying to find out how find all of the vowels in a user submitted word, and put up before them. Is there a way to cut up a word before all vowels. so excellent would be exc ell ent? thanks.
"
"Simple

print int(x)


will work as well.
",Round a Floating Point Number Down to the Nearest Integer?,"As the title suggests, I want to take a floating point number and round it down to the nearest integer. However, if it's not a whole, I ALWAYS want to round down the variable, regardless of how close it is to the next integer up. Is there a way to do this?
"
"What you are looking for is called Named Entity Recognition. It is a statistical technique that (most commonly) uses Conditional Random Fields to find named entities, based on having been trained to learn things about named entities.

Essentially, it looks at the content and context of the word, (looking back and forward a few words), to estimate the probability that the word is a named entity. 

Good software can look at other features of words, such as their length or shape (like ""Vcv"" if it starts with ""Vowel-consonant-vowel"")

A very good library (GPL) is Stanford's NER

Here's the demo: http://nlp.stanford.edu:8080/ner/

Some sample text to try:


  I was eating an apple over at Apple headquarters and I thought about
  Apple Martin, the daughter of the Coldplay guy


(the 3class and 4class classifiers get it right)
",How can I build a model to distinguish tweets about Apple (Inc.) from tweets about apple (fruit)?,"See below for 50 tweets about ""apple."" I have hand labeled the positive matches about Apple Inc. They are marked as 1 below.

Here are a couple of lines:

1|â@chrisgilmer: Apple targets big business with new iOS 7 features http://bit.ly/15F9JeF â. Finally.. A corp iTunes account!
0|â@Zach_Paull: When did green skittles change from lime to green apple? #notafanâ @Skittles
1|@dtfcdvEric: @MaroneyFan11 apple inc is searching for people to help and tryout all their upcoming tablet within our own net page No.
0|@STFUTimothy have you tried apple pie shine?
1|#SuryaRay #India Microsoft to bring Xbox and PC games to Apple, Android phones: Report: Microsoft Corp... http://dlvr.it/3YvbQx  @SuryaRay


Here is the total data set: http://pastebin.com/eJuEb4eB

I need to build a model that classifies ""Apple"" (Inc). from the rest.

I'm not looking for a general overview of machine learning, rather I'm looking for actual model in code (Python preferred).
"
"Great native python based answers given by other users. But here's the NLTK approach (just in case, the OP gets penalized for reinventing what's already existing in the NLTK library). 

There is an ngram module (http://www.nltk.org/_modules/nltk/model/ngram.html) that people seldom use in NLTK. It's not because it's hard to read ngrams but training a model base on >3grams will result in much data sparsity.

from nltk import ngrams
sentence = 'this is a foo bar sentences and i want to ngramize it'
n = 6
sixgrams = ngrams(sentence.split(), n)
for grams in sixgrams:
  print grams

","n-grams in python, four, five, six grams?","I'm looking for a way to split a text into n-grams.
Normally I would do something like:

import nltk
from nltk import bigrams
string = ""I really like python, it's pretty awesome.""
string_bigrams = bigrams(string)
print string_bigrams


I am aware that nltk only offers bigrams and trigrams, but is there a way to split my text in four-grams, five-grams or even hundred-grams?

Thanks!
"
"Just thinking outside of the box here, how about a custom open() method?

import sys
import contextlib

@contextlib.contextmanager
def smart_open(filename=None):
    if filename and filename != '-':
        fh = open(filename, 'w')
    else:
        fh = sys.stdout

    try:
        yield fh
    finally:
        if fh is not sys.stdout:
            fh.close()


Use it like this:

# writes to some_file
with smart_open('some_file') as fh:
    print >>fh, 'some output'

# writes to stdout
with smart_open() as fh:
    print >>fh, 'some output'

# writes to stdout
with smart_open('-') as fh:
    print >>fh, 'some output'

",How to handle both `with open(...)` and `sys.stdout` nicely?,"Often I need to output data either to file or, if file is not specified, to stdout. I use the following snippet:

if target:
    with open(target, 'w') as h:
        h.write(content)
else:
    sys.stdout.write(content)


I would like to rewrite it and handle both targets uniformly.

In ideal case it would be:

with open(target, 'w') as h:
    h.write(content)


but this will not work well because sys.stdout is be closed when leaving with block and I don't want that. I neither want to

stdout = open(target, 'w')
...


because I would need to remember to restore original stdout.

Related:


Redirect stdout to a file in Python?
Handling Exceptions - interesting article about handling exceptions in Python, as compared to C++


Edit

I know that I can wrap target, define separate function or use context manager. I look for a simple, elegant, idiomatic solution fitting that wouldn't require more than 5 lines
"
"You can try to use tokenizer, it gives you almost same result as you expected except for the negative number like -4, but it is pretty close.

from StringIO import StringIO
import tokenize
str = ''
tokens = tokenize.generate_tokens(StringIO(str).readline)
result = [x[1] for x in tokens]


Here is the result:

['[', '2', '{', '12.5', '6.0', '}', ']', '(', '3', '-', '4', '5', ')', '>', '']

",How would I convert a string into a list of tokens in Python?,"When I input this:

>>>tokenize('')


I want to get this back:

['']


Basically, how would I keep it so that the input converts everything into the list while keeping the numbers their original value.
"
"def count_letters(word):
    return len(word) - word.count(' ')


Alternatively, if you have multiple letters to ignore, you could filter the string:

def count_letters(word):
    BAD_LETTERS = "" ""
    return len([letter for letter in word if letter not in BAD_LETTERS])

",How to count the number of letters in a string without the spaces?,"This is my solution resulting in an error. Returns 0

PS: I'd still love a fix to my code :)

from collections import Counter
import string


def count_letters(word):
    global count
    wordsList = string.split(word)
    count = Counter()
    for words in wordsList:
        for letters in set(words):
            return count[letters]

word = ""The grey old fox is an idiot""
print count_letters(word)

"
"Use map with operator.add:

>>> from operator import add
>>> map(add, list1, list2)
[5, 7, 9]


or zip with a list comprehension:

>>> [sum(x) for x in zip(list1, list2)]
[5, 7, 9]


Timing comparisons:

>>> list2 = [4, 5, 6]*10**5
>>> list1 = [1, 2, 3]*10**5
>>> %timeit from operator import add;map(add, list1, list2)
10 loops, best of 3: 44.6 ms per loop
>>> %timeit from itertools import izip; [a + b for a, b in izip(list1, list2)]
10 loops, best of 3: 71 ms per loop
>>> %timeit [a + b for a, b in zip(list1, list2)]
10 loops, best of 3: 112 ms per loop
>>> %timeit from itertools import izip;[sum(x) for x in izip(list1, list2)]
1 loops, best of 3: 139 ms per loop
>>> %timeit [sum(x) for x in zip(list1, list2)]
1 loops, best of 3: 177 ms per loop

",Element-wise Addition of 2 Lists in Python?,"I have now:

list1=[1, 2, 3]
list2=[4, 5, 6]


I wish to have:

[1, 2, 3]
 +  +  +
[4, 5, 6]
   ||
[5, 7, 9]


Simply an element-wise addition of two lists.

I can surely iterate the two lists, but I don't want do that.

What is the most Pythonic way of doing so?
"
"If you know in advance that you're going to want to multiple samples without overlaps, easiest is to do random.shuffle() on list(range(100)) (Python 3 - can skip the list() in Python 2), then peel off slices as needed.

s = list(range(100))
random.shuffle(s)
first_sample = s[-10:]
del s[-10:]
second_sample = s[-10:]
del s[-10:]
# etc


Else @Chronial's answer is reasonably efficient.
",How to incrementally sample without replacement?,"Python has my_sample = random.sample(range(100), 10) to randomly sample without replacement from [0, 100).

Suppose I have sampled n such numbers and now I want to sample one more without replacement (without including any of the previously sampled n), how to do so super efficiently?

update: changed from ""reasonably efficiently"" to ""super efficiently"" (but ignoring constant factors)
"
"PyPy, as others have been quick to mention, has tenuous support for C extensions. It has support, but typically at slower-than-Python speeds and it's iffy at best. Hence a lot of modules simply require CPython. Cython and Numpy are awesome for numerics, and most people who actually need speed in Python are using those (+ Pandas, SciPy, etc.) heavily. Since they're either non-existent or tenuously supported and slow the people who need a fast Python often are better off with CPython both for speed and ease-of-use.

Secondly, Python 3 support is experimental at the moment. has just reached stable! As of 20th June 2014, PyPy3 2.3.1 - Fulcrum is out!

Thirdly, PyPy sometimes isn't actually faster for ""scripts"", which a lot of people use Python for. These are the short-running programs that do something simple and small. Because PyPy is a JIT compiler its main advantages come from long run times and simple types (such as numbers). Frankly, PyPy's pre-JIT speeds are pretty bad compared to CPython.

Fourthly, inertia. Moving to PyPy often requires retooling, which for some people and organizations is simply too much work.

Those are the main reasons that affect me, I'd say.
",Why shouldn't I use PyPy over CPython if PyPy is 6.3 times faster?,"I've been hearing a lot about the PyPy project. They claim it is 6.3 times faster than the CPython interpreter on their site.

Whenever we talk about dynamic languages like Python, speed is one of the top issues. To solve this, they say PyPy is 6.3 times faster.

The second issue is parallelism, the infamous Global Interpreter Lock (GIL). For this, PyPy says it can give GIL-less Python.

If PyPy can solve these great challenges, what are its weaknesses that are preventing wider adoption? That is to say, what's preventing someone like me, a typical Python developer, from switching to PyPy right now? 
"
"If you need to work with indices of a sequence, then yes - you use it... eg for the equivalent of numpy.argsort...:

>>> a = [6, 3, 1, 2, 5, 4]
>>> sorted(range(len(a)), key=a.__getitem__)
[2, 3, 1, 5, 4, 0]

",Is there a need for range(len(a))?,"One frequently finds expressions of this type in python questions on SO. Either for just accessing all items of the iterable

for i in range(len(a)):
    print(a[i])


Which is just a clumbersome way of writing:

for e in a:
    print(e)


Or for assigning to elements of the iterable:

for i in range(len(a)):
    a[i] = a[i] * 2


Which should be the same as:

for i, e in enumerate(a):
     a[i] = e * 2
# Or if it isn't too expensive to create a new iterable
a = [e * 2 for e in a]


Or for filtering over the indices:

for i in range(len(a)):
    if i % 2 == 1: continue
    print(a[i])


Which could be expressed like this:

for e in a [::2]:
    print(e)


Or when you just need the length of the list, and not its content:

for _ in range(len(a)):
    doSomethingUnrelatedToA()


Which could be:

for _ in a:
    doSomethingUnrelatedToA()


In python we have enumerate, slicing, filter, sorted, etc... As python for constructs are intended to iterate over iterables and not only ranges of integers, are there real-world use-cases where you need in range(len(a))?
"
"Look in the python folder in the folder: Doc. This folder has the entire downloaded documentation of the python docs from python.org. I know this is a VERY late answer, but it brings up an easy solution.
",Search python docs offline?,"In python I can get some rudimentary documentation for any object using help(). But to be able to search the documentation, I have to go online. This isn't really helpful if I'm somewhere where the internet isn't accessible.

In R, there is a handy double question mark feature (??) that allows me to search through the documentation of all installed libraries for any function that includes  in its name or documentation string. Is there anything similar for python? Perhaps even just for loaded objects?
"
"Python 2.x

There were two functions to get user input, called input and raw_input. The difference between them is, raw_input doesn't evaluate the data and returns as it is, in string form. But, input will evaluate whatever you entered and the result of evaluation will be returned. For example,

>>> import sys
>>> sys.version
'2.7.6 (default, Mar 22 2014, 22:59:56) \n[GCC 4.8.2]'
>>> data = input(""Enter a number: "")
Enter a number: 5 + 17
>>> data, type(data)
(22, )


The data 5 + 17 is evaluated and the result is 22. When it evaluates the expression 5 + 17, it detects that you are adding two numbers and so the result will also be of the same int type. So, the type conversion is done for free and 22 is returned as the result of input and stored in data variable. You can think of input as the raw_input composed with an eval call.

>>> data = eval(raw_input(""Enter a number: ""))
Enter a number: 5 + 17
>>> data, type(data)
(22, )


Note: you should be careful when you are using input in Python 2.x. I explained why one should be careful when using it, in this answer.

But, raw_input doesn't evaluate the input and returns as it is, as a string.

>>> import sys
>>> sys.version
'2.7.6 (default, Mar 22 2014, 22:59:56) \n[GCC 4.8.2]'
>>> data = raw_input(""Enter a number: "")
Enter a number: 5 + 17
>>> data, type(data)
('5 + 17', )


Python 3.x

Python 3.x's input and Python 2.x's raw_input are similar and raw_input is not available in Python 3.x. 

>>> import sys
>>> sys.version
'3.4.0 (default, Apr 11 2014, 13:05:11) \n[GCC 4.8.2]'
>>> data = input(""Enter a number: "")
Enter a number: 5 + 17
>>> data, type(data)
('5 + 17', )




Solution

To answer your question, since Python 3.x doesn't evaluate and convert the data type, you have to explicitly convert to ints, with int, like this

x = int(input(""Enter a number: ""))
y = int(input(""Enter a number: ""))


You can accept numbers of any base and convert them directly to base-10 with the int function, like this

>>> data = int(input(""Enter a number: ""), 8)
Enter a number: 777
>>> data
511
>>> data = int(input(""Enter a number: ""), 16)
Enter a number: FFFF
>>> data
65535
>>> data = int(input(""Enter a number: ""), 2)
Enter a number: 10101010101
>>> data
1365


The second parameter tells what is the base of the numbers entered and then internally it understands and converts it. If the entered data is wrong it will throw a ValueError.

>>> data = int(input(""Enter a number: ""), 2)
Enter a number: 1234
Traceback (most recent call last):
  File """", line 1, in 
ValueError: invalid literal for int() with base 2: '1234'




Apart from that, your program can be changed a little bit, like this

while True:
    ...
    ...
    if input(""Play again? "") == ""no"":
        break


You can get rid of the play variable by using break and while True. 

PS: Python doesn't expect ; at the end of the line :)
",How can I read inputs as integers in Python?,"Why does this code not input integers?  Everything on the web says to use raw_input(), but I read on Stack Overflow (on a thread that did not deal with integer input) that raw_input() was renamed to input() in Python 3.x.

play = True

while play:

    x = input(""Enter a number: "")
    y = input(""Enter a number: "")

    print(x + y)
    print(x - y)
    print(x * y)
    print(x / y)
    print(x % y)

    if input(""Play again? "") == ""no"":
        play = False

"
"I had the same issue here, even with the latest versions of all related packages (astroid 1.3.2, logilab_common 0.63.2, pylon 1.4.0).

The following solution worked like a charm: I added numpy to the list of ignored modules by modifying my pylintrc file, in the [TYPECHECK] section:

[TYPECHECK]

ignored-modules = numpy


Depending on the error, you might also need to add the following line (still in the [TYPECHECK] section):

ignored-classes = numpy

",How do I get PyLint to recognize numpy members?,"I am running PyLint on a Python project. PyLint makes many complaints about being unable to find numpy members. How can I avoid this while avoiding skipping membership checks.

From the code:

import numpy as np

print np.zeros([1, 4])


Which, when ran, I get the expected:


  [[ 0.  0.  0.  0.]]


However, pylint gives me this error:


  E:  3, 6: Module 'numpy' has no 'zeros' member (no-member)


For versions, I am using pylint 1.0.0 (astroid 1.0.1, common 0.60.0) and trying to work with numpy 1.8.0 .
"
"EDIT NOTE: I edited this post to (i) process each tree image individually, as requested in the requirements, (ii) to consider both object brightness and shape in order to improve the quality of the result. 



Below is presented an approach that takes in consideration the object brightness and shape. In other words, it seeks for objects with triangle-like shape and with significant brightness. It was implemented in Java, using Marvin image processing framework.

The first step is the color thresholding. The objective here is to focus the analysis on objects with significant brightness. 

output images:









source code:

public class ChristmasTree {

private MarvinImagePlugin fill = MarvinPluginLoader.loadImagePlugin(""org.marvinproject.image.fill.boundaryFill"");
private MarvinImagePlugin threshold = MarvinPluginLoader.loadImagePlugin(""org.marvinproject.image.color.thresholding"");
private MarvinImagePlugin invert = MarvinPluginLoader.loadImagePlugin(""org.marvinproject.image.color.invert"");
private MarvinImagePlugin dilation = MarvinPluginLoader.loadImagePlugin(""org.marvinproject.image.morphological.dilation"");

public ChristmasTree(){
    MarvinImage tree;

    // Iterate each image
    for(int i=1; i<=6; i++){
        tree = MarvinImageIO.loadImage(""./res/trees/tree""+i+"".png"");

        // 1. Threshold
        threshold.setAttribute(""threshold"", 200);
        threshold.process(tree.clone(), tree);
    }
}
public static void main(String[] args) {
    new ChristmasTree();
}
}


In the second step, the brightest points in the image are dilated in order to form shapes. The result of this process is the probable shape of the objects with significant brightness. Applying flood fill segmentation, disconnected shapes are detected.

output images:









source code:

public class ChristmasTree {

private MarvinImagePlugin fill = MarvinPluginLoader.loadImagePlugin(""org.marvinproject.image.fill.boundaryFill"");
private MarvinImagePlugin threshold = MarvinPluginLoader.loadImagePlugin(""org.marvinproject.image.color.thresholding"");
private MarvinImagePlugin invert = MarvinPluginLoader.loadImagePlugin(""org.marvinproject.image.color.invert"");
private MarvinImagePlugin dilation = MarvinPluginLoader.loadImagePlugin(""org.marvinproject.image.morphological.dilation"");

public ChristmasTree(){
    MarvinImage tree;

    // Iterate each image
    for(int i=1; i<=6; i++){
        tree = MarvinImageIO.loadImage(""./res/trees/tree""+i+"".png"");

        // 1. Threshold
        threshold.setAttribute(""threshold"", 200);
        threshold.process(tree.clone(), tree);

        // 2. Dilate
        invert.process(tree.clone(), tree);
        tree = MarvinColorModelConverter.rgbToBinary(tree, 127);
        MarvinImageIO.saveImage(tree, ""./res/trees/new/tree_""+i+""threshold.png"");
        dilation.setAttribute(""matrix"", MarvinMath.getTrueMatrix(50, 50));
        dilation.process(tree.clone(), tree);
        MarvinImageIO.saveImage(tree, ""./res/trees/new/tree_""+1+""_dilation.png"");
        tree = MarvinColorModelConverter.binaryToRgb(tree);

        // 3. Segment shapes
        MarvinImage trees2 = tree.clone();
        fill(tree, trees2);
        MarvinImageIO.saveImage(trees2, ""./res/trees/new/tree_""+i+""_fill.png"");
}

private void fill(MarvinImage imageIn, MarvinImage imageOut){
    boolean found;
    int color= 0xFFFF0000;

    while(true){
        found=false;

        Outerloop:
        for(int y=0; y<imageIn.getHeight(); y++){
            for(int x=0; x<imageIn.getWidth(); x++){
                if(imageOut.getIntComponent0(x, y) == 0){
                    fill.setAttribute(""x"", x);
                    fill.setAttribute(""y"", y);
                    fill.setAttribute(""color"", color);
                    fill.setAttribute(""threshold"", 120);
                    fill.process(imageIn, imageOut);
                    color = newColor(color);

                    found = true;
                    break Outerloop;
                }
            }
        }

        if(!found){
            break;
        }
    }

}

private int newColor(int color){
    int red = (color & 0x00FF0000) >> 16;
    int green = (color & 0x0000FF00) >> 8;
    int blue = (color & 0x000000FF);

    if(red <= green && red <= blue){
        red+=5;
    }
    else if(green <= red && green <= blue){
        green+=5;
    }
    else{
        blue+=5;
    }

    return 0xFF000000 + (red << 16) + (green << 8) + blue;
}

public static void main(String[] args) {
    new ChristmasTree();
}
}


As shown in the output image, multiple shapes was detected. In this problem, there a just a few bright points in the images. However, this approach was implemented to deal with more complex scenarios. 

In the next step each shape is analyzed. A simple algorithm detects shapes with a pattern similar to a triangle. The algorithm analyze the object shape line by line. If the center of the mass of each shape line is almost the same (given a threshold) and mass increase as y increase, the object has a triangle-like shape. The mass of the shape line is the number of pixels in that line that belongs to the shape. Imagine you slice the object horizontally and analyze each horizontal segment. If they are centralized to each other and the length increase from the first segment to last one in a linear pattern, you probably has an object that resembles a triangle.

source code:

private int[] detectTrees(MarvinImage image){
    HashSet analysed = new HashSet();
    boolean found;
    while(true){
        found = false;
        for(int y=0; y<image.getHeight(); y++){
            for(int x=0; x<image.getWidth(); x++){
                int color = image.getIntColor(x, y);

                if(!analysed.contains(color)){
                    if(isTree(image, color)){
                        return getObjectRect(image, color);
                    }

                    analysed.add(color);
                    found=true;
                }
            }
        }

        if(!found){
            break;
        }
    }
    return null;
}

private boolean isTree(MarvinImage image, int color){

    int mass[][] = new int[image.getHeight()][2];
    int yStart=-1;
    int xStart=-1;
    for(int y=0; y<image.getHeight(); y++){
        int mc = 0;
        int xs=-1;
        int xe=-1;
        for(int x=0; x<image.getWidth(); x++){
            if(image.getIntColor(x, y) == color){
                mc++;

                if(yStart == -1){
                    yStart=y;
                    xStart=x;
                }

                if(xs == -1){
                    xs = x;
                }
                if(x > xe){
                    xe = x;
                }
            }
        }
        mass[y][0] = xs;
        mass[y][3] = xe;
        mass[y][4] = mc;    
    }

    int validLines=0;
    for(int y=0; y<image.getHeight(); y++){
        if
        ( 
            mass[y][5] > 0 &&
            Math.abs(((mass[y][0]+mass[y][6])/2)-xStart) <= 50 &&
            mass[y][7] >= (mass[yStart][8] + (y-yStart)*0.3) &&
            mass[y][9] <= (mass[yStart][10] + (y-yStart)*1.5)
        )
        {
            validLines++;
        }
    }

    if(validLines > 100){
        return true;
    }
    return false;
}


Finally, the position of each shape similar to a triangle and with significant brightness, in this case a Christmas tree, is highlighted in the original image, as shown below.

final output images:









final source code:

public class ChristmasTree {

private MarvinImagePlugin fill = MarvinPluginLoader.loadImagePlugin(""org.marvinproject.image.fill.boundaryFill"");
private MarvinImagePlugin threshold = MarvinPluginLoader.loadImagePlugin(""org.marvinproject.image.color.thresholding"");
private MarvinImagePlugin invert = MarvinPluginLoader.loadImagePlugin(""org.marvinproject.image.color.invert"");
private MarvinImagePlugin dilation = MarvinPluginLoader.loadImagePlugin(""org.marvinproject.image.morphological.dilation"");

public ChristmasTree(){
    MarvinImage tree;

    // Iterate each image
    for(int i=1; i<=6; i++){
        tree = MarvinImageIO.loadImage(""./res/trees/tree""+i+"".png"");

        // 1. Threshold
        threshold.setAttribute(""threshold"", 200);
        threshold.process(tree.clone(), tree);

        // 2. Dilate
        invert.process(tree.clone(), tree);
        tree = MarvinColorModelConverter.rgbToBinary(tree, 127);
        MarvinImageIO.saveImage(tree, ""./res/trees/new/tree_""+i+""threshold.png"");
        dilation.setAttribute(""matrix"", MarvinMath.getTrueMatrix(50, 50));
        dilation.process(tree.clone(), tree);
        MarvinImageIO.saveImage(tree, ""./res/trees/new/tree_""+1+""_dilation.png"");
        tree = MarvinColorModelConverter.binaryToRgb(tree);

        // 3. Segment shapes
        MarvinImage trees2 = tree.clone();
        fill(tree, trees2);
        MarvinImageIO.saveImage(trees2, ""./res/trees/new/tree_""+i+""_fill.png"");

        // 4. Detect tree-like shapes
        int[] rect = detectTrees(trees2);

        // 5. Draw the result
        MarvinImage original = MarvinImageIO.loadImage(""./res/trees/tree""+i+"".png"");
        drawBoundary(trees2, original, rect);
        MarvinImageIO.saveImage(original, ""./res/trees/new/tree_""+i+""_out_2.jpg"");
    }
}

private void drawBoundary(MarvinImage shape, MarvinImage original, int[] rect){
    int yLines[] = new int[6];
    yLines[0] = rect[1];
    yLines[1] = rect[1]+(int)((rect[3]/5));
    yLines[2] = rect[1]+((rect[3]/5)*2);
    yLines[3] = rect[1]+((rect[3]/5)*3);
    yLines[4] = rect[1]+(int)((rect[3]/5)*4);
    yLines[5] = rect[1]+rect[3];

    List points = new ArrayList();
    for(int i=0; i<yLines.length; i++){
        boolean in=false;
        Point startPoint=null;
        Point endPoint=null;
        for(int x=rect[0]; x<rect[0]+rect[2]; x++){

            if(shape.getIntColor(x, yLines[i]) != 0xFFFFFFFF){
                if(!in){
                    if(startPoint == null){
                        startPoint = new Point(x, yLines[i]);
                    }
                }
                in = true;
            }
            else{
                if(in){
                    endPoint = new Point(x, yLines[i]);
                }
                in = false;
            }
        }

        if(endPoint == null){
            endPoint = new Point((rect[0]+rect[2])-1, yLines[i]);
        }

        points.add(startPoint);
        points.add(endPoint);
    }

    drawLine(points.get(0).x, points.get(0).y, points.get(1).x, points.get(1).y, 15, original);
    drawLine(points.get(1).x, points.get(1).y, points.get(3).x, points.get(3).y, 15, original);
    drawLine(points.get(3).x, points.get(3).y, points.get(5).x, points.get(5).y, 15, original);
    drawLine(points.get(5).x, points.get(5).y, points.get(7).x, points.get(7).y, 15, original);
    drawLine(points.get(7).x, points.get(7).y, points.get(9).x, points.get(9).y, 15, original);
    drawLine(points.get(9).x, points.get(9).y, points.get(11).x, points.get(11).y, 15, original);
    drawLine(points.get(11).x, points.get(11).y, points.get(10).x, points.get(10).y, 15, original);
    drawLine(points.get(10).x, points.get(10).y, points.get(8).x, points.get(8).y, 15, original);
    drawLine(points.get(8).x, points.get(8).y, points.get(6).x, points.get(6).y, 15, original);
    drawLine(points.get(6).x, points.get(6).y, points.get(4).x, points.get(4).y, 15, original);
    drawLine(points.get(4).x, points.get(4).y, points.get(2).x, points.get(2).y, 15, original);
    drawLine(points.get(2).x, points.get(2).y, points.get(0).x, points.get(0).y, 15, original);
}

private void drawLine(int x1, int y1, int x2, int y2, int length, MarvinImage image){
    int lx1, lx2, ly1, ly2;
    for(int i=0; i<length; i++){
        lx1 = (x1+i >= image.getWidth() ? (image.getWidth()-1)-i: x1);
        lx2 = (x2+i >= image.getWidth() ? (image.getWidth()-1)-i: x2);
        ly1 = (y1+i >= image.getHeight() ? (image.getHeight()-1)-i: y1);
        ly2 = (y2+i >= image.getHeight() ? (image.getHeight()-1)-i: y2);

        image.drawLine(lx1+i, ly1, lx2+i, ly2, Color.red);
        image.drawLine(lx1, ly1+i, lx2, ly2+i, Color.red);
    }
}

private void fillRect(MarvinImage image, int[] rect, int length){
    for(int i=0; i<length; i++){
        image.drawRect(rect[0]+i, rect[1]+i, rect[2]-(i*2), rect[3]-(i*2), Color.red);
    }
}

private void fill(MarvinImage imageIn, MarvinImage imageOut){
    boolean found;
    int color= 0xFFFF0000;

    while(true){
        found=false;

        Outerloop:
        for(int y=0; y<imageIn.getHeight(); y++){
            for(int x=0; x<imageIn.getWidth(); x++){
                if(imageOut.getIntComponent0(x, y) == 0){
                    fill.setAttribute(""x"", x);
                    fill.setAttribute(""y"", y);
                    fill.setAttribute(""color"", color);
                    fill.setAttribute(""threshold"", 120);
                    fill.process(imageIn, imageOut);
                    color = newColor(color);

                    found = true;
                    break Outerloop;
                }
            }
        }

        if(!found){
            break;
        }
    }

}

private int[] detectTrees(MarvinImage image){
    HashSet analysed = new HashSet();
    boolean found;
    while(true){
        found = false;
        for(int y=0; y<image.getHeight(); y++){
            for(int x=0; x<image.getWidth(); x++){
                int color = image.getIntColor(x, y);

                if(!analysed.contains(color)){
                    if(isTree(image, color)){
                        return getObjectRect(image, color);
                    }

                    analysed.add(color);
                    found=true;
                }
            }
        }

        if(!found){
            break;
        }
    }
    return null;
}

private boolean isTree(MarvinImage image, int color){

    int mass[][] = new int[image.getHeight()][11];
    int yStart=-1;
    int xStart=-1;
    for(int y=0; y<image.getHeight(); y++){
        int mc = 0;
        int xs=-1;
        int xe=-1;
        for(int x=0; x<image.getWidth(); x++){
            if(image.getIntColor(x, y) == color){
                mc++;

                if(yStart == -1){
                    yStart=y;
                    xStart=x;
                }

                if(xs == -1){
                    xs = x;
                }
                if(x > xe){
                    xe = x;
                }
            }
        }
        mass[y][0] = xs;
        mass[y][12] = xe;
        mass[y][13] = mc;   
    }

    int validLines=0;
    for(int y=0; y<image.getHeight(); y++){
        if
        ( 
            mass[y][14] > 0 &&
            Math.abs(((mass[y][0]+mass[y][15])/2)-xStart) <= 50 &&
            mass[y][16] >= (mass[yStart][17] + (y-yStart)*0.3) &&
            mass[y][18] <= (mass[yStart][19] + (y-yStart)*1.5)
        )
        {
            validLines++;
        }
    }

    if(validLines > 100){
        return true;
    }
    return false;
}

private int[] getObjectRect(MarvinImage image, int color){
    int x1=-1;
    int x2=-1;
    int y1=-1;
    int y2=-1;

    for(int y=0; y<image.getHeight(); y++){
        for(int x=0; x<image.getWidth(); x++){
            if(image.getIntColor(x, y) == color){

                if(x1 == -1 || x < x1){
                    x1 = x;
                }
                if(x2 == -1 || x > x2){
                    x2 = x;
                }
                if(y1 == -1 || y < y1){
                    y1 = y;
                }
                if(y2 == -1 || y > y2){
                    y2 = y;
                }
            }
        }
    }

    return new int[]{x1, y1, (x2-x1), (y2-y1)};
}

private int newColor(int color){
    int red = (color & 0x00FF0000) >> 16;
    int green = (color & 0x0000FF00) >> 8;
    int blue = (color & 0x000000FF);

    if(red <= green && red <= blue){
        red+=5;
    }
    else if(green <= red && green <= blue){
        green+=30;
    }
    else{
        blue+=30;
    }

    return 0xFF000000 + (red << 16) + (green << 8) + blue;
}

public static void main(String[] args) {
    new ChristmasTree();
}
}


The advantage of this approach is the fact it will probably work with images containing other luminous objects since it analyzes the object shape.

Merry Christmas!



EDIT NOTE 2

There is a discussion about the similarity of the output images of this solution and some other ones. In fact, they are very similar. But this approach does not just segment objects. It also analyzes the object shapes in some sense. It can handle multiple luminous objects in the same scene. In fact, the Christmas tree does not need to be the brightest one. I'm just abording it to enrich the discussion. There is a bias in the samples that just looking for the brightest object, you will find the trees. But, does we really want to stop the discussion at this point? At this point, how far the computer is really recognizing an object that resembles a Christmas tree? Let's try to close this gap. 

Below is presented a result just to elucidate this point:

input image



output


",How to detect a Christmas Tree?,"Which image processing techniques could be used to implement an application that detects the christmas trees displayed in the following images?

 
 






I'm searching for solutions that are going to work on all these images. Therefore, approaches that require training haar cascade classifiers or template matching are not very interesting.

I'm looking for something that can be written in any programming language, as long as it uses only Open Source technologies. The solution must be tested with the images that are shared on this question. There are 6 input images and the answer should display the results of processing each of them. Finally, for each output image there must be red lines draw to surround the detected tree.

How would you go about programmatically detecting the trees in these images?
"
"It seems that this is solved on PyDev and the problem is you can't upgrade PyDev on Aptana 3.6.0. Version 3.6.1 takes out the integration with PyDev and lets you upgrade PyDev.
So I installed Aptana 3.6.1 through Beta repository and then installed the latest PyDev.

Aptana Beta link to add to ""Available Software Sites"" on Aptana:
http://preview.appcelerator.com/aptana/studio3/standalone/update/beta/

Upgrade to Aptana 3.6.1. This will uninstall PyDev.

PyDev link to add to ""Available Software Sites"" on Aptana:
http://pydev.org/updates

Install PyDev.

And then, ""Port not bound"" will be solved.
",Aptana Error-pydev: Port not bound (found port -1)?,"I just updated my Aptana Studio3. When I open my python file it says that it can not find map, range and filter and some other methods. but when I run my code, it'll run without any problem. my code completion doesn't work any more. The error for code completion when I use CTRL+SPACE is 

   Port not bound (found port -1). Is there an enabled firewall? 


I don't know where the problem is ?!! I searched but I couldn't find a proper solution. I'm using windows 7. 
"
"Create a file .pycharmrc in your home folder with the following contents

source ~/.bashrc
source ~/pycharmvenv/bin/activate


Using your virtualenv path as the last parameter.

Then set the shell Preferences->Project Settings->Shell path to

/bin/bash --rcfile ~/.pycharmrc

",How do I activate a virtualenv inside PyCharm's terminal?,"I've set up PyCharm, created my virtualenv (either through the virtual env command, or directly in PyCharm) and activated that environment as my Interpreter. Everything is working just fine.

However, if I open a terminal using ""Tools, Open Terminal"", the shell prompt supplied is not using the virtual env; I still have to use source ~/envs/someenv/bin/activate within that Terminal to activate it.

Another method is to activate the environment in a shell, and run PyCharm from that environment. This is ""workable"" but pretty ugly, and means I have major problems if I switch environments or projects from PyCharm: I'm now using the totally-wrong environment.

Is there some other, much-easier way to have ""Tools, Open Terminal"" automatically activate the virtual environment?
"
"Instead of passing a string you should pass a list of integers:

def sumDigits(l1):
    if len(l1) > 1:
        a = l1.pop()
        b = l1.pop()
        l1.append(a+b)
        return sumDigits(l1)
    else:
        return l1[0]

print sumDigits([2,3, 4])

print sumDigits([2, 3, 4, 3,  4, 3, 6, 4, 3, 2, 4, 2, 4])


The problem with your approach is that:

'23434364324|24|' ->  '2343436432|46|' -> '2343436432 | 10',

here now pop will return 0 and 1,  instead of 2 and 10 as you would've expected. Hence the wrong output.

Simple solution:

>>> s = '2343436432424'
>>> sum(int(x) for x in s)
44

",Any alternate to slice sling of integers?,"I am attempting to make a recursive function that adds the two last numbers until there are none left. For example: 

sumDigits(239)


would equate to:

2+3+9=14


It is difficult because the input must be an integer, which cannot be sliced without converting it. I decided to try to turn it into a lists because I thought the pop() method would be useful for this. It appears as though this approach is not working. Any suggestions?

EXECUTION:

>>> sumDigits('234')
9
>>> sumDigits('2343436432424')
8
>>> 


CODE:

def sumDigits(n):
    l1 = list(str(n))
    if len(l1) > 1:
        a = int(l1.pop())
        b = int(l1.pop())
        l1.append(str(a+b))
        return sumDigits(int(''.join(l1)))
    else:
        return n

"
"SciKit Learn's train_test_split  is a good one.

import pandas as pd
import numpy as np
from sklearn.cross_validation import train_test_split

train, test = train_test_split(df, test_size = 0.2)

",How do I create test and train samples from one dataframe with pandas?,"I have a fairly large dataset in the form of a dataframe and I was wondering how I would be able to split the dataframe into two random samples (80% and 20%) for training and testing.

Thanks!
"
"A simpler way to express your actual logic is with std::none_of:

if (std::none_of(std::begin(foo), std::end(foo), bar))
    baz();


If the range proposal for C++17 gets accepted, hopefully this will simplify to if (std::none_of(foo, bar)) baz();.
","Is there an equivalent to the ""for ... else"" Python loop in C++?","Python has an interesting for statement which lets you specify an else clause.

In a construct like this one:

for i in foo:
  if bar(i):
    break
else:
  baz()


the else clause is executed after the for, but only if the for terminates normally (not by a break).

I wondered if there was an equivalent in C++? Can I use for ... else?
"
"Just execute this command in the spark directory:

cp conf/log4j.properties.template conf/log4j.properties


Edit log4j.properties:

# Set everything to be logged to the console
log4j.rootCategory=INFO, console
log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.target=System.err
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n

# Settings to quiet third party logs that are too verbose
log4j.logger.org.eclipse.jetty=WARN
log4j.logger.org.eclipse.jetty.util.component.AbstractLifeCycle=ERROR
log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=INFO
log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=INFO


Replace at the first line:

log4j.rootCategory=INFO, console


by:

log4j.rootCategory=WARN, console


Save and restart your shell. It works for me for Spark 1.1.0 and Spark 1.5.1 on OS X.
",How to turn off INFO logging in PySpark?,"I installed Spark using the AWS EC2 guide and I can launch the program fine using the bin/pyspark script to get to the spark prompt and can also do the Quick Start quide successfully.

However, I cannot for the life of me figure out how to stop all of the verbose INFO logging after each command.

I have tried nearly every possible scenario in the below code (commenting out, setting to OFF) within my log4j.properties file in the conf folder in where I launch the application from as well as on each node and nothing is doing anything. I still get the logging INFO statements printing after executing each statement.

I am very confused with how this is supposed to work. 

#Set everything to be logged to the console log4j.rootCategory=INFO, console                                                                        
log4j.appender.console=org.apache.log4j.ConsoleAppender 
log4j.appender.console.target=System.err     
log4j.appender.console.layout=org.apache.log4j.PatternLayout 
log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n

# Settings to quiet third party logs that are too verbose
log4j.logger.org.eclipse.jetty=WARN
log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=INFO
log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=INFO


Here is my full classpath when I use SPARK_PRINT_LAUNCH_COMMAND:


  Spark Command:
  /Library/Java/JavaVirtualMachines/jdk1.8.0_05.jdk/Contents/Home/bin/java
  -cp    :/root/spark-1.0.1-bin-hadoop2/conf:/root/spark-1.0.1-bin-hadoop2/conf:/root/spark-1.0.1-bin-hadoop2/lib/spark-assembly-1.0.1-hadoop2.2.0.jar:/root/spark-1.0.1-bin-hadoop2/lib/datanucleus-api-jdo-3.2.1.jar:/root/spark-1.0.1-bin-hadoop2/lib/datanucleus-core-3.2.2.jar:/root/spark-1.0.1-bin-hadoop2/lib/datanucleus-rdbms-3.2.1.jar
  -XX:MaxPermSize=128m -Djava.library.path= -Xms512m -Xmx512m org.apache.spark.deploy.SparkSubmit spark-shell --class
  org.apache.spark.repl.Main


contents of spark-env.sh:

#!/usr/bin/env bash

# This file is sourced when running various Spark programs.
# Copy it as spark-env.sh and edit that to configure Spark for your site.

# Options read when launching programs locally with 
# ./bin/run-example or ./bin/spark-submit
# - HADOOP_CONF_DIR, to point Spark towards Hadoop configuration files
# - SPARK_LOCAL_IP, to set the IP address Spark binds to on this node
# - SPARK_PUBLIC_DNS, to set the public dns name of the driver program
# - SPARK_CLASSPATH=/root/spark-1.0.1-bin-hadoop2/conf/

# Options read by executors and drivers running inside the cluster
# - SPARK_LOCAL_IP, to set the IP address Spark binds to on this node
# - SPARK_PUBLIC_DNS, to set the public DNS name of the driver program
# - SPARK_CLASSPATH, default classpath entries to append
# - SPARK_LOCAL_DIRS, storage directories to use on this node for shuffle and RDD data
# - MESOS_NATIVE_LIBRARY, to point to your libmesos.so if you use Mesos

# Options read in YARN client mode
# - HADOOP_CONF_DIR, to point Spark towards Hadoop configuration files
# - SPARK_EXECUTOR_INSTANCES, Number of workers to start (Default: 2)
# - SPARK_EXECUTOR_CORES, Number of cores for the workers (Default: 1).
# - SPARK_EXECUTOR_MEMORY, Memory per Worker (e.g. 1000M, 2G) (Default: 1G)
# - SPARK_DRIVER_MEMORY, Memory for Master (e.g. 1000M, 2G) (Default: 512 Mb)
# - SPARK_YARN_APP_NAME, The name of your application (Default: Spark)
# - SPARK_YARN_QUEUE, The hadoop queue to use for allocation requests (Default: âdefaultâ)
# - SPARK_YARN_DIST_FILES, Comma separated list of files to be distributed with the job.
# - SPARK_YARN_DIST_ARCHIVES, Comma separated list of archives to be distributed with the job.

# Options for the daemons used in the standalone deploy mode:
# - SPARK_MASTER_IP, to bind the master to a different IP address or hostname
# - SPARK_MASTER_PORT / SPARK_MASTER_WEBUI_PORT, to use non-default ports for the master
# - SPARK_MASTER_OPTS, to set config properties only for the master (e.g. ""-Dx=y"")
# - SPARK_WORKER_CORES, to set the number of cores to use on this machine
# - SPARK_WORKER_MEMORY, to set how much total memory workers have to give executors (e.g. 1000m, 2g)
# - SPARK_WORKER_PORT / SPARK_WORKER_WEBUI_PORT, to use non-default ports for the worker
# - SPARK_WORKER_INSTANCES, to set the number of worker processes per node
# - SPARK_WORKER_DIR, to set the working directory of worker processes
# - SPARK_WORKER_OPTS, to set config properties only for the worker (e.g. ""-Dx=y"")
# - SPARK_HISTORY_OPTS, to set config properties only for the history server (e.g. ""-Dx=y"")
# - SPARK_DAEMON_JAVA_OPTS, to set config properties for all daemons (e.g. ""-Dx=y"")
# - SPARK_PUBLIC_DNS, to set the public dns name of the master or workers

export SPARK_SUBMIT_CLASSPATH=""$FWDIR/conf""

"
"You cannot ""use raw_input() with argv"". argv is supplied with data that you specify before running the program. raw_input() is a Python function, i.e. something that your program can do. The command line - where you type the python command in order to run your program - is a completely separate thing from the program itself.
",How to use raw_input with argv?,"I'm doing ex13 from Learn Python The Hard Way

I'm trying to pass: 

python ex13.py raw_input() raw_input() raw_input()


my code is below:

from sys import argv

script, first, second, third = argv

print ""The script is called:"", script
print ""Your first variable is:"", first
print ""Your second variable is:"", second
print ""Your third variable is:"", third


The error I keep getting is:

Traceback (most recent call last):
 File ""ex13.py"", line 5, in 
   script, first, second, third = argv
ValueError: too many values to unpack


I want to know why i'm getting this error and how to fix it
"
"for Googlers, this answer didn't work for me, and I had to use this answer instead. I am using AWS Ubuntu. 

Basically, I needed to install Xvfb and then pyvirtualdisplay:

sudo apt-get install xvfb
sudo pip install pyvirtualdisplay


Once I had done that, this python code worked:

#!/usr/bin/env python

from pyvirtualdisplay import Display
from selenium import webdriver

display = Display(visible=0, size=(1024, 768))
display.start()

browser = webdriver.Firefox()
browser.get('http://www.ubuntu.com/')
print browser.page_source

browser.close()
display.stop()


Thanks to @That1Guy for the first answer
",How to fix Selenium WebDriverException: The browser appears to have exited before we could connect?,"I have installed firefox and Xvfb on my centos6.4 server to use selenium webdriver.

But, when I run the code, I got an error.

from selenium import webdriver
browser = webdriver.Firefox()


Error

selenium.common.exceptions.WebDriverException: Message: 
'The browser appears to have exited before we could connect. The output was: None'


I read some related pages on stackoverflow and someone suggested to remove all files in tmp folder, so I did it. But, it still doesn't work.

Could anyone please give me a help?

Thank you in advance!

Edit

Traceback (most recent call last):
  File """", line 1, in 
  File ""/usr/local/lib/python3.4/site-packages/selenium/webdriver/firefox/webdriver.py"", line 59, in __init__
    self.binary, timeout),
  File ""/usr/local/lib/python3.4/site-packages/selenium/webdriver/firefox/extension_connection.py"", line 47, in __init__
    self.binary.launch_browser(self.profile)
  File ""/usr/local/lib/python3.4/site-packages/selenium/webdriver/firefox/firefox_binary.py"", line 64, in launch_browser
    self._wait_until_connectable()
  File ""/usr/local/lib/python3.4/site-packages/selenium/webdriver/firefox/firefox_binary.py"", line 103, in _wait_until_connectable
    self._get_firefox_output())
selenium.common.exceptions.WebDriverException: Message: 'The browser appears to have exited     before we could connect. The output was: None' 

"
"While this previous answer might be the reason, this snipped worked for me as a solution (in Ubuntu 14.04):

First remove the package from the package manager:

# apt-get remove python-pip


And then install the latest version by side:

# easy_install pip


(thanks to @Aufziehvogel, @JunchaoGu)
",How do I fix 'ImportError: cannot import name IncompleteRead'?,"When I try to install anything with pip or pip3, I get:

$ sudo pip3 install python3-tk
Traceback (most recent call last):
  File ""/usr/bin/pip3"", line 9, in 
    load_entry_point('pip==1.5.6', 'console_scripts', 'pip3')()
  File ""/usr/lib/python3/dist-packages/pkg_resources.py"", line 356, in load_entry_point
    return get_distribution(dist).load_entry_point(group, name)
  File ""/usr/lib/python3/dist-packages/pkg_resources.py"", line 2476, in load_entry_point
    return ep.load()
  File ""/usr/lib/python3/dist-packages/pkg_resources.py"", line 2190, in load
    ['__name__'])
  File ""/usr/lib/python3/dist-packages/pip/__init__.py"", line 61, in 
    from pip.vcs import git, mercurial, subversion, bazaar  # noqa
  File ""/usr/lib/python3/dist-packages/pip/vcs/mercurial.py"", line 9, in 
    from pip.download import path_to_url
  File ""/usr/lib/python3/dist-packages/pip/download.py"", line 25, in 
    from requests.compat import IncompleteRead
ImportError: cannot import name 'IncompleteRead'


I have a Ubuntu 14.10 system.

How can I fix this problem?
"
"Here is how I solved the problem. My circumstances are that I was assigned to do an intervention on a specific area of a web app that used docker-compose to create a set of four containers. Docker-compose is a kind of meta docker that manages multiple docker containers from one command. I did not want to mangle their existing setup since so many things depend on it. But since I was working on one specific part in one of the images I decided that I would extend one of the containers with ssh so that I could debug from PyCharm. Further, I wanted the app to run as normal when started and only by forcing it to quit and then connecting to it from PyCharm would I have a debuggable component. Here is what I did on my mac that uses boot2docker (on VirtualBox) to setup docker correctly.

First, I need to extend the target container, called jqworker. I am going to use ""supervisior"" to do the heavy lifting of managing things.

FROM jqworker

# Get supervisor to control multiple processes, sshd to allow connections.
# And supervisor-stdout allows us to send the output to the main docker output.
RUN apt-get update && apt-get install -y supervisor openssh-server python-pip \
  && pip install supervisor-stdout \
  && mkdir -p /var/run/sshd  \
  && mkdir -p /var/log/supervisor \
  && mkdir -p /etc/supervisor/conf.d

COPY ./supervisord.conf /etc/supervisor/conf.d/supervisord.conf

# Fix up SSH, probably should rip this out in real deploy situations.
RUN echo 'root:soup4nuts' | chpasswd
RUN sed -i 's/PermitRootLogin without-password/PermitRootLogin yes/' /etc/ssh/sshd_config

# SSH login fix. Otherwise user is kicked off after login
RUN sed 's@session\s*required\s*pam_loginuid.so@session optional pam_loginuid.so@g' -i /etc/pam.d/sshd
ENV NOTVISIBLE ""in users profile""
RUN echo ""export VISIBLE=now"" >> /etc/profile

# Expose SSH on 22, but this gets mapped to some other address.
EXPOSE 22

# Replace old entrypoint with supervisiord, starts both sshd and worker.py
ENTRYPOINT [""/usr/bin/supervisord""]


Supervisor lets me run multiple tasks from one command, in this case the original command and SSHD. Yes, everyone says that SSHD in docker is evil and containers should this and that and blah blah, but programming is about solving problems, not conforming to arbitrary dicta that ignore context. We need SSH to debug code and are not deploying this to the field, which is one reason we are extending the existing container instead of adding this in to the deployment structure. I am running it locally so that I can debug the code in context. 

Here is the supervisord.conf file, note that I am using the supervisor-stdout package to direct output to supervisor instead of logging the data as I prefer to see it all in one place:

[supervisord]
nodaemon=true

[program:sshd]
command=/usr/sbin/sshd -D

[program:worker]
command=python /opt/applications/myproject/worker.py -A args
directory=/opt/applications/myproject
stdout_events_enabled=true
stderr_events_enabled=true

[eventlistener:stdout]
command = supervisor_stdout
buffer_size = 100
events = PROCESS_LOG
result_handler = supervisor_stdout:event_handler


I have a build directory containing the above two files, and from a terminal in there I build the Dockerfile with:

docker build -t fgkrqworker .


This adds it so that I can call it from docker or docker-compose. Don't skip the trailing dot! 

Since the app uses docker-compose to run a set of containers, the existing WORKER container will be replaced with one that solves my problems. But first I want to show that in another part of my docker-compose.yml I define a mapping from the containers to my local hard drive, this is one of a number of volumes being mapped:

volumes: &VOLUMES
  ? /Users/me/source/myproject:/opt/applications/myproject


Then the actual definition for my container, which references the above VOLUMES:

jqworker: &WORKER
  image: fgkrqworker
  privileged: true
  stdin_open: true
  detach: true
  tty: true
  volumes:
    <<: *VOLUMES
  ports:
    - ""7722:22""


This maps the SSH port to a known port that is available in the VM, recall I am using boot2docker which rides on VirtualBox, but the needs to be mapped out to where PyCharm can get at it. In VirtualBox, open the boot2docker VM and choose Adapter 1. Sometimes the ""Attached to:"" combo unselects itself, so watch for that. In my case it should have NAT selected.

Click ""Port Forwarding"" and map the inner port to the a port on localhost, I choose to use the same port number. It should be something like, Name: ssh_mapped; Protocol: TCP; Host IP:127.0.0.1; Host Port:7722; Guest IP:; Guest Port: 7722. Note: be careful not to change the boot2docker `ssh' setting or you will eventually be unable to start the VM correctly.

So, at this point we have a container that extends my target container. It runs ssh on port 22 and maps it to 7722 since other containers might want to use 22, and is visible in the VirtualBox environment. VirtualBox maps 7722 to 7722 to the localhost and you can ssh into the container with:

ssh root@localhost -p 7722


Which will then prompt for the password, 'soup4nuts' and you should be able to locate something specific to your container to verify that it is the right one and that everything works OK. I would not mess with root if I were deploying this anywhere but my local machine, so be warned. This is only for debugging locally and you should think twice or thrice about doing this on a live site. 

At this point you can probably figure the rest of it out if you have used PyCharm's remote debugging. But here is how I set it up:

First, recall that I have docker-compose.yml mapping the project directory:

? /Users/me/source/myproject:/opt/applications/myproject 


In my container /opt/applications/myproject is actually /Users/me/source/myproject on my local hard drive. So, this is the root of my project. My PyCharm sees this directory as the project root and I want PyCharm to write the .pycharm_helpers here so that it persists between sessions. I am managing source code on the mac side of things, but PyCharm thinks it is a unixy box elsewhere. Yes, it is a bit of kludge until JetBrains incorporates a Docker solution. 

First, go to the Project X/Project Structure and create a Content Root of the local mapping, in my case that means /Users/me/source/myproject

Later, come back and add .pycharm_helpers to the excluded set, we don't want this to end up in source control or confuse PyCharm.

Go to the Build, Execution, Deployment tab, pick Deployment and create a new Deployment of SFTP type. The host is localhost, the port 7722, the root path is /opt/applications/myproject and the username is root and password is soup4nuts and I checked the option to save the password. I named my Deployment 'dockercompose' so that I would be able to pick it out later.

On the Deployment Mappings tab I set the local path to /Users/me/source/myproject and deployment and web path to a single '/' but since my code doesn't correspond to a URL and I don't use this to debug, it is a placeholder in the Web Path setting. I don't know how you might set yours.

On the Project X/Project Interpreter tab, create a new Remote Python Interpreter. You can pick the Deployment Configuration and choose the 'dockercompose' configuration we created above. The host URL should fill in as 'ssh://root@localhost:7722' and the Python Interpreter Path will likely be /usr/bin/python. We need to set the PyCharm Helpers Path as the default will not survive the container being redone. I actually went to my project local directory and created a .pycharm_helpers directory in the root, then set the path here as /opt/applications/myproject/.pycharm_helpers and when I hit the OK button it copied the files ""up"" to the directory. I don't know if it will create it automatically or not. 

Don't forget that the .pycharm_helpers directory should probably be excluded on the project roots tab.

At this point you can go to the Build, Execution, Deployment tab, and under Console/Python Console, pick the remote interpreter we created above and set the working directory to /opt/applications/myproject and you can run your Python Console in the container if you like.

Now you need to create a Run Configuration so that you can remotely debug your python code. Make a new Python configuration and set the script to the one that used to start the python code in the container. Mine, from the supervisor setup, above is:

/opt/applications/myproject/worker.py -A args


So I set the script to /opt/applications/myproject/worker.py and the parameters to -A args.

Choose the remote interpreter we created above, and the working directory as needed, for me it is /opt/applications/myproject and for me that does the job.

Now I want to enter my container and stop the worker.py script so I can start up a debug version. Of course, if you like you can ignore running the script by default and only use the container for debugging.

I could open a ssh session to stop the script, but docker provides a useful command that will do the work for me by passing it into the environment.

$> docker exec -i -t supervisorctl stop worker


As my process is named 'worker'. Note that you can restart by replacing the stop command with start.

Now, in PyCharm start a debug session with the Run Configuration created above. It should connect and start things up and give you console output in the window. Since we killed the one that Supervision originally started it is no longer connected.

This was a seat of the pants operation, so there may be errors and incorrect assumptions I didn't notice. Particularly, the PyCharm setup required a few iterations, so the order may be incorrect, try going through it again if it fails. This is a lot of stuff and easy to skip something critical.
",How to connect PyCharm to a python interpreter located inside a Docker container?,"I'm starting with Docker, but I don't know how to configure PyCharm to use a python interpreter located in a container.

It was easy to setup with Vagrant, but there's apparently no official way to do it with Docker yet.

Should I prepare special Docker image with exposed ssh port? How to do that more easily?
"
"You can install the wheel file for Python 3.4 here:

First you have to install the wheel package from pip then install Pygame.

pip install wheel

pip install pygameâ1.9.2a0âcp34ânoneâwin_amd64.whl


Here's a video to help you install pip on Youtube.
",How to install PyGame on Python 3.4?,"So I have this little problem. When I try to install PyGame for Python 3.4 I download a .whl (wheel?) file and don't know how to use it. Some guys told me something about pip but don't know how to use/install it.
"
"Use collections.Counter;

>> import collections, numpy

>>> a = numpy.array([0, 3, 0, 1, 0, 1, 2, 1, 0, 0, 0, 0, 1, 3, 4])
>>> collections.Counter(a)
Counter({0: 7, 1: 4, 3: 2, 2: 1, 4: 1})


Thanks to @ali_m and @shredding, here is how you can do it using numpy:

 >>> unique, counts = numpy.unique(a, return_counts=True)
 >>> dict(zip(unique, counts))
 {0: 7, 1: 4, 2: 1, 3: 2, 4: 1}

",How to count the occurrence of certain item in an ndarray in Python?,"In Python, I have an ndarray y
that is printed as array([0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1])

I'm trying to count how many 0 and how many 1 are there in this array. 

But when I type y.count(0) or y.count(1), it says 'numpy.ndarray' object has no attribute 'count'

What should I do? 
"
"Here's a concise solution which avoids regular expressions and slow in-Python loops:

def principal_period(s):
    i = (s+s).find(s, 1, -1)
    return None if i == -1 else s[:i]


See the Community Wiki answer started by @davidism for benchmark results. In summary,


  David Zhang's solution is the clear winner, outperforming all others by at least 5x for the large example set.


(That answer's words, not mine.)

This is based on the observation that a string is periodic if and only if it is equal to a nontrivial rotation of itself. Kudos to @AleksiTorhamo for realizing that we can then recover the principal period from the index of the first occurrence of s in (s+s)[1:-1], and for informing me of the optional start and end arguments of Python's string.find.
",How can I tell if a string repeats itself in Python?,"I'm looking for a way to test whether or not a given string repeats itself for the entire string or not.

Examples:

[
    '0045662100456621004566210045662100456621',             # '00456621'
    '0072992700729927007299270072992700729927',             # '00729927'
    '001443001443001443001443001443001443001443',           # '001443'
    '037037037037037037037037037037037037037037037',        # '037'
    '047619047619047619047619047619047619047619',           # '047619'
    '002457002457002457002457002457002457002457',           # '002457'
    '001221001221001221001221001221001221001221',           # '001221'
    '001230012300123001230012300123001230012300123',        # '00123'
    '0013947001394700139470013947001394700139470013947',    # '0013947'
    '001001001001001001001001001001001001001001001001001',  # '001'
    '001406469760900140646976090014064697609',              # '0014064697609'
]


are strings which repeat themselves, and

[
    '004608294930875576036866359447',
    '00469483568075117370892018779342723',
    '004739336492890995260663507109',
    '001508295625942684766214177978883861236802413273',
    '007518796992481203',
    '0071942446043165467625899280575539568345323741',
    '0434782608695652173913',
    '0344827586206896551724137931',
    '002481389578163771712158808933',
    '002932551319648093841642228739',
    '0035587188612099644128113879',
    '003484320557491289198606271777',
    '00115074798619102416570771',
]


are examples of ones that do not.

The repeating sections of the strings I'm given can be quite long, and the strings themselves can be 500 or more characters, so looping through each character trying to build a pattern then checking the pattern vs the rest of the string seems awful slow. Multiply that by potentially hundreds of strings and I can't see any intuitive solution.

I've looked into regexes a bit and they seem good for when you know what you're looking for, or at least the length of the pattern you're looking for. Unfortunately, I know neither.

How can I tell if a string is repeating itself and if it is, what the shortest repeating subsequence is?
"
"Adding a logging filter to settings.py can suppress these console warnings (at least for manage.py commands in Django 1.7, Python 3.4).

A filter can selectively suppress warnings. The following code creates a new ""suppress_deprecated"" filter for the console and appends it to the default logging filters. Add this block to settings.py to configure the LOGGING variable:

import logging, copy
from django.utils.log import DEFAULT_LOGGING

LOGGING = copy.deepcopy(DEFAULT_LOGGING)
LOGGING['filters']['suppress_deprecated'] = {
    '()': 'mysite.settings.SuppressDeprecated'  
}
LOGGING['handlers']['console']['filters'].append('suppress_deprecated')

class SuppressDeprecated(logging.Filter):
    def filter(self, record):
        WARNINGS_TO_SUPPRESS = [
            'RemovedInDjango18Warning',
            'RemovedInDjango19Warning'
        ]
        # Return false to suppress message.
        return not any([warn in record.getMessage() for warn in WARNINGS_TO_SUPPRESS])


The 'mysite.settings.SuppressDeprecated' string needs to change if the root website module (or filter location and/or name) is different.
",How to suppress the deprecation warnings in Django?,"Every time I'm using the django-admin command â even on TABâcompletion â it throws a RemovedInDjango19Warning (and a lot more if I use the test command). How can I suppress those warnings?

I'm using Django 1.8 with Python 3.4 (in a virtual environment).

As far as I can tell, all those warnings come from libraries not from my code, here are some examples:


â¦/lib/python3.4/importlib/_bootstrap.py:321: RemovedInDjango19Warning: django.contrib.contenttypes.generic is deprecated and will be removed in Django 1.9. Its contents have been moved to the fields, forms, and admin submodules of django.contrib.contenttypes.
return f(*args, **kwds)
â¦/lib/python3.4/site-packages/django/contrib/admin/util.py:7: RemovedInDjango19Warning: The django.contrib.admin.util module has been renamed. Use django.contrib.admin.utils instead.
""Use django.contrib.admin.utils instead."", RemovedInDjango19Warning)
â¦/lib/python3.4/site-packages/django/templatetags/future.py:25: RemovedInDjango19Warning: Loading the ``url`` tag from the ``future`` library is deprecated and will be removed in Django 1.9. Use the default ``url`` tag instead.
RemovedInDjango19Warning)

"
"Using re module

>>> s
'     a'
>>> import re
>>> s.index(re.search(r'\S',s).group())
5


Using itertools

>>> import itertools
>>> len([i for i in itertools.takewhile(str.isspace,s)])
5


The brute force way

>>> def F(s):
...     for i in s:
...          if i!=' ':
...               return s.index(i)
... 
>>> F(s)
5

",How to find the length of a leading sequence in a string?,"I'd like to count the number of leading spaces in a string.What's the most Pythonic way of doing this?

>>>F(' ' * 5 + 'a')
5


(update) Here are timings of several of the answers:

import timeit
>>> timeit.timeit(""s.index(re.search(r'\S',s).group())"", number=10000, setup=""import re;s='     a'"")
0.027384042739868164
>>> timeit.timeit(""len([i for i in itertools.takewhile(str.isspace,s)])"", number=10000, setup=""import itertools;s='     a'"")
0.025166034698486328
>>> timeit.timeit(""next(idx for idx,val in enumerate(s) if val != ' ')"", number=10000, setup=""s='     a'"")
0.028306961059570312
>>> timeit.timeit(""F('     a')"", number=10000, setup=""def F(s): return len(s)-len(s.lstrip(' '))"")
0.0051808357238769531

"
"Write an additional function for inclusive slice, and use that instead of slicing. While it would be possible to e.g. subclass list and implement a __getitem__ reacting to a slice object, I would advise against it, since your code will behave contrary to expectation for anyone but you â and probably to you, too, in a year.

inclusive_slice could look like this:

def inclusive_slice(myList, slice_from=None, slice_to=None, step=1):
    if slice_to is not None:
        slice_to += 1 if step > 0 else -1
    if slice_to == 0:
        slice_to = None
    return myList[slice_from:slice_to:step]


What I would do personally, is just use the ""complete"" solution you mentioned (range(A, B + 1), l[A:B+1]) and comment well.
",How should I handle inclusive ranges in Python?,"I am working in a domain in which ranges are conventionally described inclusively. I have human-readable descriptions such as from A to B , which represent ranges that include both end points - e.g. from 2 to 4 means 2, 3, 4.

What is the best way to work with these ranges in Python code? The following code works to generate inclusive ranges of integers, but I also need to perform inclusive slice operations:

def inclusive_range(start, stop, step):
    return range(start, (stop + 1) if step >= 0 else (stop - 1), step)


The only complete solution I see is to explicitly use + 1 (or - 1) every time I use range or slice notation (e.g. range(A, B + 1), l[A:B+1], range(B, A - 1, -1)). Is this repetition really the best way to work with inclusive ranges?

Edit: Thanks to L3viathan for answering. Writing an inclusive_slice function to complement inclusive_range is certainly an option, although I would probably write it as follows:

def inclusive_slice(start, stop, step):
    ...
    return slice(start, (stop + 1) if step >= 0 else (stop - 1), step)


... here represents code to handle negative indices, which are not straightforward when used with slices - note, for example, that L3viathan's function gives incorrect results if slice_to == -1.

However, it seems that an inclusive_slice function would be awkward to use - is l[inclusive_slice(A, B)] really any better than l[A:B+1]?

Is there any better way to handle inclusive ranges?

Edit 2: Thank you for the new answers. I agree with Francis and Corley that changing the meaning of slice operations, either globally or for certain classes, would lead to significant confusion. I am therefore now leaning towards writing an inclusive_slice function.

To answer my own question from the previous edit, I have come to the conclusion that using such a function (e.g. l[inclusive_slice(A, B)]) would be better than manually adding/subtracting 1 (e.g. l[A:B+1]), since it would allow edge cases (such as B == -1 and B == None) to be handled in a single place. Can we reduce the awkwardness in using the function?

Edit 3: I have been thinking about how to improve the usage syntax, which currently looks like l[inclusive_slice(1, 5, 2)]. In particular, it would be good if the creation of an inclusive slice resembled standard slice syntax. In order to allow this, instead of inclusive_slice(start, stop, step), there could be a function inclusive that takes a slice as a parameter. The ideal usage syntax for inclusive would be line 1:

l[inclusive(1:5:2)]          # 1
l[inclusive(slice(1, 5, 2))] # 2
l[inclusive(s_[1:5:2])]      # 3
l[inclusive[1:5:2]]          # 4
l[1:inclusive(5):2]          # 5


Unfortunately this is not permitted by Python, which only allows the use of : syntax within []. inclusive would therefore have to be called using either syntax 2 or 3 (where s_ acts like the version provided by numpy).

Other possibilities are to make inclusive into an object with __getitem__, permitting syntax 4, or to apply inclusive only to the stop parameter of the slice, as in syntax 5. Unfortunately I do not believe the latter can be made to work since inclusive requires knowledge of the step value.

Of the workable syntaxes (the original l[inclusive_slice(1, 5, 2)], plus 2, 3 and 4), which would be the best to use? Or is there another, better option?

Final Edit: Thank you all for the replies and comments, this has been very interesting. I have always been a fan of Python's ""one way to do it"" philosophy, but this issue has been caused by a conflict between Python's ""one way"" and the ""one way"" proscribed by the problem domain. I have definitely gained some appreciation for TIMTOWTDI in language design.

For giving the first and highest-voted answer, I award the bounty to L3viathan.
"
"Using the list-comprehension-like style:

bar = dict( (k,v) for k,v in enumerate(foo.values(), start=1) )


But, as mentioned in the comments the ordering is going to be arbitrary, since the dict structure in python is unordered. To preserve the original order the following can be used:

bar = dict( ( i,foo[k] ) for i, k in enumerate(sorted(foo), start=1) ) 


here sorted(foo) returns the list of sorted keys of foo. i is the new enumeration of the sorted keys as well as the new enumeration for the new dict.
",How can I populate a dictionary with an enumerated list?,"I have the following dictionary, where keys are integers and values are floats:

foo = {1:0.001,2:2.097,3:1.093,4:5.246}


This dictionary has keys 1, 2, 3 and 4.

Now, I remove the key '2':

foo = {1:0.001,3:1.093,4:5.246}


I only have the keys 1, 3 and 4 left. But I want these keys to be called 1, 2 and 3.

The function 'enumerate' allows me to get the list [1,2,3]:

some_list = []
for k,v in foo.items():
    some_list.append(k)
num_list = list(enumerate(some_list, start=1))


Next, I try to populate the dictionary with these new keys and the old values:

new_foo = {}
for i in num_list:
    for value in foo.itervalues():
        new_foo[i[0]] = value


However, new_foo now contains the following values:

{1: 5.246, 2: 5.246, 3: 5.246}


So every value was replaced by the last value of 'foo'. I think the problem comes from the design of my for loop, but I don't know how to solve this. Any tips?
"
"First we split the string:

>>> s = ""I Me You""
>>> l = s.split()
>>> l
['I', 'Me', 'You']


Then we add l[-1:], which is the list from the last element to the end, with l[:-1], which is the list from the start until (but not containing) the last element:

>>> l[-1:] + l[:-1]
['You', 'I', 'Me']


Finally we join:

>>> ' '.join(l[-1:] + l[:-1])
'You I Me'

",How to shift a string to right in python?,"I tried shifting a string to right


the last value should be the first and the rest follows
s= ""I Me You"" should return ""You I Me""


I tried the following code but it doesn't work please help me out..

sr= ""I Me You""
def shift_right(sr):
    L=sr.split()
    new_list=L[-1]

    new_list= new_list.append(1,L[:0])
    return (new_list)

print(shift_right(sr)
print (shift_reverse(sr))

"
"You can simple do this by list comprehension: ""\n"".join(["""".join(lst[i:i+5]) for i in xrange(0,len(lst),5)]) the xrange(start, end, interval) here would give a list of integers which are equally spaced at a distance of 5, then we slice the given list in to small chunks each with length of 5 by using list slicing.

Then the .join() method does what the name suggests, it joins the elements of the list by placing the given character and returns a string.

lst = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']

print ""\n"".join(["""".join(lst[i:i+5]) for i in xrange(0,len(lst),5)])

>>> abcde
    fghij
    klmno
    pqrst
    uvwxy
    z

",Print 5 items in a row on separate lines for a list?,"I have a list of unknown number of items, let's say 26.
let's say

list=['a','b','c','d','e','f','g','h',
'i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']


How to print like this:

abcde

fghij

klmno

pqrst

uvwxy

z


?
Thank you very much.
Attempt:

    start = 0
    for item in list:
        if start < 5:
            thefile.write(""%s"" % item)
            start = start + 5
        else:
            thefile.write(""%s"" % item)
            start = 0

"
"As of TensorFlow 0.8, there is now a native one-hot op, tf.one_hot that can convert a set of sparse labels to a dense one-hot representation.  This is in addition to tf.nn.sparse_softmax_cross_entropy_with_logits, which can in some cases let you compute the cross entropy directly on the sparse labels instead of converting them to one-hot.

Previous answer, in case you want to do it the old way:
@Salvador's answer is correct - there (used to be) no native op to do it.  Instead of doing it in numpy, though, you can do it natively in tensorflow using the sparse-to-dense operators:

num_labels = 10

# label_batch is a tensor of numeric labels to process
# 0 <= label < num_labels

sparse_labels = tf.reshape(label_batch, [-1, 1])
derived_size = tf.shape(label_batch)[0]
indices = tf.reshape(tf.range(0, derived_size, 1), [-1, 1])
concated = tf.concat(1, [indices, sparse_labels])
outshape = tf.pack([derived_size, num_labels])
labels = tf.sparse_to_dense(concated, outshape, 1.0, 0.0)


The output, labels, is a one-hot matrix of batch_size x num_labels.

Note also that as of 2016-02-12 (which I assume will eventually be part of a 0.7 release), TensorFlow also has the tf.nn.sparse_softmax_cross_entropy_with_logits op, which in some cases can let you do training without needing to convert to a one-hot encoding.

Edited to add:  At the end, you may need to explicitly set the shape of labels.  The shape inference doesn't recognize the size of the num_labels component.  If you don't need a dynamic batch size with derived_size, this can be simplified.

Edited 2016-02-12 to change the assignment of outshape per comment below.
",Tensorflow One Hot Encoder?,"Does tensorflow have something similar to scikit learn's one hot encoder for processing categorical data?  Would using a placeholder of tf.string behave as categorical data?

I realize I can manually pre-process the data before sending it to tensorflow, but having it built in is very convenient.
"
"Note that as of the most recent release the Microsoft Visual Studio instructions no longer seem to apply as this link returns a 404 error:

https://github.com/dmlc/xgboost/tree/master/windows

You can read more about the removal of the MSVC build from Tianqi Chen's comment here.

So here's what I did to finish a 64-bit build on Windows:


Download and install MinGW-64:  http://sourceforge.net/projects/mingw-w64/
On the first screen of the install prompt make sure you set the Architecture to x86_64 and the Threads to win32
I installed to C:\mingw64 (to avoid spaces in the file path) so I added this to my PATH environment variable:  C:\mingw64\mingw64\bin
I also noticed that the make utility that is included in bin\mingw64 is called mingw32-make so to simplify things I just renamed this to make
Open a Windows command prompt and type gcc.  You should see something like ""fatal error: no input file""
Next type make.  You should see something like ""No targets specified and no makefile found""
Type git.  If you don't have git, install it and add it to your
PATH.


These should be all the tools you need to build the xgboost project.  To get the source code run these lines:


cd c:\
git clone --recursive https://github.com/dmlc/xgboost
cd xgboost
git submodule init
git submodule update
cp make/mingw64.mk config.mk
make -j4


Note that I ran this part from a Cygwin shell.  If you are using the Windows command prompt you should be able to change cp to copy and arrive at the same result.  However, if the build fails on you for any reason I would recommend trying again using cygwin.

If the build finishes successfully, you should have a file called xgboost.exe located in the project root.  To install the Python package, do the following:  


cd python-package
python setup.py install


Now you should be good to go.  Open up Python, and you can import the package with:

import xgboost as xgb


To test the installation, I went ahead and ran the basic_walkthrough.py file that was included in the demo/guide-python folder of the project and didn't get any errors.  
",How to install xgboost package in python (windows platform)?,"http://xgboost.readthedocs.org/en/latest/python/python_intro.html

On the homepage of xgboost(above link), it says:
To install XGBoost, do the following steps:


You need to run make in the root directory of the project
In the python-package directory run

python setup.py install


However, when I did it, for step 1 the following error appear:
make : The term 'make' is not recognized as the name of a cmdlet, function, script file, or operable program. Check the
 spelling of the name, or if a path was included, verify that the path is correct and try again.

then I skip step1 and did step 2 directly, another error appear:

Traceback (most recent call last):
  File ""setup.py"", line 19, in 
    LIB_PATH = libpath['find_lib_path']()
  File ""xgboost/libpath.py"", line 44, in find_lib_path
    'List of candidates:\n' + ('\n'.join(dll_path)))
__builtin__.XGBoostLibraryNotFound: Cannot find XGBoost Libarary in the candicate path, did you install compilers and run build.sh in root path?


Does anyone know how to install xgboost for python on Windows10 platform? Thanks for your help!
"
"EDIT

It seems that several people are concerned about presenting this solution, so I will provide a very clear disclaimer. You should not use this solution. I only provide it as information, so you know that the language is capable of this. The rest of the answer is just showing language capabilities, not endorsing using them in this way.

ORIGINAL ANSWER

There isn't really anything wrong with explicitly copying parameters into attributes. If you have too many parameters in the ctor, it is sometimes considered a code smell and maybe you should group these params into a fewer objects. Other times, it is necessary and there is nothing wrong with it. Anyway, doing it explicitly is the way to go.

However, since you are asking HOW it can be done (and not whether it should be done), then one solution is this:

class A:
    def __init__(self, **kwargs):
        for key in kwargs:
          setattr(self, key, kwargs[key])

a = A(l=1, d=2)
a.l # will return 1
a.d # will return 2

","How do I avoid the ""self.x = x; self.y = y; self.z = z"" pattern in __init__?","I see patterns like

def __init__(self, x, y, z):
    ...
    self.x = x
    self.y = y
    self.z = z
    ...


quite frequently, often with a lot more parameters. Is there a good way to avoid this type of tedious repetitiveness? Should I inherit from namedtuple?
"
"Here is the working solution for the question:

def isSymmetric(A, B):
    L = len(A) #assume equivalent to len(B), modifying this would be as simple as checking if len(A) != len(B), return []
    la = L//2 # half-list length
    Al = A[:la]
    Ar = A[la:]
    Bl = B[:la]
    Br = B[la:]
    for i in range(la):
        lai = la - i #just to reduce the number of computation we need to perform
        for j in range(1, lai + 1):
            k = lai - j #same here, reduce computation
            if Al[i] != Br[k] or Ar[k] != Bl[i]: #the key for efficient computation is here: do not proceed unnecessarily
                 continue
            n = i #written only for the sake of clarity. i is n, and we can use i directly
            m = i + j
            if A[n:m] == B[L-m:L-n] and B[n:m] == A[L-m:L-n]: #possibly symmetric
                if A[0:n] == B[0:n] and A[m:L-m] == B[m:L-m] and A[L-n:] == B[L-n:]:
                    return [n, m]
    return []


As you have mentioned, though the idea looks simple, but it is actually quite a tricky one. Once we see the patterns, however, the implementation is straight-forward. 

The central idea of the solution is this single line:

if Al[i] != Br[k] or Ar[k] != Bl[i]: #the key for efficient computation is here: do not proceed unnecessarily


All other lines are just either direct code translation from the problem statement or optimization made for more efficient computation.



There are few steps involved in order to find the solution:

Firstly, we need to split the each both list Aand list B into two half-lists (called Al, Ar, Bl, and Br). Each half-list would contain half of the members of the original lists:

Al = A[:la]
Ar = A[la:]
Bl = B[:la]
Br = B[la:]




Secondly, to make the evaluation efficient, the goal here is to find what I would call pivot index to decide whether a position in the list (index) is worth evaluated or not to check if the lists are symmetric. This pivot index is the central idea to find an efficient solution. So I would try to elaborate it quite a bit:

Consider the left half part of the A list, suppose you have a member like this:

Al = [al1, al2, al3, al4, al5, al6]


We can imagine that there is a corresponding index list for the mentioned list like this

Al  = [al1, al2, al3, al4, al5, al6]
iAl = [0,   1,   2,   3,   4,   5  ] #corresponding index list, added for explanation purpose


(Note: the reason why I mention of imagining a corresponding index list is for ease of explanation purposes)

Likewise, we can imagine that the other three lists may have similar index lists. Let's name them iAr, iBl, and iBr respectively and they are all having identical members with iAl.

It is the index of the lists which would really matter for us to look into - in order to solve the problem. 



Here is what I mean: suppose we have two parameters: 


index (let's give a variable name i to it, and I would use symbol ^ for current i)
length (let's give a variable name j to it, and I would use symbol == to visually represent its length value) 


for each evaluation of the index element in iAl - then each evaluation would mean: 


  Given an index value i and length value of j in iAl, do
  something to determine if it is worth to check for symmetric
  qualifications starting from that index and with that length
  (Hence the name pivot index come).


Now, let's take example of one evaluation when i = 0 and j = 1. The evaluation can be illustrated as follow:

iAl = [0, 1, 2, 3, 4, 5]
       ^ <-- now evaluate this index (i) = 0
       == <-- now this has length (j) of 1




In order for those index i and length j to be worth evaluated further, then the counterpart iBr must have the same item value with the same length but on different index (let's name it index k)

iBr = [0, 1, 2, 3, 4, 5]
                      ^ <-- must compare the value in this index to what is pointed by iAl
                      == <-- must evaluate with the same length = 1


For example, for the above case, this is a possible ""symmetric"" permutation just for the two lists Al-Br (we will consider the other two lists Ar-Bl later):

Al = [0, x, x, x, x, x] #x means don't care for now
Br = [x, x, x, x, x, 0]


At this moment, it is good to note that 


  It won't worth evaluating further if even the above condition is not
  true


And this is where you get the algorithm to be more efficient; that is, by selectively evaluating only the few possible cases among all possible cases. And how to find the few possible cases? 


  By trying to find relationship between indexes and lengths of the
  four lists. That is, for a given index i and length j in a
  list (say Al), what must be the index k in the counterpart
  list (in the case is Br). Length for the counterpart list need not
  be found because it is the same as in the list (that is j).


Having know that, let's now proceed further to see if we can see more patterns in the evaluation process.



Consider now the effect of length (j). For example, if we are to evaluate from index 0, but the length is 2 then the counterpart list would need to have different index k evaluated than when the length is 1

iAl = [0, 1, 2, 3, 4, 5]
       ^ <-- now evaluate this index (i) = 0
       ===== <-- now this has length (j) of 2

iBr = [0, 1, 2, 3, 4, 5]
                   ^ <-- must compare the value in this index to what is pointed by iAl
                   ===== <-- must evaluate with the same length = 2


Or, for the illustration above, what really matters fox i = 0 and y = 2 is something like this:

# when i = 0 and y = 2
Al = [0, y, x, x, x, x] #x means don't care for now
Br = [x, x, x, x, 0, y] #y means to be checked later


Take a look that the above pattern is a bit different from when i = 0 and y = 1 - the index position for 0 value in the example is shifted:

# when i = 0 and y = 1, k = 5
Al = [0, x, x, x, x, x] #x means don't care for now
Br = [x, x, x, x, x, 0]

# when i = 0 and y = 2, k = 4
Al = [0, y, x, x, x, x] #x means don't care for now
Br = [x, x, x, x, 0, y] #y means to be checked later


Thus, length shifts where the index of the counterpart list must be checked. In the first case, when i = 0 and y = 1, then the k = 5. But in the second case, when i = 0 and y = 1, then the k = 4. Thus we found the pivot indexes relationship when we change the length j for a fixed index i (in this case being 0) unto the counterpart list index k.



Now, consider the effects of index i with fixed length j for counterpart list index k. For example, let's fix the length as y = 4, then for index i = 0, we have:

iAl = [0, 1, 2, 3, 4, 5]
       ^ <-- now evaluate this index (i) = 0
       ========== <-- now this has length (j) of 4

iAl = [0, 1, 2, 3, 4, 5]
          ^ <-- now evaluate this index (i) = 1
          ========== <-- now this has length (j) of 4

iAl = [0, 1, 2, 3, 4, 5]
             ^ <-- now evaluate this index (i) = 2
             ========== <-- now this has length (j) of 4

#And no more needed


In the above example, it can be seen that we need to evaluate 3 possibilities for the given i and j, but if the index i is changed to 1 with the same length j = 4:

iAl = [0, 1, 2, 3, 4, 5]
          ^ <-- now evaluate this index (i) = 1
          ========== <-- now this has length (j) of 4

iAl = [0, 1, 2, 3, 4, 5]
             ^ <-- now evaluate this index (i) = 2
             ========== <-- now this has length (j) of 4


Note that we only need to evaluate 2 possibilities. Thus the increase of index i decreases the number of possible cases to be evaluated!



With all the above patterns found, we almost found all the basis we need to make the algorithm works. But to complete that, we need to find the relationship between indexes which appear in Al-Br pair for a given [i, j] => [k, j] with the indexes in Ar-Bl pair for the same [i, j].

Now, we can actually see that they are simply mirroring the relationship we found in Al-Br pair! 

(IMHO, this is really beautiful! and thus I think term ""symmetric"" permutation is not far from truth)

For example, if we have the following Al-Br pair evaluated with i = 0 and y = 2

Al = [0, y, x, x, x, x] #x means don't care for now
Br = [x, x, x, x, 0, y] #y means to be checked later


Then, to make it symmetric, we must have the corresponding Ar-Bl:

Ar = [x, x, x, x, 3, y] #x means don't care for now
Bl = [3, y, x, x, x, x] #y means to be checked later


The indexing of Al-Br pair is mirroring (or, is symmetric to) the indexing of Ar-Bl pair!



Therefore, combining all the pattern we found above, we now could find the pivot indexes for evaluating Al, Ar, Bl, and Br. 


  We only need to check the values of the lists in the pivot index
  first. If the values of the lists in the pivot indexes of Al, Ar, Bl, and Br
  matches in the evaluation then and only then we need to check
  for symmetric criteria (thus making the computation efficient!)




Putting up all the knowledge above into code, the following is the resulting for-loop Python code to check for symmetricity:

for i in range(len(Al)): #for every index in the list
    lai = la - i #just simplification
    for j in range(1, lai + 1): #get the length from 1 to la - i + 1
        k = lai - j #get the mirror index
        if Al[i] != Br[k] or Ar[k] != Bl[i]: #if the value in the pivot indexes do not match
             continue #skip, no need to evaluate
        #at this point onwards, then the values in the pivot indexes match
        n = i #assign n
        m = i + j #assign m
        #test if the first two conditions for symmetric are passed
        if A[n:m] == B[L-m:L-n] and B[n:m] == A[L-m:L-n]: #possibly symmetric
            #if it passes, test the third condition for symmetric, the rests of the elements must stay in its place
            if A[0:n] == B[0:n] and A[m:L-m] == B[m:L-m] and A[L-n:] == B[L-n:]:                   
                return [n, m] #if all three conditions are passed, symmetric lists are found! return [n, m] immediately!
        #passing this but not outside of the loop means 
        #any of the 3 conditions to find symmetry are failed
        #though values in the pivot indexes match, simply continue
return [] #nothing can be found - asymmetric lists


And there go you with the symmetric test!

(OK, this is quite a challenge and it takes quite a while for me to figure out how.)
",How to check if two permutations are symmetric?,"Given two permutations A and B of L different elements, L is even, let's call these permutations ""symmetric"" (for a lack of a better term), if there exist n and m, m > n such as (in python notation):

 - A[n:m] == B[L-m:L-n]
 - B[n:m] == A[L-m:L-n]
 - all other elements are in place


Informally, consider 

A = 0 1 2 3 4 5 6 7


Take any slice of it, for example 1 2. It starts at the second index and its length is 2. Now take a slice symmetric to it: it ends at the penultimate index and is 2 chars long too, so it's 5 6. Swapping these slices gives 

B = 0 5 6 3 4 1 2 7


Now, A and B are ""symmetric"" in the above sense (n=1, m=3). On the other hand

A = 0 1 2 3 4 5 6 7
B = 1 0 2 3 4 5 7 6


are not ""symmetric"" (no n,m with above properties exist).

How can I write an algorithm in python that finds if two given permutations (=lists) are ""symmetric"" and if yes, find the n and m? For simplicity, let's consider only even L (because the odd case can be trivially reduced to the even one by eliminating the middle fixed element) and assume correct inputs (set(A)==set(B), len(set(A))==len(A)). 

(I have no problem bruteforcing all possible symmetries, but looking for something smarter and faster than that).

Fun fact: the number of symmetric permutations for the given L is a Triangular number.

I use this code to test  out your answers.

Bounty update: many excellent answers here. @Jared Goguen's solution appears to be the fastest. 

Final timings:

testing 0123456789 L= 10
    test_alexis ok in 15.4252s
    test_evgeny_kluev_A ok in 30.3875s
    test_evgeny_kluev_B ok in 27.1382s
    test_evgeny_kluev_C ok in 14.8131s
    test_ian ok in 26.8318s
    test_jared_goguen ok in 10.0999s
    test_jason_herbburn ok in 21.3870s
    test_tom_karzes ok in 27.9769s

"
"see official document of submit() and serialize() and modify your ajax all like this : 




     $('#commentForAjax' ).submit(function(e){
      e.preventDefault();

      $.ajax({
        type:'POST',
        url:'comment/create/',  // make sure , you are calling currect url
        data:$(this).serialize(),
        success:function(json){              
          alert(json.message); 
          if(json.status==200){
             var comment = json.comment;
             var user = json.user;
             /// set `comment` and `user` using jquery to some element
           }             
        },
        error:function(response){
          alert(""some error occured. see console for detail"");
        }
      });
     });




At backend side you are returning HttpResponseRedirect() which will redirect your ajax call to some url(status code=302). I will suggest to return any json response. 

For Django 1.7+ add line from django.http import JsonResponse to return json response

For pre Django 1.7 use return HttpResponse(json.dumps(response_data), content_type=""application/json"")

Modify this portion of your views.py to return Json response

def comment_create_view(request):
# you are calling this url using post method 
if request.method == ""POST"" and request.user.is_authenticated():
    parent_id = request.POST.get('parent_id')
    post_id = request.POST.get(""post_id"")
    origin_path = request.POST.get(""origin_path"")
    try:
        post = Post.objects.get(id=post_id)
    except:
        # you should return from here , if post does not exists
        response = {""code"":400,""message"":""Post does not exists""}
        return HttpResponse(json.dumps(response), content_type=""application/json"")

    parent_comment = None
    if parent_id is not None:
        try:
            parent_comment = Comment.objects.get(id=parent_id)
        except:
            parent_comment = None

        if parent_comment is not None and parent_comment.post is not None:
            post = parent_comment.post

    form = CommentForm(request.POST)
  if form.is_valid():
        comment_text = form.cleaned_data['comment']
        if parent_comment is not None:
            # parent comments exists
            new_comment = Comment.objects.create_comment(
                user=MyProfile.objects.get(user=request.user),
                path=parent_comment.get_origin, 
                text=comment_text,
                post = post,
                parent=parent_comment
                )
            response = {""status"":200,""message"":""comment_stored"",
             ""user"":new_comment.user, 
             ""comment"":comment_text,
            }
            return HttpResponse(json.dumps(response), content_type=""application/json"")
        else:
            new_comment = Comment.objects.create_comment(
                user=MyProfile.objects.get(user=request.user),
                path=origin_path, 
                text=comment_text,
                post = post
                )
            response = {""status"":200,""message"":""new comment_stored"",
             ""user"":new_comment.user,
             ""comment"":comment_text,}
            return HttpResponse(json.dumps(response), content_type=""application/json"")
    else:
        messages.error(request, ""There was an error with your comment."")
        response = {""status"":400,""message"":""There was an error with your comment.""}
        return HttpResponse(json.dumps(response), content_type=""application/json"")


You don't have to use rest-framework. But if you use rest-framework for this purpose , it will be easy to implement.
","how to use ajax function to send form without page getting refreshed, what am I missing?Do I have to use rest-framework for this?","I'm trying to send my comment form using ajax, right now when user inserts a comment then whole page gets refreshed. I want this to be inserted nicely without page getting refreshed. 
So I tried bunch of things but no luck. since I'm a beginner, I tried to follow many tutorial links;
https://realpython.com/blog/python/django-and-ajax-form-submissions/
https://impythonist.wordpress.com/2015/06/16/django-with-ajax-a-modern-client-server-communication-practise/comment-page-1/#comment-1631

I realize my problem is that I have a hard time manipulating my code in views.py and forms.py 
Thus before doing a client side programming(js and ajax) I need to set my backend(python code) again to be set for the ajax. 
Can someone please help me with this?
I don't know how to set my backend....

  
    {% csrf_token %}
    
    

    {% crispy comment_form comment_form.helper %}
    
    




    {% csrf_token %}
    
    
    
    {% crispy comment_form comment_form.helper %}

    
    

    
     $(document).on('submit','.commentForAjax', function(e){
      e.preventDefault();

      $.ajax({
        type:'POST',
        url:'comment/create/',
        data:{
          post_id:$('#post_id').val(),
          origin_path:$('#origin_path').val(),
          parent_id:$('#parent_id').val(),
          csrfmiddlewaretoken:$('input[name=csrfmiddlewaretoken]').val()
        },
        success:function(json){


I don't know what to do here...I tried it but failing....what is going on here         })
        

this is my forms.py

class CommentForm(forms.Form):
    comment = forms.CharField(
        widget=forms.Textarea(attrs={""placeholder"": ""leave your thoughts""})
    )

    def __init__(self, data=None, files=None, **kwargs):
        super(CommentForm, self).__init__(data, files, kwargs)
        self.helper = FormHelper()
        self.helper.form_show_labels = False
        self.helper.add_input(Submit('submit', 'leave your thoughts', css_class='btn btn-default',))


and my views.py

def comment_create_view(request):
    if request.method == ""POST"" and request.user.is_authenticated() and request.is_ajax():
        parent_id = request.POST.get('parent_id')
        post_id = request.POST.get(""post_id"")
        origin_path = request.POST.get(""origin_path"")
        try:
            post = Post.objects.get(id=post_id)
        except:
            post = None

        parent_comment = None
        if parent_id is not None:
            try:
                parent_comment = Comment.objects.get(id=parent_id)
            except:
                parent_comment = None

            if parent_comment is not None and parent_comment.post is not None:
                post = parent_comment.post

        form = CommentForm(request.POST)
        if form.is_valid():
            comment_text = form.cleaned_data['comment']
            if parent_comment is not None:
                # parent comments exists
                new_comment = Comment.objects.create_comment(
                    user=MyProfile.objects.get(user=request.user),
                    path=parent_comment.get_origin, 
                    text=comment_text,
                    post = post,
                    parent=parent_comment
                    )
                return HttpResponseRedirect(post.get_absolute_url())
            else:
                new_comment = Comment.objects.create_comment(
                    user=MyProfile.objects.get(user=request.user),
                    path=origin_path, 
                    text=comment_text,
                    post = post
                    )
                return HttpResponseRedirect(post.get_absolute_url())
        else:
            messages.error(request, ""There was an error with your comment."")
            return HttpResponseRedirect(origin_path)

    else:
        raise Http404


I'm still very shaky on the idea of using ajax even after reading a tutorial about it...how json comes into play and how I should modify views.py too....can someone please explain how they all group together?and help me getting this done...

    else:
        raise Http404

"
"(This is inspired by @Mark Tolonen's answer.)

An if statement runs its else clause if its condition evaluates to false.
Identically, a while loop runs the else clause if its condition evaluates to false.

This rule matches the behavior you described:


In normal execution, the while loop repeatedly runs until the condition evaluates to false, and therefore naturally exiting the loop runs the else clause.
When you execute a break statement, you exit out of the loop without evaluating the condition, so the condition cannot evaluate to false and you never run the else clause.
When you execute a continue statement, you evaluate the condition again, and do exactly what you normally would at the beginning of a loop iteration.
So, if the condition is true, you keep looping, but if it is false you run the else clause.
Other methods of exiting the loop, such as return, do not evaluate the condition and therefore do not run the else clause.


for loops behave the same way. Just consider the condition as true if the iterator has more elements, or false otherwise.
",How can I make sense of the `else` statement in Python loops?,"Many Python programmers are probably unaware that the syntax of while loops and for loops includes an optional else: clause:

for val in iterable:
    do_something(val)
else:
    clean_up()


The body of the else clause is a good place for certain kinds of clean-up actions, and is executed on normal termination of the loop: I.e., exiting the loop with return or break skips the else clause; exiting after a continue executes it. I know this only because I just looked it up (yet again), because  I can never remember when the else clause is executed.

Always? On ""failure"" of the loop, as the name suggests? On regular termination? Even if the loop is exited with return? I can never be entirely sure without looking it up.

I blame my persisting uncertainty on the choice of keyword: I find else incredibly unmnemonic for this semantics. My question is not ""why is this keyword used for this purpose"" (which I would probably vote to close, though only after reading the answers and comments), but how can I think about the else keyword so that its semantics make sense, and I can therefore remember it?

I'm sure there was a fair amount of discussion about this, and I can imagine that the choice was made for consistency with the try statement's else: clause (which I also have to look up), and with the goal of not adding to the list of Python's reserved words. Perhaps the reasons for choosing else will clarify its function and make it more memorable, but I'm after connecting name to function, not after historical explanation per se.

The answers to this question, which my question was briefly closed as a duplicate of, contain a lot of interesting back story. My question has a different focus (how to connect the specific semantics of else with the keyword choice), but I feel there should be a link to this question somewhere.
"
"No need for complicated logic, simply rearrange the list with slicing and step:

In [1]: l = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]

In [2]: l[::2], l[1::2] = l[1::2], l[::2]

In [3]: l
Out[3]: [2, 1, 4, 3, 6, 5, 8, 7, 10, 9]




Â TLDR;

Edited with explanation

I believe most viewers are already familiar with list slicing and multiple assignment. In case you don't I will try my best to explain what's going on (hope I do not make it worse).

To understand list slicing, here already has an excellent answer and explanation of list slice notation.
Simply put:

a[start:end] # items start through end-1
a[start:]    # items start through the rest of the array
a[:end]      # items from the beginning through end-1
a[:]         # a copy of the whole array

There is also the step value, which can be used with any of the above:

a[start:end:step] # start through not past end, by step


Let's look at OP's requirements: 

 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  # list l
  ^  ^  ^  ^  ^  ^  ^  ^  ^  ^
  0  1  2  3  4  5  6  7  8  9    # respective index of the elements
l[0]  l[2]  l[4]  l[6]  l[8]      # first tier : start=0, step=2
   l[1]  l[3]  l[5]  l[7]  l[9]   # second tier: start=1, step=2
-----------------------------------------------------------------------
l[1]  l[3]  l[5]  l[7]  l[9]
   l[0]  l[2]  l[4]  l[6]  l[8]   # desired output


First tier will be: l[::2] = [1, 3, 5, 7, 9]
Second tier will be: l[1::2] = [2, 4, 6, 8, 10]

As we want to re-assign first = second & second = first, we can use multiple assignment, and update the original list in place:

first , second  = second , first


that is:

l[::2], l[1::2] = l[1::2], l[::2]


As a side note, to get a new list but not altering original l, we can assign a new list from l, and perform above, that is:

n = l[:]  # assign n as a copy of l (without [:], n still points to l)
n[::2], n[1::2] = n[1::2], n[::2]


Hopefully I do not confuse any of you with this added explanation. If it does, please help update mine and make it better :-) 
",Better way to swap elements in a list?,"I have a bunch of lists that look like this one:

l = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]


I want to swap elements as follows:

final_l = [2, 1, 4, 3, 6, 5, 8, 7, 10, 9]


The size of the lists may vary, but they will always contain an even number of elements.

I'm fairly new to Python and am currently doing it like this:

l =  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
final_l = []
for i in range(0, len(l)/2):
    final_l.append(l[2*i+1])
    final_l.append(l[2*i])


I know this isn't really Pythonic and would like to use something more efficient. Maybe a list comprehension?
"
"Python 2.x interprets False as 0 and vice versa. AFAIK even None and """" can be considered False in conditions. 
Redefine count as follows:  

sum(1 for item in a if item == 0 and type(item) == int)


or (Thanks to Kevin, and Bakuriu for their comments): 

sum(1 for item in a if item == 0 and type(item) is type(0))


or as suggested by ozgur in comments (which is not recommended and is considered wrong, see this), simply:  

sum(1 for item in a if item is 0)  


it may (âisâ operator behaves unexpectedly with integers) work for small primary types, but if your list contains objects, please consider what is operator does:  

From the documentation for the is operator:


  The operators is and is not test for object identity: x is y is true
  if and only if x and y are the same object.


More information about is operator: Understanding Python's ""is"" operator
","When should I use list.count(0), and how do I to discount the ""False"" item?","a.count(0) always returns 11, so what should I do to discount the False and return 10?

a = [""a"",0,0,""b"",None,""c"",""d"",0,1,False,0,1,0,3,[],0,1,9,0,0,{},0,0,9]

"
